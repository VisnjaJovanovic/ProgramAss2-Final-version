{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f15a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: simpful in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.1)\n",
      "Requirement already satisfied: fst-pso in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/visnjajovanovic/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/visnjajovanovic/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia-api in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (0.6.0)\r\n",
      "Requirement already satisfied: requests in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from wikipedia-api) (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from requests->wikipedia-api) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from requests->wikipedia-api) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from requests->wikipedia-api) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/visnjajovanovic/anaconda3/lib/python3.11/site-packages (from requests->wikipedia-api) (2023.7.22)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import gensim\n",
    "import string\n",
    "import nltk\n",
    "import contractions\n",
    "import unicodedata \n",
    "\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "!pip install wikipedia-api\n",
    "import wikipediaapi \n",
    "\n",
    "user = 'VisnjaCodingProject/1.0 (visnja.jovanovic@nulondon.ac.uk)'\n",
    "\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user, 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac6c1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(vector_size = 200, window=10, min_count=5, sg=0)\n",
    "model.save (\"word2vec_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ad8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalpha() and word.lower() not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "def train_save_model(text):\n",
    "    processed_text = preprocess_text(text)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    processed_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "    \n",
    "    model.build_vocab (processed_sentences, update=False)\n",
    "    model.train(processed_sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    model.save(\"word2vec_model.model\")\n",
    "    print(\"finished training on\"+ text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8963de57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training onThe polar bear (Ursus maritimus) is a large bear native to the Arctic and nearby areas. It is closely related to the brown bear, and the two species can interbreed. The polar bear is the largest extant species of bear and land carnivore, with adult males weighing 300–800 kg (660–1,760 lb). The species is sexually dimorphic, as adult females are much smaller. The polar bear is white- or yellowish-furred with black skin and a thick layer of fat. It is more slender than the brown bear, with a narrower skull, longer neck and lower shoulder hump. Its teeth are sharper and more adapted to cutting meat. The paws are large and allow the bear to walk on ice and paddle in the water.\n",
      "Polar bears are both terrestrial and pagophilic (ice-living) and are considered to be marine mammals due to their dependence on marine ecosystems. They prefer the annual sea ice but live on land when the ice melts in the summer. They are mostly carnivorous and specialized for preying on seals, particularly ringed seals. Such prey is typically taken by ambush; the bear may stalk its prey on the ice or in the water, but also will stay at a breathing hole or ice edge to wait for prey to swim by. The bear primarily feeds on the seal's energy-rich blubber. Other prey include walruses, beluga whales and some terrestrial animals. Polar bears are usually solitary but can be found in groups when on land. During the breeding season, male bears guard females and defend them from rivals. Mothers give birth to cubs in maternity dens during the winter. Young stay with their mother for up to two and a half years.\n",
      "The polar bear is considered to be a vulnerable species by the International Union for Conservation of Nature (IUCN) with an estimated total population of 22,000 to 31,000 individuals. Its biggest threats are climate change, pollution and energy development. Climate change has caused a decline in sea ice, giving the polar bear less access to its favoured prey and increasing the risk of malnutrition and starvation. Less sea ice also means that the bears must spend more time on land, increasing conflicts with people. Polar bears have been hunted, both by native and non-native peoples, for their coats, meat and other items. They have been kept in captivity in zoos and circuses and are prevalent in art, folklore, religion and modern culture.\n",
      "\n",
      "Naming\n",
      "The polar bear was given its common name by Thomas Pennant in A Synopsis of Quadrupeds (1771). It was known as the \"white bear\" in Europe between the 13th and 18th centuries, as well as \"ice bear\", \"sea bear\" and \"Greenland bear\". The Norse referred to it as isbjørn (\"ice bear\") and hvitebjørn (\"white bear\"). The bear is called nanook by the Inuit. The Netsilik cultures additionally have different names for bears based on certain factors, such as sex and age: these include adult males (anguraq), single adult females (tattaq), gestating females (arnaluk), newborns (hagliaqtug), large adolescents (namiaq) and dormant bears (apitiliit). The scientific name Ursus maritimus is Latin for \"sea bear\".\n",
      "\n",
      "Taxonomy\n",
      "Carl Linnaeus classified the polar bear as a type of brown bear (Ursus arctos), labelling it as Ursus maritimus albus-major, articus in the 1758 edition of his work Systema Naturae. Constantine John Phipps formally described the polar bear as a distinct species, Ursus maritimus in 1774, following his 1773 voyage towards the North Pole. Due to its adaptations to a marine environment, some taxonomists like Theodore Knottnerus-Meyer have placed the polar bear in its genus Thalarctos. However Ursus is widely considered to be the valid genus for the species based on the fossil record and the fact that it can breed with the brown bear.Different subspecies have been proposed including Ursus maritimus maritimus and U. m. marinus. However these are not supported and the polar bear is considered to be monotypic. One possible fossil subspecies, U. m. tyrannus, was posited in 1964 by Björn Kurtén, who reconstructed the subspecies from a single fragment of an ulna which was approximately 20 percent larger than expected for a polar bear. However, re-evaluation in the 21st century has indicated that the fragment likely comes from a giant brown bear.\n",
      "\n",
      "Evolution\n",
      "The polar bear is one of eight extant species in the bear family Ursidae and of six extant species in the subfamily Ursinae. A possible phylogeny of extant bear species is shown in a cladogram based on complete mitochondrial DNA sequences from Yu et al. (2007) The polar bear and the brown bear form a close grouping, while the relationships of the other species are not very well resolved.\n",
      "A more recent phylogeny below is based on a 2017 genetic study. The study concludes that Ursine bears originated around 5 million years ago and show extensive hybridization of species in their lineage.\n",
      "Fossils of polar bears are uncommon. The oldest known fossil is a 130,000- to 110,000-year-old jaw bone, found on Prince Charles Foreland, Norway, in 2004. Scientists in the 20th century surmised that polar bears directly descended from a population of brown bears, possibly in eastern Siberia or Alaska. Mitochondrial DNA studies in the 1990s and 2000s supported the status of the polar bear as a derivative of the brown bear, finding that some brown bear populations were more closely related to polar bears than to other brown bears, particularly the ABC Islands bears of Southeast Alaska. A 2010 study estimated that the polar bear lineage split from other brown bears around 150,000 years ago.\n",
      "More extensive genetic studies have refuted the idea that polar bears are directly descended from brown bears and found that the two species are separate sister lineages. The genetic similarities between polar bears and some brown bears were found to be the result of interbreeding. A 2012 study estimated the split between polar and brown bears as occurring around 600,000 years ago. A 2022 study estimated the divergence as occurring even earlier at over one million years ago. Glaciation events over hundreds of thousands of years led to both the origin of polar bears and their subsequent interactions and hybridizations with brown bears.Studies in 2011 and 2012 concluded that gene flow went from brown bears to polar bears during hybridization. In particular, a 2011 study concluded that living polar bear populations derived their maternal lines from now-extinct Irish brown bears. Later studies have clarified that gene flow went from polar to brown bears rather than the reverse. Up to 9 percent of the genome of ABC bears was transferred from polar bears, while Irish bears had up to 21.5 percent polar bear origin. Mass hybridization between the two species appears to have stopped around 200,000 years ago. Modern hybrids are relatively rare in the wild.Analysis of the number of variations of gene copies in polar bears compared with brown bears and American black bears shows distinct adaptions. Polar bears have a less diverse array of olfactory receptor genes, a result of there being fewer odours in their Arctic habitat. With its carnivorous, high-fat diet the species has fewer copies of the gene involved in making amylase, an enzyme that breaks down starch, and more selection for genes for fatty acid breakdown and a more efficient circulatory system. The polar bear's thicker coat is the result of more copies of genes involved in keratin-creating proteins.\n",
      "\n",
      "Characteristics\n",
      "The polar bear is the largest living species of bear and land carnivore, though some brown bear subspecies like the Kodiak bear can rival it in size. Males are generally 200–250 cm (6.6–8.2 ft) long with a weight of 300–800 kg (660–1,760 lb). Females are smaller at 180–200 cm (5.9–6.6 ft) with a weight of 150–300 kg (330–660 lb). Sexual dimorphism in the species is particularly high compared with most other mammals. Male polar bears also have proportionally larger heads than females. The weight of polar bears fluctuates during the year, as they can bulk up on fat and increase their mass by 50 percent. A fattened, pregnant female can weigh as much as 500 kg (1,100 lb). Adults may stand 130–160 cm (4.3–5.2 ft) tall at the shoulder. The tail is 76–126 mm (3.0–5.0 in) long. The largest polar bear on record, reportedly weighing 1,002 kg (2,209 lb), was a male shot at Kotzebue Sound in northwestern Alaska in 1960.Compared with the brown bear, this species has a more slender build, with a narrower, flatter and smaller skull, a longer neck, and a lower shoulder hump. The snout profile is curved, resembling a \"Roman nose\". They have 34–42 teeth including 12 incisors, 4 canines, 8–16 premolars and 10 molars. The teeth are adapted for a more carnivorous diet than that of the brown bear, having longer, sharper and more spaced out canines, and smaller, more pointed cheek teeth (premolars and molars). The species has a large space or diastema between the canines and cheek teeth, which may allow it to better bite into prey. Since it normally preys on animals much smaller than it, the polar bear does not have a particularly strong bite. Polar bears have large paws, with the front paws being broader than the back. The feet are hairier than in other bear species, providing warmth and friction when stepping on snow and sea ice. The claws are small but sharp and hooked and are used both to snatch prey and climb onto ice.\n",
      "The coat consists of dense underfur around 5 cm (2.0 in) long and guard hairs around 15 cm (5.9 in) long. Males have long hairs on their forelegs, which is thought to signal their fitness to females. The outer surface of the hairs has a scaly appearance, and the guard hairs are hollow, which allows the animals to trap heat and float in the water. The transparent guard hairs forward scatter ultraviolet light between the underfur and the skin, leading to a cycle of absorption and re-emission, keeping them warm. The fur appears white due to the backscatter of incident light and the absence of pigment. Polar bears gain a yellowish colouration as they are exposed more to the sun. This is reversed after they moult. It can also be grayish or brownish. Their light fur provides camouflage in their snowy environment. After emerging from the water, the bear can easily shake itself dry before freezing since the hairs are resistant to tangling when wet. The skin, including the nose and lips, is black and absorbs heat. Polar bears have a 5–10 cm (2.0–3.9 in) thick layer of fat underneath the skin, which provides both warmth and energy. Polar bears maintain their core body temperature at about 36.9 °C (98 °F). Overheating is countered by a layer of highly vascularized striated muscle tissue and finely controlled blood vessels. Bears also cool off by entering the water.The eyes of a polar bear are close to the top of the head, which may allow them to stay out of the water when the animal is swimming at the surface. They are relatively small, which may be an adaption against blowing snow and snow blindness. Polar bears are dichromats, and lack the cone cells for seeing green. They have many rod cells which allow them to see at night. The ears are small, allowing them to retain heat and not get frostbitten. They can hear best at frequencies of 11.2–22.5 kHz, a wider frequency range than expected given that their prey mostly makes low-frequency sounds. The nasal concha creates a large surface area, so more warm air can move through the nasal passages. Their olfactory system is also large and adapted for smelling prey over vast distances. The animal has reniculate kidneys which filter out the salt in their food.\n",
      "\n",
      "Distribution and habitat\n",
      "Polar bears inhabit the Arctic and adjacent areas. Their range includes Greenland, Canada, Alaska, Russia and the Svalbard Archipelago of Norway. Polar bears have been recorded 25 km (16 mi) from the North Pole. The southern limits of their range include James Bay and Newfoundland and Labrador in Canada and St. Matthew Island and the Pribilof Islands of Alaska. They are not permanent residents of Iceland but have been recorded visiting there if they can reach it via sea ice. Due to minimal human encroachment on the bears' remote habitat, they can still be found in much of their original range, more so than any other large land carnivore.Polar bears have been divided into at least 18 subpopulations labelled East Greenland (ES), Barents Sea (BS), Kara Sea (KS), Laptev Sea (LVS), Chukchi Sea (CS), northern and southern Beaufort Sea (SBS and NBS), Viscount Melville (VM), M'Clintock Channel (MC), Gulf of Boothia (GB), Lancaster Sound (LS), Norwegian Bay (NB), Kane Basin (KB), Baffin Bay (BB), Davis Strait (DS), Foxe Basin (FB) and the western and southern Hudson Bay (WHB and SHB) populations. Bears in and around the Queen Elizabeth Islands have been proposed as a subpopulation but this is not universally accepted. A 2022 study has suggested that the bears in southeast Greenland should be considered a different subpopulation based on their geographic isolation and genetics. Polar bear populations can also be divided into four gene clusters: Southern Canadian, Canadian Archipelago, Western Basin (northwestern Canada west to the Russian Far East) and Eastern Basin (Greenland east to Siberia).The polar bear is dependent enough on the ocean to be considered a marine mammal. It is pagophilic and mainly inhabits annual sea ice covering continental shelves and between islands of archipelagos. These areas, known as the \"Arctic Ring of Life\", have high biological productivity. The species tends to frequent areas where sea ice meets water, such as polynyas and leads, to hunt the seals that make up most of its diet. Polar bears travel in response to changes in ice cover throughout the year. They are forced onto land in summer when the sea ice disappears. Terrestrial habitats used by polar bears include forests, mountains, rocky areas, lakeshores and creeks. In the Chukchi and Beaufort seas, where the sea ice breaks off and floats north during the summer, polar bears generally stay on the ice, though a large portion of the population (15–40%) has been observed spending all summer on land since the 1980s. Some areas have thick multiyear ice that does not completely melt and the bears can stay on all year, though this type of ice has fewer seals and allows for less productivity in the water.\n",
      "\n",
      "Behaviour and ecology\n",
      "Polar bears may travel areas as small as 3,500 km2 (1,400 sq mi) to as large as 38,000 km2 (15,000 sq mi) in a year, while drifting ice allows them to move further. Depending on ice conditions, a bear can travel an average of 12 km (7.5 mi) per day. These movements are powered by their energy-rich diet. Polar bears move by walking and galloping and do not trot. Walking bears tilt their front paws towards each other. They can run at estimated speeds of up to 40 km/h (25 mph) but typically move at around 5.5 km/h (3.4 mph). Polar bears are also capable swimmers and can swim at up to 6 km/h (3.7 mph). One study found they can swim for an average of 3.4 days at a time and travel an average of 154.2 km (95.8 mi). They can dive for as long as three minutes.  When swimming, the broad front paws do the paddling, while the hind legs play a role in steering and diving.\n",
      "Most polar bears are active year-round. Hibernation occurs only among pregnant females. Non-hibernating bears typically have a normal 24-hour cycle even during days of all darkness or all sunlight, though cycles less than a day are more common during the former. The species is generally diurnal, being most active early in the day. Polar bears sleep close to eight hours a day on average. They will sleep in various positions, including curled up, sitting up, lying on one side, on the back with limbs spread, or on the belly with the rump elevated. On sea ice, polar bears snooze at pressure ridges where they dig on the sheltered side and lie down. After a snowstorm, a bear may rest under the snow for hours or days. On land, the bears may dig a resting spot on gravel or sand beaches. They will also sleep on rocky outcrops. In mountainous areas on the coast, mothers and subadults will sleep on slopes where they can better spot another bear coming. Adult males are less at risk from other bears and can sleep nearly anywhere.\n",
      "\n",
      "Social life\n",
      "Polar bears are typically solitary, aside from mothers with cubs and mating pairs. On land, they are found closer together and gather around food resources. Adult males, in particular, are more tolerant of each other in land environments and outside the breeding season. They have been recorded forming stable \"alliances\", travelling, resting and playing together. A dominant hierarchy exists among polar bears with the largest mature males ranking at the top. Adult females outrank subadults and adolescents and younger males outrank females of the same age. In addition, cubs with their mothers outrank those on their own. Females with dependent offspring tend to stay away from males, but are sometimes associated with other female–offspring units, creating \"composite families\".Polar bears are generally quiet but can produce various sounds. Chuffing, a soft pulsing call, is made by mother bears presumably to keep in contact with their young. During the breeding season, adult males will chuff at potential mates. Unlike other animals where chuffing is passed through the nostrils, in polar bears it is emitted through a partially open mouth. Cubs will cry for attention and produce humming noises while nursing. Teeth chops, jaw pops, blows, huffs, moans, growls and roars are heard in more hostile encounters. A polar bear visually communicates with its eyes, ears, nose and lips. Chemical communication can also be important: bears secrete their scent from their foot pads into their tracks, allowing individuals to keep track of one another.\n",
      "\n",
      "Diet and hunting\n",
      "The polar bear is a hypercarnivore, and the most carnivorous species of bear. It is an apex predator of the Arctic, preying on ice-living seals and consuming their energy-rich blubber. The most commonly taken species is the ringed seal, but they also prey on bearded seals and harp seals. Ringed seals are ideal prey as they are abundant and small enough to be overpowered by even small bears. Bearded seal adults are larger and are more likely to break free from an attacking bear, hence adult male bears are more successful in hunting them. Less common prey are hooded seals, spotted seals, ribbon seals and the more temperate-living harbour seals. Polar bears, mostly adult males, will occasionally hunt walruses, both on land and ice, though they mainly target the young, as adults are too large and formidable, with their thick skin and long tusks.\n",
      "Besides seals, bears will prey on cetacean species such as beluga whales and narwhals, as well as reindeer, birds and their eggs, fish and marine invertebrates. They rarely eat plant material as their digestive system is too specialized for animal matter, though they have been recorded eating berries, moss, grass and seaweed. In their southern range, especially near Hudson Bay and James Bay, polar bears endure all summer without sea ice to hunt from and must subsist more on terrestrial foods. Fat reserves allow polar bears to survive for months without eating. Cannibalism is known to occur in the species.Polar bears hunt their prey in several different ways. When a bear spots a seal hauling out on the sea ice, it slowly stalks it with the head and neck lowered, possibly to make its dark nose and eyes less noticeable. As it gets closer, the bear crouches more and eventually charges at a high speed, attempting to catch the seal before it can escape into its ice hole. Some stalking bears need to move through water; traversing through water cavities in the ice when approaching the seal or swimming towards a seal on an ice floe. The polar bear can stay underwater with its nose exposed. When it gets close enough, the animal lunges from the water to attack.During a limited time in spring, polar bears will search for ringed seal pups in their birth lairs underneath the ice. Once a bear catches the scent of a hiding pup and pinpoints its location, it approaches the den quietly to not alert it. It uses its front feet to smash through the ice and then pokes its head in to catch the pup before it can escape. A ringed seal's lair can be more than 1 m (3.3 ft) below the surface of the ice and thus more massive bears are better equipped for breaking in. Some bears may simply stay still near a breathing hole or other spot near the water and wait for prey to come by. This can last hours and when a seal surfaces the bear will try to pull it out with its paws and claws. This tactic is the primary hunting method from winter to early spring.\n",
      "Bears hunt walrus groups by provoking them into stampeding and then look for young that have been crushed or separated from their mothers during the turmoil. There are reports of bears trying to kill or injure walruses by throwing rocks and pieces of ice on them. Belugas and narwhals are vulnerable to bear attacks when they are stranded in shallow water or stuck in isolated breathing holes in the ice. When stalking reindeer, polar bears will hide in vegetation before an ambush. On some occasions, bears may try to catch prey in open water, swimming underneath a seal or aquatic bird. Seals in particular, however, are more agile than bears in the water. Polar bears rely on raw power when trying to kill their prey, and will employ bites or paw swipes. They have the strength to pull a mid-sized seal out of the water or haul a beluga carcass for quite some distance. Polar bears only occasionally store food for later—burying it under snow—and only in the short term.Arctic foxes routinely follow polar bears and scavenge scraps from their kills. The bears usually tolerate them but will charge a fox that gets too close when they are feeding. Polar bears themselves will scavenge. Subadult bears will eat remains left behind by others. Females with cubs often abandon a carcass when they see an adult male approaching, though are less likely to if they have not eaten in a long time. Whale carcasses are a valuable food source, particularly on land and after the sea ice melts, and attract several bears. In one area in northeastern Alaska, polar bears have been recorded competing with grizzly bears for whale carcasses. Despite their smaller size, grizzlies are more aggressive and polar bears are likely to yield to them in confrontations. Polar bears will also scavenge at garbage dumps during ice-free periods.\n",
      "\n",
      "Reproduction and development\n",
      "Polar bear mating takes place on the sea ice and during spring, mostly between March and May. Males search for females in estrus and often travel in twisting paths which reduces the chances of them encountering other males while still allowing them to find females. The movements of females remain linear and they travel more widely. The mating system can be labelled as female-defence polygyny, serial monogamy or promiscuity.Upon finding a female, a male will try to isolate and guard her. Courtship can be somewhat aggressive, and a male will pursue a female if she tries to run away. It can take days for the male to mate with the female which induces ovulation. After their first copulation, the couple bond. Undisturbed polar bear pairings typically last around two weeks during which they will sleep together and mate multiple times. Competition for mates can be intense and this has led to sexual selection for bigger males. Polar bear males often have scars from fighting. A male and female that have already bonded will flee together when another male arrives. A female mates with multiple males in a season and a single litter can have more than one father.\n",
      "When the mating season ends, the female will build up more fat reserves to sustain both herself and her young. Sometime between August and October, the female constructs and enters a maternity den for winter. Depending on the area, maternity dens can be found in sea ice just off the coastline or further inland and may be dug underneath snow, earth or a combination of both. The inside of these shelters can be around 1.5 m (4.9 ft) wide with a ceiling height of 1.2 m (3.9 ft) while the entrance may be 2.1 m (6.9 ft) long and 1.2 m (3.9 ft) wide. The temperature of a den can be much higher than the outside. Females hibernate and give birth to their cubs in the dens. Hibernating bears fast and internally recycle bodily waste. Polar bears experience delayed implantation and the fertilized embryo does not start development until the fall, between mid-September and mid-October. With delayed implantation, gestation in the species lasts seven to nine months but actual pregnancy is only two months.Mother polar bears typically give birth to two cubs per litter. As with other bear species, newborn polar bears are tiny and altricial. The newborns have woolly hair and pink skin, with a weight of around 600 g (21 oz). Their eyes remain closed for a month. The mother's fatty milk fuels their growth, and the cubs are kept warm both by the mother's body heat and the den. The mother emerges from the den between late February and early April, and her cubs are well-developed and capable of walking with her. At this time they weigh 10–15 kilograms (22–33 lb). A polar bear family stays near the den for roughly two weeks; during this time the cubs will move and play around while the mother mostly rests. They eventually head out on the sea ice.\n",
      "Cubs under a year old stay close to their mother. When she hunts, they stay still and watch until she calls them back. Observing and imitating the mother helps the cubs hone their hunting skills. After their first year they become more independent and explore. At around two years old, they are capable of hunting on their own. The young suckle their mother as she is lying on her side or sitting on her rump. A lactating female cannot conceive and give birth, and cubs are weaned between two and two-and-a-half years. She may simply leave her weaned young or they may be chased away by a courting male. Polar bears reach sexual maturity at around four years for females and six years for males. Females reach their adult size at 4 or 5 years of age while males are fully grown at twice that age.\n",
      "\n",
      "Mortality\n",
      "Polar bears can live up to 30 years. The bear's long lifespan and ability to consistently produce young offsets cub deaths in a population. Some cubs die in the dens or the womb if the female is not in good condition. Nevertheless, the female has a chance to produce a surviving litter the next spring if she can eat better in the coming year. Cubs will eventually starve if their mothers cannot kill enough prey. Cubs also face threats from wolves and adult male bears. Males kill cubs to bring their mother back into estrus but also kill young outside the breeding season for food. A female and her cubs can flee from the slower male. If the male can get close to a cub, the mother may try to fight him off, sometimes at the cost of her life.Subadult bears, who are independent but not quite mature, have a particularly rough time as they are not as successful hunters as adults. Even when they do succeed, their kill will likely be stolen by a larger bear. Hence subadults have to scavenge and are often underweight and at risk of starvation. At adulthood, polar bears have a high survival rate, though adult males suffer injuries from fights over mates. Polar bears are especially susceptible to Trichinella, a parasitic roundworm they contract through cannibalism.\n",
      "\n",
      "Conservation status\n",
      "In 2015, the IUCN Red List categorized the polar bear as vulnerable due to a \"decline in area of occupancy, extent of occurrence and/or quality of habitat\". It estimated the total population to be between 22,000 and 31,000, and the current population trend is unknown. Threats to polar bear populations include climate change, pollution and energy development.In 2021, the IUCN/SSC Polar Bear Specialist Group labelled four subpopulations (Barents and Chukchi Sea, Foxe Basin and Gulf of Boothia) as \"likely stable\", two (Kane Basin and M'Clintock Channel) as \"likely increased\" and three (Southern Beaufort Sea, Southern and Western Hudson Bay) as \"likely decreased\" over specific periods between the 1980s and 2010s. The remaining ten did not have enough data. A 2008 study predicted two-thirds of the world's polar bears may disappear by 2050, based on the reduction of sea ice, and only one population would likely survive in 50 years. A 2016 study projected a likely decline in polar bear numbers of more than 30 percent over three generations. The study concluded that declines of more than 50 percent are much less likely. A 2012 review suggested that polar bears may become regionally extinct in southern areas by 2050 if trends continue, leaving the Canadian Archipelago and northern Greenland as strongholds.The key danger from climate change is malnutrition or starvation due to habitat loss. Polar bears hunt seals on the sea ice, and rising temperatures cause the ice to melt earlier in the year, driving the bears to shore before they have built sufficient fat reserves to survive the period of scarce food in the late summer and early fall. Thinner sea ice tends to break more easily, which makes it more difficult for polar bears to access seals. Insufficient nourishment leads to lower reproductive rates in adult females and lower survival rates in cubs and juvenile bears. Lack of access to seals also causes bears to find food on land which increases the risk of conflict with humans.\n",
      "Reduction in sea ice cover also forces bears to swim longer distances, which further depletes their energy stores and occasionally leads to drowning. Increased ice mobility may result in less stable sites for dens or longer distances for mothers travelling to and from dens on land. Thawing of permafrost would lead to more fire-prone roofs for bears denning underground. Less snow may affect insulation while more rain could cause more cave-ins. The maximum corticosteroid-binding capacity of corticosteroid-binding globulin in polar bear serum correlates with stress in polar bears, and this has increased with climate warming. Disease-causing bacteria and parasites would flourish more readily in a warmer climate.Oil and gas development also affects polar bear habitat. The Chukchi Sea Planning Area of northwestern Alaska, which has had many drilling leases, was found to be an important site for non-denning female bears. Oil spills are also a risk. A 2018 study found that ten percent or less of prime bear habitat in the Chukchi Sea is vulnerable to a potential spill, but a spill at full reach could impact nearly 40 percent of the polar bear population. Polar bears accumulate high levels of persistent organic pollutants such as polychlorinated biphenyl (PCBs) and chlorinated pesticides, due to their position at the top of the ecological pyramid. Many of these chemicals have been internationally banned due to the recognition of their harm to the environment. Traces of them have slowly dwindled in polar bears but persist and have even increased in some populations.Polar bears receive some legal protection in all the countries they inhabit. The species has been labelled as threatened under the US Endangered Species Act since 2008, while the Committee on the Status of Endangered Wildlife in Canada listed it as of 'Special concern' since 1991. In 1973, the Agreement on the Conservation of Polar Bears was signed by all five nations with polar bear populations, Canada, Denmark (of which Greenland is an autonomous territory), Russia (then USSR), Norway and the US. This banned most harvesting of polar bears, allowed indigenous hunting using traditional methods, and promoted the preservation of bear habitat. The Convention on International Trade in Endangered Species of Wild Fauna lists the species under Appendix II, which allows regulated trade.\n",
      "\n",
      "Relationship with humans\n",
      "Polar bears have coexisted and interacted with circumpolar peoples for millennia. \"White bears\" are mentioned as commercial items in the Japanese book Nihon Shoki in the seventh century. It is not clear if these were polar bears or white-coloured brown bears. During the Middle Ages, Europeans considered white bears to be a novelty and were more familiar with brown- and black-coloured bears. The first known written account of the polar bear in its natural environment is found in the 13th-century anonymous Norwegian text Konungs skuggsjá, which mentions that \"the white bear of Greenland wanders most of the time on the ice of the sea, hunting seals and whales and feeding on them\" and says the bear is \"as skillful a swimmer as any seal or whale\".\n",
      "Over the next centuries, several European explorers would mention polar bears and describe their habits. Such accounts became more accurate after the Enlightenment, and both living and dead specimens were brought back. Nevertheless, some fanciful reports continued, including the idea that polar bears cover their noses during hunts. A relatively accurate drawing of a polar bear is found in Henry Ellis's work A Voyage to Hudson's Bay (1748). Polar bears were formally classified as a species by Constantine Phipps after his 1773 voyage to the Arctic. Accompanying him was a young Horatio Nelson, who was said to have wanted to get a polar bear coat for his father but failed in his hunt. In his 1785 edition of Histoire Naturelle, Comte de Buffon mentions and depicts a \"sea bear\", clearly a polar bear, and \"land bears\", likely brown and black bears. This helped promote ideas about speciation. Buffon also mentioned a \"white bear of the forest\", possibly a Kermode bear.\n",
      "\n",
      "Exploitation\n",
      "Polar bears were hunted as early as 8,000 years ago, as indicated by archaeological remains at Zhokhov Island in the East Siberian Sea. The oldest graphic depiction of a polar bear shows it being hunted by a man with three dogs. This rock art was among several petroglyphs found at Pegtymel in Siberia and dates from the fifth to eighth centuries. Before access to firearms, native people used lances, bows and arrows and hunted in groups accompanied by dogs. Though hunting typically took place on foot, some people killed swimming bears from boats with a harpoon. Polar bears were sometimes killed in their dens. Killing a polar bear was considered a rite of passage for boys in some cultures. Native people respected the animal and hunts were subject to strict rituals.  Bears were harvested for the fur, meat, fat, tendons, bones and teeth. The fur was worn and slept on, while the bones and teeth were made into tools. For the Netsilik, the individual who finally killed the bear had the right to its fur while the meat was passed to all in the party. Some people kept the cubs of slain bears.\n",
      "Norsemen in Greenland traded polar bear furs in the Middle Ages. Russia traded polar bear products as early as 1556, with Novaya Zemlya and Franz Josef Land being important commercial centres. Large-scale hunting of bears at Svalbard occurred since at least the 18th century, when no less than 150 bears were killed each year by Russian explorers. In the next century, more Norwegians were harvesting the bears on the island. From the 1870s to the 1970s, around 22,000 of the animals were hunted in total. Over 150,000 polar bears in total were either killed or captured in Russia and Svalbard, from the 18th to the 20th century. In the Canadian Arctic, bears were harvested by commercial whalers especially if they could not get enough whales. The Hudson's Bay Company is estimated to have sold 15,000 polar bear coats between the late 19th century and early 20th century. In the mid-20th century, countries began to regulate polar bear harvesting, culminating in the 1973 agreement.Polar bear meat was commonly eaten as rations by explorers and sailors in the Arctic. Its taste and texture have been described both positively and negatively. Some have called it too coarse with a powerful smell, while others praised it as a \"royal dish\". The liver was known for being too toxic to eat. This is due to the accumulation of vitamin A from their prey. Polar bear fat was also used in lamps when other fuel was unavailable. Polar bear rugs were almost ubiquitous on the floors of Norwegian churches by the 13th and 14th centuries. In more modern times, classical Hollywood actors would pose on bearskin rugs, notably Marilyn Monroe. Such images often had sexual connotations.\n",
      "\n",
      "Conflicts\n",
      "When the sea ice melts, polar bears, particularly subadults, conflict with humans over resources on land. They are attracted to the smell of human-made foods, particularly at garbage dumps and may be shot when they encroach on private property. In Churchill, Manitoba, local authorities maintain a \"polar bear jail\" where nuisance bears are held until the sea ice freezes again. Climate change has increased conflicts between the two species. Over 50 polar bears swarmed a town in Novaya Zemlya in February 2019, leading local authorities to declare a state of emergency.From 1870 to 2014, there were an estimated 73 polar bear attacks on humans, which led to 20 deaths. The majority of attacks were by hungry males, typically subadults, while female attacks were usually in defence of the young. In comparison to brown and American black bears, attacks by polar bears were more often near and around where humans lived. This may be due to the bears getting desperate for food and thus more likely to seek out human settlements. As with the other two bear species, polar bears are unlikely to target more than two people at once. Though popularly thought of as the most dangerous bear, the polar bear is no more aggressive to humans than other species.\n",
      "\n",
      "Captivity\n",
      "The polar bear was a particularly sought-after species for exotic animal collectors due to being relatively rare and remote living, and its reputation as a ferocious beast. It is one of the few marine mammals that can reproduce well in captivity. They were originally kept only by royals and elites. The Tower of London got a polar bear as early as 1252 under King Henry III. In 1609, James VI and I of Scotland, England and Ireland were given two polar bear cubs by the sailor Jonas Poole, who got them during a trip to Svalbard. At the end of the 17th century, Frederick I of Prussia housed polar bears in menageries with other wild animals. He had their claws and canines removed to perform mock fights. Around 1726, Catherine I of Russia gifted two polar bears to Augustus II the Strong of Poland, who desired them for his animal collection. Later, polar bears were displayed to the public in zoos and circuses. In early 19th century, the species was exhibited at the Exeter Exchange in London, as well as menageries in Vienna and Paris. The first zoo in North America to exhibit a polar bear was the Philadelphia Zoo in 1859.Polar bear exhibits were innovated by Carl Hagenbeck, who replaced cages and pits with settings that mimicked the animal's natural environment.  In 1907, he revealed a complex panoramic structure at the Tierpark Hagenbeck Zoo in Hamburg consisting of exhibits made of artificial snow and ice separated by moats. Different polar animals were displayed on each platform, giving the illusion of them living together. Starting in 1975, Hellabrunn Zoo in Munich housed its polar bears in an exhibit which consisted of a glass barrier, a house, concrete platforms mimicking ice floes and a large pool. Inside the house were maternity dens, and rooms for the staff to prepare and store the food. The exhibit was connected to an outdoor yard for extra room. Similar naturalistic and \"immersive\" exhibits were opened in the early 21st century, such as the \"Arctic Ring of Life\" at the Detroit Zoo and Ontario's Cochrane Polar Bear Habitat. Many zoos in Europe and North America have stopped keeping polar bears due to the size and costs of their complex exhibits. In North America, the population of polar bears in zoos reached its zenith in 1975 with 229 animals and declined in the 21st century.\n",
      "Polar bears have been trained to perform in circuses. Bears in general, being large, powerful, easy to train and human-like in form, were widespread in circuses, and the white coat of polar bears made them particularly attractive. Circuses helped change the polar bear's image from a fearsome monster to something more comical. Performing polar bears were used in 1888 by Circus Krone in Germany and later in 1904 by the Bostock and Wombwell Menagerie in England. Circus director Wilhelm Hagenbeck trained up to 75 polar bears to slide into a large tank through a chute. He began performing with them in 1908 and they had a particularly well-received show at the Hippodrome in London. Other circus tricks performed by polar bears involved tightropes, balls, roller skates and motorcycles. One of the most famous polar bear trainers in the second half of the twentieth century was the East German Ursula Böttcher, whose small stature contrasted with that of the large bears. Starting in the late 20th century, most polar bear acts were retired and the use of these bears for the circus is now prohibited in the US.Several captive polar bears gained celebrity status in the late 20th and early 21st century, notably Knut of the Berlin Zoological Garden, who was rejected by his mother and had to be hand-reared by zookeepers. Another bear, Binky of the Alaska Zoo in Anchorage, became famous for attacking two visitors who got too close. Captive polar bears may pace back and forth, a stereotypical behaviour. In one study, they were recorded to have spent 14 percent of their days pacing. Gus of the Central Park Zoo was prescribed Prozac by a therapist for constantly swimming in his pool. To reduce stereotypical behaviours, zookeepers provide the bears with enrichment items to trigger their play behaviour. Zoo polar bears may appear green due to algae concentrations.\n",
      "\n",
      "Cultural significance\n",
      "Polar bears have prominent roles in Inuit culture and religion. The deity Torngarsuk is sometimes imagined as a giant polar bear. He resides underneath the sea floor in an underworld of the dead and has power over sea creatures. Kalaallit shamans would worship him through singing and dancing and were expected to be taken by him to the sea and consumed if he considered them worthy. Polar bears were also associated with the goddess Nuliajuk who was responsible for their creation, along with other sea creatures. It is believed that shamans could reach the Moon or the bottom of the ocean by riding on a guardian spirit in the form of a polar bear. Some folklore involves people turning into or disguising themselves as polar bears by donning their skins or the reverse, with polar bears removing their  skins. In Inuit astronomy, the Pleiades star cluster is conceived of as a polar bear trapped by dogs while Orion's Belt, the Hyades and Aldebaran represent hunters, dogs and a wounded bear respectively.Nordic folklore and literature have also featured polar bears. In The Tale of Auðun of the West Fjords, written around 1275, a poor man named Auðun spends all his money on a polar bear in Greenland, but ends up wealthy after giving the bear to the king of Denmark. In the 14th-century manuscript Hauksbók, a man named Odd kills and eats a polar bear that killed his father and brother. In the story of The Grimsey Man and the Bear, a mother bear nurses and rescues a farmer stuck on an ice floe and is repaid with sheep meat. 18th-century Icelandic writings mention the legend of a \"polar bear king\" known as the bjarndýrakóngur. This beast was depicted as a polar bear with \"ruddy cheeks\" and a unicorn-like horn, which glows in the dark. The king could understand when humans talk and was considered to be very astute. Two Norwegian fairy tales, \"East of the Sun and West of the Moon\" and \"White-Bear-King-Valemon\", involve white bears turning into men and seducing women.Drawings of polar bears have been featured on maps of the northern regions. Possibly the earliest depictions of a polar bear on a map is the Swedish Carta marina of 1539, which has a white bear on Iceland or \"Islandia\". A 1544 map of North America includes two polar bears near Quebec. Notable paintings featuring polar bears include François-Auguste Biard's Fighting Polar Bears (1839) and Edwin Landseer's Man Proposes, God Disposes (1864). Polar bears have also been filmed for cinema. An Inuit polar bear hunt was shot for the 1932 documentary Igloo, while the 1974 film The White Dawn filmed a simulated stabbing of a trained bear for a scene. In the film The Big Show (1961), two characters are killed by a circus polar bear. The scenes were shot using animal trainers instead of the actors. In modern literature, polar bears have been characters in both children's fiction, like Hans Beer's Little Polar Bear and the Whales and Sakiasi Qaunaq's The Orphan and the Polar Bear, and fantasy novels, like Philip Pullman's His Dark Materials series. In radio, Mel Blanc provided the vocals for Jack Benny's pet polar bear Carmichael on The Jack Benny Program. The polar bear is featured on flags and coats of arms, like the coat of arms of Greenland, and in many advertisements, notably for Coca-Cola since 1922.As charismatic megafauna, polar bears have been used to raise awareness of the dangers of climate change. Aurora the polar bear is a giant marionette created by Greenpeace for climate protests. The World Wide Fund for Nature has sold plush polar bears as part of its \"Arctic Home\" campaign. Photographs of polar bears have been featured in National Geographic and Time magazines, including ones of them standing on ice floes, while the climate change documentary and advocacy film An Inconvenient Truth (2006) includes an animated bear swimming. Automobile manufacturer Nissan used a polar bear in one of its commercials, hugging a man for using an electric car. To make a statement about global warming, in 2009 a Copenhagen ice statue of a polar bear with a bronze skeleton was purposely left to melt in the sun.\n",
      "\n",
      "See also\n",
      "2011 Svalbard polar bear attack\n",
      "International Polar Bear Day\n",
      "List of individual bears – includes individual captive polar bears\n",
      "Polar Bears International – conservation organization\n",
      "Polar Bear Shores – an exhibit featuring polar bears at Sea World in Australia\n",
      "\n",
      "Notes\n",
      "References\n",
      "Bibliography\n",
      "External links\n",
      "Polar Bears International website\n",
      "ARKive — images and movies of the polar bear (Ursus maritimus)Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is a field of study in computer science that develops and studies intelligent machines. Such machines may be called AIs.\n",
      "AI technology is widely used throughout industry, government, and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Google Assistant, Siri, and Alexa), self-driving cars (e.g., Waymo), generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).Alan Turing was the first person to conduct substantial research in the field that he called Machine Intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI spring of the 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to complete any task performable by a human) is among the field's long-term goals.To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and other fields.\n",
      "\n",
      "Goals\n",
      "The general problem of simulating (or creating) intelligence has been broken into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\n",
      "\n",
      "Reasoning, problem-solving\n",
      "Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": they became exponentially slower as the problems grew larger. Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments. Accurate and efficient reasoning is an unsolved problem.\n",
      "\n",
      "Knowledge representation\n",
      "Knowledge representation and knowledge engineering allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval, scene interpretation, clinical decision support, knowledge discovery (mining \"interesting\" and actionable inferences from large databases), and other areas.A knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge. Knowledge bases need to represent things such as: objects, properties, categories and relations between objects; situations, events, states and time; causes and effects; knowledge about knowledge (what we know about what other people know); default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); and many other aspects and domains of knowledge.\n",
      "Among the most difficult problems in knowledge representation are: the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous); and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally). There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.\n",
      "\n",
      "Planning and decision making\n",
      "An \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen. In automated planning, the agent has a specific goal. In automated decision making, the agent has preferences – there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.In classical planning, the agent knows exactly what the effect of any action will be. In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.In some problems, the agent's preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning) or the agent can seek information to improve its preferences. Information value theory can be used to weigh the value of exploratory or experimental actions. The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain what the outcome will be.\n",
      "A Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way, and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g. by iteration), be heuristic, or it can be learned.Game theory describes rational behavior of multiple interacting agents, and is used in AI programs that make decisions that involve other agents.\n",
      "\n",
      "Learning\n",
      "Machine learning is the study of programs that can improve their performance on a given task automatically. It has been a part of AI from the beginning.There are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\". Transfer learning is when the knowledge gained from one problem is applied to a new problem. Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.\n",
      "\n",
      "Natural language processing\n",
      "Natural language processing (NLP) allows programs to read, write and communicate in human languages such as English. Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.Early work, based on Noam Chomsky's generative grammar and semantic networks, had difficulty with word-sense disambiguation unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem). Margaret Masterman believed that it was meaning, and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\n",
      "Modern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning), transformers (a deep learning architecture using an attention mechanism), and others. In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text, and by 2023 these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.\n",
      "\n",
      "Perception\n",
      "Machine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.The field includes speech recognition, image classification, facial recognition, object recognition, and robotic perception.\n",
      "\n",
      "Social intelligence\n",
      "Affective computing is an interdisciplinary umbrella that comprises systems that recognize, interpret, process or simulate human feeling, emotion and mood. For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\n",
      "However, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents. Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the affects displayed by a videotaped subject.\n",
      "\n",
      "General intelligence\n",
      "A machine with artificial general intelligence should be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.\n",
      "\n",
      "Techniques\n",
      "AI research uses a wide variety of techniques to accomplish the goals above.\n",
      "\n",
      "Search and optimization\n",
      "AI can solve many problems by intelligently searching through many possible solutions. There are two very different kinds of search used in AI: state space search and local search.\n",
      "\n",
      "State space search\n",
      "State space search searches through a tree of possible states to try to find a goal state. For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.Simple exhaustive searches are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. \"Heuristics\" or \"rules of thumb\" can help to prioritize choices that are more likely to reach a goal.Adversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and counter-moves, looking for a winning position.\n",
      "\n",
      "Local search\n",
      "Local search uses mathematical optimization to find a numeric solution to a problem. It begins with some form of a guess and then refines the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. This process is called stochastic gradient descent.Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses).Distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).Neural networks and statistical classifiers (discussed below), also use a form of local search, where the \"landscape\" to be searched is formed by learning.\n",
      "\n",
      "Logic\n",
      "Formal Logic is used for reasoning and knowledge representation.\n",
      "Formal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")\n",
      "and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").Logical inference (or deduction) is the process of proving a new statement (conclusion) from other statements that are already known to be true (the premises).\n",
      "A logical knowledge base also handles queries and assertions as a special case of inference.\n",
      "An inference rule describes what is a valid step in a proof. The most general inference rule is resolution.\n",
      "Inference can be reduced to performing a search to find a path that leads from premises to conclusions, where each step is the application of an inference rule.\n",
      "Inference performed this way is intractable except for short proofs in restricted domains. No efficient, powerful and general method has been discovered.\n",
      "Fuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.Non-monotonic logics are designed to handle default reasoning.\n",
      "Other specialized versions of logic have been developed to describe many complex domains (see knowledge representation above).\n",
      "\n",
      "Probabilistic methods for uncertain reasoning\n",
      "Many problems in AI (including in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.Bayesian networks\n",
      "are a very general tool that can be used for many problems, including reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks)\n",
      "and perception (using dynamic Bayesian networks).Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).\n",
      "Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis, and information value theory. These tools include models such as Markov decision processes, dynamic decision networks, game theory and mechanism design.\n",
      "\n",
      "Classifiers and statistical learning methods\n",
      "The simplest AI applications can be divided into two types: classifiers (e.g. \"if shiny then diamond\"), on one hand, and controllers (e.g. \"if diamond then pick up\"), on the other hand. Classifiers\n",
      "are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.There are many kinds of classifiers in use. The decision tree is the simplest and most widely used symbolic machine learning algorithm. K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.\n",
      "The naive Bayes classifier is reportedly the \"most widely used learner\" at Google, due in part to its scalability.Neural networks are also used as classifiers.\n",
      "\n",
      "Artificial neural networks\n",
      "An Artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns, once trained it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses it’s specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.Learning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.\n",
      "Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.In feedforward neural networks the signal passes in only one direction.Recurrent neural networks feed the output signal back into the input, which allows short-term memories of previous input events. Long short term memory is the most successful network architecture for recurrent networks.Perceptrons\n",
      "use only a single layer of neurons, deep learning uses multiple layers.\n",
      "Convolutional neural networks strengthen the connection between neurons that are \"close\" to each other – this is especially important in image processing, where a local set of neurons must identify an \"edge\" before the network can identify an object.\n",
      "\n",
      "Deep learning\n",
      "Deep learning\n",
      "uses several layers of neurons between the network's inputs and outputs. The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification\n",
      "and others. The reason that deep learning performs so well in so many applications is not known as of 2023.\n",
      "The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)\n",
      "but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.\n",
      "\n",
      "GPT\n",
      "Generative pre-trained transformers (GPT) are large language models that are based on the semantic relationships between words in sentences (natural language processing). Text-based GPT models are pre-trained on a large corpus of text which can be from the internet. The pre-training consists in predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pre-training, GPT models accumulate knowledge about the world, and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are still prone to generating falsehoods called \"hallucinations\", although this can be reduced with RLHF and quality data. They are used in chatbots which allow you to ask a question or request a task in simple text.Current models and services include: Bard, ChatGPT, Claude, Copilot and LLaMA. Multimodal GPT models can process different types of data (modalities) such as images, videos, sound and text.\n",
      "\n",
      "Specialized hardware and software\n",
      "In the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software, had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models' training.\n",
      "Historically, specialized languages, such as Lisp, Prolog, Python and others, had been used.\n",
      "\n",
      "Applications\n",
      "AI and machine learning technology is used in most of the essential applications of the 2020s, including: search engines (such as Google Search), targeting online advertisements, recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic, targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa), autonomous vehicles (including drones, ADAS and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace and Google's FaceNet) and image labeling (used by Facebook, Apple's iPhoto and TikTok).\n",
      "\n",
      "Health and Medicine\n",
      "The application of AI in medicine and medical research has the potential to increase patient care and quality of life. Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\n",
      "For medical research, AI is an important tool for processing and integrating Big Data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication. \n",
      "It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research, such as cardiovascular research which typically receives a disproportionately less funding that areas such as cancer research, relative to the morbidity and mortality of these diseases. New AI tools can deepen our understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.\n",
      "\n",
      "Games\n",
      "Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997. In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin. In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then it defeated Ke Jie in 2017, who at the time continuously held the world No. 1 ranking for two years. Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus and Cepheus. DeepMind in the 2010s developed a \"generalized artificial intelligence\" that could learn many diverse Atari games on its own. In 2021 an AI agent competed in a Playstation Gran Turismo competition, winning against four of the world’s best Gran Turismo drivers using deep reinforcement learning. In 2023, there was a study by Deep Mind which used StarCraft II - which is one of the most challenging simulated reinforcement learning environments with multi-agent dynamics, to improve the performance of their agents in complex environments.\n",
      "\n",
      "Military\n",
      "Various countries are deploying AI military applications. The main applications enhance command and control, communications, sensors, integration and interoperability. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles. AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles involving manned and unmanned teams. AI was incorporated into military operations in Iraq and Syria.\n",
      "\n",
      "Generative AI\n",
      "In the early 2020s, generative AI gained widespread prominence. ChatGPT, based on GPT-3, and other large language models, were tried by 14% of Americans adults. The increasing realism and ease-of-use of AI-based text-to-image generators such as Midjourney, DALL-E, and Stable Diffusion sparked a trend of viral AI-generated photos. Widespread attention was gained by a fake photo of Pope Francis wearing a white puffer coat, the fictional arrest of Donald Trump, and a hoax of an attack on the Pentagon, as well as the usage in professional creative arts.\n",
      "\n",
      "Industry Specific Tasks\n",
      "There are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported they had incorporated \"AI\" in some offerings or processes. A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\n",
      "In agriculture, AI has helped farmers identify areas that need irrigation, fertilization, pesticide treatments or increasing yield. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\n",
      "Artificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights\" for example for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. It could also be used for activities in space such as space exploration, including analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\n",
      "\n",
      "Ethics\n",
      "AI, like any powerful technology, has potential benefits and potential risks. AI may be able to advance science and find solutions for serious problems: Demis Hassabis of Deep Mind hopes to \"solve intelligence, and then use that to solve everything else\". However, as the use of AI has become widespread, several unintended consequences and risks have been identified.Anyone looking to use machine learning as part of real-world, in-production systems needs to factor ethics into their AI training processes and strive to avoid bias. This is especially true when using AI algorithms that are inherently unexplainable in deep learning.\n",
      "\n",
      "Risks and harm\n",
      "Privacy and copyright\n",
      "Machine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\n",
      "Technology companies collect a wide range of data from their users, including online activity, geolocation data, video and audio.\n",
      "For example, in order to build speech recognition algorithms, Amazon have recorded millions of private conversations and allowed temps to listen to and transcribe some of them.\n",
      "Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.AI developers argue that this is the only way to deliver valuable applications. and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy. Since 2016, some privacy experts, such as Cynthia Dwork, began to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of 'what they know' to the question of 'what they're doing with it'.\".Generative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under a rationale of \"fair use\". Also website owners who do not wish to have their copyrighted content be AI indexed or ‘scraped’ can add code to their site, as you would, if you did not want your website to be indexed by a search engine which is currently available to certain services such as OpenAI. Experts disagree about how well, and under what circumstances, this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\". In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.\n",
      "\n",
      "Misinformation\n",
      "YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation. This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government. The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem.\n",
      "In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda. AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.\n",
      "\n",
      "Algorithmic bias and fairness\n",
      "Machine learning applications will be biased if they learn from biased data.\n",
      "The developers may not be aware that the bias exists.\n",
      "Bias can be introduced by the way training data is selected and by the way a model is deployed. If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.Fairness in machine learning is the study of how to prevent the harm caused by algorithmic bias. It has become serious area of academic study within AI. Researchers have discovered it is not always possible to define \"fairness\" in a way that satisfies all stakeholders.On June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people, a problem called \"sample size disparity\". Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist.\n",
      "In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend. In 2017, several researchers showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".\n",
      "Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"Criticism of COMPAS highlighted a deeper problem with the misuse of AI. Machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. Unfortunately, if an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist. Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is necessarily descriptive and not proscriptive.Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.At its 2022 Conference on Fairness, Accountability, and Transparency (ACM FAccT 2022) the Association for Computing Machinery, in Seoul, South Korea, presented and published findings recommending that until AI and robotics systems are demonstrated to be free of bias mistakes, they are unsafe and the use of self-learning neural networks trained on vast, unregulated sources of flawed internet data should be curtailed.\n",
      "\n",
      "Lack of transparency\n",
      "Many AI systems are so complex that their designers cannot explain how they reach their decisions. Particularly with deep neural networks, in which there are a large amount of non-linear relationships between inputs and outputs. But some popular explainability techniques exist.There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale. Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.People who have been harmed by an algorithm's decision have a right to an explanation. Doctors, for example, are required to clearly and completely explain the reasoning behind any decision they make. Early drafts of the European Union's General Data Protection Regulation in 2016 included an explicit statement that this right exists. Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.DARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try and solve these problems.There are several potential solutions to the transparency problem. SHAP helps visualise the contribution of each feature to the output. LIME can locally approximate a model with a simpler, interpretable model. Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned. Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network have learned and produce output that can suggest what the network is learning.\n",
      "\n",
      "Conflict, surveillance and weaponized AI\n",
      "A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision. By 2015, over fifty countries were reported to be researching battlefield robots. These weapons are considered especially dangerous for several reasons: if they kill an innocent person it is not clear who should be held accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian centralized decision making more competitive with liberal and decentralized systems such as markets.AI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic. Terrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons. Machine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.\n",
      "\n",
      "Technological unemployment\n",
      "From the early days of the development of artificial intelligence there have been arguments, for example those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.Economists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we're in uncharted territory\" with AI. A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed. Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\". The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\". Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.In April 2023, it was reported that 70% of the jobs for Chinese video game illlustrators had been eliminated by generative artificial intelligence.\n",
      "\n",
      "Existential risk\n",
      "It has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\". This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character. These sci-fi scenarios are misleading in several ways.\n",
      "First, AI does not require human-like \"sentience\" to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of a paperclip factory manager). Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can't fetch the coffee if you're dead.\" In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity's morality and values so that it is \"fundamentally on our side\".Second, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are made of language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.The opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI. Personalities such as Stephen Hawking, Bill Gates, and Elon Musk have expressed concern about existential risk from AI.In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine. However, after 2016, the study of current and future risks and possible solutions became a serious area of research.AI pioneers including Fei-Fei Li, Geoffrey Hinton, Yoshua Bengio, Cynthia Breazeal, Rana el Kaliouby, Demis Hassabis, Joy Buolamwini, and Sam Altman have expressed concerns about the risks of AI. In 2023, many leading AI experts issued the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".Other researchers, however, spoke in favor of a less dystopian view. AI pioneer Juergen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\" While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\" Andrew Ng also argued that \"it’s a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\" Yann LeCun \"scoffs at his peers’ dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"\n",
      "\n",
      "Limiting AI\n",
      "Possible options for limiting AI include: using Embedded Ethics or Constitutional AI where companies or governments can add a policy, restricting high levels of compute power in training, restricting the ability to rewrite its own code base, restrict certain AI techniques but not in the training phase, open-source (transparency) vs proprietary (could be more restricted), backup model with redundancy, restricting security, privacy and copyright, restricting or controlling the memory, real-time monitoring, risk analysis, emergency shut-off, rigorous simulation and testing, model certification, assess known vulnerabilities, restrict the training material, restrict access to the internet, issue terms of use.\n",
      "\n",
      "Ethical machines and alignment\n",
      "Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.\n",
      "The field of machine ethics is also called computational morality,\n",
      "and was founded at an AAAI symposium in 2005.Other approaches include Wendell Wallach's \"artificial moral agents\"\n",
      "and Stuart J. Russell's three principles for developing provably beneficial machines.\n",
      "\n",
      "Frameworks\n",
      "Artificial Intelligence projects can have their ethical permissibility tested while designing, developing, and implementing an AI system. An AI framework such as the Care and Act Framework containing the SUM values – developed by the Alan Turing Institute tests projects in four main areas:\n",
      "RESPECT the dignity of individual people\n",
      "CONNECT with other people sincerely, openly and inclusively\n",
      "CARE for the wellbeing of everyone\n",
      "PROTECT social values, justice and the public interestOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE's Ethics of Autonomous Systems initiative, among others; however, these principles do not go without their criticisms, especially regards to the people chosen contributes to these frameworks.Promotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.\n",
      "\n",
      "Regulation\n",
      "The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.\n",
      "The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally. According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\n",
      "Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.\n",
      "Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, US and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.\n",
      "The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology. Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.\n",
      "In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years. In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, governments officials and academics.In a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\". A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.\n",
      "In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".In November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks. 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.\n",
      "\n",
      "History\n",
      "The study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate both mathematical deduction and formal reasoning, which is known as the Church–Turing thesis. This, along with concurrent discoveries in cybernetics and information theory, led researchers to consider the possibility of building an \"electronic brain\".Alan Turing was thinking about machine intelligence at least as early as 1941, when he circulated a paper on machine intelligence which could be the earliest paper in the field of AI – though it is now lost. The first available paper generally recognized as \"AI\" was McCullouch and Pitts design for Turing-complete \"artificial neurons\" in 1943 – the first mathematical model of a neural network. The paper was influenced by Turing's earlier paper 'On Computable Numbers' from 1936 using similar two-state boolean 'neurons', but was the first to apply it to neuronal function.The term 'Machine Intelligence' was used by Alan Turing during his life which was later often referred to as 'Artificial Intelligence' after his death in 1954. In 1950 Turing published the best known of his papers 'Computing Machinery and Intelligence', the paper introduced his concept of what is now known as the Turing test to the general public. Then followed three radio broadcasts on AI by Turing, the lectures: 'Intelligent Machinery, A Heretical Theory’, ‘Can Digital Computers Think’? and the panel discussion ‘Can Automatic Calculating Machines be Said to Think’. By 1956 computer intelligence had been actively pursued for more than a decade in Britain; the earliest AI programmes were written there in 1951–1952.In 1951, using a Ferranti Mark 1 computer of the University of Manchester, checkers and chess programs were wrote where you could play against the computer. The field of American AI research was founded at a workshop at Dartmouth College in 1956. The attendees became the leaders of AI research in the 1960s. They and their students produced programs that the press described as \"astonishing\": computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English. Artificial Intelligence laboratories were set up at a number of British and US Universities in the latter 1950s and early 1960s.They had, however, underestimated the difficulty of the problem. Both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill and ongoing pressure from the U.S. Congress to fund more productive projects. Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether. The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.In the early 1980s, AI research was revived by the commercial success of expert systems, a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research. However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.Many researchers began to doubt that the current practices would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into \"sub-symbolic\" approaches. Robotics researchers, such as Rodney Brooks, rejected \"representation\" in general and focussed directly on engineering machines that move and survive. Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic. But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others. In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).\n",
      "By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".Several academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.\n",
      "For many specific tasks, other methods were abandoned.\n",
      "Deep learning's success was based on both hardware improvements (faster computers, graphics processing units, cloud computing)\n",
      "and access to large amounts of data (including curated datasets, such as ImageNet).\n",
      "Deep learning's success led to an enormous increase in interest and funding in AI.\n",
      "The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019,\n",
      "and WIPO reported that AI was the most prolific emerging technology in terms of the number of patent applications and granted patents.\n",
      "According to 'AI Impacts', about $50 billion annually was invested in \"AI\" around 2022 in the US alone and about 20% of new US Computer Science PhD graduates have specialized in \"AI\";\n",
      "about 800,000 \"AI\"-related US job openings existed in 2022. The large majority of the advances have occurred within the United States, with its companies, universities, and research labs leading artificial intelligence research.In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.\n",
      "\n",
      "Philosophy\n",
      "Defining artificial intelligence\n",
      "Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\" He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\". He devised the Turing test, which measures the ability of a machine to simulate human conversation. Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks\"Russell and Norvig agree with Turing that AI must be defined in terms of \"acting\" and not \"thinking\". However, they are critical that the test compares machines to people. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\" AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world.\" Another AI founder, Marvin Minsky similarly defines it as \"the ability to solve hard problems\". These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\n",
      "Another definition has been adopted by Google, a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\n",
      "\n",
      "Evaluating approaches to AI\n",
      "No established unifying theory or paradigm has guided AI research for most of its history. The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.\n",
      "\n",
      "Symbolic AI and its limits\n",
      "Symbolic AI (or \"GOFAI\") simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"However, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult. Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge. Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence, in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\n",
      "\n",
      "Neat vs. scruffy\n",
      "\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s, but eventually was seen as irrelevant. Modern AI has elements of both.\n",
      "\n",
      "Soft vs. hard computing\n",
      "Finding a provably correct or optimal solution is intractable for many important problems. Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\n",
      "\n",
      "Narrow vs. general AI\n",
      "AI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals. General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.\n",
      "\n",
      "Machine consciousness, sentience and mind\n",
      "The philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\" However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n",
      "\n",
      "Consciousness\n",
      "David Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness. The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). Human information processing is easy to explain, however, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.\n",
      "\n",
      "Computationalism and functionalism\n",
      "Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\" Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.\n",
      "\n",
      "Robot rights\n",
      "If a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so it could also suffer; it has been argued that this could entitle it to certain rights. Any hypothetical robot rights would lie on a spectrum with animal rights and human rights. This issue has been considered in fiction for centuries, and is now being considered by, for example, California's Institute for the Future; however, critics argue that the discussion is premature.\n",
      "\n",
      "Future\n",
      "Superintelligence and the singularity\n",
      "A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n",
      "\n",
      "Transhumanism\n",
      "Robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.Edward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.\n",
      "\n",
      "In fiction\n",
      "Thought-capable artificial beings have appeared as storytelling devices since antiquity, and have been a persistent theme in science fiction.A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the \"Multivac\" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics; while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n",
      "\n",
      "See also\n",
      "AI effect\n",
      "Artificial intelligence detection software – Software to detect AI-generated contentPages displaying short descriptions of redirect targets\n",
      "Artificial intelligence in healthcare – Overview of the use of artificial intelligence in healthcare\n",
      "Behavior selection algorithm – Algorithm that selects actions for intelligent agents\n",
      "Business process automation – Technology-enabled automation of complex business processes\n",
      "Case-based reasoning – Process of solving new problems based on the solutions of similar past problems\n",
      "Emergent algorithm – Algorithm exhibiting emergent behavior\n",
      "Female gendering of AI technologies\n",
      "Glossary of artificial intelligence – List of definitions of terms and concepts commonly used in the study of artificial intelligence\n",
      "Robotic process automation – Form of business process automation technology\n",
      "Weak artificial intelligence – Form of artificial intelligence\n",
      "Wetware computer – Computer composed of organic material\n",
      "Intelligence amplification – Use of information technology to augment human intelligence\n",
      "\n",
      "Explanatory notes\n",
      "References\n",
      "AI textbooks\n",
      "The two most widely used textbooks in 2023. (See the Open Syllabus).\n",
      "\n",
      "Russell, Stuart J.; Norvig, Peter. (2021). Artificial Intelligence: A Modern Approach (4th ed.). Hoboken: Pearson. ISBN 978-0134610993. LCCN 20190474.\n",
      "Rich, Elaine; Knight, Kevin; Nair, Shivashankar B (2010). Artificial Intelligence (3rd ed.). New Delhi: Tata McGraw Hill India. ISBN 978-0070087705.These were the four of the most widely used AI textbooks in 2008:\n",
      "\n",
      "History of AI\n",
      "Other sources\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "\"Artificial Intelligence\". Internet Encyclopedia of Philosophy.\n",
      "Thomason, Richmond. \"Logic and Artificial Intelligence\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n",
      "Artificial Intelligence. BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, 8 December 2005).\n",
      "Theranostics and AI—The Next Advance in Cancer Precision Medicine.Leonardo di ser Piero da Vinci (15 April 1452 – 2 May 1519) was an Italian polymath of the High Renaissance who was active as a painter, draughtsman, engineer, scientist, theorist, sculptor, and architect. While his fame initially rested on his achievements as a painter, he also became known for his notebooks, in which he made drawings and notes on a variety of subjects, including anatomy, astronomy, botany, cartography, painting, and paleontology. Leonardo is widely regarded to have been a genius who epitomized the Renaissance humanist ideal, and his collective works comprise a contribution to later generations of artists matched only by that of his younger contemporary by 23 years Michelangelo Buonarroti.Born out of wedlock to a successful notary and a lower-class woman in, or near, Vinci, he was educated in Florence by the Italian painter and sculptor Andrea del Verrocchio. He began his career in the city, but then spent much time in the service of Ludovico Sforza in Milan. Later, he worked in Florence and Milan again, as well as briefly in Rome, all while attracting a large following of imitators and students. Upon the invitation of Francis I, he spent his last three years in France, where he died in 1519. Since his death, there has not been a time where his achievements, diverse interests, personal life, and empirical thinking have failed to incite interest and admiration, making him a frequent namesake and subject in culture.\n",
      "Leonardo is identified as one of the greatest painters in the history of art and is often credited as the founder of the High Renaissance. Despite having many lost works and fewer than 25 attributed major works –  including numerous unfinished works –  he created some of the most influential paintings in Western art. His magnum opus, the Mona Lisa, is his best known work and often regarded as the world's most famous painting. The Last Supper is the most reproduced religious painting of all time and his Vitruvian Man drawing is also regarded as a cultural icon. In 2017, Salvator Mundi, attributed in whole or part to Leonardo, was sold at auction for US$450.3 million, setting a new record for the most expensive painting ever sold at public auction.\n",
      "Revered for his technological ingenuity, he conceptualized flying machines, a type of armored fighting vehicle, concentrated solar power, a ratio machine that could be used in an adding machine, and the double hull. Relatively few of his designs were constructed or were even feasible during his lifetime, as the modern scientific approaches to metallurgy and engineering were only in their infancy during the Renaissance. Some of his smaller inventions, however, entered the world of manufacturing unheralded, such as an automated bobbin winder and a machine for testing the tensile strength of wire. He made substantial discoveries in anatomy, civil engineering, hydrodynamics, geology, optics, and tribology, but he did not publish his findings and they had little to no direct influence on subsequent science.\n",
      "\n",
      "Biography\n",
      "Early life (1452–1472)\n",
      "Birth and background\n",
      "Leonardo da Vinci, properly named Leonardo di ser Piero da Vinci (\"Leonardo, son of ser Piero from Vinci\"), was born on 15 April 1452 in, or close to, the Tuscan hill town of Vinci, 20 miles from Florence. He was born out of wedlock to Piero da Vinci (Ser Piero da Vinci d'Antonio di ser Piero di ser Guido; 1426–1504), a Florentine legal notary, and Caterina di Meo Lippi (c. 1434–1494), from the lower class. It remains uncertain where Leonardo was born; the traditional account, from a local oral tradition recorded by the historian Emanuele Repetti, is that he was born in Anchiano, a country hamlet that would have offered sufficient privacy for the illegitimate birth, though it is still possible he was born in a house in Florence that Ser Piero almost certainly had. Leonardo's parents both married separately the year after his birth. Caterina –  who later appears in Leonardo's notes as only \"Caterina\" or \"Catelina\" –  is usually identified as the Caterina Buti del Vacca, who married the local artisan Antonio di Piero Buti del Vacca, nicknamed L'Accattabriga, 'the quarrelsome one'. Ser Piero married Albiera Amadori –   having been betrothed to her the previous year –   and after her death in 1464, went on to have three subsequent marriages. From all the marriages, Leonardo eventually had 16 half-siblings (of whom 11 survived infancy) who were much younger than he (the last was born when Leonardo was 46 years old) and with whom he had very little contact.\n",
      "Very little is known about Leonardo's childhood and much is shrouded in myth, partially because of his biography in the frequently apocryphal Lives of the Most Excellent Painters, Sculptors, and Architects (1550) by 16th-century art historian Giorgio Vasari. Tax records indicate that by at least 1457 he lived in the household of his paternal grandfather, Antonio da Vinci, but it is possible that he spent the years before then in the care of his mother in Vinci, either Anchiano or Campo Zeppi in the parish of San Pantaleone. He is thought to have been close to his uncle, Francesco da Vinci, but his father was probably in Florence most of the time. Ser Piero, who was the descendant of a long line of notaries, established an official residence in Florence by at least 1469 and had a successful career. Despite his family history, Leonardo only received a basic and informal education in (vernacular) writing, reading, and mathematics; possibly because his artistic talents were recognised early, so his family decided to focus their attention there.Later in life, Leonardo recorded his earliest memory, now in the Codex Atlanticus. While writing on the flight of birds, he recalled as an infant when a kite came to his cradle and opened his mouth with its tail; commentators still debate whether the anecdote was an actual memory or a fantasy.\n",
      "\n",
      "Verrocchio's workshop\n",
      "In the mid-1460s, Leonardo's family moved to Florence, which at the time was the centre of Christian Humanist thought and culture. Around the age of 14, he became a garzone (studio boy) in the workshop of Andrea del Verrocchio, who was the leading Florentine painter and sculptor of his time. This was about the time of the death of Verrocchio's master, the great sculptor Donatello. Leonardo became an apprentice by the age of 17 and remained in training for seven years. Other famous painters apprenticed in the workshop or associated with it include Ghirlandaio, Perugino, Botticelli, and Lorenzo di Credi. Leonardo was exposed to both theoretical training and a wide range of technical skills, including drafting, chemistry, metallurgy, metal working, plaster casting, leather working, mechanics, and woodwork, as well as the artistic skills of drawing, painting, sculpting, and modelling.Leonardo was a contemporary of Botticelli, Ghirlandaio and Perugino, who were all slightly older than he was. He would have met them at the workshop of Verrocchio or at the Platonic Academy of the Medici. Florence was ornamented by the works of artists such as Donatello's contemporaries Masaccio, whose figurative frescoes were imbued with realism and emotion, and Ghiberti, whose Gates of Paradise, gleaming with gold leaf, displayed the art of combining complex figure compositions with detailed architectural backgrounds. Piero della Francesca had made a detailed study of perspective, and was the first painter to make a scientific study of light. These studies and Leon Battista Alberti's treatise De pictura were to have a profound effect on younger artists and in particular on Leonardo's own observations and artworks.Much of the painting in Verrocchio's workshop was done by his assistants. According to Vasari, Leonardo collaborated with Verrocchio on his The Baptism of Christ (c. 1472–1475), painting the young angel holding Jesus's robe with skill so far superior to his master's that Verrocchio purportedly put down his brush and never painted again (the latter claim probably being apocryphal). The new technique of oil paint was applied to areas of the mostly tempera work, including the landscape, the rocks seen through the brown mountain stream, and much of Jesus's figure, indicating Leonardo's hand. Additionally, Leonardo may have been a model for two works by Verrocchio: the bronze statue of David in the Bargello and the archangel Raphael in Tobias and the Angel.Vasari tells a story of Leonardo as a very young man: a local peasant made himself a round buckler shield and requested that Ser Piero have it painted for him. Leonardo, inspired by the story of Medusa, responded with a painting of a monster spitting fire that was so terrifying that his father bought a different shield to give to the peasant and sold Leonardo's to a Florentine art dealer for 100 ducats, who in turn sold it to the Duke of Milan.\n",
      "\n",
      "First Florentine period (1472–c. 1482)\n",
      "By 1472, at the age of 20, Leonardo qualified as a master in the Guild of Saint Luke, the guild of artists and doctors of medicine, but even after his father set him up in his own workshop, his attachment to Verrocchio was such that he continued to collaborate and live with him. Leonardo's earliest known dated work is a 1473 pen-and-ink drawing of the Arno valley (see below). According to Vasari, the young Leonardo was the first to suggest making the Arno river a navigable channel between Florence and Pisa.In January 1478, Leonardo received an independent commission to paint an altarpiece for the Chapel of Saint Bernard in the Palazzo Vecchio, an indication of his independence from Verrocchio's studio. An anonymous early biographer, known as Anonimo Gaddiano, claims that in 1480 Leonardo was living with the Medici and often worked in the garden of the Piazza San Marco, Florence, where a Neoplatonic academy of artists, poets and philosophers organized by the Medici met. In March 1481, he received a commission from the monks of San Donato in Scopeto for The Adoration of the Magi. Neither of these initial commissions were completed, being abandoned when Leonardo went to offer his services to Duke of Milan Ludovico Sforza. Leonardo wrote Sforza a letter which described the diverse things that he could achieve in the fields of engineering and weapon design, and mentioned that he could paint. He brought with him a silver string instrument –  either a lute or lyre –  in the form of a horse's head.With Alberti, Leonardo visited the home of the Medici and through them came to know the older Humanist philosophers of whom Marsiglio Ficino, proponent of Neoplatonism; Cristoforo Landino, writer of commentaries on Classical writings, and John Argyropoulos, teacher of Greek and translator of Aristotle were the foremost. Also associated with the Platonic Academy of the Medici was Leonardo's contemporary, the brilliant young poet and philosopher Pico della Mirandola. In 1482, Leonardo was sent as an ambassador by Lorenzo de' Medici to Ludovico il Moro, who ruled Milan between 1479 and 1499.\n",
      "\n",
      "First Milanese period (c. 1482–1499)\n",
      "Leonardo worked in Milan from 1482 until 1499. He was commissioned to paint the Virgin of the Rocks for the Confraternity of the Immaculate Conception and The Last Supper for the monastery of Santa Maria delle Grazie. In the spring of 1485, Leonardo travelled to Hungary (on behalf of Sforza) to meet king Matthias Corvinus, and was commissioned by him to paint a Madonna. In 1490 he was called as a consultant, together with Francesco di Giorgio Martini, for the building site of the cathedral of Pavia and was struck by the equestrian statue of Regisole, of which he left a sketch. Leonardo was employed on many other projects for Sforza, such as preparation of floats and pageants for special occasions; a drawing of, and wooden model for, a competition to design the cupola for Milan Cathedral; and a model for a huge equestrian monument to Ludovico's predecessor Francesco Sforza. This would have surpassed in size the only two large equestrian statues of the Renaissance, Donatello's Gattamelata in Padua and Verrocchio's Bartolomeo Colleoni in Venice, and became known as the Gran Cavallo. Leonardo completed a model for the horse and made detailed plans for its casting, but in November 1494, Ludovico gave the metal to his brother-in-law to be used for a cannon to defend the city from Charles VIII of France.\n",
      "Contemporary correspondence records that Leonardo and his assistants were commissioned by the Duke of Milan to paint the Sala delle Asse in the Sforza Castle, c. 1498. The project became a trompe-l'œil decoration that made the great hall appear to be a pergola created by the interwoven limbs of sixteen mulberry trees, whose canopy included an intricate labyrinth of leaves and knots on the ceiling.\n",
      "\n",
      "Second Florentine period (1500–1508)\n",
      "When Ludovico Sforza was overthrown by France in 1500, Leonardo fled Milan for Venice, accompanied by his assistant Salaì and friend, the mathematician Luca Pacioli. In Venice, Leonardo was employed as a military architect and engineer, devising methods to defend the city from naval attack. On his return to Florence in 1500, he and his household were guests of the Servite monks at the monastery of Santissima Annunziata and were provided with a workshop where, according to Vasari, Leonardo created the cartoon of The Virgin and Child with Saint Anne and Saint John the Baptist, a work that won such admiration that \"men [and] women, young and old\" flocked to see it \"as if they were going to a solemn festival.\"In Cesena in 1502, Leonardo entered the service of Cesare Borgia, the son of Pope Alexander VI, acting as a military architect and engineer and travelling throughout Italy with his patron. Leonardo created a map of Cesare Borgia's stronghold, a town plan of Imola in order to win his patronage. Upon seeing it, Cesare hired Leonardo as his chief military engineer and architect. Later in the year, Leonardo produced another map for his patron, one of Chiana Valley, Tuscany, so as to give his patron a better overlay of the land and greater strategic position. He created this map in conjunction with his other project of constructing a dam from the sea to Florence, in order to allow a supply of water to sustain the canal during all seasons.\n",
      "Leonardo had left Borgia's service and returned to Florence by early 1503, where he rejoined the Guild of Saint Luke on 18 October of that year. By this same month, Leonardo had begun working on a portrait of Lisa del Giocondo, the model for the Mona Lisa, which he would continue working on until his twilight years. In January 1504, he was part of a committee formed to recommend where Michelangelo's statue of David should be placed. He then spent two years in Florence designing and painting a mural of The Battle of Anghiari for the Signoria, with Michelangelo designing its companion piece, The Battle of Cascina.In 1506, Leonardo was summoned to Milan by Charles II d'Amboise, the acting French governor of the city. There, Leonardo took on another pupil, Count Francesco Melzi, the son of a Lombard aristocrat, who is considered to have been his favourite student. The Council of Florence wished Leonardo to return promptly to finish The Battle of Anghiari, but he was given leave at the behest of Louis XII, who considered commissioning the artist to make some portraits. Leonardo may have commenced a project for an equestrian figure of d'Amboise; a wax model survives and, if genuine, is the only extant example of Leonardo's sculpture. Leonardo was otherwise free to pursue his scientific interests. Many of Leonardo's most prominent pupils either knew or worked with him in Milan, including Bernardino Luini, Giovanni Antonio Boltraffio, and Marco d'Oggiono. In 1507, Leonardo was in Florence sorting out a dispute with his brothers over the estate of his father, who had died in 1504.\n",
      "\n",
      "Second Milanese period (1508–1513)\n",
      "By 1508, Leonardo was back in Milan, living in his own house in Porta Orientale in the parish of Santa Babila.In 1512, Leonardo was working on plans for an equestrian monument for Gian Giacomo Trivulzio, but this was prevented by an invasion of a confederation of Swiss, Spanish and Venetian forces, which drove the French from Milan. Leonardo stayed in the city, spending several months in 1513 at the Medici's Vaprio d'Adda villa.\n",
      "\n",
      "Rome and France (1513–1519)\n",
      "In March 1513, Lorenzo de' Medici's son Giovanni assumed the papacy (as Leo X); Leonardo went to Rome that September, where he was received by the pope's brother Giuliano. From September 1513 to 1516, Leonardo spent much of his time living in the Belvedere Courtyard in the Apostolic Palace, where Michelangelo and Raphael were both active. Leonardo was given an allowance of 33 ducats a month, and according to Vasari, decorated a lizard with scales dipped in quicksilver. The pope gave him a painting commission of unknown subject matter, but cancelled it when the artist set about developing a new kind of varnish. Leonardo became ill, in what may have been the first of multiple strokes leading to his death. He practiced botany in the Gardens of Vatican City, and was commissioned to make plans for the pope's proposed draining of the Pontine Marshes. He also dissected cadavers, making notes for a treatise on vocal cords; these he gave to an official in hopes of regaining the pope's favor, but was unsuccessful.In October 1515, King Francis I of France recaptured Milan. Leonardo was present at the 19 December meeting of Francis I and Leo X, which took place in Bologna. In 1516, Leonardo entered Francis' service, being given the use of the manor house Clos Lucé, near the king's residence at the royal Château d'Amboise. Being frequently visited by Francis, he drew plans for an immense castle town the king intended to erect at Romorantin, and made a mechanical lion, which during a pageant walked toward the king and –  upon being struck by a wand –  opened its chest to reveal a cluster of lilies. Leonardo was accompanied during this time by his friend and apprentice Francesco Melzi, and supported by a pension totalling 10,000 scudi. At some point, Melzi drew a portrait of Leonardo; the only others known from his lifetime were a sketch by an unknown assistant on the back of one of Leonardo's studies (c. 1517) and a drawing by Giovanni Ambrogio Figino depicting an elderly Leonardo with his right arm wrapped in clothing. The latter, in addition to the record of an October 1517 visit by Louis d'Aragon, confirms an account of Leonardo's right hand being paralytic when he was 65, which may indicate why he left works such as the Mona Lisa unfinished. He continued to work at some capacity until eventually becoming ill and bedridden for several months.\n",
      "\n",
      "Death\n",
      "Leonardo died at Clos Lucé on 2 May 1519 at the age of 67, possibly of a stroke. Francis I had become a close friend. Vasari describes Leonardo as lamenting on his deathbed, full of repentance, that \"he had offended against God and men by failing to practice his art as he should have done.\" Vasari states that in his last days, Leonardo sent for a priest to make his confession and to receive the Holy Sacrament. Vasari also records that the king held Leonardo's head in his arms as he died, although this story may be legend rather than fact. In accordance with his will, sixty beggars carrying tapers followed Leonardo's casket. Melzi was the principal heir and executor, receiving, as well as money, Leonardo's paintings, tools, library and personal effects. Leonardo's other long-time pupil and companion, Salaì, and his servant Baptista de Vilanis, each received half of Leonardo's vineyards. His brothers received land, and his serving woman received a fur-lined cloak. On 12 August 1519, Leonardo's remains were interred in the Collegiate Church of Saint Florentin at the Château d'Amboise.Some 20 years after Leonardo's death, Francis was reported by the goldsmith and sculptor Benvenuto Cellini as saying: \"There had never been another man born in the world who knew as much as Leonardo, not so much about painting, sculpture and architecture, as that he was a very great philosopher.\"\n",
      "Salaì, or Il Salaino (\"The Little Unclean One\", i.e., the devil), entered Leonardo's household in 1490 as an assistant. After only a year, Leonardo made a list of his misdemeanours, calling him \"a thief, a liar, stubborn, and a glutton,\" after he had made off with money and valuables on at least five occasions and spent a fortune on clothes. Nevertheless, Leonardo treated him with great indulgence, and he remained in Leonardo's household for the next thirty years. Salaì executed a number of paintings under the name of Andrea Salaì, but although Vasari claims that Leonardo \"taught him many things about painting,\" his work is generally considered to be of less artistic merit than others among Leonardo's pupils, such as Marco d'Oggiono and Boltraffio.\n",
      "At the time of his death in 1524, Salaì owned a painting referred to as Joconda in a posthumous inventory of his belongings; it was assessed at 505 lire, an exceptionally high valuation for a small panel portrait.\n",
      "\n",
      "Personal life\n",
      "Despite the thousands of pages Leonardo left in notebooks and manuscripts, he scarcely made reference to his personal life.Within Leonardo's lifetime, his extraordinary powers of invention, his \"great physical beauty\" and \"infinite grace,\" as described by Vasari, as well as all other aspects of his life, attracted the curiosity of others. One such aspect was his love for animals, likely including vegetarianism and according to Vasari, a habit of purchasing caged birds and releasing them.Leonardo had many friends who are now notable either in their fields or for their historical significance, including mathematician Luca Pacioli, with whom he collaborated on the book Divina proportione in the 1490s. Leonardo appears to have had no close relationships with women except for his friendship with Cecilia Gallerani and the two Este sisters, Beatrice and Isabella. While on a journey that took him through Mantua, he drew a portrait of Isabella that appears to have been used to create a painted portrait, now lost.Beyond friendship, Leonardo kept his private life secret. His sexuality has been the subject of satire, analysis, and speculation. This trend began in the mid-16th century and was revived in the 19th and 20th centuries, most notably by Sigmund Freud in his Leonardo da Vinci, A Memory of His Childhood. Leonardo's most intimate relationships were perhaps with his pupils Salaì and Melzi. Melzi, writing to inform Leonardo's brothers of his death, described Leonardo's feelings for his pupils as both loving and passionate. It has been claimed since the 16th century that these relationships were of a sexual or erotic nature. Walter Isaacson in his biography of Leonardo makes explicit his opinion that the relations with Salai were intimate and homosexual.\n",
      "Earlier in Leonardo's life, court records of 1476, when he was aged twenty-four, show that Leonardo and three other young men were charged with sodomy in an incident involving a known male prostitute. The charges were dismissed for lack of evidence, and there is speculation that since one of the accused, Lionardo de Tornabuoni, was related to Lorenzo de' Medici, the family exerted its influence to secure the dismissal. Since that date much has been written about his presumed homosexuality and its role in his art, particularly in the androgyny and eroticism manifested in Saint John the Baptist and Bacchus and more explicitly in a number of erotic drawings.\n",
      "\n",
      "Paintings\n",
      "Despite the recent awareness and admiration of Leonardo as a scientist and inventor, for the better part of four hundred years his fame rested on his achievements as a painter. A handful of works that are either authenticated or attributed to him have been regarded as among the great masterpieces. These paintings are famous for a variety of qualities that have been much imitated by students and discussed at great length by connoisseurs and critics. By the 1490s Leonardo had already been described as a \"Divine\" painter.Among the qualities that make Leonardo's work unique are his innovative techniques for laying on the paint; his detailed knowledge of anatomy, light, botany and geology; his interest in physiognomy and the way humans register emotion in expression and gesture; his innovative use of the human form in figurative composition; and his use of subtle gradation of tone. All these qualities come together in his most famous painted works, the Mona Lisa, the Last Supper, and the Virgin of the Rocks.\n",
      "\n",
      "Early works\n",
      "Leonardo first gained attention for his work on the Baptism of Christ, painted in conjunction with Verrocchio. Two other paintings appear to date from his time at Verrocchio's workshop, both of which are Annunciations. One is small, 59 centimetres (23 in) long and 14 cm (5.5 in) high. It is a \"predella\" to go at the base of a larger composition, a painting by Lorenzo di Credi from which it has become separated. The other is a much larger work, 217 cm (85 in) long. In both Annunciations, Leonardo used a formal arrangement, like two well-known pictures by Fra Angelico of the same subject, of the Virgin Mary sitting or kneeling to the right of the picture, approached from the left by an angel in profile, with a rich flowing garment, raised wings and bearing a lily. Although previously attributed to Ghirlandaio, the larger work is now generally attributed to Leonardo.In the smaller painting, Mary averts her eyes and folds her hands in a gesture that symbolised submission to God's will. Mary is not submissive, however, in the larger piece. The girl, interrupted in her reading by this unexpected messenger, puts a finger in her bible to mark the place and raises her hand in a formal gesture of greeting or surprise. This calm young woman appears to accept her role as the Mother of God, not with resignation but with confidence. In this painting, the young Leonardo presents the humanist face of the Virgin Mary, recognising humanity's role in God's incarnation.\n",
      "\n",
      "Paintings of the 1480s\n",
      "In the 1480s, Leonardo received two very important commissions and commenced another work that was of ground-breaking importance in terms of composition. Two of the three were never finished, and the third took so long that it was subject to lengthy negotiations over completion and payment.\n",
      "One of these paintings was Saint Jerome in the Wilderness, which Bortolon associates with a difficult period of Leonardo's life, as evidenced in his diary: \"I thought I was learning to live; I was only learning to die.\" Although the painting is barely begun, the composition can be seen and is very unusual. Jerome, as a penitent, occupies the middle of the picture, set on a slight diagonal and viewed somewhat from above. His kneeling form takes on a trapezoid shape, with one arm stretched to the outer edge of the painting and his gaze looking in the opposite direction. J. Wasserman points out the link between this painting and Leonardo's anatomical studies. Across the foreground sprawls his symbol, a great lion whose body and tail make a double spiral across the base of the picture space. The other remarkable feature is the sketchy landscape of craggy rocks against which the figure is silhouetted.\n",
      "The daring display of figure composition, the landscape elements and personal drama also appear in the great unfinished masterpiece, the Adoration of the Magi, a commission from the Monks of San Donato a Scopeto. It is a complex composition, of about 250 x 250 centimetres. Leonardo did numerous drawings and preparatory studies, including a detailed one in linear perspective of the ruined classical architecture that forms part of the background. In 1482 Leonardo went to Milan at the behest of Lorenzo de' Medici in order to win favour with Ludovico il Moro, and the painting was abandoned.\n",
      "The third important work of this period is the Virgin of the Rocks, commissioned in Milan for the Confraternity of the Immaculate Conception. The painting, to be done with the assistance of the de Predis brothers, was to fill a large complex altarpiece. Leonardo chose to paint an apocryphal moment of the infancy of Christ when the infant John the Baptist, in protection of an angel, met the Holy Family on the road to Egypt. The painting demonstrates an eerie beauty as the graceful figures kneel in adoration around the infant Christ in a wild landscape of tumbling rock and whirling water. While the painting is quite large, about 200×120 centimetres, it is not nearly as complex as the painting ordered by the monks of San Donato, having only four figures rather than about fifty and a rocky landscape rather than architectural details. The painting was eventually finished; in fact, two versions of the painting were finished: one remained at the chapel of the Confraternity, while Leonardo took the other to France. The Brothers did not get their painting, however, nor the de Predis their payment, until the next century.Leonardo's most remarkable portrait of this period is the Lady with an Ermine, presumed to be Cecilia Gallerani (c. 1483–1490), lover of Ludovico Sforza. The painting is characterised by the pose of the figure with the head turned at a very different angle to the torso, unusual at a date when many portraits were still rigidly in profile. The ermine plainly carries symbolic meaning, relating either to the sitter, or to Ludovico who belonged to the prestigious Order of the Ermine.\n",
      "\n",
      "Paintings of the 1490s\n",
      "Leonardo's most famous painting of the 1490s is The Last Supper, commissioned for the refectory of the Convent of Santa Maria della Grazie in Milan. It represents the last meal shared by Jesus with his disciples before his capture and death, and shows the moment when Jesus has just said \"one of you will betray me\", and the consternation that this statement caused.The writer Matteo Bandello observed Leonardo at work and wrote that some days he would paint from dawn till dusk without stopping to eat and then not paint for three or four days at a time. This was beyond the comprehension of the prior of the convent, who hounded him until Leonardo asked Ludovico to intervene. Vasari describes how Leonardo, troubled over his ability to adequately depict the faces of Christ and the traitor Judas, told the duke that he might be obliged to use the prior as his model.The painting was acclaimed as a masterpiece of design and characterization, but it deteriorated rapidly, so that within a hundred years it was described by one viewer as \"completely ruined.\" Leonardo, instead of using the reliable technique of fresco, had used tempera over a ground that was mainly gesso, resulting in a surface subject to mould and to flaking. Despite this, the painting remains one of the most reproduced works of art; countless copies have been made in various mediums.\n",
      "Toward the end of this period, in 1498 Leonardo's trompe-l'œil decoration of the Sala delle Asse was painted for the Duke of Milan in the Castello Sforzesco.\n",
      "\n",
      "Paintings of the 1500s\n",
      "In 1505, Leonardo was commissioned to paint The Battle of Anghiari in the Salone dei Cinquecento (Hall of the Five Hundred) in the Palazzo Vecchio, Florence. Leonardo devised a dynamic composition depicting four men riding raging war horses engaged in a battle for possession of a standard, at the Battle of Anghiari in 1440. Michelangelo was assigned the opposite wall to depict the Battle of Cascina. Leonardo's painting deteriorated rapidly and is now known from a copy by Rubens.\n",
      "Among the works created by Leonardo in the 16th century is the small portrait known as the Mona Lisa or La Gioconda, the laughing one. In the present era, it is arguably the most famous painting in the world. Its fame rests, in particular, on the elusive smile on the woman's face, its mysterious quality perhaps due to the subtly shadowed corners of the mouth and eyes such that the exact nature of the smile cannot be determined. The shadowy quality for which the work is renowned came to be called \"sfumato\", or Leonardo's smoke. Vasari wrote that the smile was \"so pleasing that it seems more divine than human, and it was considered a wondrous thing that it was as lively as the smile of the living original.\"Other characteristics of the painting are the unadorned dress, in which the eyes and hands have no competition from other details; the dramatic landscape background, in which the world seems to be in a state of flux; the subdued colouring; and the extremely smooth nature of the painterly technique, employing oils laid on much like tempera, and blended on the surface so that the brushstrokes are indistinguishable. Vasari expressed that the painting's quality would make even \"the most confident master ... despair and lose heart.\" The perfect state of preservation and the fact that there is no sign of repair or overpainting is rare in a panel painting of this date.In the painting Virgin and Child with Saint Anne, the composition again picks up the theme of figures in a landscape, which Wasserman describes as \"breathtakingly beautiful\" and harkens back to the Saint Jerome with the figure set at an oblique angle. What makes this painting unusual is that there are two obliquely set figures superimposed. Mary is seated on the knee of her mother, Saint Anne. She leans forward to restrain the Christ Child as he plays roughly with a lamb, the sign of his own impending sacrifice. This painting, which was copied many times, influenced Michelangelo, Raphael, and Andrea del Sarto, and through them Pontormo and Correggio. The trends in composition were adopted in particular by the Venetian painters Tintoretto and Veronese.\n",
      "\n",
      "Drawings\n",
      "Leonardo was a prolific draughtsman, keeping journals full of small sketches and detailed drawings recording all manner of things that took his attention. As well as the journals there exist many studies for paintings, some of which can be identified as preparatory to particular works such as The Adoration of the Magi, The Virgin of the Rocks and The Last Supper. His earliest dated drawing is a Landscape of the Arno Valley, 1473, which shows the river, the mountains, Montelupo Castle and the farmlands beyond it in great detail.Among his famous drawings are the Vitruvian Man, a study of the proportions of the human body; the Head of an Angel, for The Virgin of the Rocks in the Louvre; a botanical study of Star of Bethlehem; and a large drawing (160×100 cm) in black chalk on coloured paper of The Virgin and Child with Saint Anne and Saint John the Baptist in the National Gallery, London. This drawing employs the subtle sfumato technique of shading, in the manner of the Mona Lisa. It is thought that Leonardo never made a painting from it, the closest similarity being to The Virgin and Child with Saint Anne in the Louvre.\n",
      "Other drawings of interest include numerous studies generally referred to as \"caricatures\" because, although exaggerated, they appear to be based upon observation of live models. Vasari relates that Leonardo would look for interesting faces in public to use as models for some of his work. There are numerous studies of beautiful young men, often associated with Salaì, with the rare and much admired facial feature, the so-called \"Grecian profile\". These faces are often contrasted with that of a warrior. Salaì is often depicted in fancy-dress costume. Leonardo is known to have designed sets for pageants with which these may be associated. Other, often meticulous, drawings show studies of drapery. A marked development in Leonardo's ability to draw drapery occurred in his early works. Another often-reproduced drawing is a macabre sketch that was done by Leonardo in Florence in 1479 showing the body of Bernardo Baroncelli, hanged in connection with the murder of Giuliano, brother of Lorenzo de' Medici, in the Pazzi conspiracy. In his notes, Leonardo recorded the colours of the robes that Baroncelli was wearing when he died.\n",
      "Like the two contemporary architects Donato Bramante (who designed the Belvedere Courtyard) and Antonio da Sangallo the Elder, Leonardo experimented with designs for centrally planned churches, a number of which appear in his journals, as both plans and views, although none was ever realised.\n",
      "\n",
      "Journals and notes\n",
      "Renaissance humanism recognised no mutually exclusive polarities between the sciences and the arts, and Leonardo's studies in science and engineering are sometimes considered as impressive and innovative as his artistic work. These studies were recorded in 13,000 pages of notes and drawings, which fuse art and natural philosophy (the forerunner of modern science). They were made and maintained daily throughout Leonardo's life and travels, as he made continual observations of the world around him. Leonardo's notes and drawings display an enormous range of interests and preoccupations, some as mundane as lists of groceries and people who owed him money and some as intriguing as designs for wings and shoes for walking on water. There are compositions for paintings, studies of details and drapery, studies of faces and emotions, of animals, babies, dissections, plant studies, rock formations, whirlpools, war machines, flying machines and architecture.\n",
      "These notebooks –  originally loose papers of different types and sizes –  were largely entrusted to Leonardo's pupil and heir Francesco Melzi after the master's death. These were to be published, a task of overwhelming difficulty because of its scope and Leonardo's idiosyncratic writing. Some of Leonardo's drawings were copied by an anonymous Milanese artist for a planned treatise on art c. 1570. After Melzi's death in 1570, the collection passed to his son, the lawyer Orazio, who initially took little interest in the journals. In 1587, a Melzi household tutor named Lelio Gavardi took 13 of the manuscripts to Pisa; there, the architect Giovanni Magenta reproached Gavardi for having taken the manuscripts illicitly and returned them to Orazio. Having many more such works in his possession, Orazio gifted the volumes to Magenta. News spread of these lost works of Leonardo's, and Orazio retrieved seven of the 13 manuscripts, which he then gave to Pompeo Leoni for publication in two volumes; one of these was the Codex Atlanticus. The other six works had been distributed to a few others. After Orazio's death, his heirs sold the rest of Leonardo's possessions, and thus began their dispersal.Some works have found their way into major collections such as the Royal Library at Windsor Castle, the Louvre, the Biblioteca Nacional de España, the Victoria and Albert Museum, the Biblioteca Ambrosiana in Milan, which holds the 12-volume Codex Atlanticus, and the British Library in London, which has put a selection from the Codex Arundel (BL Arundel MS 263) online. Works have also been at Holkham Hall, the Metropolitan Museum of Art, and in the private hands of John Nicholas Brown I and Robert Lehman. The Codex Leicester is the only privately owned major scientific work of Leonardo; it is owned by Bill Gates and displayed once a year in different cities around the world.\n",
      "\n",
      "Most of Leonardo's writings are in mirror-image cursive. Since Leonardo wrote with his left hand, it was probably easier for him to write from right to left. Leonardo used a variety of shorthand and symbols, and states in his notes that he intended to prepare them for publication. In many cases a single topic is covered in detail in both words and pictures on a single sheet, together conveying information that would not be lost if the pages were published out of order. Why they were not published during Leonardo's lifetime is unknown.\n",
      "\n",
      "Science and inventions\n",
      "Leonardo's approach to science was observational: he tried to understand a phenomenon by describing and depicting it in utmost detail and did not emphasise experiments or theoretical explanation. Since he lacked formal education in Latin and mathematics, contemporary scholars mostly ignored Leonardo the scientist, although he did teach himself Latin. His keen observations in many areas were noted, such as when he wrote \"Il sole non si move.\" (\"The Sun does not move.\")In the 1490s he studied mathematics under Luca Pacioli and prepared a series of drawings of regular solids in a skeletal form to be engraved as plates for Pacioli's book Divina proportione, published in 1509. While living in Milan, he studied light from the summit of Monte Rosa. Scientific writings in his notebook on fossils have been considered as influential on early palaeontology.The content of his journals suggest that he was planning a series of treatises on a variety of subjects. A coherent treatise on anatomy is said to have been observed during a visit by Cardinal Louis d'Aragon's secretary in 1517. Aspects of his work on the studies of anatomy, light and the landscape were assembled for publication by Melzi and eventually published as A Treatise on Painting in France and Italy in 1651 and Germany in 1724, with engravings based upon drawings by the Classical painter Nicolas Poussin. According to Arasse, the treatise, which in France went into 62 editions in fifty years, caused Leonardo to be seen as \"the precursor of French academic thought on art.\"While Leonardo's experimentation followed scientific methods, a recent and exhaustive analysis of Leonardo as a scientist by Fritjof Capra argues that Leonardo was a fundamentally different kind of scientist from Galileo, Newton and other scientists who followed him in that, as a \"Renaissance Man\", his theorising and hypothesising integrated the arts and particularly painting.\n",
      "\n",
      "Anatomy and physiology\n",
      "Leonardo started his study in the anatomy of the human body under the apprenticeship of Verrocchio, who demanded that his students develop a deep knowledge of the subject. As an artist, he quickly became master of topographic anatomy, drawing many studies of muscles, tendons and other visible anatomical features.As a successful artist, Leonardo was given permission to dissect human corpses at the Hospital of Santa Maria Nuova in Florence and later at hospitals in Milan and Rome. From 1510 to 1511 he collaborated in his studies with the doctor Marcantonio della Torre, professor of Anatomy at the University of Pavia. Leonardo made over 240 detailed drawings and wrote about 13,000 words toward a treatise on anatomy. Only a small amount of the material on anatomy was published in Leonardo's Treatise on painting. During the time that Melzi was ordering the material into chapters for publication, they were examined by a number of anatomists and artists, including Vasari, Cellini and Albrecht Dürer, who made a number of drawings from them.Leonardo's anatomical drawings include many studies of the human skeleton and its parts, and of muscles and sinews. He studied the mechanical functions of the skeleton and the muscular forces that are applied to it in a manner that prefigured the modern science of biomechanics. He drew the heart and vascular system, the sex organs and other internal organs, making one of the first scientific drawings of a fetus in utero. The drawings and notation are far ahead of their time, and if published would undoubtedly have made a major contribution to medical science.Leonardo also closely observed and recorded the effects of age and of human emotion on the physiology, studying in particular the effects of rage. He drew many figures who had significant facial deformities or signs of illness. Leonardo also studied and drew the anatomy of many animals, dissecting cows, birds, monkeys, bears, and frogs, and comparing in his drawings their anatomical structure with that of humans. He also made a number of studies of horses.Leonardo's dissections and documentation of muscles, nerves, and vessels helped to describe the physiology and mechanics of movement. He attempted to identify the source of 'emotions' and their expression. He found it difficult to incorporate the prevailing system and theories of bodily humours, but eventually he abandoned these physiological explanations of bodily functions. He made the observations that humours were not located in cerebral spaces or ventricles. He documented that the humours were not contained in the heart or the liver, and that it was the heart that defined the circulatory system. He was the first to define atherosclerosis and liver cirrhosis. He created models of the cerebral ventricles with the use of melted wax and constructed a glass aorta to observe the circulation of blood through the aortic valve by using water and grass seed to watch flow patterns.\n",
      "\n",
      "Engineering and inventions\n",
      "During his lifetime, Leonardo was also valued as an engineer. With the same rational and analytical approach that moved him to represent the human body and to investigate anatomy, Leonardo studied and designed many machines and devices. He drew their \"anatomy\" with unparalleled mastery, producing the first form of the modern technical drawing, including a perfected \"exploded view\" technique, to represent internal components. Those studies and projects collected in his codices fill more than 5,000 pages. In a letter of 1482 to the lord of Milan Ludovico il Moro, he wrote that he could create all sorts of machines both for the protection of a city and for siege. When he fled from Milan to Venice in 1499, he found employment as an engineer and devised a system of moveable barricades to protect the city from attack. In 1502, he created a scheme for diverting the flow of the Arno river, a project on which Niccolò Machiavelli also worked. He continued to contemplate the canalization of Lombardy's plains while in Louis XII's company and of the Loire and its tributaries in the company of Francis I. Leonardo's journals include a vast number of inventions, both practical and impractical. They include musical instruments, a mechanical knight, hydraulic pumps, reversible crank mechanisms, finned mortar shells, and a steam cannon.\n",
      "Leonardo was fascinated by the phenomenon of flight for much of his life, producing many studies, including Codex on the Flight of Birds (c. 1505), as well as plans for several flying machines, such as a flapping ornithopter and a machine with a helical rotor. In a 2003 documentary by British television station Channel Four, titled Leonardo's Dream Machines, various designs by Leonardo, such as a parachute and a giant crossbow, were interpreted and constructed. Some of those designs proved successful, whilst others fared less well when tested. Similarly, a team of engineers built ten machines designed by Leonardo in the 2009 American television series Doing DaVinci, including a fighting vehicle and a self-propelled cart.\n",
      "Research performed by Marc van den Broek revealed older prototypes for more than 100 inventions that are ascribed to Leonardo. Similarities between Leonardo's illustrations and drawings from the Middle Ages and from Ancient Greece and Rome, the Chinese and Persian Empires, and Egypt suggest that a large portion of Leonardo's inventions had been conceived before his lifetime. Leonardo's innovation was to combine different functions from existing drafts and set them into scenes that illustrated their utility. By reconstituting technical inventions he created something new.In his notebooks, Leonardo first stated the 'laws' of sliding friction in 1493. His inspiration for investigating friction came about in part from his study of perpetual motion, which he correctly concluded was not possible. His results were never published and the friction laws were not rediscovered until 1699 by Guillaume Amontons, with whose name they are now usually associated. For this contribution, Leonardo was named as the first of the 23 \"Men of Tribology\" by Duncan Dowson.\n",
      "\n",
      "Legacy\n",
      "Although he had no formal academic training, many historians and scholars regard Leonardo as the prime exemplar of the \"Universal Genius\" or \"Renaissance Man\", an individual of \"unquenchable curiosity\" and \"feverishly inventive imagination.\" He is widely considered one of the most diversely talented individuals ever to have lived. According to art historian Helen Gardner, the scope and depth of his interests were without precedent in recorded history, and \"his mind and personality seem to us superhuman, while the man himself mysterious and remote.\" Scholars interpret his view of the world as being based in logic, though the empirical methods he used were unorthodox for his time.Leonardo's fame within his own lifetime was such that the King of France carried him away like a trophy, and was claimed to have supported him in his old age and held him in his arms as he died. Interest in Leonardo and his work has never diminished. Crowds still queue to see his best-known artworks, T-shirts still bear his most famous drawing, and writers continue to hail him as a genius while speculating about his private life, as well as about what one so intelligent actually believed in.The continued admiration that Leonardo commanded from painters, critics and historians is reflected in many other written tributes. Baldassare Castiglione, author of Il Cortegiano (The Courtier), wrote in 1528: \"...Another of the greatest painters in this world looks down on this art in which he is unequalled...\" while the biographer known as \"Anonimo Gaddiano\" wrote, c. 1540: \"His genius was so rare and universal that it can be said that nature worked a miracle on his behalf...\" Vasari, in his Lives of the Artists (1568), opens his chapter on Leonardo:\n",
      "In the normal course of events many men and women are born with remarkable talents; but occasionally, in a way that transcends nature, a single person is marvellously endowed by Heaven with beauty, grace and talent in such abundance that he leaves other men far behind, all his actions seem inspired and indeed everything he does clearly comes from God rather than from human skill. Everyone acknowledged that this was true of Leonardo da Vinci, an artist of outstanding physical beauty, who displayed infinite grace in everything that he did and who cultivated his genius so brilliantly that all problems he studied he solved with ease.\n",
      "The 19th century brought a particular admiration for Leonardo's genius, causing Henry Fuseli to write in 1801: \"Such was the dawn of modern art, when Leonardo da Vinci broke forth with a splendour that distanced former excellence: made up of all the elements that constitute the essence of genius...\" This is echoed by A.E. Rio who wrote in 1861: \"He towered above all other artists through the strength and the nobility of his talents.\"By the 19th century, the scope of Leonardo's notebooks was known, as well as his paintings. Hippolyte Taine wrote in 1866: \"There may not be in the world an example of another genius so universal, so incapable of fulfilment, so full of yearning for the infinite, so naturally refined, so far ahead of his own century and the following centuries.\"\n",
      "Art historian Bernard Berenson wrote in 1896: Leonardo is the one artist of whom it may be said with perfect literalness: Nothing that he touched but turned into a thing of eternal beauty. Whether it be the cross section of a skull, the structure of a weed, or a study of muscles, he, with his feeling for line and for light and shade, forever transmuted it into life-communicating values.\n",
      "The interest in Leonardo's genius has continued unabated; experts study and translate his writings, analyse his paintings using scientific techniques, argue over attributions and search for works which have been recorded but never found. Liana Bortolon, writing in 1967, said: Because of the multiplicity of interests that spurred him to pursue every field of knowledge...Leonardo can be considered, quite rightly, to have been the universal genius par excellence, and with all the disquieting overtones inherent in that term. Man is as uncomfortable today, faced with a genius, as he was in the 16th century. Five centuries have passed, yet we still view Leonardo with awe. The Elmer Belt Library of Vinciana is a special collection at the University of California, Los Angeles.Twenty-first-century author Walter Isaacson based much of his biography of Leonardo on thousands of notebook entries, studying the personal notes, sketches, budget notations, and musings of the man whom he considers the greatest of innovators. Isaacson was surprised to discover a \"fun, joyous\" side of Leonardo in addition to his limitless curiosity and creative genius.On the 500th anniversary of Leonardo's death, the Louvre in Paris arranged for the largest ever single exhibit of his work, called Leonardo, between November 2019 and February 2020. The exhibit includes over 100 paintings, drawings and notebooks. Eleven of the paintings that Leonardo completed in his lifetime were included. Five of these are owned by the Louvre, but the Mona Lisa was not included because it is in such great demand among general visitors to the Louvre; it remains on display in its gallery. Vitruvian Man, however, is on display following a legal battle with its owner, the Gallerie dell'Accademia in Venice. Salvator Mundi was also not included because its Saudi owner did not agree to lease the work.The Mona Lisa, considered Leonardo's magnum opus, is often regarded as the most famous portrait ever made. The Last Supper is the most reproduced religious painting of all time, and Leonardo's Vitruvian Man drawing is also considered a cultural icon.More than a decade of analysis of Leonardo's genetic genealogy, conducted by Alessandro Vezzosi and Agnese Sabato, came to a conclusion in mid-2021. It was determined that the artist has 14 living male relatives. The work could also help determine the authenticity of remains thought to belong to Leonardo.\n",
      "\n",
      "Location of remains\n",
      "While Leonardo was certainly buried in the collegiate church of Saint Florentin at the Château d'Amboise in 12 August 1519, the current location of his remains is unclear. Much of Château d'Amboise was damaged during the French Revolution, leading to the church's demolition in 1802. Some of the graves were destroyed in the process, scattering the bones interred there and thereby leaving the whereabouts of Leonardo's remains subject to dispute; a gardener may have even buried some in the corner of the courtyard.In 1863, fine-arts inspector general Arsène Houssaye received an imperial commission to excavate the site and discovered a partially complete skeleton with a bronze ring on one finger, white hair, and stone fragments bearing the inscriptions \"EO\", \"AR\", \"DUS\", and \"VINC\" –  interpreted as forming \"Leonardus Vinci\". The skull's eight teeth corresponds to someone with approximately the same age and a silver shield found near the bones depicts a beardless Francis I, corresponding to the king's appearance during Leonardo's time in France.Houssaye postulated that the unusually large skull was an indicator of Leonardo's intelligence; author Charles Nicholl describes this as a \"dubious phrenological deduction\". At the same time, Houssaye noted some issues with his observations, including that the feet were turned toward the high altar, a practice generally reserved for laymen, and that the skeleton of 1.73 metres (5.7 ft) seemed too short. Art historian Mary Margaret Heaton wrote in 1874 that the height would be appropriate for Leonardo. The skull was allegedly presented to Napoleon III before being returned to the Château d'Amboise, where they were re-interred in the chapel of Saint Hubert in 1874. A plaque above the tomb states that its contents are only presumed to be those of Leonardo.It has since been theorized that the folding of the skeleton's right arm over the head may correspond to the paralysis of Leonardo's right hand. In 2016, it was announced that DNA tests would be conducted to determine whether the attribution is correct. The DNA of the remains will be compared to that of samples collected from Leonardo's work and his half-brother Domenico's descendants; it may also be sequenced.In 2019, documents were published revealing that Houssaye had kept the ring and a lock of hair. In 1925, his great-grandson sold these to an American collector. Sixty years later, another American acquired them, leading to their being displayed at the Leonardo Museum in Vinci beginning on 2 May 2019, the 500th anniversary of the artist's death.\n",
      "\n",
      "Notes\n",
      "General\n",
      "\n",
      "Dates of works\n",
      "\n",
      "References\n",
      "Citations\n",
      "Early\n",
      "\n",
      "Modern\n",
      "\n",
      "Works cited\n",
      "Early\n",
      "Modern\n",
      "Books\n",
      "\n",
      "Journals and encyclopedia articles\n",
      "\n",
      "Further reading\n",
      "See Kemp (2003) and Bambach (2019, pp. 442–579) for extensive bibliographies\n",
      "\n",
      "External links\n",
      "General\n",
      "\n",
      "Universal Leonardo, a database of Leonardo's life and works maintained by Martin Kemp and Marina Wallace\n",
      "Leonardo da Vinci on the National Gallery websiteWorks\n",
      "\n",
      "Biblioteca Leonardiana, online bibliography (in Italian)\n",
      "e-Leo: Archivio digitale di storia della tecnica e della scienza, archive of drawings, notes and manuscripts\n",
      "Works by Leonardo da Vinci at Project Gutenberg\n",
      "Works by Leonardo da Vinci at LibriVox (public domain audiobooks) \n",
      "Complete text and images of Richter's translation of the Notebooks\n",
      "The Notebooks of Leonardo da VinciQuantum mechanics is a fundamental theory in physics that describes the behavior of nature at and below the scale of atoms.: 1.1  It is the foundation of all quantum physics including quantum chemistry, quantum field theory, quantum technology, and quantum information science.\n",
      "Classical physics, the collection of theories that existed before the advent of quantum mechanics, describes many aspects of nature at an ordinary (macroscopic) scale, but is not sufficient for describing them at small (atomic and subatomic) scales. Most theories in classical physics can be derived from quantum mechanics as an approximation valid at large (macroscopic) scale.Unlike classical systems, quantum systems have bound states quantized to discrete values of energy, momentum, angular momentum, and other quantities; measurements of systems show characteristics of both particles and waves (wave–particle duality); and there are limits to how accurately the value of a physical quantity can be predicted prior to its measurement, given a complete set of initial conditions (the uncertainty principle).\n",
      "Quantum mechanics arose gradually from theories to explain observations that could not be reconciled with classical physics, such as Max Planck's solution in 1900 to the black-body radiation problem, and the correspondence between energy and frequency in Albert Einstein's 1905 paper, which explained the photoelectric effect. These early attempts to understand microscopic phenomena, now known as the \"old quantum theory\", led to the full development of quantum mechanics in the mid-1920s by Niels Bohr, Erwin Schrödinger, Werner Heisenberg, Max Born, Paul Dirac and others. The modern theory is formulated in various specially developed mathematical formalisms. In one of them, a mathematical entity called the wave function provides information, in the form of probability amplitudes, about what measurements of a particle's energy, momentum, and other physical properties may yield.\n",
      "\n",
      "Overview and fundamental concepts\n",
      "Quantum mechanics allows the calculation of properties and behaviour of physical systems. It is typically applied to microscopic systems: molecules, atoms and sub-atomic particles. It has been demonstrated to hold for complex molecules with thousands of atoms, but its application to human beings raises philosophical problems, such as Wigner's friend, and its application to the universe as a whole remains speculative. Predictions of quantum mechanics have been verified experimentally to an extremely high degree of accuracy. For example, the refinement of quantum mechanics for the interaction of light and matter, known as quantum electrodynamics (QED), has been  shown to agree with experiment to within 1 part in 108 for some atomic properties.\n",
      "A fundamental feature of the theory is that it usually cannot predict with certainty what will happen, but only give probabilities. Mathematically, a probability is found by taking the square of the absolute value of a complex number, known as a probability amplitude. This is known as the Born rule, named after physicist Max Born. For example, a quantum particle like an electron can be described by a wave function, which associates to each point in space a probability amplitude. Applying the Born rule to these amplitudes gives a probability density function for the position that the electron will be found to have when an experiment is performed to measure it. This is the best the theory can do; it cannot say for certain where the electron will be found. The Schrödinger equation relates the collection of probability amplitudes that pertain to one moment of time to the collection of probability amplitudes that pertain to another.\n",
      "One consequence of the mathematical rules of quantum mechanics is a tradeoff in predictability between different measurable quantities. The most famous form of this uncertainty principle says that no matter how a quantum particle is prepared or how carefully experiments upon it are arranged, it is impossible to have a precise prediction for a measurement of its position and also at the same time for a measurement of its momentum.\n",
      "Another consequence of the mathematical rules of quantum mechanics is the phenomenon of quantum interference, which is often illustrated with the double-slit experiment. In the basic version of this experiment, a coherent light source, such as a laser beam, illuminates a plate pierced by two parallel slits, and the light passing through the slits is observed on a screen behind the plate.: 102–111 : 1.1–1.8  The wave nature of light causes the light waves passing through the two slits to interfere, producing bright and dark bands on the screen – a result that would not be expected if light consisted of classical particles. However, the light is always found to be absorbed at the screen at discrete points, as individual particles rather than waves; the interference pattern appears via the varying density of these particle hits on the screen. Furthermore, versions of the experiment that include detectors at the slits find that each detected photon passes through one slit (as would a classical particle), and not through both slits (as would a wave).: 109  However, such experiments demonstrate that particles do not form the interference pattern if one detects which slit they pass through.  This behavior is known as wave–particle duality. In addition to light, electrons, atoms, and molecules are all found to exhibit the same dual behavior when fired towards a double slit.Another non-classical phenomenon predicted by quantum mechanics is quantum tunnelling: a particle that goes up against a potential barrier can cross it, even if its kinetic energy is smaller than the maximum of the potential. In classical mechanics this particle would be trapped. Quantum tunnelling has several important consequences, enabling radioactive decay, nuclear fusion in stars, and applications such as scanning tunnelling microscopy and the tunnel diode.When quantum systems interact, the result can be the creation of quantum entanglement: their properties become so intertwined that a description of the whole solely in terms of the individual parts is no longer possible. Erwin Schrödinger called entanglement \"...the characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought\". Quantum entanglement enables quantum computing and is part of quantum communication protocols, such as quantum key distribution and superdense coding. Contrary to popular misconception, entanglement does not allow sending signals faster than light, as demonstrated by the no-communication theorem.Another possibility opened by entanglement is testing for \"hidden variables\", hypothetical properties more fundamental than the quantities addressed in quantum theory itself, knowledge of which would allow more exact predictions than quantum theory can provide. A collection of results, most significantly Bell's theorem, have demonstrated that broad classes of such hidden-variable theories are in fact incompatible with quantum physics. According to Bell's theorem, if nature actually operates in accord with any theory of local hidden variables, then the results of a Bell test will be constrained in a particular, quantifiable way. Many Bell tests have been performed and they have shown results incompatible with the constraints imposed by local hidden variables.It is not possible to present these concepts in more than a superficial way without introducing the actual mathematics involved; understanding quantum mechanics requires not only manipulating complex numbers, but also linear algebra, differential equations, group theory, and other more advanced subjects. Accordingly, this article will present a mathematical formulation of quantum mechanics and survey its application to some useful and oft-studied examples.\n",
      "\n",
      "Mathematical formulation\n",
      "In the mathematically rigorous formulation of quantum mechanics, the state of a quantum mechanical system is a vector \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi }\n",
      "   belonging to a (separable) complex Hilbert space \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            H\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\mathcal {H}}}\n",
      "  . This vector is postulated to be normalized under the Hilbert space inner product, that is, it obeys \n",
      "  \n",
      "    \n",
      "      \n",
      "        ⟨\n",
      "        ψ\n",
      "        ,\n",
      "        ψ\n",
      "        ⟩\n",
      "        =\n",
      "        1\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\langle \\psi ,\\psi \\rangle =1}\n",
      "  , and it is well-defined up to a complex number of modulus 1 (the global phase), that is, \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi }\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          e\n",
      "          \n",
      "            i\n",
      "            α\n",
      "          \n",
      "        \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle e^{i\\alpha }\\psi }\n",
      "   represent the same physical system. In other words, the possible states are points in the projective space of a Hilbert space, usually called the complex projective space. The exact nature of this Hilbert space is dependent on the system – for example, for describing position and momentum the Hilbert space is the space of complex square-integrable functions \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          L\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        (\n",
      "        \n",
      "          C\n",
      "        \n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle L^{2}(\\mathbb {C} )}\n",
      "  , while the Hilbert space for the spin of a single proton is simply the space of two-dimensional complex vectors \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            C\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\mathbb {C} ^{2}}\n",
      "   with the usual inner product.\n",
      "Physical quantities of interest – position, momentum, energy, spin – are represented by observables, which are Hermitian (more precisely, self-adjoint) linear operators acting on the Hilbert space. A quantum state can be an eigenvector of an observable, in which case it is called an eigenstate, and the associated eigenvalue corresponds to the value of the observable in that eigenstate. More generally, a quantum state will be a linear combination of the eigenstates, known as a quantum superposition. When an observable is measured, the result will be one of its eigenvalues with probability given by the Born rule: in the simplest case the eigenvalue \n",
      "  \n",
      "    \n",
      "      \n",
      "        λ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\lambda }\n",
      "   is non-degenerate and the probability is given by \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          |\n",
      "        \n",
      "        ⟨\n",
      "        \n",
      "          \n",
      "            \n",
      "              λ\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "        ,\n",
      "        ψ\n",
      "        ⟩\n",
      "        \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle |\\langle {\\vec {\\lambda }},\\psi \\rangle |^{2}}\n",
      "  , where \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              λ\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\vec {\\lambda }}}\n",
      "   is its associated eigenvector. More generally, the eigenvalue is degenerate and the probability is given by \n",
      "  \n",
      "    \n",
      "      \n",
      "        ⟨\n",
      "        ψ\n",
      "        ,\n",
      "        \n",
      "          P\n",
      "          \n",
      "            λ\n",
      "          \n",
      "        \n",
      "        ψ\n",
      "        ⟩\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\langle \\psi ,P_{\\lambda }\\psi \\rangle }\n",
      "  , where \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          P\n",
      "          \n",
      "            λ\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle P_{\\lambda }}\n",
      "   is the projector onto its associated eigenspace. In the continuous case, these formulas give instead the probability density.\n",
      "After the measurement, if result \n",
      "  \n",
      "    \n",
      "      \n",
      "        λ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\lambda }\n",
      "   was obtained, the quantum state is postulated to collapse to \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              λ\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\vec {\\lambda }}}\n",
      "  , in the non-degenerate case, or to \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          P\n",
      "          \n",
      "            λ\n",
      "          \n",
      "        \n",
      "        ψ\n",
      "        \n",
      "          \n",
      "            /\n",
      "          \n",
      "        \n",
      "        \n",
      "        \n",
      "          \n",
      "            ⟨\n",
      "            ψ\n",
      "            ,\n",
      "            \n",
      "              P\n",
      "              \n",
      "                λ\n",
      "              \n",
      "            \n",
      "            ψ\n",
      "            ⟩\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\textstyle P_{\\lambda }\\psi {\\big /}\\!{\\sqrt {\\langle \\psi ,P_{\\lambda }\\psi \\rangle }}}\n",
      "  , in the general case. The probabilistic nature of quantum mechanics thus stems from the act of measurement. This is one of the most difficult aspects of quantum systems to understand. It was the central topic in the famous Bohr–Einstein debates, in which the two scientists attempted to clarify these fundamental principles by way of thought experiments. In the decades after the formulation of quantum mechanics, the question of what constitutes a \"measurement\" has been extensively studied. Newer interpretations of quantum mechanics have been formulated that do away with the concept of \"wave function collapse\" (see, for example, the many-worlds interpretation). The basic idea is that when a quantum system interacts with a measuring apparatus, their respective wave functions become entangled so that the original quantum system ceases to exist as an independent entity. For details, see the article on measurement in quantum mechanics.The time evolution of a quantum state is described by the Schrödinger equation:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        i\n",
      "        ℏ\n",
      "        \n",
      "          \n",
      "            d\n",
      "            \n",
      "              d\n",
      "              t\n",
      "            \n",
      "          \n",
      "        \n",
      "        ψ\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "        =\n",
      "        H\n",
      "        ψ\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle i\\hbar {\\frac {d}{dt}}\\psi (t)=H\\psi (t).}\n",
      "  Here \n",
      "  \n",
      "    \n",
      "      \n",
      "        H\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H}\n",
      "   denotes the Hamiltonian, the observable corresponding to the total energy of the system, and \n",
      "  \n",
      "    \n",
      "      \n",
      "        ℏ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\hbar }\n",
      "   is the reduced Planck constant. The constant \n",
      "  \n",
      "    \n",
      "      \n",
      "        i\n",
      "        ℏ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle i\\hbar }\n",
      "   is introduced so that the Hamiltonian is reduced to the classical Hamiltonian in cases where the quantum system can be approximated by a classical system; the ability to make such an approximation in certain limits is called the correspondence principle.\n",
      "The solution of this differential equation is given by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            i\n",
      "            H\n",
      "            t\n",
      "            \n",
      "              /\n",
      "            \n",
      "            ℏ\n",
      "          \n",
      "        \n",
      "        ψ\n",
      "        (\n",
      "        0\n",
      "        )\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (t)=e^{-iHt/\\hbar }\\psi (0).}\n",
      "  The operator \n",
      "  \n",
      "    \n",
      "      \n",
      "        U\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            i\n",
      "            H\n",
      "            t\n",
      "            \n",
      "              /\n",
      "            \n",
      "            ℏ\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle U(t)=e^{-iHt/\\hbar }}\n",
      "   is known as the time-evolution operator, and has the crucial property that it is unitary. This time evolution is deterministic in the sense that – given an initial quantum state \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        0\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (0)}\n",
      "    – it makes a definite prediction of what the quantum state \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (t)}\n",
      "   will be at any later time.\n",
      "Some wave functions produce probability distributions that are independent of time, such as eigenstates of the Hamiltonian. Many systems that are treated dynamically in classical mechanics are described by such \"static\" wave functions. For example, a single electron in an unexcited atom is pictured classically as a particle moving in a circular trajectory around the atomic nucleus, whereas in quantum mechanics, it is described by a static wave function surrounding the nucleus. For example, the electron wave function for an unexcited hydrogen atom is a spherically symmetric function known as an s orbital (Fig. 1).\n",
      "Analytic solutions of the Schrödinger equation are known for very few relatively simple model Hamiltonians including the quantum harmonic oscillator, the particle in a box, the dihydrogen cation, and the hydrogen atom. Even the helium atom – which contains just two electrons – has defied all attempts at a fully analytic treatment.\n",
      "However, there are techniques for finding approximate solutions. One method, called perturbation theory, uses the analytic result for a simple quantum mechanical model to create a result for a related but more complicated model by (for example) the addition of a weak potential energy. Another method is called \"semi-classical equation of motion\", which applies to systems for which quantum mechanics produces only small deviations from classical behavior. These deviations can then be computed based on the classical motion. This approach is particularly important in the field of quantum chaos.\n",
      "\n",
      "Uncertainty principle\n",
      "One consequence of the basic quantum formalism is the uncertainty principle. In its most familiar form, this states that no preparation of a quantum particle can imply simultaneously precise predictions both for a measurement of its position and for a measurement of its momentum. Both position and momentum are observables, meaning that they are represented by Hermitian operators. The position operator \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\hat {X}}}\n",
      "   and momentum operator \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              P\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\hat {P}}}\n",
      "   do not commute, but rather satisfy the canonical commutation relation:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        [\n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "        ,\n",
      "        \n",
      "          \n",
      "            \n",
      "              P\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "        ]\n",
      "        =\n",
      "        i\n",
      "        ℏ\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle [{\\hat {X}},{\\hat {P}}]=i\\hbar .}\n",
      "  Given a quantum state, the Born rule lets us compute expectation values for both \n",
      "  \n",
      "    \n",
      "      \n",
      "        X\n",
      "      \n",
      "    \n",
      "    {\\displaystyle X}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        P\n",
      "      \n",
      "    \n",
      "    {\\displaystyle P}\n",
      "  , and moreover for powers of them. Defining \n",
      "the uncertainty for an observable by a standard deviation, we have\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            X\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                \n",
      "                  ⟨\n",
      "                  \n",
      "                    X\n",
      "                    \n",
      "                      2\n",
      "                    \n",
      "                  \n",
      "                  ⟩\n",
      "                \n",
      "                −\n",
      "                \n",
      "                  \n",
      "                    ⟨\n",
      "                    X\n",
      "                    ⟩\n",
      "                  \n",
      "                  \n",
      "                    2\n",
      "                  \n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\sigma _{X}={\\textstyle {\\sqrt {\\left\\langle X^{2}\\right\\rangle -\\left\\langle X\\right\\rangle ^{2}}}},}\n",
      "  and likewise for the momentum:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            P\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              ⟨\n",
      "              \n",
      "                P\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              ⟩\n",
      "            \n",
      "            −\n",
      "            \n",
      "              \n",
      "                ⟨\n",
      "                P\n",
      "                ⟩\n",
      "              \n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\sigma _{P}={\\sqrt {\\left\\langle P^{2}\\right\\rangle -\\left\\langle P\\right\\rangle ^{2}}}.}\n",
      "  The uncertainty principle states that\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            X\n",
      "          \n",
      "        \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            P\n",
      "          \n",
      "        \n",
      "        ≥\n",
      "        \n",
      "          \n",
      "            ℏ\n",
      "            2\n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\sigma _{X}\\sigma _{P}\\geq {\\frac {\\hbar }{2}}.}\n",
      "  Either standard deviation can in principle be made arbitrarily small, but not both simultaneously. This inequality generalizes to arbitrary pairs of self-adjoint operators \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "  . The commutator of these two operators is\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        [\n",
      "        A\n",
      "        ,\n",
      "        B\n",
      "        ]\n",
      "        =\n",
      "        A\n",
      "        B\n",
      "        −\n",
      "        B\n",
      "        A\n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle [A,B]=AB-BA,}\n",
      "  and this provides the lower bound on the product of standard deviations:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "        \n",
      "          σ\n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "        ≥\n",
      "        \n",
      "          \n",
      "            \n",
      "              1\n",
      "              2\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          |\n",
      "          \n",
      "            \n",
      "              \n",
      "                ⟨\n",
      "              \n",
      "            \n",
      "            [\n",
      "            A\n",
      "            ,\n",
      "            B\n",
      "            ]\n",
      "            \n",
      "              \n",
      "                ⟩\n",
      "              \n",
      "            \n",
      "          \n",
      "          |\n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\sigma _{A}\\sigma _{B}\\geq {\\tfrac {1}{2}}\\left|{\\bigl \\langle }[A,B]{\\bigr \\rangle }\\right|.}\n",
      "  Another consequence of the canonical commutation relation is that the position and momentum operators are Fourier transforms of each other, so that a description of an object according to its momentum is the Fourier transform of its description according to its position. The fact that dependence in momentum is the Fourier transform of the dependence in position means that the momentum operator is equivalent (up to an \n",
      "  \n",
      "    \n",
      "      \n",
      "        i\n",
      "        \n",
      "          /\n",
      "        \n",
      "        ℏ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle i/\\hbar }\n",
      "   factor) to taking the derivative according to the position, since in Fourier analysis differentiation corresponds to multiplication in the dual space. This is why in quantum equations in position space, the momentum \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          p\n",
      "          \n",
      "            i\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle p_{i}}\n",
      "   is replaced by \n",
      "  \n",
      "    \n",
      "      \n",
      "        −\n",
      "        i\n",
      "        ℏ\n",
      "        \n",
      "          \n",
      "            ∂\n",
      "            \n",
      "              ∂\n",
      "              x\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle -i\\hbar {\\frac {\\partial }{\\partial x}}}\n",
      "  , and in particular in the non-relativistic Schrödinger equation in position space the momentum-squared term is replaced with a Laplacian times \n",
      "  \n",
      "    \n",
      "      \n",
      "        −\n",
      "        \n",
      "          ℏ\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle -\\hbar ^{2}}\n",
      "  .\n",
      "\n",
      "Composite systems and entanglement\n",
      "When two different quantum systems are considered together, the Hilbert space of the combined system is the tensor product of the Hilbert spaces of the two components. For example, let A and B be two quantum systems, with Hilbert spaces \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\mathcal {H}}_{A}}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\mathcal {H}}_{B}}\n",
      "  , respectively. The Hilbert space of the composite system is then\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            A\n",
      "            B\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "        ⊗\n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\mathcal {H}}_{AB}={\\mathcal {H}}_{A}\\otimes {\\mathcal {H}}_{B}.}\n",
      "  If the state for the first system is the vector \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{A}}\n",
      "   and the state for the second system is \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{B}}\n",
      "  , then the state of the composite system is\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "        ⊗\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{A}\\otimes \\psi _{B}.}\n",
      "  Not all states in the joint Hilbert space \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              H\n",
      "            \n",
      "          \n",
      "          \n",
      "            A\n",
      "            B\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\mathcal {H}}_{AB}}\n",
      "   can be written in this form, however, because the superposition principle implies that linear combinations of these \"separable\" or \"product states\" are also valid. For example, if \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{A}}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ϕ\n",
      "          \n",
      "            A\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\phi _{A}}\n",
      "   are both possible states for system \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "  , and likewise \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{B}}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ϕ\n",
      "          \n",
      "            B\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\phi _{B}}\n",
      "   are both possible states for system \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "  , then\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              1\n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          (\n",
      "          \n",
      "            \n",
      "              ψ\n",
      "              \n",
      "                A\n",
      "              \n",
      "            \n",
      "            ⊗\n",
      "            \n",
      "              ψ\n",
      "              \n",
      "                B\n",
      "              \n",
      "            \n",
      "            +\n",
      "            \n",
      "              ϕ\n",
      "              \n",
      "                A\n",
      "              \n",
      "            \n",
      "            ⊗\n",
      "            \n",
      "              ϕ\n",
      "              \n",
      "                B\n",
      "              \n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\tfrac {1}{\\sqrt {2}}}\\left(\\psi _{A}\\otimes \\psi _{B}+\\phi _{A}\\otimes \\phi _{B}\\right)}\n",
      "  is a valid joint state that is not separable. States that are not separable are called entangled.If the state for a composite system is entangled, it is impossible to describe either component system A or system B by a state vector. One can instead define reduced density matrices that describe the statistics that can be obtained by making measurements on either component system alone. This necessarily causes a loss of information, though: knowing the reduced density matrices of the individual systems is not enough to reconstruct the state of the composite system. Just as density matrices specify the state of a subsystem of a larger system, analogously, positive operator-valued measures (POVMs) describe the effect on a subsystem of a measurement performed on a larger system. POVMs are extensively used in quantum information theory.As described above, entanglement is a key feature of models of measurement processes in which an apparatus becomes entangled with the system being measured. Systems interacting with the environment in which they reside generally become entangled with that environment, a phenomenon known as quantum decoherence. This can explain why, in practice, quantum effects are difficult to observe in systems larger than microscopic.\n",
      "\n",
      "Equivalence between formulations\n",
      "There are many mathematically equivalent formulations of quantum mechanics. One of the oldest and most common is the \"transformation theory\" proposed by Paul Dirac, which unifies and generalizes the two earliest formulations of quantum mechanics – matrix mechanics (invented by Werner Heisenberg) and wave mechanics (invented by Erwin Schrödinger). An alternative formulation of quantum mechanics is Feynman's path integral formulation, in which a quantum-mechanical amplitude is considered as a sum over all possible classical and non-classical paths between the initial and final states. This is the quantum-mechanical counterpart of the action principle in classical mechanics.\n",
      "\n",
      "Symmetries and conservation laws\n",
      "The Hamiltonian \n",
      "  \n",
      "    \n",
      "      \n",
      "        H\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H}\n",
      "   is known as the generator of time evolution, since it defines a unitary time-evolution operator \n",
      "  \n",
      "    \n",
      "      \n",
      "        U\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            i\n",
      "            H\n",
      "            t\n",
      "            \n",
      "              /\n",
      "            \n",
      "            ℏ\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle U(t)=e^{-iHt/\\hbar }}\n",
      "   for each value of \n",
      "  \n",
      "    \n",
      "      \n",
      "        t\n",
      "      \n",
      "    \n",
      "    {\\displaystyle t}\n",
      "  . From this relation between \n",
      "  \n",
      "    \n",
      "      \n",
      "        U\n",
      "        (\n",
      "        t\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle U(t)}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        H\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H}\n",
      "  , it follows that any observable \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "   that commutes with \n",
      "  \n",
      "    \n",
      "      \n",
      "        H\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H}\n",
      "   will be conserved: its expectation value will not change over time. This statement generalizes, as mathematically, any Hermitian operator \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "   can generate a family of unitary operators parameterized by a variable \n",
      "  \n",
      "    \n",
      "      \n",
      "        t\n",
      "      \n",
      "    \n",
      "    {\\displaystyle t}\n",
      "  . Under the evolution generated by \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "  , any observable \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "   that commutes with \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "   will be conserved. Moreover, if \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "   is conserved by evolution under \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "  , then \n",
      "  \n",
      "    \n",
      "      \n",
      "        A\n",
      "      \n",
      "    \n",
      "    {\\displaystyle A}\n",
      "   is conserved under the evolution generated by \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "  . This implies a quantum version of the result proven by Emmy Noether in classical (Lagrangian) mechanics: for every differentiable symmetry of a Hamiltonian, there exists a corresponding conservation law.\n",
      "\n",
      "Examples\n",
      "Free particle\n",
      "The simplest example of a quantum system with a position degree of freedom is a free particle in a single spatial dimension. A free particle is one which is not subject to external influences, so that its Hamiltonian consists only of its kinetic energy:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        H\n",
      "        =\n",
      "        \n",
      "          \n",
      "            1\n",
      "            \n",
      "              2\n",
      "              m\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          P\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        =\n",
      "        −\n",
      "        \n",
      "          \n",
      "            \n",
      "              ℏ\n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "            \n",
      "              2\n",
      "              m\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              d\n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "            \n",
      "              d\n",
      "              \n",
      "                x\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H={\\frac {1}{2m}}P^{2}=-{\\frac {\\hbar ^{2}}{2m}}{\\frac {d^{2}}{dx^{2}}}.}\n",
      "  The general solution of the Schrödinger equation is given by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        x\n",
      "        ,\n",
      "        t\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          \n",
      "            1\n",
      "            \n",
      "              2\n",
      "              π\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          ∫\n",
      "          \n",
      "            −\n",
      "            ∞\n",
      "          \n",
      "          \n",
      "            ∞\n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              ψ\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "        (\n",
      "        k\n",
      "        ,\n",
      "        0\n",
      "        )\n",
      "        \n",
      "          e\n",
      "          \n",
      "            i\n",
      "            (\n",
      "            k\n",
      "            x\n",
      "            −\n",
      "            \n",
      "              \n",
      "                \n",
      "                  ℏ\n",
      "                  \n",
      "                    k\n",
      "                    \n",
      "                      2\n",
      "                    \n",
      "                  \n",
      "                \n",
      "                \n",
      "                  2\n",
      "                  m\n",
      "                \n",
      "              \n",
      "            \n",
      "            t\n",
      "            )\n",
      "          \n",
      "        \n",
      "        \n",
      "          d\n",
      "        \n",
      "        k\n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (x,t)={\\frac {1}{\\sqrt {2\\pi }}}\\int _{-\\infty }^{\\infty }{\\hat {\\psi }}(k,0)e^{i(kx-{\\frac {\\hbar k^{2}}{2m}}t)}\\mathrm {d} k,}\n",
      "  which is a superposition of all possible plane waves \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          e\n",
      "          \n",
      "            i\n",
      "            (\n",
      "            k\n",
      "            x\n",
      "            −\n",
      "            \n",
      "              \n",
      "                \n",
      "                  ℏ\n",
      "                  \n",
      "                    k\n",
      "                    \n",
      "                      2\n",
      "                    \n",
      "                  \n",
      "                \n",
      "                \n",
      "                  2\n",
      "                  m\n",
      "                \n",
      "              \n",
      "            \n",
      "            t\n",
      "            )\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle e^{i(kx-{\\frac {\\hbar k^{2}}{2m}}t)}}\n",
      "  , which are eigenstates of the momentum operator with momentum \n",
      "  \n",
      "    \n",
      "      \n",
      "        p\n",
      "        =\n",
      "        ℏ\n",
      "        k\n",
      "      \n",
      "    \n",
      "    {\\displaystyle p=\\hbar k}\n",
      "  . The coefficients of the superposition are \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              ψ\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "        (\n",
      "        k\n",
      "        ,\n",
      "        0\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\hat {\\psi }}(k,0)}\n",
      "  , which is the Fourier transform of the initial quantum state \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        x\n",
      "        ,\n",
      "        0\n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (x,0)}\n",
      "  .\n",
      "It is not possible for the solution to be a single momentum eigenstate, or a single position eigenstate, as these are not normalizable quantum states. Instead, we can consider a Gaussian wave packet:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        x\n",
      "        ,\n",
      "        0\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          \n",
      "            1\n",
      "            \n",
      "              \n",
      "                π\n",
      "                a\n",
      "              \n",
      "              \n",
      "                4\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            \n",
      "              \n",
      "                \n",
      "                  x\n",
      "                  \n",
      "                    2\n",
      "                  \n",
      "                \n",
      "                \n",
      "                  2\n",
      "                  a\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (x,0)={\\frac {1}{\\sqrt[{4}]{\\pi a}}}e^{-{\\frac {x^{2}}{2a}}}}\n",
      "  which has Fourier transform, and therefore momentum distribution\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              ψ\n",
      "              ^\n",
      "            \n",
      "          \n",
      "        \n",
      "        (\n",
      "        k\n",
      "        ,\n",
      "        0\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              a\n",
      "              π\n",
      "            \n",
      "            \n",
      "              4\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            \n",
      "              \n",
      "                \n",
      "                  a\n",
      "                  \n",
      "                    k\n",
      "                    \n",
      "                      2\n",
      "                    \n",
      "                  \n",
      "                \n",
      "                2\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\hat {\\psi }}(k,0)={\\sqrt[{4}]{\\frac {a}{\\pi }}}e^{-{\\frac {ak^{2}}{2}}}.}\n",
      "  We see that as we make \n",
      "  \n",
      "    \n",
      "      \n",
      "        a\n",
      "      \n",
      "    \n",
      "    {\\displaystyle a}\n",
      "   smaller the spread in position gets smaller, but the spread in momentum gets larger. Conversely, by making \n",
      "  \n",
      "    \n",
      "      \n",
      "        a\n",
      "      \n",
      "    \n",
      "    {\\displaystyle a}\n",
      "   larger we make the spread in momentum smaller, but the spread in position gets larger. This illustrates the uncertainty principle.\n",
      "As we let the Gaussian wave packet evolve in time, we see that its center moves through space at a constant velocity (like a classical particle with no forces acting on it). However, the wave packet will also spread out as time progresses, which means that the position becomes more and more uncertain. The uncertainty in momentum, however, stays constant.\n",
      "\n",
      "Particle in a box\n",
      "The particle in a one-dimensional potential energy box is the most mathematically simple example where restraints lead to the quantization of energy levels. The box is defined as having zero potential energy everywhere inside a certain region, and therefore infinite potential energy everywhere outside that region.: 77–78  For the one-dimensional case in the \n",
      "  \n",
      "    \n",
      "      \n",
      "        x\n",
      "      \n",
      "    \n",
      "    {\\displaystyle x}\n",
      "   direction, the time-independent Schrödinger equation may be written\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        −\n",
      "        \n",
      "          \n",
      "            \n",
      "              ℏ\n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "            \n",
      "              2\n",
      "              m\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                d\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              ψ\n",
      "            \n",
      "            \n",
      "              d\n",
      "              \n",
      "                x\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        =\n",
      "        E\n",
      "        ψ\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle -{\\frac {\\hbar ^{2}}{2m}}{\\frac {d^{2}\\psi }{dx^{2}}}=E\\psi .}\n",
      "  With the differential operator defined by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                p\n",
      "                ^\n",
      "              \n",
      "            \n",
      "          \n",
      "          \n",
      "            x\n",
      "          \n",
      "        \n",
      "        =\n",
      "        −\n",
      "        i\n",
      "        ℏ\n",
      "        \n",
      "          \n",
      "            d\n",
      "            \n",
      "              d\n",
      "              x\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\hat {p}}_{x}=-i\\hbar {\\frac {d}{dx}}}\n",
      "  the previous equation is evocative of the classic kinetic energy analogue,\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            1\n",
      "            \n",
      "              2\n",
      "              m\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                p\n",
      "                ^\n",
      "              \n",
      "            \n",
      "          \n",
      "          \n",
      "            x\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        =\n",
      "        E\n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\frac {1}{2m}}{\\hat {p}}_{x}^{2}=E,}\n",
      "  with state \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi }\n",
      "   in this case having energy \n",
      "  \n",
      "    \n",
      "      \n",
      "        E\n",
      "      \n",
      "    \n",
      "    {\\displaystyle E}\n",
      "   coincident with the kinetic energy of the particle.\n",
      "The general solutions of the Schrödinger equation for the particle in a box are\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "        =\n",
      "        A\n",
      "        \n",
      "          e\n",
      "          \n",
      "            i\n",
      "            k\n",
      "            x\n",
      "          \n",
      "        \n",
      "        +\n",
      "        B\n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            i\n",
      "            k\n",
      "            x\n",
      "          \n",
      "        \n",
      "        \n",
      "        \n",
      "        E\n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                ℏ\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              \n",
      "                k\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "            \n",
      "              2\n",
      "              m\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (x)=Ae^{ikx}+Be^{-ikx}\\qquad \\qquad E={\\frac {\\hbar ^{2}k^{2}}{2m}}}\n",
      "  or, from Euler's formula,\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "        =\n",
      "        C\n",
      "        sin\n",
      "        ⁡\n",
      "        (\n",
      "        k\n",
      "        x\n",
      "        )\n",
      "        +\n",
      "        D\n",
      "        cos\n",
      "        ⁡\n",
      "        (\n",
      "        k\n",
      "        x\n",
      "        )\n",
      "        .\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (x)=C\\sin(kx)+D\\cos(kx).\\!}\n",
      "  The infinite potential walls of the box determine the values of \n",
      "  \n",
      "    \n",
      "      \n",
      "        C\n",
      "        ,\n",
      "        D\n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle C,D,}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        k\n",
      "      \n",
      "    \n",
      "    {\\displaystyle k}\n",
      "   at \n",
      "  \n",
      "    \n",
      "      \n",
      "        x\n",
      "        =\n",
      "        0\n",
      "      \n",
      "    \n",
      "    {\\displaystyle x=0}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        x\n",
      "        =\n",
      "        L\n",
      "      \n",
      "    \n",
      "    {\\displaystyle x=L}\n",
      "   where \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi }\n",
      "   must be zero. Thus, at \n",
      "  \n",
      "    \n",
      "      \n",
      "        x\n",
      "        =\n",
      "        0\n",
      "      \n",
      "    \n",
      "    {\\displaystyle x=0}\n",
      "  ,\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        0\n",
      "        )\n",
      "        =\n",
      "        0\n",
      "        =\n",
      "        C\n",
      "        sin\n",
      "        ⁡\n",
      "        (\n",
      "        0\n",
      "        )\n",
      "        +\n",
      "        D\n",
      "        cos\n",
      "        ⁡\n",
      "        (\n",
      "        0\n",
      "        )\n",
      "        =\n",
      "        D\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (0)=0=C\\sin(0)+D\\cos(0)=D}\n",
      "  and \n",
      "  \n",
      "    \n",
      "      \n",
      "        D\n",
      "        =\n",
      "        0\n",
      "      \n",
      "    \n",
      "    {\\displaystyle D=0}\n",
      "  . At \n",
      "  \n",
      "    \n",
      "      \n",
      "        x\n",
      "        =\n",
      "        L\n",
      "      \n",
      "    \n",
      "    {\\displaystyle x=L}\n",
      "  ,\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        (\n",
      "        L\n",
      "        )\n",
      "        =\n",
      "        0\n",
      "        =\n",
      "        C\n",
      "        sin\n",
      "        ⁡\n",
      "        (\n",
      "        k\n",
      "        L\n",
      "        )\n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi (L)=0=C\\sin(kL),}\n",
      "  in which \n",
      "  \n",
      "    \n",
      "      \n",
      "        C\n",
      "      \n",
      "    \n",
      "    {\\displaystyle C}\n",
      "   cannot be zero as this would conflict with the postulate that \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi }\n",
      "   has norm 1. Therefore, since \n",
      "  \n",
      "    \n",
      "      \n",
      "        sin\n",
      "        ⁡\n",
      "        (\n",
      "        k\n",
      "        L\n",
      "        )\n",
      "        =\n",
      "        0\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\sin(kL)=0}\n",
      "  , \n",
      "  \n",
      "    \n",
      "      \n",
      "        k\n",
      "        L\n",
      "      \n",
      "    \n",
      "    {\\displaystyle kL}\n",
      "   must be an integer multiple of \n",
      "  \n",
      "    \n",
      "      \n",
      "        π\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\pi }\n",
      "  ,\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        k\n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              n\n",
      "              π\n",
      "            \n",
      "            L\n",
      "          \n",
      "        \n",
      "        \n",
      "        \n",
      "        n\n",
      "        =\n",
      "        1\n",
      "        ,\n",
      "        2\n",
      "        ,\n",
      "        3\n",
      "        ,\n",
      "        …\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle k={\\frac {n\\pi }{L}}\\qquad \\qquad n=1,2,3,\\ldots .}\n",
      "  This constraint on \n",
      "  \n",
      "    \n",
      "      \n",
      "        k\n",
      "      \n",
      "    \n",
      "    {\\displaystyle k}\n",
      "   implies a constraint on the energy levels, yielding\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          E\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                ℏ\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              \n",
      "                π\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              \n",
      "                n\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "            \n",
      "              2\n",
      "              m\n",
      "              \n",
      "                L\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                n\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "              \n",
      "                h\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "            \n",
      "              8\n",
      "              m\n",
      "              \n",
      "                L\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle E_{n}={\\frac {\\hbar ^{2}\\pi ^{2}n^{2}}{2mL^{2}}}={\\frac {n^{2}h^{2}}{8mL^{2}}}.}\n",
      "  \n",
      "A finite potential well is the generalization of the infinite potential well problem to potential wells having finite depth. The finite potential well problem is mathematically more complicated than the infinite particle-in-a-box problem as the wave function is not pinned to zero at the walls of the well. Instead, the wave function must satisfy more complicated mathematical boundary conditions as it is nonzero in regions outside the well. Another related problem is that of the rectangular potential barrier, which furnishes a model for the quantum tunneling effect that plays an important role in the performance of modern technologies such as flash memory and scanning tunneling microscopy.\n",
      "\n",
      "Harmonic oscillator\n",
      "As in the classical case, the potential for the quantum harmonic oscillator is given by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        V\n",
      "        (\n",
      "        x\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          \n",
      "            1\n",
      "            2\n",
      "          \n",
      "        \n",
      "        m\n",
      "        \n",
      "          ω\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        \n",
      "          x\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle V(x)={\\frac {1}{2}}m\\omega ^{2}x^{2}.}\n",
      "  This problem can either be treated by directly solving the Schrödinger equation, which is not trivial, or by using the more elegant \"ladder method\" first proposed by Paul Dirac. The eigenstates are given by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        (\n",
      "        x\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              1\n",
      "              \n",
      "                \n",
      "                  2\n",
      "                  \n",
      "                    n\n",
      "                  \n",
      "                \n",
      "                \n",
      "                n\n",
      "                !\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        ⋅\n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  m\n",
      "                  ω\n",
      "                \n",
      "                \n",
      "                  π\n",
      "                  ℏ\n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "          \n",
      "            1\n",
      "            \n",
      "              /\n",
      "            \n",
      "            4\n",
      "          \n",
      "        \n",
      "        ⋅\n",
      "        \n",
      "          e\n",
      "          \n",
      "            −\n",
      "            \n",
      "              \n",
      "                \n",
      "                  m\n",
      "                  ω\n",
      "                  \n",
      "                    x\n",
      "                    \n",
      "                      2\n",
      "                    \n",
      "                  \n",
      "                \n",
      "                \n",
      "                  2\n",
      "                  ℏ\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        ⋅\n",
      "        \n",
      "          H\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        \n",
      "          (\n",
      "          \n",
      "            \n",
      "              \n",
      "                \n",
      "                  \n",
      "                    m\n",
      "                    ω\n",
      "                  \n",
      "                  ℏ\n",
      "                \n",
      "              \n",
      "            \n",
      "            x\n",
      "          \n",
      "          )\n",
      "        \n",
      "        ,\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{n}(x)={\\sqrt {\\frac {1}{2^{n}\\,n!}}}\\cdot \\left({\\frac {m\\omega }{\\pi \\hbar }}\\right)^{1/4}\\cdot e^{-{\\frac {m\\omega x^{2}}{2\\hbar }}}\\cdot H_{n}\\left({\\sqrt {\\frac {m\\omega }{\\hbar }}}x\\right),\\qquad }\n",
      "  \n",
      "  \n",
      "    \n",
      "      \n",
      "        n\n",
      "        =\n",
      "        0\n",
      "        ,\n",
      "        1\n",
      "        ,\n",
      "        2\n",
      "        ,\n",
      "        …\n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle n=0,1,2,\\ldots .}\n",
      "  where Hn are the Hermite polynomials\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          H\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        (\n",
      "        x\n",
      "        )\n",
      "        =\n",
      "        (\n",
      "        −\n",
      "        1\n",
      "        \n",
      "          )\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        \n",
      "          e\n",
      "          \n",
      "            \n",
      "              x\n",
      "              \n",
      "                2\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              d\n",
      "              \n",
      "                n\n",
      "              \n",
      "            \n",
      "            \n",
      "              d\n",
      "              \n",
      "                x\n",
      "                \n",
      "                  n\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          (\n",
      "          \n",
      "            e\n",
      "            \n",
      "              −\n",
      "              \n",
      "                x\n",
      "                \n",
      "                  2\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle H_{n}(x)=(-1)^{n}e^{x^{2}}{\\frac {d^{n}}{dx^{n}}}\\left(e^{-x^{2}}\\right),}\n",
      "  and the corresponding energy levels are\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          E\n",
      "          \n",
      "            n\n",
      "          \n",
      "        \n",
      "        =\n",
      "        ℏ\n",
      "        ω\n",
      "        \n",
      "          (\n",
      "          \n",
      "            n\n",
      "            +\n",
      "            \n",
      "              \n",
      "                1\n",
      "                2\n",
      "              \n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle E_{n}=\\hbar \\omega \\left(n+{1 \\over 2}\\right).}\n",
      "  This is another example illustrating the discretization of energy for bound states.\n",
      "\n",
      "Mach–Zehnder interferometer\n",
      "The Mach–Zehnder interferometer (MZI) illustrates the concepts of superposition and interference with linear algebra in dimension 2, rather than differential equations. It can be seen as a simplified version of the double-slit experiment, but it is of interest in its own right, for example in the delayed choice quantum eraser, the Elitzur–Vaidman bomb tester, and in studies of quantum entanglement.We can model a photon going through the interferometer by considering that at each point it can be in a superposition of only two paths: the \"lower\" path which starts from the left, goes straight through both beam splitters, and ends at the top, and the \"upper\" path which starts from the bottom, goes straight through both beam splitters, and ends at the right. The quantum state of the photon is therefore a vector \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        ∈\n",
      "        \n",
      "          \n",
      "            C\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi \\in \\mathbb {C} ^{2}}\n",
      "   that is a superposition of the \"lower\" path \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  1\n",
      "                \n",
      "              \n",
      "              \n",
      "                \n",
      "                  0\n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{l}={\\begin{pmatrix}1\\\\0\\end{pmatrix}}}\n",
      "   and the \"upper\" path \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            u\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  0\n",
      "                \n",
      "              \n",
      "              \n",
      "                \n",
      "                  1\n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi _{u}={\\begin{pmatrix}0\\\\1\\end{pmatrix}}}\n",
      "  , that is, \n",
      "  \n",
      "    \n",
      "      \n",
      "        ψ\n",
      "        =\n",
      "        α\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        +\n",
      "        β\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            u\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\psi =\\alpha \\psi _{l}+\\beta \\psi _{u}}\n",
      "   for complex \n",
      "  \n",
      "    \n",
      "      \n",
      "        α\n",
      "        ,\n",
      "        β\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\alpha ,\\beta }\n",
      "  . In order to respect the postulate that \n",
      "  \n",
      "    \n",
      "      \n",
      "        ⟨\n",
      "        ψ\n",
      "        ,\n",
      "        ψ\n",
      "        ⟩\n",
      "        =\n",
      "        1\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\langle \\psi ,\\psi \\rangle =1}\n",
      "   we require that \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          |\n",
      "        \n",
      "        α\n",
      "        \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        +\n",
      "        \n",
      "          |\n",
      "        \n",
      "        β\n",
      "        \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        =\n",
      "        1\n",
      "      \n",
      "    \n",
      "    {\\displaystyle |\\alpha |^{2}+|\\beta |^{2}=1}\n",
      "  .\n",
      "Both beam splitters are modelled as the unitary matrix \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "        =\n",
      "        \n",
      "          \n",
      "            1\n",
      "            \n",
      "              2\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  1\n",
      "                \n",
      "                \n",
      "                  i\n",
      "                \n",
      "              \n",
      "              \n",
      "                \n",
      "                  i\n",
      "                \n",
      "                \n",
      "                  1\n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle B={\\frac {1}{\\sqrt {2}}}{\\begin{pmatrix}1&i\\\\i&1\\end{pmatrix}}}\n",
      "  , which means that when a photon meets the beam splitter it will either stay on the same path with a probability amplitude of \n",
      "  \n",
      "    \n",
      "      \n",
      "        1\n",
      "        \n",
      "          /\n",
      "        \n",
      "        \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle 1/{\\sqrt {2}}}\n",
      "  , or be reflected to the other path with a probability amplitude of \n",
      "  \n",
      "    \n",
      "      \n",
      "        i\n",
      "        \n",
      "          /\n",
      "        \n",
      "        \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle i/{\\sqrt {2}}}\n",
      "  . The phase shifter on the upper arm is modelled as the unitary matrix \n",
      "  \n",
      "    \n",
      "      \n",
      "        P\n",
      "        =\n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  1\n",
      "                \n",
      "                \n",
      "                  0\n",
      "                \n",
      "              \n",
      "              \n",
      "                \n",
      "                  0\n",
      "                \n",
      "                \n",
      "                  \n",
      "                    e\n",
      "                    \n",
      "                      i\n",
      "                      Δ\n",
      "                      Φ\n",
      "                    \n",
      "                  \n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle P={\\begin{pmatrix}1&0\\\\0&e^{i\\Delta \\Phi }\\end{pmatrix}}}\n",
      "  , which means that if the photon is on the \"upper\" path it will gain a relative phase of \n",
      "  \n",
      "    \n",
      "      \n",
      "        Δ\n",
      "        Φ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\Delta \\Phi }\n",
      "  , and it will stay unchanged if it is in the lower path.\n",
      "A photon that enters the interferometer from the left will then be acted upon with a beam splitter \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "  , a phase shifter \n",
      "  \n",
      "    \n",
      "      \n",
      "        P\n",
      "      \n",
      "    \n",
      "    {\\displaystyle P}\n",
      "  , and another beam splitter \n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "      \n",
      "    \n",
      "    {\\displaystyle B}\n",
      "  , and so end up in the state \n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        B\n",
      "        P\n",
      "        B\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        =\n",
      "        i\n",
      "        \n",
      "          e\n",
      "          \n",
      "            i\n",
      "            Δ\n",
      "            Φ\n",
      "            \n",
      "              /\n",
      "            \n",
      "            2\n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            (\n",
      "            \n",
      "              \n",
      "                \n",
      "                  −\n",
      "                  sin\n",
      "                  ⁡\n",
      "                  (\n",
      "                  Δ\n",
      "                  Φ\n",
      "                  \n",
      "                    /\n",
      "                  \n",
      "                  2\n",
      "                  )\n",
      "                \n",
      "              \n",
      "              \n",
      "                \n",
      "                  cos\n",
      "                  ⁡\n",
      "                  (\n",
      "                  Δ\n",
      "                  Φ\n",
      "                  \n",
      "                    /\n",
      "                  \n",
      "                  2\n",
      "                  )\n",
      "                \n",
      "              \n",
      "            \n",
      "            )\n",
      "          \n",
      "        \n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle BPB\\psi _{l}=ie^{i\\Delta \\Phi /2}{\\begin{pmatrix}-\\sin(\\Delta \\Phi /2)\\\\\\cos(\\Delta \\Phi /2)\\end{pmatrix}},}\n",
      "  and the probabilities that it will be detected at the right or at the top are given respectively by\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        p\n",
      "        (\n",
      "        u\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          |\n",
      "        \n",
      "        ⟨\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            u\n",
      "          \n",
      "        \n",
      "        ,\n",
      "        B\n",
      "        P\n",
      "        B\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        ⟩\n",
      "        \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          cos\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        ⁡\n",
      "        \n",
      "          \n",
      "            \n",
      "              Δ\n",
      "              Φ\n",
      "            \n",
      "            2\n",
      "          \n",
      "        \n",
      "        ,\n",
      "      \n",
      "    \n",
      "    {\\displaystyle p(u)=|\\langle \\psi _{u},BPB\\psi _{l}\\rangle |^{2}=\\cos ^{2}{\\frac {\\Delta \\Phi }{2}},}\n",
      "  \n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        p\n",
      "        (\n",
      "        l\n",
      "        )\n",
      "        =\n",
      "        \n",
      "          |\n",
      "        \n",
      "        ⟨\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        ,\n",
      "        B\n",
      "        P\n",
      "        B\n",
      "        \n",
      "          ψ\n",
      "          \n",
      "            l\n",
      "          \n",
      "        \n",
      "        ⟩\n",
      "        \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          sin\n",
      "          \n",
      "            2\n",
      "          \n",
      "        \n",
      "        ⁡\n",
      "        \n",
      "          \n",
      "            \n",
      "              Δ\n",
      "              Φ\n",
      "            \n",
      "            2\n",
      "          \n",
      "        \n",
      "        .\n",
      "      \n",
      "    \n",
      "    {\\displaystyle p(l)=|\\langle \\psi _{l},BPB\\psi _{l}\\rangle |^{2}=\\sin ^{2}{\\frac {\\Delta \\Phi }{2}}.}\n",
      "  One can therefore use the Mach–Zehnder interferometer to estimate the phase shift by estimating these probabilities.\n",
      "It is interesting to consider what would happen if the photon were definitely in either the \"lower\" or \"upper\" paths between the beam splitters. This can be accomplished by blocking one of the paths, or equivalently by removing the first beam splitter (and feeding the photon from the left or the bottom, as desired). In both cases, there will be no interference between the paths anymore, and the probabilities are given by \n",
      "  \n",
      "    \n",
      "      \n",
      "        p\n",
      "        (\n",
      "        u\n",
      "        )\n",
      "        =\n",
      "        p\n",
      "        (\n",
      "        l\n",
      "        )\n",
      "        =\n",
      "        1\n",
      "        \n",
      "          /\n",
      "        \n",
      "        2\n",
      "      \n",
      "    \n",
      "    {\\displaystyle p(u)=p(l)=1/2}\n",
      "  , independently of the phase \n",
      "  \n",
      "    \n",
      "      \n",
      "        Δ\n",
      "        Φ\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\Delta \\Phi }\n",
      "  . From this we can conclude that the photon does not take one path or another after the first beam splitter, but rather that it is in a genuine quantum superposition of the two paths.\n",
      "\n",
      "Applications\n",
      "Quantum mechanics has had enormous success in explaining many of the features of our universe, with regard to small-scale and discrete quantities and interactions which cannot be explained by classical methods. Quantum mechanics is often the only theory that can reveal the individual behaviors of the subatomic particles that make up all forms of matter (electrons, protons, neutrons, photons, and others). Solid-state physics and materials science are dependent upon quantum mechanics.In many aspects, modern technology operates at a scale where quantum effects are significant. Important applications of quantum theory include quantum chemistry, quantum optics, quantum computing, superconducting magnets, light-emitting diodes, the optical amplifier and the laser, the transistor and semiconductors such as the microprocessor, medical and research imaging such as magnetic resonance imaging and electron microscopy. Explanations for many biological and physical phenomena are rooted in the nature of the chemical bond, most notably the macro-molecule DNA.\n",
      "\n",
      "Relation to other scientific theories\n",
      "Classical mechanics\n",
      "The rules of quantum mechanics assert that the state space of a system is a Hilbert space and that observables of the system are Hermitian operators acting on vectors in that space – although they do not tell us which Hilbert space or which operators. These can be chosen appropriately in order to obtain a quantitative description of a quantum system, a necessary step in making physical predictions. An important guide for making these choices is the correspondence principle, a heuristic which states that the predictions of quantum mechanics reduce to those of classical mechanics in the regime of large quantum numbers. One can also start from an established classical model of a particular system, and then try to guess the underlying quantum model that would give rise to the classical model in the correspondence limit. This approach is known as quantization.\n",
      "When quantum mechanics was originally formulated, it was applied to models whose correspondence limit was non-relativistic classical mechanics. For instance, the well-known model of the quantum harmonic oscillator uses an explicitly non-relativistic expression for the kinetic energy of the oscillator, and is thus a quantum version of the classical harmonic oscillator.\n",
      "Complications arise with chaotic systems, which do not have good quantum numbers, and quantum chaos studies the relationship between classical and quantum descriptions in these systems.\n",
      "Quantum decoherence is a mechanism through which quantum systems lose coherence, and thus become incapable of displaying many typically quantum effects: quantum superpositions become simply probabilistic mixtures, and quantum entanglement becomes simply classical correlations. Quantum coherence is not typically evident at macroscopic scales, except maybe at temperatures approaching absolute zero at which quantum behavior may manifest macroscopically.Many macroscopic properties of a classical system are a direct consequence of the quantum behavior of its parts. For example, the stability of bulk matter (consisting of atoms and molecules which would quickly collapse under electric forces alone), the rigidity of solids, and the mechanical, thermal, chemical, optical and magnetic properties of matter are all results of the interaction of electric charges under the rules of quantum mechanics.\n",
      "\n",
      "Special relativity and electrodynamics\n",
      "Early attempts to merge quantum mechanics with special relativity involved the replacement of the Schrödinger equation with a covariant equation such as the Klein–Gordon equation or the Dirac equation. While these theories were successful in explaining many experimental results, they had certain unsatisfactory qualities stemming from their neglect of the relativistic creation and annihilation of particles. A fully relativistic quantum theory required the development of quantum field theory, which applies quantization to a field (rather than a fixed set of particles). The first complete quantum field theory, quantum electrodynamics, provides a fully quantum description of the electromagnetic interaction. Quantum electrodynamics is, along with general relativity, one of the most accurate physical theories ever devised.The full apparatus of quantum field theory is often unnecessary for describing electrodynamic systems. A simpler approach, one that has been used since the inception of quantum mechanics, is to treat charged particles as quantum mechanical objects being acted on by a classical electromagnetic field. For example, the elementary quantum model of the hydrogen atom describes the electric field of the hydrogen atom using a classical \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          −\n",
      "          \n",
      "            e\n",
      "            \n",
      "              2\n",
      "            \n",
      "          \n",
      "          \n",
      "            /\n",
      "          \n",
      "          (\n",
      "          4\n",
      "          π\n",
      "          \n",
      "            ϵ\n",
      "            \n",
      "              \n",
      "                \n",
      "                \n",
      "                  0\n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "          r\n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle -e^{2}/(4\\pi \\epsilon _{_{0}}r)}\n",
      "   Coulomb potential. This \"semi-classical\" approach fails if quantum fluctuations in the electromagnetic field play an important role, such as in the emission of photons by charged particles.\n",
      "Quantum field theories for the strong nuclear force and the weak nuclear force have also been developed. The quantum field theory of the strong nuclear force is called quantum chromodynamics, and describes the interactions of subnuclear particles such as quarks and gluons. The weak nuclear force and the electromagnetic force were unified, in their quantized forms, into a single quantum field theory (known as electroweak theory), by the physicists Abdus Salam, Sheldon Glashow and Steven Weinberg.\n",
      "\n",
      "Relation to general relativity\n",
      "Even though the predictions of both quantum theory and general relativity have been supported by rigorous and repeated empirical evidence, their abstract formalisms contradict each other and they have proven extremely difficult to incorporate into one consistent, cohesive model. Gravity is negligible in many areas of particle physics, so that unification between general relativity and quantum mechanics is not an urgent issue in those particular applications. However, the lack of a correct theory of quantum gravity is an important issue in physical cosmology and the search by physicists for an elegant \"Theory of Everything\" (TOE). Consequently, resolving the inconsistencies between both theories has been a major goal of 20th- and 21st-century physics. This TOE would combine not only the models of subatomic physics but also derive the four fundamental forces of nature from a single force or phenomenon.One proposal for doing so is string theory, which posits that the point-like particles of particle physics are replaced by one-dimensional objects called strings. String theory describes how these strings propagate through space and interact with each other. On distance scales larger than the string scale, a string looks just like an ordinary particle, with its mass, charge, and other properties determined by the vibrational state of the string. In string theory, one of the many vibrational states of the string corresponds to the graviton, a quantum mechanical particle that carries gravitational force.Another popular theory is loop quantum gravity (LQG), which describes quantum properties of gravity and is thus a theory of quantum spacetime. LQG is an attempt to merge and adapt standard quantum mechanics and standard general relativity. This theory describes space as an extremely fine fabric \"woven\" of finite loops called spin networks. The evolution of a spin network over time is called a spin foam. The characteristic length scale of a spin foam is the Planck length, approximately 1.616×10−35 m, and so lengths shorter than the Planck length are not physically meaningful in LQG.\n",
      "\n",
      "Philosophical implications\n",
      "Since its inception, the many counter-intuitive aspects and results of quantum mechanics have provoked strong philosophical debates and many interpretations. The arguments centre on the probabilistic nature of quantum mechanics, the difficulties with wavefunction collapse and the related measurement problem, and quantum nonlocality. Perhaps the only consensus that exists about these issues is that there is no consensus. Richard Feynman once said, \"I think I can safely say that nobody understands quantum mechanics.\" According to Steven Weinberg, \"There is now in my opinion no entirely satisfactory interpretation of quantum mechanics.\"The views of Niels Bohr, Werner Heisenberg and other physicists are often grouped together as the \"Copenhagen interpretation\". According to these views, the probabilistic nature of quantum mechanics is not a temporary feature which will eventually be replaced by a deterministic theory, but is instead a final renunciation of the classical idea of \"causality\". Bohr in particular emphasized that any well-defined application of the quantum mechanical formalism must always make reference to the experimental arrangement, due to the complementary nature of evidence obtained under different experimental situations. Copenhagen-type interpretations were adopted by Nobel laureates in quantum physics, including Bohr, Heisenberg, Schrödinger, Feynman, and Zeilinger as well as 21st century researchers in quantum foundations.Albert Einstein, himself one of the founders of quantum theory, was troubled by its apparent failure to respect some cherished metaphysical principles, such as determinism and locality. Einstein's long-running exchanges with Bohr about the meaning and status of quantum mechanics are now known as the Bohr–Einstein debates. Einstein believed that underlying quantum mechanics must be a theory that explicitly forbids action at a distance. He argued that quantum mechanics was incomplete, a theory that was valid but not fundamental, analogous to how thermodynamics is valid, but the fundamental theory behind it is statistical mechanics. In 1935, Einstein and his collaborators Boris Podolsky and Nathan Rosen published an argument that the principle of locality implies the incompleteness of quantum mechanics, a thought experiment later termed the Einstein–Podolsky–Rosen paradox. In 1964, John Bell showed that EPR's principle of locality, together with determinism, was actually incompatible with quantum mechanics: they implied constraints on the correlations produced by distance systems, now known as Bell inequalities, that can be violated by entangled particles. Since then several experiments have been performed to obtain these correlations, with the result that they do in fact violate Bell inequalities, and thus falsify the conjunction of locality with determinism.Bohmian mechanics shows that it is possible to reformulate quantum mechanics to make it deterministic, at the price of making it explicitly nonlocal. It attributes not only a wave function to a physical system, but in addition a real position, that evolves deterministically under a nonlocal guiding equation. The evolution of a physical system is given at all times by the Schrödinger equation together with the guiding equation; there is never a collapse of the wave function. This solves the measurement problem.Everett's many-worlds interpretation, formulated in 1956, holds that all the possibilities described by quantum theory simultaneously occur in a multiverse composed of mostly independent parallel universes. This is a consequence of removing the axiom of the collapse of the wave packet. All possible states of the measured system and the measuring apparatus, together with the observer, are present in a real physical quantum superposition. While the multiverse is deterministic, we perceive non-deterministic behavior governed by probabilities, because we do not observe the multiverse as a whole, but only one parallel universe at a time. Exactly how this is supposed to work has been the subject of much debate. Several attempts have been made to make sense of this and derive the Born rule, with no consensus on whether they have been successful.Relational quantum mechanics appeared in the late 1990s as a modern derivative of Copenhagen-type ideas, and QBism was developed some years later.\n",
      "\n",
      "History\n",
      "Quantum mechanics was developed in the early decades of the 20th century, driven by the need to explain phenomena that, in some cases, had been observed in earlier times. Scientific inquiry into the wave nature of light began in the 17th and 18th centuries, when scientists such as Robert Hooke, Christiaan Huygens and Leonhard Euler proposed a wave theory of light based on experimental observations. In 1803 English polymath Thomas Young described the famous double-slit experiment. This experiment played a major role in the general acceptance of the wave theory of light.\n",
      "During the early 19th century, chemical research by John Dalton and Amedeo Avogadro lent weight to the atomic theory of matter, an idea that James Clerk Maxwell, Ludwig Boltzmann and others built upon to establish the kinetic theory of gases. The successes of kinetic theory gave further credence to the idea that matter is composed of atoms, yet the theory also had shortcomings that would only be resolved by the development of quantum mechanics. While the early conception of atoms from Greek philosophy had been that they were indivisible units –  the word \"atom\" deriving from the Greek for \"uncuttable\" –  the 19th century saw the formulation of hypotheses about subatomic structure. One important discovery in that regard was Michael Faraday's 1838 observation of a glow caused by an electrical discharge inside a glass tube containing gas at low pressure. Julius Plücker, Johann Wilhelm Hittorf and Eugen Goldstein carried on and improved upon Faraday's work, leading to the identification of cathode rays, which J. J. Thomson found to consist of subatomic particles that would be called electrons.The black-body radiation problem was discovered by Gustav Kirchhoff in 1859. In 1900, Max Planck proposed the hypothesis that energy is radiated and absorbed in discrete \"quanta\" (or energy packets), yielding a calculation that precisely matched the observed patterns of black-body radiation. The word quantum derives from the Latin, meaning \"how great\" or \"how much\". According to Planck, quantities of energy could be thought of as divided into \"elements\" whose size (E) would be proportional to their frequency (ν):\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        E\n",
      "        =\n",
      "        h\n",
      "        ν\n",
      "         \n",
      "      \n",
      "    \n",
      "    {\\displaystyle E=h\\nu \\ }\n",
      "  ,where h is Planck's constant. Planck cautiously insisted that this was only an aspect of the processes of absorption and emission of radiation and was not the physical reality of the radiation. In fact, he considered his quantum hypothesis a mathematical trick to get the right answer rather than a sizable discovery. However, in 1905 Albert Einstein interpreted Planck's quantum hypothesis realistically and used it to explain the photoelectric effect, in which shining light on certain materials can eject electrons from the material. Niels Bohr then developed Planck's ideas about radiation into a model of the hydrogen atom that successfully predicted the spectral lines of hydrogen. Einstein further developed this idea to show that an electromagnetic wave such as light could also be described as a particle (later called the photon), with a discrete amount of energy that depends on its frequency. In his paper \"On the Quantum Theory of Radiation\", Einstein expanded on the interaction between energy and matter to explain the absorption and emission of energy by atoms. Although overshadowed at the time by his general theory of relativity, this paper articulated the mechanism underlying the stimulated emission of radiation, which became the basis of the laser.\n",
      "\n",
      "This phase is known as the old quantum theory. Never complete or self-consistent, the old quantum theory was rather a set of heuristic corrections to classical mechanics. The theory is now understood as a semi-classical approximation to modern quantum mechanics. Notable results from this period include, in addition to the work of Planck, Einstein and Bohr mentioned above, Einstein and Peter Debye's work on the specific heat of solids, Bohr and Hendrika Johanna van Leeuwen's proof that classical physics cannot account for diamagnetism, and Arnold Sommerfeld's extension of the Bohr model to include special-relativistic effects.\n",
      "In the mid-1920s quantum mechanics was developed to become the standard formulation for atomic physics. In 1923, the French physicist Louis de Broglie put forward his theory of matter waves by stating that particles can exhibit wave characteristics and vice versa. Building on de Broglie's approach, modern quantum mechanics was born in 1925, when the German physicists Werner Heisenberg, Max Born, and Pascual Jordan developed matrix mechanics and the Austrian physicist Erwin Schrödinger invented wave mechanics. Born introduced the probabilistic interpretation of Schrödinger's wave function in July 1926. Thus, the entire field of quantum physics emerged, leading to its wider acceptance at the Fifth Solvay Conference in 1927.By 1930 quantum mechanics had been further unified and formalized by David Hilbert, Paul Dirac and John von Neumann with greater emphasis on measurement, the statistical nature of our knowledge of reality, and philosophical speculation about the 'observer'. It has since permeated many disciplines, including quantum chemistry, quantum electronics, quantum optics, and quantum information science. It also provides a useful framework for many features of the modern periodic table of elements, and describes the behaviors of atoms during chemical bonding and the flow of electrons in computer semiconductors, and therefore plays a crucial role in many modern technologies. While quantum mechanics was constructed to describe the world of the very small, it is also needed to explain some macroscopic phenomena such as superconductors and superfluids.\n",
      "\n",
      "See also\n",
      "Explanatory notes\n",
      "References\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "J. O'Connor and E. F. Robertson: A history of quantum mechanics.\n",
      "Introduction to Quantum Theory at Quantiki.\n",
      "Quantum Physics Made Relatively Simple: three video lectures by Hans BetheCourse materialQuantum Cook Book and PHYS 201: Fundamentals of Physics II by Ramamurti Shankar, Yale OpenCourseware\n",
      "Modern Physics: With waves, thermodynamics, and optics – an online textbook.\n",
      "MIT OpenCourseWare: Chemistry and Physics. See 8.04, 8.05 and 8.06\n",
      "5½ Examples in Quantum Mechanics\n",
      "Imperial College Quantum Mechanics Course.PhilosophyIsmael, Jenann. \"Quantum Mechanics\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.\n",
      "Krips, Henry. \"Measurement in Quantum Theory\". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.The Great Wall of China (traditional Chinese: 萬里長城; simplified Chinese: 万里长城; pinyin: Wànlǐ Chángchéng, literally \"ten thousand li long wall\") is a series of fortifications that were built across the historical northern borders of ancient Chinese states and Imperial China as protection against various nomadic groups from the Eurasian Steppe. Several walls were built from as early as the 7th century BC, with selective stretches later joined by Qin Shi Huang (220–206 BC), the first emperor of China. Little of the Qin wall remains. Later on, many successive dynasties built and maintained multiple stretches of border walls. The best-known sections of the wall were built by the Ming dynasty (1368–1644).\n",
      "Apart from defense, other purposes of the Great Wall have included border controls, allowing the imposition of duties on goods transported along the Silk Road, regulation or encouragement of trade and the control of immigration and emigration. Furthermore, the defensive characteristics of the Great Wall were enhanced by the construction of watchtowers, troop barracks, garrison stations, signaling capabilities through the means of smoke or fire, and the fact that the path of the Great Wall also served as a transportation corridor.\n",
      "The frontier walls built by different dynasties have multiple courses. Collectively, they stretch from Liaodong in the east to Lop Lake in the west, from the present-day Sino–Russian border in the north to Tao River (Taohe) in the south; along an arc that roughly delineates the edge of the Mongolian steppe; spanning 21,196.18 km (13,170.70 mi) in total. Today, the defensive system of the Great Wall is generally recognized as one of the most impressive architectural feats in history.\n",
      "\n",
      "Names\n",
      "The collection of fortifications known as the Great Wall of China has historically had a number of different names in both Chinese and English.\n",
      "In Chinese histories, the term \"Long Wall(s)\" (t 長城, s 长城, Chángchéng) appears in Sima Qian's Records of the Grand Historian, where it referred both to the separate great walls built between and north of the Warring States and to the more unified construction of the First Emperor. The Chinese character 城, meaning city or fortress, is a phono-semantic compound of the \"earth\" radical 土 and phonetic 成, whose Old Chinese pronunciation has been reconstructed as *deŋ. It originally referred to the rampart which surrounded traditional Chinese cities and was used by extension for these walls around their respective states; today, however, it is much more often the Chinese word for \"city\".The longer Chinese name \"Ten-Thousand Mile Long Wall\" (t 萬里長城, s 万里长城, Wànlǐ Chángchéng) came from Sima Qian's description of it in the Records, though he did not name the walls as such. The AD 493 Book of Song quotes the frontier general Tan Daoji referring to \"the long wall of 10,000 miles\", closer to the modern name, but the name rarely features in pre-modern times otherwise. The traditional Chinese mile (里, lǐ) was an often irregular distance that was intended to show the length of a standard village and varied with terrain but was usually standardized at distances around a third of an English mile (540 m). However, this use of \"ten-thousand\" (wàn) is figurative in a similar manner to the Greek and English myriad and simply means \"innumerable\" or \"immeasurable\".Because of the wall's association with the First Emperor's supposed tyranny, the Chinese dynasties after Qin usually avoided referring to their own additions to the wall by the name \"Long Wall\". Instead, various terms were used in medieval records, including \"frontier(s)\" (塞, Sài), \"rampart(s)\" (垣, Yuán), \"barrier(s)\" (障, Zhàng), \"the outer fortresses\" (外堡, Wàibǎo), and \"the border wall(s)\" (t 邊牆, s 边墙, Biānqiáng). Poetic and informal names for the wall included \"the Purple Frontier\" (紫塞, Zǐsài) and \"the Earth Dragon\" (t 土龍, s 土龙, Tǔlóng). Only during the Qing period did \"Long Wall\" become the catch-all term to refer to the many border walls regardless of their location or dynastic origin, equivalent to the English \"Great Wall\".Sections of the wall in south Gobi Desert and Mongolian steppe are sometimes referred to as \"Wall of Genghis Khan\", even though Genghis Khan did not construct any walls or permanent defense lines himself.The current English name evolved from accounts of \"the Chinese wall\" from early modern European travelers. By the nineteenth century, \"the Great Wall of China\" had become standard in English and French, although other European languages such as German continue to refer to it as \"the Chinese wall\".\n",
      "\n",
      "History\n",
      "Early walls\n",
      "The Chinese were already familiar with the techniques of wall-building by the time of the Spring and Autumn period between the 8th and 5th centuries BC. During this time and the subsequent Warring States period, the states of Qin, Wei, Zhao, Qi, Han, Yan, and Zhongshan all constructed extensive fortifications to defend their own borders. Built to withstand the attack of small arms such as swords and spears, these walls were made mostly of stone or by stamping earth and gravel between board frames.\n",
      "\n",
      "King Zheng of Qin conquered the last of his opponents and unified China as the First Emperor of the Qin dynasty (\"Qin Shi Huang\") in 221 BC.  Intending to impose centralized rule and prevent the resurgence of feudal lords, he ordered the destruction of the sections of the walls that divided his empire among the former states. To position the empire against the Xiongnu people from the north, however, he ordered the building of new walls to connect the remaining fortifications along the empire's northern frontier. \"Build and move on\" was a central guiding principle in constructing the wall, implying that the Chinese were not erecting a permanently fixed border.Transporting the large quantity of materials required for construction was difficult, so builders always tried to use local resources. Stones from the mountains were used over mountain ranges, while rammed earth was used for construction in the plains. There are no surviving historical records indicating the exact length and course of the Qin walls. Most of the ancient walls have eroded away over the centuries, and very few sections remain today. The human cost of the construction is unknown, but it has been estimated by some authors that hundreds of thousands of workers died building the Qin wall. Later, the Han, the Northern dynasties and the Sui all repaired, rebuilt, or expanded sections of the Great Wall at great cost to defend themselves against northern invaders. The Tang and Song dynasties did not undertake any significant effort in the region. Dynasties founded by non-Han ethnic groups also built their border walls: the Xianbei-ruled Northern Wei, the Khitan-ruled Liao, Jurchen-led Jin and the Tangut-established Western Xia, who ruled vast territories over Northern China throughout centuries, all constructed defensive walls but those were located much to the north of the other Great Walls as we know it, within China's autonomous region of Inner Mongolia and in modern-day Mongolia itself.\n",
      "\n",
      "Ming era\n",
      "The Great Wall concept was revived again under the Ming in the 14th century, and following the Ming army's defeat by the Oirats in the Battle of Tumu. The Ming had failed to gain a clear upper hand over the Mongol tribes after successive battles, and the long-drawn conflict was taking a toll on the empire. The Ming adopted a new strategy to keep the nomadic tribes out by constructing walls along the northern border of China. Acknowledging the Mongol control established in the Ordos Desert, the wall followed the desert's southern edge instead of incorporating the bend of the Yellow River.\n",
      "Unlike the earlier fortifications, the Ming construction was stronger and more elaborate due to the use of bricks and stone instead of rammed earth. Up to 25,000 watchtowers are estimated to have been constructed on the wall. As Mongol raids continued periodically over the years, the Ming devoted considerable resources to repair and reinforce the walls. Sections near the Ming capital of Beijing were especially strong. Qi Jiguang between 1567 and 1570 also repaired and reinforced the wall, faced sections of the ram-earth wall with bricks and constructed 1,200 watchtowers from Shanhaiguan Pass to Changping to warn of approaching Mongol raiders. During the 1440s–1460s, the Ming also built a so-called \"Liaodong Wall\". Similar in function to the Great Wall (whose extension, in a sense, it was), but more basic in construction, the Liaodong Wall enclosed the agricultural heartland of the Liaodong province, protecting it against potential incursions by Jurchen-Mongol Oriyanghan from the northwest and the Jianzhou Jurchens from the north. While stones and tiles were used in some parts of the Liaodong Wall, most of it was in fact simply an earth dike with moats on both sides.Towards the end of the Ming, the Great Wall helped defend the empire against the Manchu invasions that began around 1600. Even after the loss of all of Liaodong, the Ming army held the heavily fortified Shanhai Pass, preventing the Manchus from conquering the Chinese heartland. The Manchus were finally able to cross the Great Wall in 1644, after Beijing had already fallen to Li Zicheng's short-lived Shun dynasty. Before this time, the Manchus had crossed the Great Wall multiple times to raid, but this time it was for conquest. The gates at Shanhai Pass were opened on May 25 by the commanding Ming general, Wu Sangui, who formed an alliance with the Manchus, hoping to use the Manchus to expel the rebels from Beijing. The Manchus quickly seized Beijing, and eventually defeated both the Shun dynasty and the remaining Ming resistance, consolidating the rule of the Qing dynasty over all of China proper.Under Qing rule, China's borders extended beyond the walls and Mongolia was annexed into the empire, so constructions on the Great Wall were discontinued. On the other hand, the so-called Willow Palisade, following a line similar to that of the Ming Liaodong Wall, was constructed by the Qing rulers in Manchuria. Its purpose, however, was not defense but rather to prevent Han Chinese migration into Manchuria.\n",
      "\n",
      "Foreign accounts\n",
      "None of the Europeans who visited China or Mongolia in the 13th and 14th centuries, such as Giovanni da Pian del Carpine, William of Rubruck, Marco Polo, Odoric of Pordenone and Giovanni de' Marignolli, mentioned the Great Wall.The North African traveler Ibn Battuta, who also visited China during the Yuan dynasty c. 1346, had heard about China's Great Wall, possibly before he had arrived in China. He wrote that the wall is \"sixty days' travel\" from Zeitun (modern Quanzhou) in his travelogue Gift to Those Who Contemplate the Wonders of Cities and the Marvels of Travelling. He associated it with the legend of the wall mentioned in the Qur'an, which Dhul-Qarnayn (commonly associated with Alexander the Great) was said to have erected to protect people near the land of the rising sun from the savages of Gog and Magog. However, Ibn Battuta could find no one who had either seen it or knew of anyone who had seen it, suggesting that although there were remnants of the wall at that time, they were not significant.Soon after Europeans reached Ming China by ship in the early 16th century, accounts of the Great Wall started to circulate in Europe, even though no European was to see it for another century. Possibly one of the earliest European descriptions of the wall and of its significance for the defense of the country against the \"Tartars\" (i.e. Mongols) may be the one contained in João de Barros's 1563 Asia. Other early accounts in Western sources include those of Gaspar da Cruz, Bento de Goes, Matteo Ricci, and Bishop Juan González de Mendoza, the latter in 1585 describing it as a \"superbious and mightie work\" of architecture, though he had not seen it. In 1559, in his work \"A Treatise of China and the Adjoyning Regions\", Gaspar da Cruz offers an early discussion of the Great Wall. Perhaps the first recorded instance of a European actually entering China via the Great Wall came in 1605, when the Portuguese Jesuit brother Bento de Góis reached the northwestern Jiayu Pass from India. Early European accounts were mostly modest and empirical, closely mirroring contemporary Chinese understanding of the Wall, although later they slid into hyperbole, including the erroneous but ubiquitous claim that the Ming walls were the same ones that were built by the first emperor in the 3rd century BC.When China opened its borders to foreign merchants and visitors after its defeat in the First and Second Opium Wars, the Great Wall became a main attraction for tourists. The travelogues of the later 19th century further enhanced the reputation and the mythology of the Great Wall.\n",
      "\n",
      "Course\n",
      "A formal definition of what constitutes a \"Great Wall\" has not been agreed upon, making the full course of the Great Wall difficult to describe in its entirety. The defensive lines contain multiple stretches of ramparts, trenches and ditches, as well as individual fortresses.\n",
      "In 2012, based on existing research and the results of a comprehensive mapping survey, the National Cultural Heritage Administration of China concluded that the remaining Great Wall associated sites include 10,051 wall sections, 1,764 ramparts or trenches, 29,510 individual buildings, and 2,211 fortifications or passes, with the walls and trenches spanning a total length of 21,196.18 km (13,170.70 mi). Incorporating advanced technologies, the study has concluded that the Ming Great Wall measures 8,850 km (5,500 mi). This consists of 6,259 km (3,889 mi) of wall sections, 359 km (223 mi) of trenches and 2,232 km (1,387 mi) of natural defensive barriers such as hills and rivers. In addition, Qin, Han and earlier Great Wall sites are 3,080 km (1,914 mi) long in total; Jin dynasty (1115–1234) border fortifications are 4,010 km (2,492 mi) in length; the remainder date back to Northern Wei, Northern Qi, Sui, Tang, the Five Dynasties, Song, Liao and Xixia. About half of the sites are located in Inner Mongolia (31%) and Hebei (19%).\n",
      "\n",
      "Han Great Wall\n",
      "Han fortifications starts from Yumen Pass and Yang Pass, southwest of Dunhuang, in Gansu province. Ruins of the remotest Han border posts are found in Mamitu (t 馬迷途, s 马迷途, Mǎmítú, l \"horses losing their way\") near Yumen Pass.\n",
      "\n",
      "Ming Great Wall\n",
      "The Jiayu Pass, located in Gansu province, is the western terminus of the Ming Great Wall. From Jiayu Pass the wall travels discontinuously down the Hexi Corridor and into the deserts of Ningxia, where it enters the western edge of the Yellow River loop at Yinchuan. Here the first major walls erected during the Ming dynasty cut through the Ordos Desert to the eastern edge of the Yellow River loop. There at Piantou Pass (t 偏頭關, s 偏头关, Piāntóuguān) in Xinzhou, Shanxi province, the Great Wall splits in two with the \"Outer Great Wall\" (t 外長城, s 外长城, Wài Chǎngchéng) extending along the Inner Mongolia border with Shanxi into Hebei province, and the \"Inner Great Wall\" (t 內長城, s 內长城, Nèi Chǎngchéng) running southeast from Piantou Pass for some 400 km (250 mi), passing through important passes like the Pingxing Pass and Yanmen Pass before joining the Outer Great Wall at Sihaiye (四海冶, Sìhǎiyě), in Beijing's Yanqing County.\n",
      "The sections of the Great Wall around Beijing municipality are especially famous: they were frequently renovated and are regularly visited by tourists today. The Badaling Great Wall near Zhangjiakou is the most famous stretch of the wall, for this was the first section to be opened to the public in the People's Republic of China, as well as the showpiece stretch for foreign dignitaries. The Badaling Great Wall saw nearly 10 million visitors in 2018, and in 2019, a daily limit of 65,000 visitors was instated. South of Badaling is the Juyong Pass; when it was used by the Chinese to protect their land, this section of the wall had many guards to defend the capital Beijing. Made of stone and bricks from the hills, this portion of the Great Wall is 7.8 m (25 ft 7 in) high and 5 m (16 ft 5 in) wide.\n",
      "\n",
      "One of the most striking sections of the Ming Great Wall is where it climbs extremely steep slopes in Jinshanling. There it runs 11 km (7 mi) long, ranges from 5 to 8 m (16 ft 5 in to 26 ft 3 in) in height, and 6 m (19 ft 8 in) across the bottom, narrowing up to 5 m (16 ft 5 in) across the top. Wangjing Lou (t 望京樓, s 望京楼, Wàngjīng Lóu) is one of Jinshanling's 67 watchtowers, 980 m (3,220 ft) above sea level. Southeast of Jinshanling is the Mutianyu Great Wall which winds along lofty, cragged mountains from the southeast to the northwest for 2.25 km (1.40 mi). It is connected with Juyongguan Pass to the west and Gubeikou to the east. This section was one of the first to be renovated following the turmoil of the Cultural Revolution.At the edge of the Bohai Gulf is Shanhai Pass, considered the traditional end of the Great Wall and the \"First Pass Under Heaven\". The part of the wall inside Shanhai Pass that meets the sea is named the \"Old Dragon Head\". 3 km (2 mi) north of Shanhai Pass is Jiaoshan Great Wall (t 焦山長城, s 焦山长城, Jiāoshān Chángchéng), the site of the first mountain of the Great Wall. 15 km (9 mi) northeast from Shanhaiguan is Jiumenkou (t 九門口, s 九门口, Jiǔménkǒu), which is the only portion of the wall that was built as a bridge.\n",
      "In 2009, 180 km of previously unknown sections of the Ming wall concealed by hills, trenches and rivers were discovered with the help of infrared range finders and GPS devices. In March and April 2015, nine sections with a total length of more than 10 km (6 mi), believed to be part of the Great Wall, were discovered along the border of Ningxia autonomous region and Gansu province.\n",
      "\n",
      "Characteristics\n",
      "Before the use of bricks, the Great Wall was mainly built from rammed earth, stones, and wood. During the Ming, however, bricks were heavily used in many areas of the wall, as were materials such as tiles, lime, and stone. The size and weight of the bricks made them easier to work with than earth and stone, so construction quickened. Additionally, bricks could bear more weight and endure better than rammed earth. Stone can hold under its own weight better than brick, but is more difficult to use. Consequently, stones cut into rectangular shapes were used for the foundation, inner and outer brims, and gateways of the wall. Battlements line the uppermost portion of the vast majority of the wall, with defensive gaps a little over 30 cm (12 in) tall, and about 23 cm (9.1 in) wide. From the parapets, guards could survey the surrounding land.Sticky rice mortar, consisting of sticky rice soup mixed with slaked lime, was extensively used to hold bricks together; no human bones or body parts were ever incorporated into the mortar or any part of the wall, contrary to what a legend states. Communication between the army units along the length of the Great Wall, including the ability to call reinforcements and warn garrisons of enemy movements, was of high importance. Signal towers were built upon hill tops or other high points along the wall for their visibility. Wooden gates could be used as a trap against those going through. Barracks, stables, and armories were built near the wall's inner surface.\n",
      "\n",
      "Condition\n",
      "While portions north of Beijing and near tourist centers have been preserved and even extensively renovated, in many other locations the wall is in disrepair. The wall sometimes provided a source of stones to build houses and roads. Sections of the wall are also prone to graffiti and vandalism, while inscribed bricks were pilfered and sold on the market for up to 50 renminbi. Parts have been destroyed to make way for construction or mining.A 2012 report by the National Cultural Heritage Administration states that 22% of the Ming Great Wall has disappeared, while 1,961 km (1,219 mi) of wall have vanished. In 2007 it was estimated that more than 60 km (37 mi) of the wall in Gansu province may disappear in the next 20 years, due to erosion from sandstorms. In some places, the height of the wall has been reduced from more than 5 m (16 ft 5 in) to less than 2 m (6 ft 7 in). Various square lookout towers that characterize the most famous images of the wall have disappeared. Many western sections of the wall are constructed from mud, rather than brick and stone, and thus are more susceptible to erosion. In 2014 a portion of the wall near the border of Liaoning and Hebei province was repaired with concrete. The work has been much criticized.A section of the wall in Shanxi province was severely damaged in 2023 by construction workers, who widened an existing gap in the wall to make a shortcut for an excavator to pass through. Police described the act as causing \"irreversible damage to the integrity of the Ming Great Wall and to the safety of the cultural relics\".\n",
      "\n",
      "Visibility from space\n",
      "Various factoids in popular culture claim that the Great Wall can be seen (with the naked eye) from space, with questionable degrees of veracity.\n",
      "\n",
      "From the Moon\n",
      "The Great Wall of China cannot be seen by the naked human eye from the Moon. Even though the myth is thoroughly debunked, it is still ingrained in popular culture. The apparent width of the Great Wall from the Moon would be the same as that of a human hair viewed from 3 km (2 mi) away.One of the earliest known references to the myth that the Great Wall can be seen from the moon appears in a letter written in 1754 by the English antiquary William Stukeley. Stukeley wrote that, \"This mighty wall [Hadrian's wall] of four score miles [130 km] in length is only exceeded by the Chinese Wall, which makes a considerable figure upon the terrestrial globe, and may be discerned at the Moon.\" The claim was also mentioned by Henry Norman in 1895 where he states \"besides its age it enjoys the reputation of being the only work of human hands on the globe visible from the Moon.\" The issue of \"canals\" on Mars was prominent in the late 19th century and may have led to the belief that long, thin objects were visible from space. The claim that the Great Wall is visible from the moon also appears in 1932's Ripley's Believe It or Not! strip.\n",
      "\n",
      "From low Earth orbit\n",
      "A more controversial question is whether the wall is visible from low Earth orbit (an altitude of as little as 160 km (100 mi)). NASA claims that it is barely visible, and only under nearly perfect conditions; it is no more conspicuous than many other human-made objects.Veteran US astronaut Gene Cernan has stated: \"At Earth orbit of 100 to 200 miles [160 to 320 km] high, the Great Wall of China is, indeed, visible to the naked eye.\" Ed Lu, Expedition 7 Science Officer aboard the International Space Station, adds that, \"It's less visible than a lot of other objects. And you have to know where to look.\"\n",
      "In October 2003, Chinese astronaut Yang Liwei stated that he had not been able to see the Great Wall of China. In response, the European Space Agency (ESA) issued a press release reporting that from an orbit between 160 and 320 km (100 and 200 mi), the Great Wall is visible to the naked eye. The image was actually a river in Beijing.Leroy Chiao, a Chinese-American astronaut, took a photograph from the International Space Station that shows the wall. It was so indistinct that the photographer was not certain he had actually captured it. Based on the photograph, the China Daily later reported that the Great Wall can be seen from 'space' with the naked eye, under favorable viewing conditions, if one knows exactly where to look.\n",
      "\n",
      "Gallery\n",
      "See also\n",
      "Notes\n",
      "References\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "International Friends of the Great Wall Archived February 17, 2009, at the Wayback Machine – organization focused on conservation\n",
      "UNESCO World Heritage Centre profile\n",
      "Enthusiast/scholar website (in Chinese)\n",
      "Great Wall of China on In Our Time at the BBC\n",
      "Photoset of lesser visited areas of the Great Wall\n",
      " Geographic data related to Great Wall of China at OpenStreetMapNeuroscience is the scientific study of the nervous system (the brain, spinal cord, and peripheral nervous system), its functions and disorders. It is a multidisciplinary science that combines physiology, anatomy, molecular biology, developmental biology, cytology, psychology, physics, computer science, chemistry, medicine, statistics, and mathematical modeling to understand the fundamental and emergent properties of neurons, glia and neural circuits. The understanding of the biological basis of learning, memory, behavior, perception, and consciousness has been described by Eric Kandel as the \"epic challenge\" of the biological sciences.The scope of neuroscience has broadened over time to include different approaches used to study the nervous system at different scales. The techniques used by neuroscientists have expanded enormously, from molecular and cellular studies of individual neurons to imaging of sensory, motor and cognitive tasks in the brain.\n",
      "\n",
      "History\n",
      "The earliest study of the nervous system dates to ancient Egypt. Trepanation, the surgical practice of either drilling or scraping a hole into the skull for the purpose of curing head injuries or mental disorders, or relieving cranial pressure, was first recorded during the Neolithic period. Manuscripts dating to 1700 BC indicate that the Egyptians had some knowledge about symptoms of brain damage.Early views on the function of the brain regarded it to be a \"cranial stuffing\" of sorts. In Egypt, from the late Middle Kingdom onwards, the brain was regularly removed in preparation for mummification. It was believed at the time that the heart was the seat of intelligence. According to Herodotus, the first step of mummification was to \"take a crooked piece of iron, and with it draw out the brain through the nostrils, thus getting rid of a portion, while the skull is cleared of the rest by rinsing with drugs.\"The view that the heart was the source of consciousness was not challenged until the time of the Greek physician Hippocrates. He believed that the brain was not only involved with sensation—since most specialized organs (e.g., eyes, ears, tongue) are located in the head near the brain—but was also the seat of intelligence. Plato also speculated that the brain was the seat of the rational part of the soul. Aristotle, however, believed the heart was the center of intelligence and that the brain regulated the amount of heat from the heart. This view was generally accepted until the Roman physician Galen, a follower of Hippocrates and physician to Roman gladiators, observed that his patients lost their mental faculties when they had sustained damage to their brains.Abulcasis, Averroes, Avicenna, Avenzoar, and Maimonides, active in the Medieval Muslim world, described a number of medical problems related to the brain. In Renaissance Europe, Vesalius (1514–1564), René Descartes (1596–1650), Thomas Willis (1621–1675) and Jan Swammerdam (1637–1680) also made several contributions to neuroscience.\n",
      "\n",
      "Luigi Galvani's pioneering work in the late 1700s set the stage for studying the electrical excitability of muscles and neurons. In 1843 Emil du Bois-Reymond demonstrated the electrical nature of the nerve signal, whose speed Hermann von Helmholtz proceeded to measure, and in 1875 Richard Caton found electrical phenomena in the cerebral hemispheres of rabbits and monkeys. Adolf Beck published in 1890 similar observations of spontaneous electrical activity of the brain of rabbits and dogs. Studies of the brain became more sophisticated after the invention of the microscope and the development of a staining procedure by Camillo Golgi during the late 1890s. The procedure used a silver chromate salt to reveal the intricate structures of individual neurons. His technique was used by Santiago Ramón y Cajal and led to the formation of the neuron doctrine, the hypothesis that the functional unit of the brain is the neuron. Golgi and Ramón y Cajal shared the Nobel Prize in Physiology or Medicine in 1906 for their extensive observations, descriptions, and categorizations of neurons throughout the brain.\n",
      "In parallel with this research, in 1815 Jean Pierre Flourens induced localized lesions of the brain in living animals to observe their effects on motricity, sensibility and behavior. Work with brain-damaged patients by Marc Dax in 1836 and Paul Broca in 1865 suggested that certain regions of the brain were responsible for certain functions. At the time, these findings were seen as a confirmation of Franz Joseph Gall's theory that language was localized and that certain psychological functions were localized in specific areas of the cerebral cortex. The localization of function hypothesis was supported by observations of epileptic patients conducted by John Hughlings Jackson, who correctly inferred the organization of the motor cortex by watching the progression of seizures through the body. Carl Wernicke further developed the theory of the specialization of specific brain structures in language comprehension and production. Modern research through neuroimaging techniques, still uses the Brodmann cerebral cytoarchitectonic map (referring to the study of cell structure) anatomical definitions from this era in continuing to show that distinct areas of the cortex are activated in the execution of specific tasks.During the 20th century, neuroscience began to be recognized as a distinct academic discipline in its own right, rather than as studies of the nervous system within other disciplines. Eric Kandel and collaborators have cited David Rioch, Francis O. Schmitt, and Stephen Kuffler as having played critical roles in establishing the field. Rioch originated the integration of basic anatomical and physiological research with clinical psychiatry at the Walter Reed Army Institute of Research, starting in the 1950s. During the same period, Schmitt established a neuroscience research program within the Biology Department at the Massachusetts Institute of Technology, bringing together biology, chemistry, physics, and mathematics. The first freestanding neuroscience department (then called Psychobiology) was founded in 1964 at the University of California, Irvine by James L. McGaugh. This was followed by the Department of Neurobiology at Harvard Medical School, which was founded in 1966 by Stephen Kuffler.\n",
      "In the process of treating epilepsy, Wilder Penfield produced maps of the location of various functions (motor, sensory, memory, vision) in the brain. He summarized his findings in a 1950 book called The Cerebral Cortex of Man. Wilder Penfield and his co-investigators Edwin Boldrey and Theodore Rasmussen are considered to be the originators of the cortical homunculus.The understanding of neurons and of nervous system function became increasingly precise and molecular during the 20th century. For example, in 1952, Alan Lloyd Hodgkin and Andrew Huxley presented a mathematical model for the transmission of electrical signals in neurons of the giant axon of a squid, which they called \"action potentials\", and how they are initiated and propagated, known as the Hodgkin–Huxley model. In 1961–1962, Richard FitzHugh and J. Nagumo simplified Hodgkin–Huxley, in what is called the FitzHugh–Nagumo model. In 1962, Bernard Katz modeled neurotransmission across the space between neurons known as synapses. Beginning in 1966, Eric Kandel and collaborators examined biochemical changes in neurons associated with learning and memory storage in Aplysia. In 1981 Catherine Morris and Harold Lecar combined these models in the Morris–Lecar model. Such increasingly quantitative work gave rise to numerous biological neuron models and models of neural computation.\n",
      "As a result of the increasing interest about the nervous system, several prominent neuroscience organizations have been formed to provide a forum to all neuroscientists during the 20th century. For example, the International Brain Research Organization was founded in 1961, the International Society for Neurochemistry in 1963, the European Brain and Behaviour Society in 1968, and the Society for Neuroscience in 1969. Recently, the application of neuroscience research results has also given rise to applied disciplines as neuroeconomics, neuroeducation, neuroethics, and neurolaw.Over time, brain research has gone through philosophical, experimental, and theoretical phases, with work on neural implants and brain simulation predicted to be important in the future.\n",
      "\n",
      "Modern neuroscience\n",
      "The scientific study of the nervous system increased significantly during the second half of the twentieth century, principally due to advances in molecular biology, electrophysiology, and computational neuroscience. This has allowed neuroscientists to study the nervous system in all its aspects: how it is structured, how it works, how it develops, how it malfunctions, and how it can be changed.\n",
      "For example, it has become possible to understand, in much detail, the complex processes occurring within a single neuron. Neurons are cells specialized for communication. They are able to communicate with neurons and other cell types through specialized junctions called synapses, at which electrical or electrochemical signals can be transmitted from one cell to another. Many neurons extrude a long thin filament of axoplasm called an axon, which may extend to distant parts of the body and are capable of rapidly carrying electrical signals, influencing the activity of other neurons, muscles, or glands at their termination points. A nervous system emerges from the assemblage of neurons that are connected to each other.\n",
      "The vertebrate nervous system can be split into two parts: the central nervous system (defined as the brain and spinal cord), and the peripheral nervous system. In many species—including all vertebrates—the nervous system is the most complex organ system in the body, with most of the complexity residing in the brain. The human brain alone contains around one hundred billion neurons and one hundred trillion synapses; it consists of thousands of distinguishable substructures, connected to each other in synaptic networks whose intricacies have only begun to be unraveled. At least one out of three of the approximately 20,000 genes belonging to the human genome is expressed mainly in the brain.Due to the high degree of plasticity of the human brain, the structure of its synapses and their resulting functions change throughout life.Making sense of the nervous system's dynamic complexity is a formidable research challenge. Ultimately, neuroscientists would like to understand every aspect of the nervous system, including how it works, how it develops, how it malfunctions, and how it can be altered or repaired. Analysis of the nervous system is therefore performed at multiple levels, ranging from the molecular and cellular levels to the systems and cognitive levels. The specific topics that form the main focus of research change over time, driven by an ever-expanding base of knowledge and the availability of increasingly sophisticated technical methods. Improvements in technology have been the primary drivers of progress. Developments in electron microscopy, computer science, electronics, functional neuroimaging, and genetics and genomics have all been major drivers of progress.\n",
      "Perhaps one of the main unsolved problems in modern neuroscience is the so-called \"cell types\" problem which refers to the categorization, definition, and identification of all neuronal/astrocytic cell types in an organism. Usually, this refers to the mouse brain since an understanding of the mouse brain is seen as a stepping stone to understand the human. Modern advances in the classification of neuronal cells have been enabled by electrophysiological recording, single-cell genetic sequencing, and high-quality microscopy, which have been recently combined into a single method pipeline called Patch-seq in which all three methods are simultaneously applied using miniature tools. The efficiency of this method and the large amounts of data that is generated allowed researchers to make some general conclusions about cell types; for example that the human and mouse brain have different versions of fundamentally the same cell types.\n",
      "\n",
      "Molecular and cellular neuroscience\n",
      "Basic questions addressed in molecular neuroscience include the mechanisms by which neurons express and respond to molecular signals and how axons form complex connectivity patterns. At this level, tools from molecular biology and genetics are used to understand how neurons develop and how genetic changes affect biological functions. The morphology, molecular identity, and physiological characteristics of neurons and how they relate to different types of behavior are also of considerable interest.Questions addressed in cellular neuroscience include the mechanisms of how neurons process signals physiologically and electrochemically. These questions include how signals are processed by neurites and somas and how neurotransmitters and electrical signals are used to process information in a neuron. Neurites are thin extensions from a neuronal cell body, consisting of dendrites (specialized to receive synaptic inputs from other neurons) and axons (specialized to conduct nerve impulses called action potentials). Somas are the cell bodies of the neurons and contain the nucleus.Another major area of cellular neuroscience is the investigation of the development of the nervous system. Questions include the patterning and regionalization of the nervous system, axonal and dendritic development, trophic interactions, synapse formation and the implication of fractones in neural stem cells, differentiation of neurons and glia (neurogenesis and gliogenesis), and neuronal migration.Computational neurogenetic modeling is concerned with the development of dynamic neuronal models for modeling brain functions with respect to genes and dynamic interactions between genes, on the cellular level (CNGM can also be used to model neural systems as well).\n",
      "\n",
      "Neural circuits and systems\n",
      "Systems neuroscience research centers on the structural and functional architecture of the developing human brain, and the functions of  large-scale brain networks, or functionally-connected systems within the brain. Alongside brain development, systems neuroscience also focuses on how the structure and function of the brain enables or restricts the processing of sensory information, using learned mental models of the world, to motivate behavior. \n",
      "Questions in systems neuroscience include how neural circuits are formed and used anatomically and physiologically to produce functions such as reflexes, multisensory integration, motor coordination, circadian rhythms, emotional responses, learning, and memory. In other words, this area of research studies how connections are made and morphed in the brain, and the effect it has on human sensation, movement, attention, inhibitory control, decision-making, reasoning, memory formation, reward, and emotion regulation.Specific areas of interest for the field include observations of how the structure of neural circuits effect skill acquisition, how specialized regions of the brain develop and change (neuroplasticity), and the development of brain atlases, or wiring diagrams of individual developing brains.The related fields of neuroethology and neuropsychology address the question of how neural substrates underlie specific animal and human behaviors. Neuroendocrinology and psychoneuroimmunology examine interactions between the nervous system and the endocrine and immune systems, respectively. Despite many advancements, the way that networks of neurons perform complex cognitive processes and behaviors is still poorly understood.\n",
      "\n",
      "Cognitive and behavioral neuroscience\n",
      "Cognitive neuroscience addresses the questions of how psychological functions are produced by neural circuitry. The emergence of powerful new measurement techniques such as neuroimaging (e.g., fMRI, PET, SPECT), EEG, MEG, electrophysiology, optogenetics and human genetic analysis combined with sophisticated experimental techniques from cognitive psychology allows neuroscientists and psychologists to address abstract questions such as how cognition and emotion are mapped to specific neural substrates. Although many studies still hold a reductionist stance looking for the neurobiological basis of cognitive phenomena, recent research shows that there is an interesting interplay between neuroscientific findings and conceptual research, soliciting and integrating both perspectives. For example, neuroscience research on empathy solicited an interesting interdisciplinary debate involving philosophy, psychology and psychopathology. Moreover, the neuroscientific identification of multiple memory systems related to different brain areas has challenged the idea of memory as a literal reproduction of the past, supporting a view of memory as a generative, constructive and dynamic process.Neuroscience is also allied with the social and behavioral sciences, as well as with nascent interdisciplinary fields. Examples of such alliances include neuroeconomics, decision theory, social neuroscience, and neuromarketing to address complex questions about interactions of the brain with its environment. A study into consumer responses for example uses EEG to investigate neural correlates associated with narrative transportation into stories about energy efficiency.\n",
      "\n",
      "Computational neuroscience\n",
      "Questions in computational neuroscience can span a wide range of levels of traditional analysis, such as development, structure, and cognitive functions of the brain. Research in this field utilizes mathematical models, theoretical analysis, and computer simulation to describe and verify biologically plausible neurons and nervous systems. For example, biological neuron models are mathematical descriptions of spiking neurons which can be used to describe both the behavior of single neurons as well as the dynamics of neural networks. Computational neuroscience is often referred to as theoretical neuroscience.\n",
      "Nanoparticles in medicine are versatile in treating neurological disorders showing promising results in mediating drug transport across the blood–brain barrier. Implementing nanoparticles in antiepileptic drugs enhances their medical efficacy by increasing bioavailability in the bloodstream, as well as offering a measure of control in release time concentration. Although nanoparticles can assist therapeutic drugs by adjusting physical properties to achieve desirable effects, inadvertent increases in toxicity often occur in preliminary drug trials. Furthermore, production of nanomedicine for drug trials is economically consuming, hindering progress in their implementation. Computational models in nanoneuroscience provide alternatives to study the efficacy of nanotechnology-based medicines in neurological disorders while mitigating potential side effects and development costs.Nanomaterials often operate at length scales between classical and quantum regimes. Due to the associated uncertainties at the length scales that nanomaterials operate, it is difficult to predict their behavior prior to in vivo studies. Classically, the physical processes which occur throughout neurons are analogous to electrical circuits. Designers focus on such analogies and model brain activity as a neural circuit. Success in computational modeling of neurons have led to the development of stereochemical models that accurately predict acetylcholine receptor-based synapses operating at microsecond time scales.Ultrafine nanoneedles for cellular manipulations are thinner than the smallest single walled carbon nanotubes. Computational quantum chemistry is used to design ultrafine nanomaterials with highly symmetrical structures to optimize geometry, reactivity and stability.Behavior of nanomaterials are dominated by long ranged non-bonding interactions. Electrochemical processes that occur throughout the brain generate an electric field which can inadvertently affect the behavior of some nanomaterials. Molecular dynamics simulations can mitigate the development phase of nanomaterials as well as prevent neural toxicity of nanomaterials following in vivo clinical trials. Testing nanomaterials using molecular dynamics optimizes nano characteristics for therapeutic purposes by testing different environment conditions, nanomaterial shape fabrications, nanomaterial surface properties, etc. without the need for in vivo experimentation. Flexibility in molecular dynamic simulations allows medical practitioners to personalize treatment. Nanoparticle related data from translational nanoinformatics links neurological patient specific data to predict treatment response.\n",
      "\n",
      "Neuroscience and medicine\n",
      "Clinical neuroscience\n",
      "Neurology, psychiatry, neurosurgery, psychosurgery, anesthesiology and pain medicine, neuropathology, neuroradiology, ophthalmology, otolaryngology, clinical neurophysiology, addiction medicine, and sleep medicine are some medical specialties that specifically address the diseases of the nervous system. These terms also refer to clinical disciplines involving diagnosis and treatment of these diseases.Neurology works with diseases of the central and peripheral nervous systems, such as amyotrophic lateral sclerosis (ALS) and stroke, and their medical treatment. Psychiatry focuses on affective, behavioral, cognitive, and perceptual disorders. Anesthesiology focuses on perception of pain, and pharmacologic alteration of consciousness. Neuropathology focuses upon the classification and underlying pathogenic mechanisms of central and peripheral nervous system and muscle diseases, with an emphasis on morphologic, microscopic, and chemically observable alterations. Neurosurgery and psychosurgery work primarily with surgical treatment of diseases of the central and peripheral nervous systems.\n",
      "\n",
      "Translational research\n",
      "Recently, the boundaries between various specialties have blurred, as they are all influenced by basic research in neuroscience. For example, brain imaging enables objective biological insight into mental illnesses, which can lead to faster diagnosis, more accurate prognosis, and improved monitoring of patient progress over time.Integrative neuroscience describes the effort to combine models and information from multiple levels of research to develop a coherent model of the nervous system. For example, brain imaging coupled with physiological numerical models and theories of fundamental mechanisms may shed light on psychiatric disorders.Another important area of translational research is brain–computer interfaces, or machines that are able to communicate and influence the brain. Brain–computer interfaces (BCIs) are currently being researched for their potential to repair neural systems and restore certain cognitive functions. However, some ethical considerations have to be dealt with before they are accepted.\n",
      "\n",
      "Major branches\n",
      "Modern neuroscience education and research activities can be very roughly categorized into the following major branches, based on the subject and scale of the system in examination as well as distinct experimental or curricular approaches. Individual neuroscientists, however, often work on questions that span several distinct subfields.\n",
      "\n",
      "Neuroscience organizations\n",
      "The largest professional neuroscience organization is the Society for Neuroscience (SFN), which is based in the United States but includes many members from other countries. Since its founding in 1969 the SFN has grown steadily: as of 2010 it recorded 40,290 members from 83 countries. Annual meetings, held each year in a different American city, draw attendance from researchers, postdoctoral fellows, graduate students, and undergraduates, as well as educational institutions, funding agencies, publishers, and hundreds of businesses that supply products used in research.\n",
      "Other major organizations devoted to neuroscience include the International Brain Research Organization (IBRO), which holds its meetings in a country from a different part of the world each year, and the Federation of European Neuroscience Societies (FENS), which holds a meeting in a different European city every two years. FENS comprises a set of 32 national-level organizations, including the British Neuroscience Association, the German Neuroscience Society (Neurowissenschaftliche Gesellschaft), and the French Société des Neurosciences. The first National Honor Society in Neuroscience, Nu Rho Psi, was founded in 2006. Numerous youth neuroscience societies which support undergraduates, graduates and early career researchers also exist, such as Simply Neuroscience and Project Encephalon.In 2013, the BRAIN Initiative was announced in the US. The International Brain Initiative was created in 2017, currently integrated by more than seven national-level brain research initiatives (US, Europe, Allen Institute, Japan, China, Australia, Canada, Korea, and Israel) spanning four continents.\n",
      "\n",
      "Public education and outreach\n",
      "In addition to conducting traditional research in laboratory settings, neuroscientists have also been involved in the promotion of awareness and knowledge about the nervous system among the general public and government officials. Such promotions have been done by both individual neuroscientists and large organizations. For example, individual neuroscientists have promoted neuroscience education among young students by organizing the International Brain Bee, which is an academic competition for high school or secondary school students worldwide. In the United States, large organizations such as the Society for Neuroscience have promoted neuroscience education by developing a primer called Brain Facts, collaborating with public school teachers to develop Neuroscience Core Concepts for K-12 teachers and students, and cosponsoring a campaign with the Dana Foundation called Brain Awareness Week to increase public awareness about the progress and benefits of brain research. In Canada, the CIHR Canadian National Brain Bee is held annually at McMaster University.Neuroscience educators formed Faculty for Undergraduate Neuroscience (FUN) in 1992 to share best practices and provide travel awards for undergraduates presenting at Society for Neuroscience meetings.Neuroscientists have also collaborated with other education experts to study and refine educational techniques to optimize learning among students, an emerging field called educational neuroscience. Federal agencies in the United States, such as the National Institute of Health (NIH) and National Science Foundation (NSF), have also funded research that pertains to best practices in teaching and learning of neuroscience concepts.\n",
      "\n",
      "Engineering applications of neuroscience\n",
      "Neuromorphic computer chips\n",
      "Neuromorphic engineering is a branch of neuroscience that deals with creating functional physical models of neurons for the purposes of useful computation. The emergent computational properties of neuromorphic computers are fundamentally different from conventional computers in the sense that they are a complex system, and that the computational components are interrelated with no central processor.One example of such a computer is the SpiNNaker supercomputer.Sensors can also be made smart with neuromorphic technology. An example of this is the Event Camera's BrainScaleS (brain-inspired Multiscale Computation in Neuromorphic Hybrid Systems), a hybrid analog neuromorphic supercomputer located at Heidelberg University in Germany. It was developed as part of the Human Brain Project's neuromorphic computing platform and is the complement to the SpiNNaker supercomputer, which is based on digital technology. The architecture used in BrainScaleS mimics biological neurons and their connections on a physical level; additionally, since the components are made of silicon, these model neurons operate on average 864 times (24 hours of real time is 100 seconds in the machine simulation) that of their biological counterparts.Recent advances in neuromorphic microchip technology have led a group of scientists to create an artificial neuron that can replace real neurons in diseases.\n",
      "\n",
      "Nobel prizes related to neuroscience\n",
      "See also\n",
      "References\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "Neuroscience on In Our Time at the BBC\n",
      "Neuroscience Information Framework (NIF)\n",
      "Neurobiology at Curlie\n",
      "American Society for Neurochemistry\n",
      "British Neuroscience Association (BNA)\n",
      "Federation of European Neuroscience Societies\n",
      "Neuroscience Online (electronic neuroscience textbook)\n",
      "HHMI Neuroscience lecture series - Making Your Mind: Molecules, Motion, and Memory Archived 2013-06-24 at the Wayback Machine\n",
      "Société des Neurosciences\n",
      "Neuroscience For KidsThe Mona Lisa ( MOH-nə LEE-sə; Italian: Gioconda [dʒoˈkonda] or Monna Lisa [ˈmɔnna ˈliːza]; French: Joconde [ʒɔkɔ̃d]) is a half-length portrait painting by Italian artist Leonardo da Vinci. Considered an archetypal masterpiece of the Italian Renaissance, it has been described as \"the best known, the most visited, the most written about, the most sung about, [and] the most parodied work of art in the world\". The painting's novel qualities include the subject's enigmatic expression, monumentality of the composition, the subtle modelling of forms, and the atmospheric illusionism.The painting has been traditionally considered to depict the Italian noblewoman Lisa del Giocondo. It is painted in oil on a white Lombardy poplar panel. Leonardo never gave the painting to the Giocondo family, and it is believed he later left it in his will to his favored apprentice, Salaì. It was believed to have been painted between 1503 and 1506; however, Leonardo may have continued working on it as late as 1517. It was acquired by King Francis I of France and is now the property of the French Republic. It has been on permanent display at the Louvre in Paris since 1797.The painting's global fame and popularity stem from its 1911 theft by Vincenzo Peruggia, who attributed his actions to Italian patriotism—a belief it should belong to Italy. The theft and subsequent recovery in 1914 generated unprecedented publicity for an art theft, and led to the publication of many cultural depictions such as the 1915 opera Mona Lisa, two early 1930s films (The Theft of the Mona Lisa and Arsène Lupin) and the song Mona Lisa recorded by Nat King Cole—one of the most successful songs of the 1950s.The Mona Lisa is one of the most valuable paintings in the world. It holds the Guinness World Record for the highest known painting insurance valuation in history at US$100 million in 1962, equivalent to $1 billion as of 2023.\n",
      "\n",
      "Title and subject\n",
      "The title of the painting, which is known in English as Mona Lisa, is based on the presumption that it depicts Lisa del Giocondo, although her likeness is uncertain. Renaissance art historian Giorgio Vasari wrote that \"Leonardo undertook to paint, for Francesco del Giocondo, the portrait of Mona Lisa, his wife.\" Monna in Italian is a polite form of address originating as ma donna—similar to Ma'am, Madam, or my lady in English. This became madonna, and its contraction monna. The title of the painting, though traditionally spelled Mona in English, is spelled in Italian as Monna Lisa (mona being a vulgarity in Italian), but this is rare in English.Lisa del Giocondo was a member of the Gherardini family of Florence and Tuscany, and the wife of wealthy Florentine silk merchant Francesco del Giocondo. The painting is thought to have been commissioned for their new home, and to celebrate the birth of their second son, Andrea. The Italian name for the painting, La Gioconda, means 'jocund' ('happy' or 'jovial') or, literally, 'the jocund one', a pun on the feminine form of Lisa's married name, Giocondo. In French, the title La Joconde has the same meaning.\n",
      "Vasari's account of the Mona Lisa comes from his biography of Leonardo published in 1550, 31 years after the artist's death. It has long been the best-known source of information on the provenance of the work and identity of the sitter. Leonardo's assistant Salaì, at his death in 1524, owned a portrait which in his personal papers was named la Gioconda, a painting bequeathed to him by Leonardo.That Leonardo painted such a work, and its date, were confirmed in 2005 when a scholar at Heidelberg University discovered a marginal note in a 1477 printing of a volume by ancient Roman philosopher Cicero. Dated October 1503, the note was written by Leonardo's contemporary Agostino Vespucci. This note likens Leonardo to renowned Greek painter Apelles, who is mentioned in the text, and states that Leonardo was at that time working on a painting of Lisa del Giocondo.\n",
      "In response to the announcement of the discovery of this document, Vincent Delieuvin, the Louvre representative, stated \"Leonardo da Vinci was painting, in 1503, the portrait of a Florentine lady by the name of Lisa del Giocondo. About this we are now certain. Unfortunately, we cannot be absolutely certain that this portrait of Lisa del Giocondo is the painting of the Louvre.\"The catalogue raisonné Leonardo da Vinci (2019) confirms that the painting probably depicts Lisa del Giocondo, with Isabella d'Este being the only plausible alternative. Scholars have developed several alternative views, arguing that Lisa del Giocondo was the subject of a different portrait, and identifying at least four other paintings referred to by Vasari as the Mona Lisa. Several other people have been proposed as the subject of the painting, including Isabella of Aragon, Cecilia Gallerani, Costanza d'Avalos, Duchess of Francavilla, Pacifica Brandano/Brandino, Isabella Gualanda, Caterina Sforza, Bianca Giovanna Sforza, Salaì, and even Leonardo himself. Psychoanalyst Sigmund Freud theorized that Leonardo imparted an approving smile from his mother, Caterina, onto the Mona Lisa and other works.\n",
      "\n",
      "Description\n",
      "The Mona Lisa bears a strong resemblance to many Renaissance depictions of the Virgin Mary, who was at that time seen as an ideal for womanhood. The woman sits markedly upright in a \"pozzetto\" armchair with her arms folded, a sign of her reserved posture. Her gaze is fixed on the observer.  The woman appears alive to an unusual extent, which Leonardo achieved by his method of not drawing outlines (sfumato). The soft blending creates an ambiguous mood \"mainly in two features: the corners of the mouth, and the corners of the eyes\".The depiction of the sitter in three-quarter profile is similar to late 15th-century works by Lorenzo di Credi and Agnolo di Domenico del Mazziere. Zöllner notes that the sitter's general position can be traced back to Flemish models and that \"in particular the vertical slices of columns at both sides of the panel had precedents in Flemish portraiture.\" Woods-Marsden cites Hans Memling's portrait of Benedetto Portinari (1487) or Italian imitations such as Sebastiano Mainardi's pendant portraits for the use of a loggia, which has the effect of mediating between the sitter and the distant landscape, a feature missing from Leonardo's earlier portrait of Ginevra de' Benci.\n",
      "The painting was one of the first Italian portraits to depict the sitter in front of an imaginary landscape, and Leonardo was one of the first painters to use aerial perspective. The enigmatic woman is portrayed seated in what appears to be an open loggia with dark pillar bases on either side. Behind her, a vast landscape recedes to icy mountains, winding paths and a distant bridge, giving only the slightest indications of human presence. Leonardo has chosen to place the horizon line not at the neck, as he did with Ginevra de' Benci, but on a level with the eyes, thus linking the figure with the landscape and emphasizing the mysterious nature of the painting. The bridge in the background was identified by Silvano Vincenti as the four-arched Romito di Laterina bridge from Etruscan-Roman times near Laterina, Arezzo over the Arno river. Other bridges with similar arches suggested as possible locations had more arches.Mona Lisa has no clearly visible eyebrows or eyelashes, although Vasari describes the eyebrows in detail. In 2007, French engineer Pascal Cotte announced that his ultra-high resolution scans of the painting provide evidence that Mona Lisa was originally painted with eyelashes and eyebrows, but that these had gradually disappeared over time, perhaps as a result of overcleaning. Cotte discovered that the painting had been reworked several times, with changes made to the size of the face and the direction of gaze. He also found that in one layer the subject was depicted wearing numerous hairpins and a headdress adorned with pearls which was later scrubbed out and overpainted.There has been much speculation regarding the painting's model and landscape. For example, Leonardo probably painted his model faithfully since her beauty is not seen as being among the best, \"even when measured by late quattrocento (15th century) or even twenty-first century standards.\" Some historians in Eastern art, such as Yukio Yashiro, argue that the landscape in the background of the picture was influenced by Chinese paintings, but this thesis has been contested for lack of clear evidence.Research in 2003 by Professor Margaret Livingstone of Harvard University said that Mona Lisa's smile disappears when observed with direct vision, known as foveal. Because of the way the human eye processes visual information, it is less suited to pick up shadows directly; however, peripheral vision can pick up shadows well.Research in 2008 by a geomorphology professor at Urbino University and an artist-photographer revealed that Mona Lisa's landscape was similar to some views in the Montefeltro region in the Italian provinces of Pesaro and Urbino, and Rimini.\n",
      "\n",
      "History\n",
      "Creation and date\n",
      "Of Leonardo da Vinci's works, the Mona Lisa is the only portrait whose authenticity has never been seriously questioned, and one of four works – the others being Saint Jerome in the Wilderness, Adoration of the Magi and The Last Supper – whose attribution has avoided controversy. He had begun working on a portrait of Lisa del Giocondo, the model of the Mona Lisa, by October 1503. It is believed by some that the Mona Lisa was begun in 1503 or 1504 in Florence. Although the Louvre states that it was \"doubtless painted between 1503 and 1506\", art historian Martin Kemp says that there are some difficulties in confirming the dates with certainty. Alessandro Vezzosi believes that the painting is characteristic of Leonardo's style in the final years of his life, post-1513. Other academics argue that, given the historical documentation, Leonardo would have painted the work from 1513. According to Vasari, \"after he had lingered over it four years, [he] left it unfinished\". In 1516, Leonardo was invited by King Francis I to work at the Clos Lucé near the Château d'Amboise; it is believed that he took the Mona Lisa with him and continued to work on it after he moved to France. Art historian Carmen C. Bambach has concluded that Leonardo probably continued refining the work until 1516 or 1517. Leonardo's right hand was paralytic c. 1517, which may indicate why he left the Mona Lisa unfinished.\n",
      "c. 1505, Raphael executed a pen-and-ink sketch, in which the columns flanking the subject are more apparent. Experts universally agree that it is based on Leonardo's portrait. Other later copies of the Mona Lisa, such as those in the National Museum of Art, Architecture and Design and The Walters Art Museum, also display large flanking columns. As a result, it was thought that the Mona Lisa had been trimmed. However, by 1993, Frank Zöllner observed that the painting surface had never been trimmed; this was confirmed through a series of tests in 2004. In view of this, Vincent Delieuvin, curator of 16th-century Italian painting at the Louvre, states that the sketch and these other copies must have been inspired by another version, while Zöllner states that the sketch may be after another Leonardo portrait of the same subject.The record of an October 1517 visit by Louis d'Aragon states that the Mona Lisa was executed for the deceased Giuliano de' Medici, Leonardo's steward at Belvedere, Vienna, between 1513 and 1516—but this was likely an error. According to Vasari, the painting was created for the model's husband, Francesco del Giocondo. A number of experts have argued that Leonardo made two versions (because of the uncertainty concerning its dating and commissioner, as well as its fate following Leonardo's death in 1519, and the difference of details in Raphael's sketch—which may be explained by the possibility that he made the sketch from memory). The hypothetical first portrait, displaying prominent columns, would have been commissioned by Giocondo c. 1503, and left unfinished in Leonardo's pupil and assistant Salaì's possession until his death in 1524. The second, commissioned by Giuliano de' Medici c. 1513, would have been sold by Salaì to Francis I in 1518 and is the one in the Louvre today. Others believe that there was only one true Mona Lisa but are divided as to the two aforementioned fates. At some point in the 16th century, a varnish was applied to the painting. It was kept at the Palace of Fontainebleau until Louis XIV moved it to the Palace of Versailles, where it remained until the French Revolution. In 1797, it went on permanent display at the Louvre.\n",
      "\n",
      "Refuge, theft, and vandalism\n",
      "After the French Revolution, the painting was moved to the Louvre, but spent a brief period in the bedroom of Napoleon (d. 1821) in the Tuileries Palace. The Mona Lisa was not widely known outside the art world, but in the 1860s, a portion of the French intelligentsia began to hail it as a masterwork of Renaissance painting.\n",
      "During the Franco-Prussian War (1870–1871), the painting was moved from the Louvre to the Brest Arsenal.In 1911, the painting was still not popular among the lay-public. On 21 August 1911, the painting was stolen from the Louvre. The painting was first missed the next day by painter Louis Béroud. After some confusion as to whether the painting was being photographed somewhere, the Louvre was closed for a week for investigation. French poet Guillaume Apollinaire came under suspicion and was arrested and imprisoned. Apollinaire implicated his friend Pablo Picasso, who was brought in for questioning. Both were later exonerated. The real culprit was Louvre employee Vincenzo Peruggia, who had helped construct the painting's glass case. He carried out the theft by entering the building during regular hours, hiding in a broom closet, and walking out with the painting hidden under his coat after the museum had closed.\n",
      " \n",
      "Peruggia was an Italian patriot who believed that Leonardo's painting should have been returned to an Italian museum. Peruggia may have been motivated by an associate whose copies of the original would significantly rise in value after the painting's theft. After having kept the Mona Lisa in his apartment for two years, Peruggia grew impatient and was caught when he attempted to sell it to Giovanni Poggi, director of the Uffizi Gallery in Florence. It was exhibited in the Uffizi Gallery for over two weeks and returned to the Louvre on 4 January 1914. Peruggia served six months in prison for the crime and was hailed for his patriotism in Italy. A year after the theft, Saturday Evening Post journalist Karl Decker wrote that he met an alleged accomplice named Eduardo de Valfierno, who claimed to have masterminded the theft. Forger Yves Chaudron was to have created six copies of the painting to sell in the US while concealing the location of the original. Decker published this account of the theft in 1932.During World War II, it was again removed from the Louvre and taken first to the Château d'Amboise, then to the Loc-Dieu Abbey and Château de Chambord, then finally to the Ingres Museum in Montauban.On 30 December 1956, Bolivian Ugo Ungaza Villegas threw a rock at the Mona Lisa while it was on display at the Louvre. He did so with such force that it shattered the glass case and dislodged a speck of pigment near the left elbow. The painting was protected by glass because a few years earlier a man who claimed to be in love with the painting had cut it with a razor blade and tried to steal it. Since then, bulletproof glass has been used to shield the painting from any further attacks. Subsequently, on 21 April 1974, while the painting was on display at the Tokyo National Museum, a woman sprayed it with red paint as a protest against that museum's failure to provide access for disabled people. On 2 August 2009, a Russian woman, distraught over being denied French citizenship, threw a ceramic teacup purchased at the Louvre; the vessel shattered against the glass enclosure. In both cases, the painting was undamaged.\n",
      "In recent decades, the painting has been temporarily moved to accommodate renovations to the Louvre on three occasions: between 1992 and 1995, from 2001 to 2005, and again in 2019. A new queuing system introduced in 2019 reduces the amount of time museum visitors have to wait in line to see the painting. After going through the queue, a group has about 30 seconds to see the painting.On 29 May 2022, a male activist, disguised as a woman in a wheelchair, threw cake at the protective glass covering the painting in an apparent attempt to raise awareness for climate change. The painting was not damaged. The man was arrested and placed in psychiatric care in the police headquarters. An investigation was opened after the Louvre filed a complaint.\n",
      "\n",
      "Modern analysis\n",
      "In the early 21st century, French scientist Pascal Cotte hypothesized a hidden portrait underneath the surface of the painting. He analyzed the painting in the Louvre with  reflective light technology beginning in 2004, and produced circumstantial evidence for his theory. Cotte admits that his investigation was carried out only in support of his hypotheses and should not be considered as definitive proof. The underlying portrait appears to be of a model looking to the side, and lacks flanking columns, but does not fit with historical descriptions of the painting. Both Vasari and Gian Paolo Lomazzo describe the subject as smiling, unlike the subject in Cotte's supposed portrait. In 2020, Cotte published a study alleging that the painting has an underdrawing, transferred from a preparatory drawing via the spolvero technique.\n",
      "\n",
      "Conservation\n",
      "The Mona Lisa has survived for more than 500 years, and an international commission convened in 1952 noted that \"the picture is in a remarkable state of preservation.\" It has never been fully restored, so the current condition is partly due to a variety of conservation treatments the painting has undergone. A detailed analysis in 1933 by Madame de Gironde revealed that earlier restorers had \"acted with a great deal of restraint.\" Nevertheless, applications of varnish made to the painting had darkened even by the end of the 16th century, and an aggressive 1809 cleaning and revarnishing removed some of the uppermost portion of the paint layer, resulting in a washed-out appearance to the face of the figure. Despite the treatments, the Mona Lisa has been well cared for throughout its history, and although the panel's warping caused the curators \"some worry\", the 2004–05 conservation team was optimistic about the future of the work.\n",
      "\n",
      "Poplar panel\n",
      "At some point, the Mona Lisa was removed from its original frame. The unconstrained poplar panel warped freely with changes in humidity, and as a result, a crack developed near the top of the panel, extending down to the hairline of the figure. In the mid-18th century to early 19th century, two butterfly-shaped walnut braces were inserted into the back of the panel to a depth of about one third the thickness of the panel. This intervention was skilfully executed, and successfully stabilized the crack. Sometime between 1888 and 1905, or perhaps during the picture's theft, the upper brace fell out. A later restorer glued and lined the resulting socket and crack with cloth.The picture is kept under strict, climate-controlled conditions in its bulletproof glass case. The humidity is maintained at 50% ±10%, and the temperature is maintained between 18 and 21 °C. To compensate for fluctuations in relative humidity, the case is supplemented with a bed of silica gel treated to provide 55% relative humidity.\n",
      "\n",
      "Frame\n",
      "Because the Mona Lisa's poplar support expands and contracts with changes in humidity, the picture has experienced some warping. In response to warping and swelling experienced during its storage during World War II, and to prepare the picture for an exhibit to honour the anniversary of Leonardo's 500th birthday, the Mona Lisa was fitted in 1951 with a flexible oak frame with beech crosspieces. This flexible frame, which is used in addition to the decorative frame described below, exerts pressure on the panel to keep it from warping further. In 1970, the beech crosspieces were switched to maple after it was found that the beechwood had been infested with insects. In 2004–05, a conservation and study team replaced the maple crosspieces with sycamore ones, and an additional metal crosspiece was added for scientific measurement of the panel's warp.The Mona Lisa has had many different decorative frames in its history, owing to changes in taste over the centuries. In 1909, the art collector Comtesse de Béhague gave the portrait its current frame, a Renaissance-era work consistent with the historical period of the Mona Lisa. The edges of the painting have been trimmed at least once in its history to fit the picture into various frames, but no part of the original paint layer has been trimmed.\n",
      "\n",
      "Cleaning and touch-up\n",
      "The first and most extensive recorded cleaning, revarnishing, and touch-up of the Mona Lisa was an 1809 wash and revarnishing undertaken by Jean-Marie Hooghstoel, who was responsible for restoration of paintings for the galleries of the Musée Napoléon. The work involved cleaning with spirits, touch-up of colour, and revarnishing the painting. In 1906, Louvre restorer Eugène Denizard performed watercolour retouches on areas of the paint layer disturbed by the crack in the panel. Denizard also retouched the edges of the picture with varnish, to mask areas that had been covered initially by an older frame. In 1913, when the painting was recovered after its theft, Denizard was again called upon to work on the Mona Lisa. Denizard was directed to clean the picture without solvent, and to lightly touch up several scratches to the painting with watercolour. In 1952, the varnish layer over the background in the painting was evened out. After the second 1956 attack, restorer Jean-Gabriel Goulinat was directed to touch up the damage to Mona Lisa's left elbow with watercolour.In 1977, a new insect infestation was discovered in the back of the panel as a result of crosspieces installed to keep the painting from warping. This was treated on the spot with carbon tetrachloride, and later with an ethylene oxide treatment. In 1985, the spot was again treated with carbon tetrachloride as a preventive measure.\n",
      "\n",
      "Display\n",
      "On 6 April 2005—following a period of curatorial maintenance, recording, and analysis—the painting was moved to a new location within the museum's Salle des États. It is displayed in a purpose-built, climate-controlled enclosure behind bulletproof glass. Since 2005 the painting has been illuminated by an LED lamp, and in 2013 a new 20 watt LED lamp was installed, specially designed for this painting. The lamp has a Colour Rendering Index up to 98, and minimizes infrared and ultraviolet radiation which could otherwise degrade the painting. The renovation of the gallery where the painting now resides was financed by the Japanese broadcaster Nippon Television. As of 2019, about 10.2 million people view the painting at the Louvre each year.On the 500th anniversary of the master's death, the Louvre held the largest ever single exhibit of Leonardo works, from 24 October 2019 to 24 February 2020. The Mona Lisa was not included because it is in such great demand among visitors to the museum; the painting remained on display in its gallery.\n",
      "\n",
      "Legacy\n",
      "The Mona Lisa began influencing contemporary Florentine painting even before its completion. Raphael, who had been to Leonardo's workshop several times, promptly used elements of the portrait's composition and format in several of his works, such as Young Woman with Unicorn (c. 1506), and Portrait of Maddalena Doni (c. 1506). Later paintings by Raphael, such as La velata (1515–16) and Portrait of Baldassare Castiglione (c. 1514–15), continued to borrow from Leonardo's painting. Zollner states that \"None of Leonardo's works would exert more influence upon the evolution of the genre than the Mona Lisa.  It became the definitive example of the Renaissance portrait and perhaps for this reason is seen not just as the likeness of a real person, but also as the embodiment of an ideal.\"Early commentators such as Vasari and André Félibien praised the picture for its realism, but by the Victorian era, writers began to regard the Mona Lisa as imbued with a sense of mystery and romance.  In 1859, Théophile Gautier wrote that the Mona Lisa was a \"sphinx of beauty who smiles so mysteriously\" and that \"Beneath the form expressed one feels a thought that is vague, infinite, inexpressible. One is moved, troubled ... repressed desires, hopes that drive one to despair, stir painfully.\" Walter Pater's famous essay of 1869 described the sitter as \"older than the rocks among which she sits; like the vampire, she has been dead many times, and learned the secrets of the grave; and has been a diver in the deep seas, and keeps their fallen day about her.\"By the early 20th century, some critics started to feel the painting had become a repository for subjective exegeses and theories. Upon the painting's theft in 1911, Renaissance historian Bernard Berenson admitted that it had \"simply become an incubus, and [he] was glad to be rid of her.\" Jean Metzinger's Le goûter (Tea Time) was exhibited at the 1911 Salon d'Automne and was sarcastically described as \"la Joconde à la cuiller\" (Mona Lisa with a spoon) by art critic Louis Vauxcelles on the front page of Gil Blas. André Salmon subsequently described the painting as \"The Mona Lisa of Cubism\".The avant-garde art world has made note of the Mona Lisa's undeniable popularity. Because of the painting's overwhelming stature, Dadaists and Surrealists often produce modifications and caricatures. In 1883, Le rire, an image of a Mona Lisa smoking a pipe, by Sapeck (Eugène Bataille), was shown at the \"Incoherents\" show in Paris. In 1919, Marcel Duchamp, one of the most influential modern artists, created L.H.O.O.Q., a Mona Lisa parody made by adorning a cheap reproduction with a moustache and goatee. Duchamp added an inscription, which when read out loud in French sounds like \"Elle a chaud au cul\" meaning: \"she has a hot ass\", implying the woman in the painting is in a state of sexual excitement and intended as a Freudian joke. According to Rhonda R. Shearer, the apparent reproduction is in fact a copy partly modelled on Duchamp's own face.Salvador Dalí, famous for his surrealist work, painted Self portrait as Mona Lisa in 1954. Andy Warhol created serigraph prints of multiple Mona Lisas, called Thirty Are Better than One, following the painting's visit to the United States in 1963. The French urban artist known pseudonymously as Invader has created versions of the Mona Lisa on city walls in Paris and Tokyo using a mosaic style. A 2014 New Yorker magazine cartoon parodies the supposed enigma of the Mona Lisa smile in an animation showing progressively more maniacal smiles.\n",
      "\n",
      "Fame\n",
      "Today the Mona Lisa is considered the most famous painting in the world, a destination painting, but until the 20th century it was simply one among many highly regarded artworks.\n",
      "Once part of King Francis I of France's collection, the Mona Lisa was among the first artworks to be exhibited in the Louvre, which became a national museum after the French Revolution. Leonardo began to be revered as a genius, and the painting's popularity grew in the mid-19th century when French intelligentsia praised it as mysterious and a representation of the femme fatale. The Baedeker guide in 1878 called it \"the most celebrated work of Leonardo in the Louvre\", but the painting was known more by the intelligentsia than the general public.The 1911 theft of the Mona Lisa and its subsequent return was reported worldwide, leading to a massive increase in public recognition of the painting. During the 20th century it was an object for mass reproduction, merchandising, lampooning and speculation, and was claimed to have been reproduced in \"300 paintings and 2,000 advertisements\". The Mona Lisa was regarded as \"just another Leonardo until early last century, when the scandal of the painting's theft from the Louvre and subsequent return kept a spotlight on it over several years.\"\n",
      "From December 1962 to March 1963, the French government lent it to the United States to be displayed in New York City and Washington, D.C. It was shipped on the new ocean liner SS France. In New York, an estimated 1.7 million people queued \"in order to cast a glance at the Mona Lisa for 20 seconds or so.\" While exhibited in the Metropolitan Museum of Art, the painting was nearly drenched in water because of a faulty sprinkler, but the painting's bullet-proof glass case protected it.In 1974, the painting was exhibited in Tokyo and Moscow.In 2014, 9.3 million people visited the Louvre. Former director Henri Loyrette reckoned that \"80 percent of the people only want to see the Mona Lisa.\"\n",
      "\n",
      "Financial worth\n",
      "Before the 1962–1963 tour, the painting was assessed for insurance at $100 million (equivalent to $740 million in 2022), making it, in practice, the most highly-valued painting in the world. The insurance was not purchased; instead, more was spent on security.In 2014, a France 24 article suggested that the painting could be sold to help ease the national debt, although it was observed that the Mona Lisa and other such art works were prohibited from being sold by French heritage law, which states that \"Collections held in museums that belong to public bodies are considered public property and cannot be otherwise.\"\n",
      "\n",
      "Cultural depictions\n",
      "Cultural depictions of the Mona Lisa include: \n",
      "\n",
      "The 1915 Mona Lisa by German composer Max von Schillings.\n",
      "Two 1930s films written about the theft, (The Theft of the Mona Lisa and Arsène Lupin).\n",
      "The 1950 song \"Mona Lisa\" recorded by Nat King Cole.\n",
      "The 2011 song \"The Ballad of Mona Lisa\" by American rock band Panic! at the Disco.\n",
      "The 2022 mystery film Glass Onion: A Knives Out Mystery depicts the destruction of the Mona Lisa, which has been borrowed from its location by a billionaire.\n",
      "\n",
      "Early versions and copies\n",
      "Prado Museum La Gioconda\n",
      "A version of Mona Lisa known as Mujer de mano de Leonardo Abince (\"Woman by Leonardo da Vinci's hand\", Museo del Prado, Madrid) was for centuries considered to be a work by Leonardo. However, since its restoration in 2012, it is now thought to have been executed by one of Leonardo's pupils in his studio at the same time as Mona Lisa was being painted. The Prado's conclusion that the painting is probably by Salaì (1480–1524) or by Melzi (1493–1572) has been called into question by others.The restored painting is from a slightly different perspective than the original Mona Lisa, leading to the speculation that it is part of the world's first stereoscopic pair. However, a more recent report has demonstrated that this stereoscopic pair in fact gives no reliable stereoscopic depth.\n",
      "\n",
      "Isleworth Mona Lisa\n",
      "A version of the Mona Lisa known as the Isleworth Mona Lisa was first bought by an English nobleman in 1778 and was rediscovered in 1913 by Hugh Blaker, an art connoisseur. The painting was presented to the media in 2012 by the Mona Lisa Foundation. It is a painting of the same subject as Leonardo da Vinci's Mona Lisa. The current scholarly consensus on attribution is unclear. Some experts, including Frank Zöllner, Martin Kemp and Luke Syson denied the attribution to Leonardo; professors such as Salvatore Lorusso, Andrea Natali, and John F Asmus supported it; others like Alessandro Vezzosi and Carlo Pedretti were uncertain.\n",
      "\n",
      "Hermitage Mona Lisa\n",
      "A version known as the Hermitage Mona Lisa is in the Hermitage Museum and it was made by an unknown 16th-century artist.\n",
      "\n",
      "The Mona Lisa illusion\n",
      "If a person being photographed looks into the camera lens, the image produced provides an illusion that viewers perceive as the subject looking at them, irrespective of the photographs' position. It is presumably for this reason that many people, while taking photographs, ask subjects to look at the camera rather than anywhere else. In psychology, this is known as \"the Mona Lisa illusion\" after the famous painting which also presents the same illusion.\n",
      "\n",
      "See also\n",
      "List of works by Leonardo da Vinci\n",
      "List of most expensive paintings\n",
      "List of stolen paintings\n",
      "Speculations about Mona Lisa\n",
      "Male Mona Lisa theories\n",
      "Two-Mona Lisa theory\n",
      "\n",
      "Footnotes\n",
      "References\n",
      "Sources\n",
      "External links\n",
      "\n",
      "Sassoon, Donald (21 January 2014). #26: Why is the Mona Lisa Famous?. La Trobe University podcast blog. Archived from the original on 4 July 2015.  of the podcast audio.\n",
      "\"Mona Lisa, Leonardo's Earlier Version\". Zürich, Switzerland: The Mona Lisa Foundation. 14 October 2012. Archived from the original on 26 June 2015. Retrieved 5 November 2015.\n",
      "\"True Colors of the Mona Lisa Revealed\" (Press release). Paris: Lumiere Technology. 19 October 2006. Archived from the original on 26 June 2015. Retrieved 5 November 2015.\n",
      "Scientific analyses conducted by the Center for Research and Restoration of the Museums of France (C2RMF) Compare layers of the painting as revealed by x-radiography, infrared reflectography and ultraviolet fluorescence\n",
      "\"Stealing Mona Lisa\". Dorothy & Thomas Hoobler. May 2009. excerpt of book. Vanity Fair\n",
      "Discussion by Janina Ramirez and Martin Kemp: Art Detective Podcast, 18 Jan 2017\n",
      "Leonardo's Mona Lisa Archived 4 November 2014 at the Wayback Machine, Smarthistory (video)\n",
      "Secrets of the Mona Lisa, Discovery Channel documentary on YouTube\n",
      "The Tricks of Leonardo da Vinci & Hieronymus Bosch. Xavier d'Hérouville & Aurore Caulier. December 2023. HAL Open ScienceMachine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks. ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\n",
      "The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning. From a theoretical point of view Probably approximately correct learning provides a framework for describing machine learning.\n",
      "\n",
      "History and relationships to other fields\n",
      "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.By the early 1960s an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to re-evaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".Modern-day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.\n",
      "\n",
      "Artificial intelligence\n",
      "As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics. Probabilistic reasoning was also employed, especially in automated medical diagnosis.: 488 However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.: 488  By 1980, expert systems had come to dominate AI, and statistics was out of favor. Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming, but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.: 708–710, 755  Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including Hopfield, Rumelhart, and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.: 25 Machine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.\n",
      "\n",
      "Data mining\n",
      "Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\n",
      "Machine learning also has intimate ties to optimization: many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the pre-assigned labels of a set of examples).\n",
      "\n",
      "Generalization\n",
      "The difference between optimization and machine learning arises from the goal of generalization: while optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples. Characterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\n",
      "\n",
      "Statistics\n",
      "Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns. According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics. He also suggested the term data science as a placeholder to call the overall field.Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.Leo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model, wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\n",
      "Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.\n",
      "\n",
      "Statistical Physics\n",
      "Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks. Statistical physics is thus finding applications in the area of medical diagnostics.\n",
      "\n",
      "Theory\n",
      "A core objective of a learner is to generalize from its experience. Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\n",
      "The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.\n",
      "For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\n",
      "\n",
      "Approaches\n",
      "Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n",
      "\n",
      "Supervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\n",
      "Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\n",
      "Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximize.Although each algorithm has advantages and limitations, no single algorithm works for all problems.\n",
      "\n",
      "Supervised learning\n",
      "Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs. The data is known as training data, and consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal.  In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs. An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.Types of supervised-learning algorithms include active learning, classification and regression. Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email.\n",
      "Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.\n",
      "\n",
      "Unsupervised learning\n",
      "Unsupervised learning algorithms find structures in data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction, and density estimation. Unsupervised learning algorithms also streamlined the process of identifying large indel based haplotypes of a gene of interest from pan-genome.\n",
      "Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\n",
      "\n",
      "Semi-supervised learning\n",
      "Semi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.\n",
      "In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.\n",
      "\n",
      "Reinforcement learning\n",
      "Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques. Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\n",
      "\n",
      "Dimensionality reduction\n",
      "Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables. In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). This results in a smaller dimension of data (2D instead of 3D), while keeping all original variables in the model without changing the data.\n",
      "The manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.\n",
      "\n",
      "Other types\n",
      "Other approaches have been developed which do not fit neatly into this three-fold categorization, and sometimes more than one is used by the same machine learning system. For example, topic modeling, meta-learning.\n",
      "\n",
      "Self-learning\n",
      "Self-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA). It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.\n",
      "The self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: \n",
      "\n",
      "in situation s perform action a\n",
      "receive consequence situation s\n",
      "compute emotion of being in consequence situation v(s')\n",
      "update crossbar memory  w'(a,s) = w(a,s) + v(s')It is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.\n",
      "\n",
      "Feature learning\n",
      "Several learning algorithms aim at discovering better representations of the inputs provided during training. Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\n",
      "Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabeled input data.  Examples include dictionary learning, independent component analysis, autoencoders, matrix factorization and various forms of clustering.Manifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors. Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\n",
      "\n",
      "Sparse dictionary learning\n",
      "Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions, and is assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately. A popular heuristic method for sparse dictionary learning is the K-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.\n",
      "\n",
      "Anomaly detection\n",
      "In data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.Three broad categories of anomaly detection techniques exist. Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference to many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.\n",
      "\n",
      "Robot learning\n",
      "Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning, and finally meta-learning (e.g. MAML).\n",
      "\n",
      "Association rules\n",
      "Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction. Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\n",
      "Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets. For example, the rule \n",
      "  \n",
      "    \n",
      "      \n",
      "        {\n",
      "        \n",
      "          o\n",
      "          n\n",
      "          i\n",
      "          o\n",
      "          n\n",
      "          s\n",
      "          ,\n",
      "          p\n",
      "          o\n",
      "          t\n",
      "          a\n",
      "          t\n",
      "          o\n",
      "          e\n",
      "          s\n",
      "        \n",
      "        }\n",
      "        ⇒\n",
      "        {\n",
      "        \n",
      "          b\n",
      "          u\n",
      "          r\n",
      "          g\n",
      "          e\n",
      "          r\n",
      "        \n",
      "        }\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\n",
      "   found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\n",
      "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\n",
      "Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting. Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples. The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\n",
      "\n",
      "Models\n",
      "Performing machine learning can involve creating a model, which is trained on some training data and then can process additional data to make predictions. Various types of models have been used and researched for machine learning systems.\n",
      "\n",
      "Artificial neural networks\n",
      "Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\n",
      "An ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\n",
      "The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\n",
      "Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.\n",
      "\n",
      "Decision trees\n",
      "Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\n",
      "\n",
      "Support-vector machines\n",
      "Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.  An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
      "\n",
      "Regression analysis\n",
      "Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\n",
      "\n",
      "Bayesian networks\n",
      "A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\n",
      "\n",
      "Gaussian processes\n",
      "A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\n",
      "Given a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.\n",
      "Gaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.\n",
      "\n",
      "Genetic algorithms\n",
      "A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s. Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.\n",
      "\n",
      "Belief functions\n",
      "The theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and  imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster's rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and Uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving. However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead a much higher computation time when compared to other machine learning approaches.\n",
      "\n",
      "Training models\n",
      "Typically, machine learning models require a high quantity of reliable data in order for the models to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Bias models may result in detrimental outcomes thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably be integrated within machine learning engineering teams.\n",
      "\n",
      "Federated learning\n",
      "Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.\n",
      "\n",
      "Applications\n",
      "There are many applications for machine learning, including:\n",
      "\n",
      "In 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million. Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly. In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis. In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software. In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists. In 2019 Springer Nature published the first research book created using machine learning. In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19. Machine learning was recently applied to predict the pro-environmental behavior of travelers. Recently, machine learning technology was also applied to optimize smartphone's performance and thermal behavior based on the user's interaction with the phone. When applied correctly, machine learning algorithms (MLAs) can utilize a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.\n",
      "\n",
      "Limitations\n",
      "Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results. Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.The \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data. The House of Lords Select Committee, which claimed that such an “intelligence system” that could have a “substantial impact on an individual’s life” would not be considered acceptable unless it provided “a full and satisfactory explanation for the decisions” it makes.In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision. Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested. Microsoft's chatbot has been reported to produce hostile and offensive response against its users.Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.\n",
      "\n",
      "Bias\n",
      "Machine learning approaches in particular can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.Language models learned from data have been shown to contain human-like biases. An experiment carried out by ProPublica, a predictive policing company, regarding machine learning algorithm’s insight towards the recidivism rates among prisoners falsely flagged “black defendants high risk twice as often as white defendants.” In 2015, Google photos would often tag black people as gorillas, and in 2018 this still was not well resolved, but Google reportedly was still using the workaround to remove all gorillas from the training data, and thus was not able to recognize real gorillas at all. Similar issues with recognizing non-white people have been found in many other systems. In 2016, Microsoft tested a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains. Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who reminds engineers that \"There's nothing artificial about AI...It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"\n",
      "\n",
      "Explainability\n",
      "Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI. It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision. By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\n",
      "\n",
      "Overfitting\n",
      "Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalizing the theory in accordance with how complex the theory is.\n",
      "\n",
      "Other limitations and vulnerabilities\n",
      "Learners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses. A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel. Machine learning models are often vulnerable to manipulation and/or evasion via adversarial machine learning.Researchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and well-visible \"not spam\" of posts) machine learning models which are often developed and/or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.\n",
      "\n",
      "Model assessments\n",
      "Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).\n",
      "\n",
      "Ethics\n",
      "Machine learning poses a host of ethical questions. Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices. For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to be either women or had non-European sounding names. Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants. Another example includes predictive policing company Geolitica's predictive algorithm that resulted in “disproportionately high levels of over-policing in low-income and minority communities” after being trained with historical crime data.While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases. In fact, according to research carried out by the Computing Research Association (CRA) in 2021, “female faculty merely make up 16.1%” of all faculty members who focus on AI among several universities around the world. Furthermore, among the group of “new U.S. resident AI PhD graduates,” 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning. Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines. This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.\n",
      "\n",
      "Hardware\n",
      "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of non-linear hidden units. By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI. OpenAI estimated the hardware computing used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.\n",
      "\n",
      "Neuromorphic/Physical Neural Networks\n",
      "A physical neural network or Neuromorphic computer  is a type of artificial neural network in which an electrically adjustable material is used to emulate the function of a neural synapse. \"Physical\" neural network is used to emphasize the reliance on physical hardware used to emulate neurons as opposed to software-based approaches. More generally the term is applicable to other artificial neural networks in which a memristor or other electrically adjustable resistance material is used to emulate a neural synapse.\n",
      "\n",
      "Embedded Machine Learning\n",
      "Embedded Machine Learning is a sub-field of machine learning, where the machine learning model is run on embedded systems with limited computing resources such as wearable computers, edge devices and microcontrollers. Running machine learning model in embedded devices removes the need for transferring and storing data on cloud servers for further processing, henceforth, reducing data breaches and privacy leaks happening because of transferring data, and also minimizes theft of intellectual properties, personal data and business secrets. Embedded Machine Learning could be applied through several techniques including hardware acceleration, using approximate computing, optimization of machine learning models and many more.\n",
      "\n",
      "Software\n",
      "Software suites containing a variety of machine learning algorithms include the following:\n",
      "\n",
      "Free and open-source software\n",
      "Proprietary software with free and open-source editions\n",
      "KNIME\n",
      "RapidMiner\n",
      "\n",
      "Proprietary software\n",
      "Journals\n",
      "Journal of Machine Learning Research\n",
      "Machine Learning\n",
      "Nature Machine Intelligence\n",
      "Neural Computation\n",
      "IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
      "\n",
      "Conferences\n",
      "AAAI Conference on Artificial Intelligence\n",
      "Association for Computational Linguistics (ACL)\n",
      "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\n",
      "International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\n",
      "International Conference on Machine Learning (ICML)\n",
      "International Conference on Learning Representations (ICLR)\n",
      "International Conference on Intelligent Robots and Systems (IROS)\n",
      "Conference on Knowledge Discovery and Data Mining (KDD)\n",
      "Conference on Neural Information Processing Systems (NeurIPS)\n",
      "\n",
      "See also\n",
      "Automated machine learning – Process of automating the application of machine learning\n",
      "Big data – Extremely large or complex datasets\n",
      "Differentiable programming – Programming paradigm\n",
      "Force control\n",
      "List of important publications in machine learning\n",
      "List of datasets for machine-learning research\n",
      "\n",
      "References\n",
      "Sources\n",
      "Domingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0465065707.\n",
      "Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n",
      "Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.\n",
      "Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n",
      "\n",
      "Further reading\n",
      "External links\n",
      "\n",
      " Quotations related to Machine learning at Wikiquote\n",
      "International Machine Learning Society\n",
      "mloss is an academic database of open-source machine learning software.The Amazon rainforest, also called Amazon jungle or Amazonia, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km2 (2,700,000 sq mi), of which 5,500,000 km2 (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations and 3,344 formally acknowledged indigenous territories.\n",
      "The majority of the forest, 60%, is in Brazil, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Bolivia, Ecuador, French Guiana, Guyana, Suriname, and Venezuela. Four nations have \"Amazonas\" as the name of one of their first-level administrative regions, and France uses the name \"Guiana Amazonian Park\" for French Guiana's protected rainforest area. The Amazon represents over half of Earth's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees in about 16,000 species.More than 30 million people of 350 different ethnic groups live in the Amazon, which are subdivided into 9 different national political systems and 3,344 formally acknowledged indigenous territories. Indigenous peoples make up 9% of the total population, and 60 of the groups remain largely isolated.Large scale deforestation is occurring in the forest, creating different harmful effects. Economic losses due to deforestation in Brazil could be approximately 7 times higher in comparison to the cost of all commodities produced through deforestation. In 2023, the World Bank published a report proposing a non-deforestation based economic program in the region.\n",
      "\n",
      "Etymology\n",
      "The name Amazon is said to arise from a war Francisco de Orellana fought with the Tapuyas and other tribes. The women of the tribe fought alongside the men, as was their custom. Orellana derived the name Amazonas from the Amazons of Greek mythology, described by Herodotus and Diodorus.\n",
      "\n",
      "History\n",
      "Based on archaeological evidence from an excavation at Caverna da Pedra Pintada, human inhabitants first settled in the Amazon region at least 11,200 years ago. Subsequent development led to late-prehistoric settlements along the periphery of the forest by AD 1250, which induced alterations in the forest cover.For a long time, it was thought that the Amazon rainforest was never more than sparsely populated, as it was impossible to sustain a large population through agriculture given the poor soil. Archeologist Betty Meggers was a prominent proponent of this idea, as described in her book Amazonia: Man and Culture in a Counterfeit Paradise. She claimed that a population density of 0.2 inhabitants per square kilometre (0.52/sq mi) is the maximum that can be sustained in the rainforest through hunting, with agriculture needed to host a larger population. However, recent anthropological findings have suggested that the region was actually densely populated. Some 5 million people may have lived in the Amazon region in AD 1500, divided between dense coastal settlements, such as that at Marajó, and inland dwellers. By 1900, the population had fallen to 1 million and by the early 1980s it was less than 200,000.The first European to travel the length of the Amazon River was Francisco de Orellana in 1542. The BBC's Unnatural Histories presents evidence that Orellana, rather than exaggerating his claims as previously thought, was correct in his observations that a complex civilization was flourishing along the Amazon in the 1540s. The pre-Columbian agriculture in the Amazon basin was sufficiently advanced to support prosperous and populous societies. It is believed that civilization was later devastated by the spread of diseases from Europe, such as smallpox. This civilization was investigated by the British explorer Percy Fawcett in the early twentieth century.  The results of his expeditions were inconclusive and he disappeared mysteriously on his last trip.  His name for this lost civilization was the City of Z.\n",
      "Since the 1970s, numerous geoglyphs have been discovered on deforested land dating between AD 1–1250, furthering claims about Pre-Columbian civilizations. Ondemar Dias is accredited with first discovering the geoglyphs in 1977, and Alceu Ranzi is credited with furthering their discovery after flying over Acre. The BBC's Unnatural Histories presented evidence that the Amazon rainforest, rather than being a pristine wilderness, has been shaped by man for at least 11,000 years through practices such as forest gardening and terra preta. Terra preta is found over large areas in the Amazon forest; and is now widely accepted as a product of indigenous soil management. The development of this fertile soil allowed agriculture and silviculture in the previously hostile environment; meaning that large portions of the Amazon rainforest are probably the result of centuries of human management, rather than naturally occurring as has previously been supposed. In the region of the Xingu tribe, remains of some of these large settlements in the middle of the Amazon forest were found in 2003 by Michael Heckenberger and colleagues of the University of Florida. Among those were evidence of roads, bridges and large plazas.In the Amazonas, there has been fighting and wars between the neighboring tribes of the Jivaro. Several tribes of the Jivaroan group, including the Shuar, practised headhunting for trophies and headshrinking. The accounts of missionaries to the area in the borderlands between Brazil and Venezuela have recounted constant infighting in the Yanomami tribes. More than a third of the Yanomamo males, on average, died from warfare.The Munduruku were a warlike tribe that expanded along the Tapajós river and its tributaries and were feared by neighboring tribes. In the early 19th century, the Munduruku were pacified and subjugated by the Brazilians.During the Amazon rubber boom it is estimated that diseases brought by immigrants, such as typhus and malaria, killed 40,000 native Amazonians.In the 1950s, Brazilian explorer and defender of indigenous people, Cândido Rondon, supported the Villas-Bôas brothers' campaign, which faced strong opposition from the government and the ranchers of Mato Grosso and led to the establishment of the first Brazilian National Park for indigenous people along the Xingu River in 1961.In 1961, British explorer Richard Mason was killed by an uncontacted Amazon tribe known as the Panará.The Matsés made their first permanent contact with the outside world in 1969. Before that date, they were effectively at-war with the Peruvian government.\n",
      "\n",
      "Geography\n",
      "Location\n",
      "Nine countries share the Amazon basin—most of the rainforest, 58.4%, is contained within the borders of Brazil. The other eight countries are Peru with 12.8%, Bolivia with 7.7%, Colombia with 7.1%, Venezuela with 6.1%, Guyana with 3.1%, Suriname with 2.5%, French Guiana with 1.4% and Ecuador with 1%.\n",
      "\n",
      "Natural\n",
      "The rainforest likely formed during the Eocene era (from 56 million years to 33.9 million years ago). It appeared following a global reduction of tropical temperatures when the Atlantic Ocean had widened sufficiently to provide a warm, moist climate to the Amazon basin. The rainforest has been in existence for at least 55 million years, and most of the region remained free of savanna-type biomes at least until the current ice age when the climate was drier and savanna more widespread.Following the Cretaceous–Paleogene extinction event, the extinction of the dinosaurs and the wetter climate may have allowed the tropical rainforest to spread out across the continent. From 66 to 34 Mya, the rainforest extended as far south as 45°. Climate fluctuations during the last 34 million years have allowed savanna regions to expand into the tropics. During the Oligocene, for example, the rainforest spanned a relatively narrow band. It expanded again during the Middle Miocene, then retracted to a mostly inland formation at the last glacial maximum. However, the rainforest still managed to thrive during these glacial periods, allowing for the survival and evolution of a broad diversity of species.\n",
      "During the mid-Eocene, it is believed that the drainage basin of the Amazon was split along the middle of the continent by the Purus Arch. Water on the eastern side flowed toward the Atlantic, while to the west water flowed toward the Pacific across the Amazonas Basin. As the Andes Mountains rose, however, a large basin was created that enclosed a lake; now known as the Solimões Basin. Within the last 5–10 million years, this accumulating water broke through the Purus Arch, joining the easterly flow toward the Atlantic.\n",
      "There is evidence that there have been significant changes in the Amazon rainforest vegetation over the last 21,000 years through the last glacial maximum (LGM) and subsequent deglaciation. Analyses of sediment deposits from Amazon basin paleolakes and the Amazon Fan indicate that rainfall in the basin during the LGM was lower than for the present, and this was almost certainly associated with reduced moist tropical vegetation cover in the basin. In present day, the Amazon receives approximately 9 feet of rainfall annually. There is a debate, however, over how extensive this reduction was. Some scientists argue that the rainforest was reduced to small, isolated refugia separated by open forest and grassland; other scientists argue that the rainforest remained largely intact but extended less far to the north, south, and east than is seen today. This debate has proved difficult to resolve because the practical limitations of working in the rainforest mean that data sampling is biased away from the center of the Amazon basin, and both explanations are reasonably well supported by the available data.\n",
      "\n",
      "Sahara Desert dust windblown to the Amazon\n",
      "More than 56% of the dust fertilizing the Amazon rainforest comes from the Bodélé depression in Northern Chad in the Sahara desert. The dust contains phosphorus, important for plant growth. The yearly Sahara dust replaces the equivalent amount of phosphorus washed away yearly in Amazon soil from rains and floods.NASA's CALIPSO satellite has measured the amount of dust transported by wind from the Sahara to the Amazon: an average of 182 million tons of dust are windblown out of the Sahara each year, at 15 degrees west longitude, across 2,600 km (1,600 mi) over the Atlantic Ocean (some dust falls into the Atlantic), then at 35 degrees West longitude at the eastern coast of South America, 27.7 million tons (15%) of dust fall over the Amazon basin (22 million tons of it consisting of phosphorus), 132 million tons of dust remain in the air, 43 million tons of dust are windblown and falls on the Caribbean Sea, past 75 degrees west longitude.CALIPSO uses a laser range finder to scan the Earth's atmosphere for the vertical distribution of dust and other aerosols. CALIPSO regularly tracks the Sahara-Amazon dust plume. CALIPSO has measured variations in the dust amounts transported – an 86 percent drop between the highest amount of dust transported in 2007 and the lowest in 2011.\n",
      "A possibility causing the variation is the Sahel, a strip of semi-arid land on the southern border of the Sahara. When rain amounts in the Sahel are higher, the volume of dust is lower. The higher rainfall could make more vegetation grow in the Sahel, leaving less sand exposed to winds to blow away.Amazon phosphorus also comes as smoke due to biomass burning in Africa.\n",
      "\n",
      "Biodiversity, flora and fauna\n",
      "Wet tropical forests are the most species-rich biome, and tropical forests in the Americas are consistently more species rich than the wet forests in Africa and Asia. As the largest tract of tropical rainforest in the Americas, the Amazonian rainforests have unparalleled biodiversity. One in ten known species in the world lives in the Amazon rainforest. This constitutes the largest collection of living plants and animal species in the world.\n",
      "The region is home to about 2.5 million insect species, tens of thousands of plants, and some 2,000 birds and mammals. To date, at least 40,000 plant species, 2,200 fishes, 1,294 birds, 427 mammals, 428 amphibians, and 378 reptiles have been scientifically classified in the region. One in five of all bird species are found in the Amazon rainforest, and one in five of the fish species live in Amazonian rivers and streams. Scientists have described between 96,660 and 128,843 invertebrate species in Brazil alone.The biodiversity of plant species is the highest on Earth with one 2001 study finding a quarter square kilometer (62 acres) of Ecuadorian rainforest supports more than 1,100 tree species. A study in 1999 found one square kilometer (247 acres) of Amazon rainforest can contain about 90,790 tonnes of living plants. The average plant biomass is estimated at 356 ± 47 tonnes per hectare. To date, an estimated 438,000 species of plants of economic and social interest have been registered in the region with many more remaining to be discovered or catalogued. The total number of tree species in the region is estimated at 16,000.The green leaf area of plants and trees in the rainforest varies by about 25% as a result of seasonal changes. Leaves expand during the dry season when sunlight is at a maximum, then undergo abscission in the cloudy wet season. These changes provide a balance of carbon between photosynthesis and respiration.Each hectare of the Amazon rainforest contains around 1 billion of invertebrates. The amount of species per hectare in the Amazon rainforest can be presented in the next table:\n",
      "The rainforest contains several species that can pose a hazard. Among the largest predatory creatures are the black caiman, jaguar, cougar, and anaconda. In the river, electric eels can produce an electric shock that can stun or kill, while piranha are known to bite and injure humans. Various species of poison dart frogs secrete lipophilic alkaloid toxins through their flesh. There are also numerous parasites and disease vectors. Vampire bats dwell in the rainforest and can spread the rabies virus. Malaria, yellow fever and dengue fever can also be contracted in the Amazon region.\n",
      "The biodiversity in the Amazon is becoming increasingly threatened, primarily by habitat loss from deforestation as well as increased frequency of fires. Over 90% of Amazonian plant and vertebrate species (13,000-14,000 in total) may have been impacted to some degree by fires.\n",
      "\n",
      "Deforestation\n",
      "Deforestation is the conversion of forested areas to non-forested areas. The main sources of deforestation in the Amazon are human settlement and the development of the land. In 2022, about 20% of the Amazon rainforest has already been deforested and a further 6% was “highly degraded”. Research suggests that upon reaching about 20–25% (hence 0–5% more), the tipping point to flip it into a non-forest ecosystem – degraded savannah – (in eastern, southern and central Amazonia) will be reached. This process of savanisation would take decades to take full effect.Prior to the early 1960s, access to the forest's interior was highly restricted, and the forest remained basically intact. Farms established during the 1960s were based on crop cultivation and the slash and burn method. However, the colonists were unable to manage their fields and the crops because of the loss of soil fertility and weed invasion. The soils in the Amazon are productive for just a short period of time, so farmers are constantly moving to new areas and clearing more land. These farming practices led to deforestation and caused extensive environmental damage. Deforestation is considerable, and areas cleared of forest are visible to the naked eye from outer space.\n",
      "In the 1970s, construction began on the Trans-Amazonian highway. This highway represented a major threat to the Amazon rainforest. The highway still has not been completed, limiting the environmental damage.\n",
      "Between 1991 and 2000, the total area of forest lost in the Amazon rose from 415,000 to 587,000 km2 (160,000 to 227,000 sq mi), with most of the lost forest becoming pasture for cattle. Seventy percent of formerly forested land in the Amazon, and 91% of land deforested since 1970, have been used for livestock pasture. Currently, Brazil is the largest global producer of soybeans. New research however, conducted by Leydimere Oliveira et al., has shown that the more rainforest is logged in the Amazon, the less precipitation reaches the area and so the lower the yield per hectare becomes. So despite the popular perception, there has been no economical advantage for Brazil from logging rainforest zones and converting these to pastoral fields.\n",
      "The needs of soy farmers have been used to justify many of the controversial transportation projects that are currently developing in the Amazon. The first two highways successfully opened up the rainforest and led to increased settlement and deforestation. The mean annual deforestation rate from 2000 to 2005 (22,392 km2 or 8,646 sq mi per year) was 18% higher than in the previous five years (19,018 km2 or 7,343 sq mi per year). Although deforestation declined significantly in the Brazilian Amazon between 2004 and 2014, there has been an increase to the present day.\n",
      "Brazil's President, Jair Bolsonaro, has supported the relaxation of regulations placed on agricultural land. He has used his time in office to allow for more deforestation and more exploitation of the Amazon's rich natural resources.\n",
      "Since the discovery of fossil fuel reservoirs in the Amazon rainforest, oil drilling activity has steadily increased, peaking in the Western Amazon in the 1970s and ushering another drilling boom in the 2000s. Oil companies have to set up their operations by opening new roads through the forests, which often contributes to deforestation in the region.The European Union–Mercosur free trade agreement, which would form one of the world's largest free trade areas, has been denounced by environmental activists and indigenous rights campaigners. The fear is that the deal could lead to more deforestation of the Amazon rainforest as it expands market access to Brazilian beef.According to a November 2021 report by Brazil's INPE, based on satellite data, deforestation has increased by 22% over 2020 and is at its highest level since 2006.\n",
      "\n",
      "2019 fires\n",
      "There were 72,843 fires in Brazil in 2019, with more than half within the Amazon region.  In August 2019 there were a record number of fires.  Deforestation in the Brazilian Amazon rose more than 88% in June 2019 compared with the same month in 2018.\n",
      "\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "The increased area of fire-impacted forest coincided with a relaxation of environmental regulations from the Brazilian government. Notably, before those regulations were put in place in 2008 the fire-impacted area was also larger compared to the regulation period of 2009–2018. As these fire continue to move closer to the heart of the Amazon basin, their impact on biodiversity will only increase in scale, as the cumulative fire-impacted area is correlated with the number of species impacted.\n",
      "\n",
      "Conservation and climate change\n",
      "Environmentalists are concerned about loss of biodiversity that will result from destruction of the forest, and also about the release of the carbon contained within the vegetation, which could accelerate global warming. Amazonian evergreen forests account for about 10% of the world's terrestrial primary productivity and 10% of the carbon stores in ecosystems – of the order of 1.1 × 1011 metric tonnes of carbon. Amazonian forests are estimated to have accumulated 0.62 ± 0.37 tons of carbon per hectare per year between 1975 and 1996. In 2021 it was reported that the Amazon for the first time emitted more greenhouse gases than it absorbed. Though often referenced as producing more than a quarter of the Earth's oxygen, this often stated, but misused statistic actually refers to oxygen turnover.  The net contribution of the ecosystem is approximately zero.One computer model of future climate change caused by greenhouse gas emissions shows that the Amazon rainforest could become unsustainable under conditions of severely reduced rainfall and increased temperatures, leading to an almost complete loss of rainforest cover in the basin by 2100., and severe economic, natural capital and ecosystem services impacts of not averting the tipping point. However, simulations of Amazon basin climate change across many different models are not consistent in their estimation of any rainfall response, ranging from weak increases to strong decreases. The result indicates that the rainforest could be threatened through the 21st century by climate change in addition to deforestation.\n",
      "\n",
      "In 1989, environmentalist C.M. Peters and two colleagues stated there is economic as well as biological incentive to protecting the rainforest. One hectare in the Peruvian Amazon has been calculated to have a value of $6820 if intact forest is sustainably harvested for fruits, latex, and timber; $1000 if clear-cut for commercial timber (not sustainably harvested); or $148 if used as cattle pasture.\n",
      "As indigenous territories continue to be destroyed by deforestation and ecocide (such as in the Peruvian Amazon), indigenous peoples' rainforest communities continue to disappear, while others, like the Urarina continue to struggle to fight for their cultural survival and the fate of their forested territories. Meanwhile, the relationship between non-human primates in the subsistence and symbolism of indigenous lowland South American peoples has gained increased attention, as have ethno-biology and community-based conservation efforts.\n",
      "From 2002 to 2006, the conserved land in the Amazon rainforest almost tripled and deforestation rates dropped up to 60%. About 1,000,000 km2 (250,000,000 acres) have been put onto some sort of conservation, which adds up to a current amount of 1,730,000 km2 (430,000,000 acres).In April 2019, the Ecuadorian court stopped oil exploration activities in 180,000 hectares (440,000 acres) of the Amazon rainforest.In July 2019, the Ecuadorian court forbade the government to sell territory with forests to oil companies.In September 2019, the US and Brazil agreed to promote private-sector development in the Amazon. They also pledged a $100m  biodiversity conservation fund for the Amazon led by the private sector. Brazil's foreign minister stated that opening the rainforest to economic development was the only way to protect it.\n",
      "\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\n",
      "A 2009 study found that a 4 °C rise (above pre-industrial levels) in global temperatures by 2100 would kill 85% of the Amazon rainforest while a temperature rise of 3 °C would kill some 75% of the Amazon.\n",
      "A new study by an international team of environmental scientists in the Brazilian Amazon shows that protection of freshwater biodiversity can be increased by up to 600% through integrated freshwater-terrestrial planning \n",
      ".Deforestation in the Amazon rainforest region has a negative impact on local climate. It was one of the main causes of the severe drought  of 2014–2015 in Brazil. This is because the moisture from the forests is important to the rainfall in Brazil, Paraguay and Argentina. Half of the rainfall in the Amazon area is produced by the forests.Results of a 2021 scientific synthesis indicate that, in terms of global warming,  the Amazon basin with the Amazon rainforest is currently emitting more greenhouse gases than it absorbs overall. Climate change impacts and human activities in the area – mainly wildfires, current land-use and deforestation – are causing a release of forcing agents that likely result in a net warming effect.In 2022 the supreme court of Ecuador decided that \"“under no circumstances can a project be carried out that generates excessive sacrifices to the collective rights of communities and nature.” It also required the government to respect the opinion of Indigenous peoples of the Americas about different industrial projects on their land. Advocates of the decision argue that it will have consequences far beyond Ecuador. In general, ecosystems are in better shape when indigenous peoples own or manage the land.Due to the conservation policies of Luiz Inácio Lula da Silva in the first 10 months of 2023 deforestation in the Brazilian Amazon decreased by around 50% compared to the same period in 2022. This was despite a severe drought, one of the worst on record, that exacerbated the situation. Climate change, El Nino, deforestation increases the likelihood of drought condition in the Amazon.According to Amazon Conservation's MAAP forest monitoring program, the deforestation rate in the Amazon from the 1 January to 8 November 2023 decreased by 56% in comparison to the same period in 2022. The main cause is the decline in deforestation rate in Brazil, due to the government's policies, while Columbia, Peru and Bolivia also reduced deforestation.In January 2024 published data showed a 50% decline in deforestation rate in the Amazon rainforest and 43% rise in vegetation loss in the neighbor Cerrado during the year of 2023 in comparison to 2022. Both biomes together lose 12,980 km², 18% less than in 2022.\n",
      "\n",
      "Remote sensing\n",
      "The use of remotely sensed data is dramatically improving conservationists' knowledge of the Amazon basin. Given the objectivity and lowered costs of satellite-based land cover and -change analysis, it appears likely that remote sensing technology will be an integral part of assessing the extents, locations and damage of deforestation in the basin. Furthermore, remote sensing is the best and perhaps only possible way to study the Amazon on a large scale.The use of remote sensing for the conservation of the Amazon is also being used by the indigenous tribes of the basin to protect their tribal lands from commercial interests. Using handheld GPS devices and programs like Google Earth, members of the Trio Tribe, who live in the rainforests of southern Suriname, map out their ancestral lands to help strengthen their territorial claims. Currently, most tribes in the Amazon do not have clearly defined boundaries, making it easier for commercial ventures to target their territories.\n",
      "To accurately map the Amazon's biomass and subsequent carbon-related emissions, the classification of tree growth stages within different parts of the forest is crucial. In 2006, Tatiana Kuplich organized the trees of the Amazon into four categories: mature forest, regenerating forest [less than three years], regenerating forest [between three and five years of regrowth], and regenerating forest [eleven to eighteen years of continued development]. The researcher used a combination of synthetic aperture radar (SAR) and Thematic Mapper (TM) to accurately place the different portions of the Amazon into one of the four classifications.\n",
      "\n",
      "Impact of early 21st-century Amazon droughts\n",
      "In 2005, parts of the Amazon basin experienced the worst drought in one hundred years, and there were indications that 2006 may have been a second successive year of drought. A 2006 article in the UK newspaper The Independent reported the Woods Hole Research Center results, showing that the forest in its present form could survive only three years of drought. Scientists at the Brazilian National Institute of Amazonian Research argued in the article that this drought response, coupled with the effects of deforestation on regional climate, are pushing the rainforest towards a \"tipping point\" where it would irreversibly start to die. It concluded that the forest is on the brink of being turned into savanna or desert, with catastrophic consequences for the world's climate. A study published in Nature Communications in October 2020 found that about 40% of the Amazon rainforest is at risk of becoming a savanna-like ecosystem due to reduced rainfall. A study published in Nature climate change provided direct empirical evidence that more than three-quarters of the Amazon rainforest has been losing resilience since the early 2000s, risking dieback with profound implications for biodiversity, carbon storage and climate change at a global scale.According to the World Wide Fund for Nature, the combination of climate change and deforestation increases the drying effect of dead trees that fuels forest fires.In 2010, the Amazon rainforest experienced another severe drought, in some ways more extreme than the 2005 drought. The affected region was approximately 3,000,000 km2 (1,160,000 sq mi) of rainforest, compared with 1,900,000 km2 (734,000 sq mi) in 2005. The 2010 drought had three epicenters where vegetation died off, whereas in 2005, the drought was focused on the southwestern part. The findings were published in the journal Science. In a typical year, the Amazon absorbs 1.5 gigatons of carbon dioxide; during 2005 instead 5 gigatons were released and in 2010 8 gigatons were released. Additional severe droughts occurred in 2010, 2015, and 2016.In 2019 Brazil's protections of the Amazon rainforest were slashed, resulting in a severe loss of trees. According to Brazil's National Institute for Space Research (INPE), deforestation in the Brazilian Amazon rose more than 50% in the first three months of 2020 compared to the same three-month period in 2019.In 2020, a 17 percent rise was noted in the Amazon wildfires, marking the worst start to the fire season in a decade. The first 10 days of August 2020 witnessed 10,136 fires. An analysis of the government figures reflected 81 per cent increase in fires in federal reserves, in comparison with the same period in 2019. However, President Jair Bolsonaro turned down the existence of fires, calling it a \"lie\", despite the data produced by his own government. Satellites in September recorded 32,017 hotspots in the world's largest rainforest, a 61% rise from the same month in 2019. In addition, October saw a huge surge in the number of hotspots in the forest (more than 17,000 fires are burning in the Amazon's rainforest) - with more than double the amount detected in the same month last year.\n",
      "\n",
      "Possibility of forest-friendly economy\n",
      "In 2023 the World Bank, published a report named: \"A Balancing Act for Brazil’s Amazonian States: An Economic Memorandum\". The report stating that economic losses due to deforestation in Brazil could reach around 317 billion dollars per year, approximately 7 times higher in comparison to the cost of all commodities produced through deforestation, proposed non-deforestation based economic program in the region of the Amazon rainforest.\n",
      "Silvopasture (integrating trees, forage and grazing) can help to stop deforestation in the region.According to WWF, ecotourism could help the Amazon to reduce deforestation and climate change. Ecotourism is currently still little practiced in the Amazon, partly due to lack of information about places where implementation is possible. Ecotourism is a sector that can also be taken up by the Indigenous community in the Amazon as a source of income and revenue. An ecotourism project in the Brazilian section of the rainforest had been under consideration by Brazil's State Secretary for the Environment and Sustainable Development in 2009, along the Aripuanã River, in the Aripuanã Sustainable Development Reserve. Also, some community-based ecotourism exists in the Mamirauá Sustainable Development Reserve. Ecotourism is also practiced in the Peruvian section of the rainforest. A few ecolodges are for instance present between Cusco and Madre de Dios.In May 2023 Brazil's bank federation decided to implement a new sustainability standard demanding from meatpackers to ensure their meat is not coming from illegally deforested area. Credits will not be given to those who will not meet the new standards. The decision came after the European Union decides to implement regulations to stop deforestation. Brazil beef exporters, said the standard is not just because it is not applied to land owners. 21 banks representing 81% of the credit market in Brazil agree to follow those rules.According to a statement of the Colombian government deforestation rates in the Colombian Amazon fell by 70% in the first 9 months of 2023 compared to the same period in the previous year, what can be attributed to the conservation policies of the government. One of them is paying local residents for conserving the forest.\n",
      "\n",
      "See also\n",
      "TechnologyAmazon Surveillance System (Sistema de Vigilância da Amazônia)\n",
      "Global Forest Watch\n",
      "\n",
      "Notes\n",
      "References\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "Journey into Amazonia\n",
      "The Amazon: The World's Largest Rainforest\n",
      "WWF in the Amazon rainforest\n",
      "Amazonia.org.br Good daily updated Amazon information database on the web, held by Friends of The Earth – Brazilian Amazon.\n",
      "Seasons in the Amazon and river levels\n",
      "amazonia.org Sustainable Development in the Extractive Reserve of the Baixo Rio Branco – Rio Jauaperi – Brazilian Amazon.\n",
      "Amazon Rainforest News Original news updates on the Amazon.\n",
      "Amazon-Rainforest.org Information about the Amazon rainforest, its people, places of interest, and how everyone can help.\n",
      "Conference: Climate change and the fate of the Amazon. Podcasts of talks given at Oriel College, University of Oxford, 20–22 March 2007.\n",
      "Dead humpback whale calf in the AmazonA cryptocurrency, crypto-currency, or crypto is a digital currency designed to work as a medium of exchange through a computer network that is not reliant on any central authority, such as a government or bank, to uphold or maintain it. It is a decentralized system for verifying that the parties to a transaction have the money they claim to have, eliminating the need for traditional intermediaries, such as banks, when funds are being transferred between two entities.Individual coin ownership records are stored in a digital ledger, which is a computerized database using strong cryptography to secure transaction records, control the creation of additional coins, and verify the transfer of coin ownership. Despite their name, cryptocurrencies are not considered to be currencies in the traditional sense, and while varying treatments have been applied to them, including classification as commodities, securities, and currencies, cryptocurrencies are generally viewed as a distinct asset class in practice. Some crypto schemes use validators to maintain the cryptocurrency. In a proof-of-stake model, owners put up their tokens as collateral. In return, they get authority over the token in proportion to the amount they stake. Generally, these token stakers get additional ownership in the token over time via network fees, newly minted tokens, or other such reward mechanisms.Cryptocurrency does not exist in physical form (like paper money) and is typically not issued by a central authority. Cryptocurrencies typically use decentralized control as opposed to a central bank digital currency (CBDC). When a cryptocurrency is minted, created prior to issuance, or issued by a single issuer, it is generally considered centralized. When implemented with decentralized control, each cryptocurrency works through distributed ledger technology, typically a blockchain, that serves as a public financial transaction database.The first cryptocurrency was Bitcoin, which was first released as open-source software in 2009. As of June 2023, there were more than 25,000 other cryptocurrencies in the marketplace, of which more than 40 had a market capitalization exceeding $1 billion.\n",
      "\n",
      "History\n",
      "In 1983, American cryptographer David Chaum conceived of a type of cryptographic electronic money called ecash. Later, in 1995, he implemented it through Digicash, an early form of cryptographic electronic payments. Digicash required user software in order to withdraw notes from a bank and designate specific encrypted keys before it can be sent to a recipient. This allowed the digital currency to be untraceable by a third party.\n",
      "In 1996, the National Security Agency published a paper entitled How to Make a Mint: The Cryptography of Anonymous Electronic Cash, describing a cryptocurrency system. The paper was first published in an MIT mailing list and later in 1997 in The American Law Review.In 1998, Wei Dai described \"b-money\", an anonymous, distributed electronic cash system. Shortly thereafter, Nick Szabo described bit gold. Like Bitcoin and other cryptocurrencies that would follow it, bit gold (not to be confused with the later gold-based exchange BitGold) was described as an electronic currency system which required users to complete a proof of work function with solutions being cryptographically put together and published.\n",
      "In January 2009, Bitcoin was created by pseudonymous developer Satoshi Nakamoto. It used SHA-256, a cryptographic hash function, in its proof-of-work scheme. In April 2011, Namecoin was created as an attempt at forming a decentralized DNS. In October 2011, Litecoin was released which used scrypt as its hash function instead of SHA-256. Peercoin, created in August 2012, used a hybrid of proof-of-work and proof-of-stake.\n",
      "\n",
      "Cryptocurrency has undergone several periods of growth and retraction, including several bubbles and market crashes, such as in 2011, 2013-2014–15, 2017-2018 and 2021–2023.On 6 August 2014, the UK announced its Treasury had commissioned a study of cryptocurrencies, and what role, if any, they could play in the UK economy. The study was also to report on whether regulation should be considered. Its final report was published in 2018, and it issued a consultation on cryptoassets and stablecoins in January 2021.In June 2021, El Salvador became the first country to accept Bitcoin as legal tender, after the Legislative Assembly had voted 62–22 to pass a bill submitted by President Nayib Bukele classifying the cryptocurrency as such.In August 2021, Cuba followed with Resolution 215 to recognize and regulate cryptocurrencies such as Bitcoin.In September 2021, the government of China, the single largest market for cryptocurrency, declared all cryptocurrency transactions illegal. This completed a crackdown on cryptocurrency that had previously banned the operation of intermediaries and miners within China.On 15 September 2022, the world's second largest cryptocurrency at that time, Ethereum transitioned its consensus mechanism from proof-of-work (PoW) to proof-of-stake (PoS) in an upgrade process known as \"the Merge\".  According to the Ethereum Founder, the upgrade can cut both Ethereum's energy use and carbon-dioxide emissions by 99.9%.On 11 November 2022, FTX Trading Ltd., a cryptocurrency exchange, which also operated a crypto hedge fund, and had been valued at $18 billion, filed for bankruptcy. The financial impact of the collapse extended beyond the immediate FTX customer base, as reported, while, at a Reuters conference, financial industry executives said that \"regulators must step in to protect crypto investors.\" Technology analyst Avivah Litan commented on the cryptocurrency ecosystem that \"everything...needs to improve dramatically in terms of user experience, controls, safety, customer service.\"\n",
      "\n",
      "Formal definition\n",
      "According to Jan Lansky, a cryptocurrency is a system that meets six conditions:\n",
      "The system does not require a central authority; its state is maintained through distributed consensus.\n",
      "The system keeps an overview of cryptocurrency units and their ownership.\n",
      "The system defines whether new cryptocurrency units can be created. If new cryptocurrency units can be created, the system defines the circumstances of their origin and how to determine the ownership of these new units.\n",
      "Ownership of cryptocurrency units can be proved exclusively cryptographically.\n",
      "The system allows transactions to be performed in which ownership of the cryptographic units is changed. A transaction statement can only be issued by an entity proving the current ownership of these units.\n",
      "If two different instructions for changing the ownership of the same cryptographic units are simultaneously entered, the system performs at most one of them.In March 2018, the word cryptocurrency was added to the Merriam-Webster Dictionary.\n",
      "\n",
      "Altcoins\n",
      "Tokens, cryptocurrencies, and other digital assets other than Bitcoin are collectively known as alternative cryptocurrencies, typically shortened to \"altcoins\" or \"alt coins\", or disparagingly \"shitcoins\". Paul Vigna of The Wall Street Journal also described altcoins as \"alternative versions of Bitcoin\" given its role as the model protocol for altcoin designers.\n",
      "\n",
      " Altcoins often have underlying differences when compared to Bitcoin. For example, Litecoin aims to process a block every 2.5 minutes, rather than Bitcoin's 10 minutes, which allows Litecoin to confirm transactions faster than Bitcoin. Another example is Ethereum, which has smart contract functionality that allows decentralized applications to be run on its blockchain. Ethereum was the most used blockchain in 2020, according to Bloomberg News. In 2016, it had the largest \"following\" of any altcoin, according to the New York Times.Significant rallies across altcoin markets are often referred to as an \"altseason\".\n",
      "\n",
      "Stablecoins\n",
      "Stablecoins are cryptocurrencies designed to maintain a stable level of purchasing power. Notably, these designs are not foolproof, as a number of stablecoins have crashed or lost their peg. For example, on 11 May 2022, Terra's stablecoin UST fell from $1 to 26 cents. The subsequent failure of Terraform Labs resulted in the loss of nearly $40B invested in the Terra and Luna coins. In September 2022, South Korean prosecutors requested the issuance of an Interpol Red Notice against the company's founder, Do Kwon. In Hong Kong, the expected regulatory framework for stablecoins in 2023/24 is being shaped and includes a few considerations.\n",
      "\n",
      "Architecture\n",
      "Cryptocurrency is produced by an entire cryptocurrency system collectively, at a rate which is defined when the system is created and which is publicly stated. In centralized banking and economic systems such as the US Federal Reserve System, corporate boards or governments control the supply of currency. In the case of cryptocurrency, companies or governments cannot produce new units, and have not so far provided backing for other firms, banks or corporate entities which hold asset value measured in it. The underlying technical system upon which cryptocurrencies are based was created by Satoshi Nakamoto.Within a proof-of-work system such as Bitcoin, the safety, integrity and balance of ledgers is maintained by a community of mutually distrustful parties referred to as miners. Miners use their computers to help validate and timestamp transactions, adding them to the ledger in accordance with a particular timestamping scheme. In a proof-of-stake blockchain, transactions are validated by holders of the associated cryptocurrency, sometimes grouped together in stake pools.\n",
      "Most cryptocurrencies are designed to gradually decrease the production of that currency, placing a cap on the total amount of that currency that will ever be in circulation. Compared with ordinary currencies held by financial institutions or kept as cash on hand, cryptocurrencies can be more difficult for seizure by law enforcement.\n",
      "\n",
      "Blockchain\n",
      "The validity of each cryptocurrency's coins is provided by a blockchain. A blockchain is a continuously growing list of records, called blocks, which are linked and secured using cryptography. Each block typically contains a hash pointer as a link to a previous block, a timestamp and transaction data. By design, blockchains are inherently resistant to modification of the data. It is \"an open, distributed ledger that can record transactions between two parties efficiently and in a verifiable and permanent way\". For use as a distributed ledger, a blockchain is typically managed by a peer-to-peer network collectively adhering to a protocol for validating new blocks. Once recorded, the data in any given block cannot be altered retroactively without the alteration of all subsequent blocks, which requires collusion of the network majority.\n",
      "Blockchains are secure by design and are an example of a distributed computing system with high Byzantine fault tolerance. Decentralized consensus has therefore been achieved with a blockchain.\n",
      "\n",
      "Nodes\n",
      "A node is a computer that connects to a cryptocurrency network. The node supports the cryptocurrency's network through either relaying transactions, validation, or hosting a copy of the blockchain. In terms of relaying transactions, each network computer (node) has a copy of the blockchain of the cryptocurrency it supports. When a transaction is made, the node creating the transaction broadcasts details of the transaction using encryption to other nodes throughout the node network so that the transaction (and every other transaction) is known.\n",
      "Node owners are either volunteers, those hosted by the organization or body responsible for developing the cryptocurrency blockchain network technology, or those who are enticed to host a node to receive rewards from hosting the node network.\n",
      "\n",
      "Timestamping\n",
      "Cryptocurrencies use various timestamping schemes to \"prove\" the validity of transactions added to the blockchain ledger without the need for a trusted third party.\n",
      "The first timestamping scheme invented was the proof-of-work scheme. The most widely used proof-of-work schemes are based on SHA-256 and scrypt.Some other hashing algorithms that are used for proof-of-work include CryptoNote, Blake, SHA-3, and X11.\n",
      "Another method is called the proof-of-stake scheme. Proof-of-stake is a method of securing a cryptocurrency network and achieving distributed consensus through requesting users to show ownership of a certain amount of currency. It is different from proof-of-work systems that run difficult hashing algorithms to validate electronic transactions. The scheme is largely dependent on the coin, and there is currently no standard form of it. Some cryptocurrencies use a combined proof-of-work and proof-of-stake scheme.\n",
      "\n",
      "Mining\n",
      "On a blockchain, mining is the validation of transactions. For this effort, successful miners obtain new cryptocurrency as a reward. The reward decreases transaction fees by creating a complementary incentive to contribute to the processing power of the network. The rate of generating hashes, which validate any transaction, has been increased by the use of specialized machines such as FPGAs and ASICs running complex hashing algorithms like SHA-256 and scrypt. This arms race for cheaper-yet-efficient machines has existed since Bitcoin was introduced in 2009. Mining is measured by hash rate typically in TH/s.With more people venturing into the world of virtual currency, generating hashes for validation has become more complex over time, forcing miners to invest increasingly large sums of money to improve computing performance. Consequently, the reward for finding a hash has diminished and often does not justify the investment in equipment and cooling facilities (to mitigate the heat the equipment produces), and the electricity required to run them. Popular regions for mining include those with inexpensive electricity, a cold climate, and jurisdictions with clear and conducive regulations. By July 2019, Bitcoin's electricity consumption was estimated to be approximately 7 gigawatts, around 0.2% of the global total, or equivalent to the energy consumed nationally by Switzerland.Some miners pool resources, sharing their processing power over a network to split the reward equally, according to the amount of work they contributed to the probability of finding a block. A \"share\" is awarded to members of the mining pool who present a valid partial proof-of-work.\n",
      "As of February 2018, the Chinese Government has halted trading of virtual currency, banned initial coin offerings and shut down mining. Many Chinese miners have since relocated to Canada and Texas. One company is operating data centers for mining operations at Canadian oil and gas field sites, due to low gas prices. In June 2018, Hydro Quebec proposed to the provincial government to allocate 500 megawatts of power to crypto companies for mining. According to a February 2018 report from Fortune, Iceland has become a haven for cryptocurrency miners in part because of its cheap electricity.In March 2018, the city of Plattsburgh, New York put an 18-month moratorium on all cryptocurrency mining in an effort to preserve natural resources and the \"character and direction\" of the city. In 2021, Kazakhstan became the second-biggest crypto-currency mining country, producing 18.1% of the global exahash rate. The country built a compound containing 50,000 computers near Ekibastuz.\n",
      "\n",
      "GPU price rise\n",
      "An increase in cryptocurrency mining increased the demand for graphics cards (GPU) in 2017. The computing power of GPUs makes them well-suited to generating hashes. Popular favorites of cryptocurrency miners such as Nvidia's GTX 1060 and GTX 1070 graphics cards, as well as AMD's RX 570 and RX 580 GPUs, doubled or tripled in price – or were out of stock. A GTX 1070 Ti which was released at a price of $450 sold for as much as $1,100. Another popular card, the GTX 1060 (6 GB model) was released at an MSRP of $250, and sold for almost $500. RX 570 and RX 580 cards from AMD were out of stock for almost a year. Miners regularly buy up the entire stock of new GPU's as soon as they are available.Nvidia has asked retailers to do what they can when it comes to selling GPUs to gamers instead of miners. Boris Böhles, PR manager for Nvidia in the German region, said: \"Gamers come first for Nvidia.\"\n",
      "\n",
      "Mining accelerator chips\n",
      "Numerous companies developed dedicated crypto-mining accelerator chips, capable of price-performance far higher than that of CPU or GPU mining. At one point Intel marketed its own brand of crypto accelerator chip, named Blockscale.\n",
      "\n",
      "Wallets\n",
      "A cryptocurrency wallet is a means of storing the public and private \"keys\" (address) or seed which can be used to receive or spend the cryptocurrency. With the private key, it is possible to write in the public ledger, effectively spending the associated cryptocurrency. With the public key, it is possible for others to send currency to the wallet.\n",
      "There exist multiple methods of storing keys or seed in a wallet. These methods range from using paper wallets (which are public, private or seed keys written on paper), to using hardware wallets (which are hardware to store your wallet information), to a digital wallet (which is a computer with a software hosting your wallet information), to hosting your wallet using an exchange where cryptocurrency is traded, or by storing your wallet information on a digital medium such as plaintext.\n",
      "\n",
      "Anonymity\n",
      "Bitcoin is pseudonymous, rather than anonymous; the cryptocurrency in a wallet is not tied to a person, but rather to one or more specific keys (or \"addresses\"). Thereby, Bitcoin owners are not immediately identifiable, but all transactions are publicly available in the blockchain. Still, cryptocurrency exchanges are often required by law to collect the personal information of their users.Some cryptocurrencies, such as Monero, Zerocoin, Zerocash, and CryptoNote, implement additional measures to increase privacy, such as by using zero-knowledge proofs.A recent 2020 study presented different attacks on privacy in cryptocurrencies. The attacks demonstrated how the anonymity techniques are not sufficient safeguards. In order to improve privacy, researchers suggested several different ideas including new cryptographic schemes and mechanisms for hiding the IP address of the source.\n",
      "\n",
      "Economics\n",
      "Cryptocurrencies are used primarily outside banking and governmental institutions and are exchanged over the Internet.\n",
      "\n",
      "Block rewards\n",
      "Proof-of-work cryptocurrencies, such as Bitcoin, offer block rewards incentives for miners. There has been an implicit belief that whether miners are paid by block rewards or transaction fees does not affect the security of the blockchain, but a study suggests that this may not be the case under certain circumstances.The rewards paid to miners increase the supply of the cryptocurrency. By making sure that verifying transactions is a costly business, the integrity of the network can be preserved as long as benevolent nodes control a majority of computing power. The verification algorithm requires a lot of processing power, and thus electricity in order to make verification costly enough to accurately validate public blockchain. Not only do miners have to factor in the costs associated with expensive equipment necessary to stand a chance of solving a hash problem, they further must consider the significant amount of electrical power in search of the solution. Generally, the block rewards outweigh electricity and equipment costs, but this may not always be the case.The current value, not the long-term value, of the cryptocurrency supports the reward scheme to incentivize miners to engage in costly mining activities. In 2018, Bitcoin's design caused a 1.4% welfare loss compared to an efficient cash system, while a cash system with 2% money growth has a minor 0.003% welfare cost. The main source for this inefficiency is the large mining cost, which is estimated to be US$360 million per year. This translates into users being willing to accept a cash system with an inflation rate of 230% before being better off using Bitcoin as a means of payment. However, the efficiency of the Bitcoin system can be significantly improved by optimizing the rate of coin creation and minimizing transaction fees. Another potential improvement is to eliminate inefficient mining activities by changing the consensus protocol altogether.\n",
      "\n",
      "Transaction fees\n",
      "Transaction fees for cryptocurrency depend mainly on the supply of network capacity at the time, versus the demand from the currency holder for a faster transaction. The currency holder can choose a specific transaction fee, while network entities process transactions in order of highest offered fee to lowest. Cryptocurrency exchanges can simplify the process for currency holders by offering priority alternatives and thereby determine which fee will likely cause the transaction to be processed in the requested time.For Ethereum, transaction fees differ by computational complexity, bandwidth use, and storage needs, while Bitcoin transaction fees differ by transaction size and whether the transaction uses SegWit. In February 2023, the median transaction fee for Ether corresponded to $2.2845, while for Bitcoin it corresponded to $0.659.Some cryptocurrencies have no transaction fees, and instead rely on client-side proof-of-work as the transaction prioritization and anti-spam mechanism.\n",
      "\n",
      "Exchanges\n",
      "Cryptocurrency exchanges allow customers to trade cryptocurrencies for other assets, such as conventional fiat money, or to trade between different digital currencies.\n",
      "Crypto marketplaces do not guarantee that an investor is completing a purchase or trade at the optimal price. As a result, as of 2020 it was possible to arbitrage to find the difference in price across several markets.\n",
      "\n",
      "Atomic swaps\n",
      "Atomic swaps are a mechanism where one cryptocurrency can be exchanged directly for another cryptocurrency, without the need for a trusted third party such as an exchange.\n",
      "\n",
      "ATMs\n",
      "Jordan Kelley, founder of Robocoin, launched the first Bitcoin ATM in the United States on 20 February 2014. The kiosk installed in Austin, Texas, is similar to bank ATMs but has scanners to read government-issued identification such as a driver's license or a passport to confirm users' identities.\n",
      "\n",
      "Initial coin offerings\n",
      "An initial coin offering (ICO) is a controversial means of raising funds for a new cryptocurrency venture. An ICO may be used by startups with the intention of avoiding regulation. However, securities regulators in many jurisdictions, including in the U.S., and Canada, have indicated that if a coin or token is an \"investment contract\" (e.g., under the Howey test, i.e., an investment of money with a reasonable expectation of profit based significantly on the entrepreneurial or managerial efforts of others), it is a security and is subject to securities regulation. In an ICO campaign, a percentage of the cryptocurrency (usually in the form of \"tokens\") is sold to early backers of the project in exchange for legal tender or other cryptocurrencies, often Bitcoin or Ether.According to PricewaterhouseCoopers, four of the 10 biggest proposed initial coin offerings have used Switzerland as a base, where they are frequently registered as non-profit foundations. The Swiss regulatory agency FINMA stated that it would take a \"balanced approach\" to ICO projects and would allow \"legitimate innovators to navigate the regulatory landscape and so launch their projects in a way consistent with national laws protecting investors and the integrity of the financial system.\" In response to numerous requests by industry representatives, a legislative ICO working group began to issue legal guidelines in 2018, which are intended to remove uncertainty from cryptocurrency offerings and to establish sustainable business practices.\n",
      "\n",
      "Price trends\n",
      "The market capitalization of a cryptocurrency is calculated by multiplying the price by the number of coins in circulation. The total cryptocurrency market cap has historically been dominated by Bitcoin accounting for at least 50% of the market cap value where altcoins have increased and decreased in market cap value in relation to Bitcoin. Bitcoin's value is largely determined by speculation among other technological limiting factors known as blockchain rewards coded into the architecture technology of Bitcoin itself. The cryptocurrency market cap follows a trend known as the \"halving\", which is when the block rewards received from Bitcoin are halved due to technological mandated limited factors instilled into Bitcoin which in turn limits the supply of Bitcoin. As the date reaches near of a halving (twice thus far historically) the cryptocurrency market cap increases, followed by a downtrend.By June 2021, cryptocurrency had begun to be offered by some wealth managers in the US for 401(k)s.\n",
      "\n",
      "Volatility\n",
      "Cryptocurrency prices are much more volatile than established financial assets such as stocks. For example, over one week in May 2022, Bitcoin lost 20% of its value and Ethereum lost 26%, while Solana and Cardano lost 41% and 35% respectively. The falls were attributed to warnings about inflation. By comparison, in the same week, the Nasdaq tech stock index fell 7.6 per cent and the FTSE 100 was 3.6 per cent down.In the longer term, of the 10 leading cryptocurrencies identified by the total value of coins in circulation in January 2018, only four (Bitcoin, Ethereum, Cardano and Ripple (XRP)) were still in that position in early 2022. The total value of all cryptocurrencies was  $2 trillion at the end of 2021, but had halved nine months later. The Wall Street Journal has commented that the crypto sector has become \"intertwined\" with the rest of the capital markets and \"sensitive to the same forces that drive tech stocks and other risk assets\", such as inflation forecasts.\n",
      "\n",
      "Databases\n",
      "There are also centralized databases, outside of blockchains, that store crypto market data. Compared to the blockchain, databases perform fast as there is no verification process. Four of the most popular cryptocurrency market databases are CoinMarketCap, CoinGecko, BraveNewCoin, and Cryptocompare.\n",
      "\n",
      "Social and political aspects\n",
      "According to Alan Feuer of The New York Times, libertarians and anarcho-capitalists were attracted to the philosophical idea behind Bitcoin. Early Bitcoin supporter Roger Ver said: \"At first, almost everyone who got involved did so for philosophical reasons. We saw Bitcoin as a great idea, as a way to separate money from the state.\" Economist Paul Krugman argues that cryptocurrencies like Bitcoin are \"something of a cult\" based in \"paranoid fantasies\" of government power.David Golumbia says that the ideas influencing Bitcoin advocates emerge from right-wing extremist movements such as the Liberty Lobby and the John Birch Society and their anti-Central Bank rhetoric, or, more recently, Ron Paul and Tea Party-style libertarianism. Steve Bannon, who owns a \"good stake\" in Bitcoin, sees cryptocurrency as a form of disruptive populism, taking control back from central authorities.Bitcoin's founder, Satoshi Nakamoto, has supported the idea that cryptocurrencies go well with libertarianism. \"It's very attractive to the libertarian viewpoint if we can explain it properly,\" Nakamoto said in 2008.According to the European Central Bank, the decentralization of money offered by Bitcoin has its theoretical roots in the Austrian school of economics, especially with Friedrich von Hayek in his book Denationalisation of Money: The Argument Refined, in which Hayek advocates a complete free market in the production, distribution and management of money to end the monopoly of central banks.\n",
      "\n",
      "Increasing regulation\n",
      "The rise in the popularity of cryptocurrencies and their adoption by financial institutions has led some governments to assess whether regulation is needed to protect users. The Financial Action Task Force (FATF) has defined cryptocurrency-related services as \"virtual asset service providers\" (VASPs) and recommended that they be regulated with the same money laundering (AML) and know your customer (KYC) requirements as financial institutions.In May 2020, the Joint Working Group on interVASP Messaging Standards published \"IVMS 101\", a universal common language for communication of required originator and beneficiary information between VASPs. The FATF and financial regulators were informed as the data model was developed.In June 2020, FATF updated its guidance to include the \"Travel Rule\" for cryptocurrencies, a measure which mandates that VASPs obtain, hold, and exchange information about the originators and beneficiaries of virtual asset transfers. Subsequent standardized protocol specifications recommended using JSON for relaying data between VASPs and identity services. As of December 2020, the IVMS 101 data model has yet to be finalized and ratified by the three global standard setting bodies that created it.The European Commission published a digital finance strategy in September 2020. This included a draft regulation on Markets in Crypto-Assets (MiCA), which aimed to provide a comprehensive regulatory framework for digital assets in the EU.On 10 June 2021, the Basel Committee on Banking Supervision proposed that banks that held cryptocurrency assets must set aside capital to cover all potential losses. For instance, if a bank were to hold Bitcoin worth $2 billion, it would be required to set aside enough capital to cover the entire $2 billion. This is a more extreme standard than banks are usually held to when it comes to other assets. However, this is a proposal and not a regulation.\n",
      "The IMF is seeking a coordinated, consistent and comprehensive approach to supervising cryptocurrencies. Tobias Adrian, the IMF's financial counsellor and head of its monetary and capital markets department said in a January 2022 interview that \"Agreeing global regulations is never quick. But if we start now, we can achieve the goal of maintaining financial stability while also enjoying the benefits which the underlying technological innovations bring,\"\n",
      "\n",
      "United States\n",
      "In 2021, 17 states passed laws and resolutions concerning cryptocurrency regulation. The U.S. Securities and Exchange Commission (SEC) is considering what steps to take. On 8 July 2021, Senator Elizabeth Warren, part of the Senate Banking Committee, wrote to the chairman of the SEC and demanded answers on cryptocurrency regulation due to the increase in cryptocurrency exchange use and the danger this posed to consumers. On 5 August 2021, SEC Chairman Gary Gensler responded to Senator Elizabeth Warren's letter regarding cryptocurrency regulation and called for legislation focused on \"crypto trading, lending and DeFi platforms,\" because of how vulnerable the investors could be when they traded on crypto trading platforms without a broker. He also argued that many tokens in the crypto market may be unregistered securities without required disclosures or market oversight. Additionally, Gensler did not hold back in his criticism of stablecoins. These tokens, which are pegged to the value of fiat currencies, may allow individuals to bypass important public policy goals related to traditional banking and financial systems, such as anti-money laundering, tax compliance, and sanctions.On 19 October 2021, the first bitcoin-linked exchange-traded fund (ETF) from ProShares started trading on the NYSE under the ticker \"BITO.\" ProShares CEO Michael L. Sapir said the ETF would expose Bitcoin to a wider range of investors without the hassle of setting up accounts with cryptocurrency providers. Ian Balina, the CEO of Token Metrics, stated that the approval of the \"BITO\" ETF by the SEC was a significant endorsement for the crypto industry because many regulators globally were not in favor of crypto as well as the hesitance to accept crypto from retail investors. This event would eventually open more opportunities for new capital and new people in this space.The United States Department of the Treasury, on 20 May 2021, announced that it would require any transfer worth $10,000 or more to be reported to the Internal Revenue Service since cryptocurrency already posed a problem where illegal activity like tax evasion was facilitated broadly. This release from the IRS was a part of efforts to promote better compliance and consider more severe penalties for tax evaders.On 17 February 2022, the Justice department named Eun Young Choi as the first director of a National Cryptocurrency Enforcement Team to aid in identification of and dealing with misuse of cryptocurrencies and other digital assets.The Biden administration faced a dilemma as it tried to develop regulations for the cryptocurrency industry. On one hand, officials were hesitant to restrict the growing and profitable industry. On the other hand, they were committed to preventing illegal cryptocurrency transactions. To reconcile these conflicting goals, on 9 March 2022, President Biden issued an executive order. Followed by the executive order, on 16 September 2022, the Comprehensive Framework for Responsible Development of Digital Assets document was released  to support development of cryptocurrencies and restrict their illegal use. The executive order included all digital assets, but cryptocurrencies posed both the greatest security risks and potential economic benefits. Though this might not address all of the challenges in crypto industry, it was a significant milestone in the U.S. cryptocurrency regulation history.In February 2023, the Securities and Exchange Commission (SEC) ruled that cryptocurrency exchange Kraken's estimated $42 billion in staked assets globally operated as an illegal securities seller. The company agreed to a $30 million settlement with the SEC and to cease selling its staking service in the U.S. The case would impact other major crypto exchanges operating staking programs.On 23 March 2023, the U.S. Securities and Exchange Commission (SEC) issued an alert to investors stating that firms offering crypto asset securities may not be complying with U.S. laws. The SEC stated that unregistered offerings of crypto asset securities may not include important information.\n",
      "\n",
      "China\n",
      "In September 2017, China banned ICOs to cause abnormal return from cryptocurrency decreasing during announcement window. The liquidity changes by banning ICOs in China was temporarily negative while the liquidity effect became positive after news.On 18 May 2021, China banned financial institutions and payment companies from being able to provide cryptocurrency transaction related services. This led to a sharp fall in the price of the biggest proof of work cryptocurrencies. For instance, Bitcoin fell 31%, Ethereum fell 44%, Binance Coin fell 32% and Dogecoin fell 30%. Proof of work mining was the next focus, with regulators in popular mining regions citing the use of electricity generated from highly polluting sources such as coal to create Bitcoin and Ethereum.In September 2021, the Chinese government declared all cryptocurrency transactions of any kind illegal, completing its crackdown on cryptocurrency.\n",
      "\n",
      "United Kingdom\n",
      "In the United Kingdom, as of 10 January 2021, all cryptocurrency firms, such as exchanges, advisors and professionals that have either a presence, market product or provide services within the UK market must register with the Financial Conduct Authority. Additionally, on 27 June 2021, the financial watchdog demanded that Binance, the world's largest cryptocurrency exchange, cease all regulated activities in the UK.\n",
      "\n",
      "South Africa\n",
      "South Africa, which has seen a large number of scams related to cryptocurrency, is said to be putting a regulatory timeline in place that will produce a regulatory framework. The largest scam occurred in April 2021, where the two founders of an African-based cryptocurrency exchange called Africrypt, Raees Cajee and Ameer Cajee, disappeared with $3.8 billion worth of Bitcoin. Additionally, Mirror Trading International disappeared with $170 million worth of cryptocurrency in January 2021.\n",
      "\n",
      "South Korea\n",
      "In March 2021, South Korea implemented new legislation to strengthen their oversight of digital assets. This legislation requires all digital asset managers, providers and exchanges to be registered with the Korea Financial Intelligence Unit in order to operate in South Korea. Registering with this unit requires that all exchanges are certified by the Information Security Management System and that they ensure all customers have real name bank accounts. It also requires that the CEO and board members of the exchanges have not been convicted of any crimes and that the exchange holds sufficient levels of deposit insurance to cover losses arising from hacks.\n",
      "\n",
      "Turkey\n",
      "On 30 April 2021, the Central Bank of the Republic of Turkey banned the use of cryptocurrencies and cryptoassets for making purchases on the grounds that the use of cryptocurrencies for such payments poses significant transaction risks.\n",
      "\n",
      "El Salvador\n",
      "On 9 June 2021, El Salvador announced that it will adopt Bitcoin as legal tender, becoming the first country to do so.\n",
      "\n",
      "India\n",
      "At present, India neither prohibits nor allows investment in the cryptocurrency market. In 2020, the Supreme Court of India had lifted the ban on cryptocurrency, which was imposed by the Reserve Bank of India. Since then, an investment in cryptocurrency is considered legitimate, though there is still ambiguity about the issues regarding the extent and payment of tax on the income accrued thereupon and also its regulatory regime. But it is being contemplated that the Indian Parliament will soon pass a specific law to either ban or regulate the cryptocurrency market in India. Expressing his public policy opinion on the Indian cryptocurrency market to a well-known online publication, a leading public policy lawyer and Vice President of SAARCLAW (South Asian Association for Regional Co-operation in Law) Hemant Batra has said that the \"cryptocurrency market has now become very big with involvement of billions of dollars in the market hence, it is now unattainable and irreconcilable for the government to completely ban all sorts of cryptocurrency and its trading and investment\". He mooted regulating the cryptocurrency market rather than completely banning it. He favoured following IMF and FATF guidelines in this regard.\n",
      "\n",
      "Switzerland\n",
      "Switzerland was one of the first countries to implement the FATF's Travel Rule. FINMA, the Swiss regulator, issued its own guidance to VASPs in 2019. The guidance followed the FATF's Recommendation 16, however with stricter requirements. According to FINMA's requirements, VASPs need to verify the identity of the beneficiary of the transfer.\n",
      "\n",
      "Legality\n",
      "The legal status of cryptocurrencies varies substantially from country to country and is still undefined or changing in many of them. At least one study has shown that broad generalizations about the use of Bitcoin in illicit finance are significantly overstated and that blockchain analysis is an effective crime fighting and intelligence gathering tool. While some countries have explicitly allowed their use and trade, others have banned or restricted it. According to the Library of Congress in 2021,\n",
      "an \"absolute ban\" on trading or using cryptocurrencies applies in 9 countries:\n",
      "Algeria, Bangladesh, Bolivia, China, Egypt, Iraq, Morocco, Nepal, and the United Arab Emirates. An \"implicit ban\" applies in another 39 countries or regions, which include: Bahrain, Benin, Burkina Faso, Burundi, Cameroon, Chad, Cote d’Ivoire, the Dominican Republic, Ecuador, Gabon, Georgia, Guyana, Indonesia, Iran, Jordan, Kazakhstan, Kuwait, Lebanon, Lesotho, Macau, Maldives, Mali, Moldova, Namibia, Niger, Nigeria, Oman, Pakistan, Palau, Republic of Congo, Saudi Arabia, Sengeal, Tajikistan, Tanzania, Togo, Turkey, Turkmenistan, Qatar and Vietnam. In the United States and Canada, state and provincial securities regulators, coordinated through the North American Securities Administrators Association, are investigating \"Bitcoin scams\" and ICOs in 40 jurisdictions.Various government agencies, departments, and courts have classified Bitcoin differently. China Central Bank banned the handling of Bitcoins by financial institutions in China in early 2014.\n",
      "In Russia, though owning cryptocurrency is legal, its residents are only allowed to purchase goods from other residents using the Russian ruble while nonresidents are allowed to use foreign currency. Regulations and bans that apply to Bitcoin probably extend to similar cryptocurrency systems.In August 2018, the Bank of Thailand announced its plans to create its own cryptocurrency, the Central Bank Digital Currency (CBDC).\n",
      "\n",
      "Advertising bans\n",
      "Cryptocurrency advertisements have been banned on the following platforms:\n",
      "\n",
      "Google - Ended August 2021\n",
      "Twitter\n",
      "Facebook - Ended December 2021\n",
      "Bing - Ended June 2022\n",
      "Snapchat\n",
      "LinkedIn\n",
      "MailChimp\n",
      "Baidu\n",
      "Tencent\n",
      "Weibo\n",
      "Line\n",
      "Yandex\n",
      "\n",
      "U.S. tax status\n",
      "On 25 March 2014, the United States Internal Revenue Service (IRS) ruled that Bitcoin will be treated as property for tax purposes. Therefore, virtual currencies are considered commodities subject to capital gains tax.\n",
      "\n",
      "Legal concerns relating to an unregulated global economy\n",
      "As the popularity and demand for online currencies has increased since the inception of Bitcoin in 2009, so have concerns that such an unregulated person to person global economy that cryptocurrencies offer may become a threat to society. Concerns abound that altcoins may become tools for anonymous web criminals.Cryptocurrency networks display a lack of regulation that has been criticized as enabling criminals who seek to evade taxes and launder money. Money laundering issues are also present in regular bank transfers, however with bank-to-bank wire transfers for instance, the account holder must at least provide a proven identity.\n",
      "Transactions that occur through the use and exchange of these altcoins are independent from formal banking systems, and therefore can make tax evasion simpler for individuals. Since charting taxable income is based upon what a recipient reports to the revenue service, it becomes extremely difficult to account for transactions made using existing cryptocurrencies, a mode of exchange that is complex and difficult to track.Systems of anonymity that most cryptocurrencies offer can also serve as a simpler means to launder money. Rather than laundering money through an intricate net of financial actors and offshore bank accounts, laundering money through altcoins can be achieved through anonymous transactions.Cryptocurrency makes legal enforcement against extremist groups more complicated, which consequently strengthens them. White supremacist Richard Spencer went as far as to declare Bitcoin the \"currency of the alt-right\".\n",
      "\n",
      "Loss, theft, and fraud\n",
      "In February 2014, the world's largest Bitcoin exchange, Mt. Gox, declared bankruptcy. Likely due to theft, the company claimed that it had lost nearly 750,000 Bitcoins belonging to their clients. This added up to approximately 7% of all Bitcoins in existence, worth a total of $473 million. Mt. Gox blamed hackers, who had exploited the transaction malleability problems in the network. The price of a Bitcoin fell from a high of about $1,160 in December to under $400 in February.On 21 November 2017, Tether announced that it had been hacked, losing $31 million in USDT from its core treasury wallet.On 7 December 2017, Slovenian cryptocurrency exchange Nicehash reported that hackers had stolen over $70M using a hijacked company computer.On 19 December 2017, Yapian, the owner of South Korean exchange Youbit, filed for bankruptcy after suffering two hacks that year. Customers were still granted access to 75% of their assets.\n",
      "In May 2018, Bitcoin Gold had its transactions hijacked and abused by unknown hackers. Exchanges lost an estimated $18m and Bitcoin Gold was delisted from Bittrex after it refused to pay its share of the damages.\n",
      "On 13 September 2018, Homero Josh Garza was sentenced to 21 months of imprisonment, followed by three years of supervised release. Garza had founded the cryptocurrency startups GAW Miners and ZenMiner in 2014, acknowledged in a plea agreement that the companies were part of a pyramid scheme, and pleaded guilty to wire fraud in 2015. The U.S. Securities and Exchange Commission separately brought a civil enforcement action against Garza, who was eventually ordered to pay a judgment of $9.1 million plus $700,000 in interest. The SEC's complaint stated that Garza, through his companies, had fraudulently sold \"investment contracts representing shares in the profits they claimed would be generated\" from mining.In January 2018, Japanese exchange Coincheck reported that hackers had stolen $530M worth of cryptocurrencies.In June 2018, South Korean exchange Coinrail was hacked, losing over $37M worth of cryptos. The hack worsened an already ongoing cryptocurrency selloff by an additional $42 billion.On 9 July 2018, the exchange Bancor, whose code and fundraising had been subjects of controversy, had $23.5 million in cryptocurrency stolen.A 2020 EU report found that users had lost crypto-assets worth hundreds of millions of US dollars in security breaches at exchanges and storage providers. Between 2011 and 2019, reported breaches ranged from four to twelve a year. In 2019, more than a billion dollars worth of cryptoassets was reported stolen. Stolen assets \"typically find their way to illegal markets and are used to fund further criminal activity\".According to a 2020 report produced by the United States Attorney General's Cyber-Digital Task Force, the following three categories make up the majority of illicit cryptocurrency uses: \"(1) financial transactions associated with the commission of crimes; (2) money laundering and the shielding of legitimate activity from tax, reporting, or other legal requirements; or (3) crimes, such as theft, directly implicating the cryptocurrency marketplace itself.\" The report concludes that \"for cryptocurrency to realize its truly transformative potential, it is imperative that these risks be addressed\" and that \"the government has legal and regulatory tools available at its disposal to confront the threats posed by cryptocurrency's illicit uses\".According to the UK 2020 national risk assessment—a comprehensive assessment of money laundering and terrorist financing risk in the UK—the risk of using cryptoassets such as Bitcoin for money laundering and terrorism financing is assessed as \"medium\" (from \"low\" in the previous 2017 report). Legal scholars suggested that the money laundering opportunities may be more perceived than real. Blockchain analysis company Chainalysis concluded that illicit activities like cybercrime, money laundering and terrorism financing made up only 0.15% of all crypto transactions conducted in 2021, representing a total of $14 billion.In December 2021, Monkey Kingdom, a NFT project based in Hong Kong, lost US$1.3 million worth of cryptocurrencies via a phishing link used by the hacker.\n",
      "\n",
      "Money laundering\n",
      "According to blockchain data company Chainalysis, criminals laundered US$8,600,000,000 worth of cryptocurrency in 2021, up by 30% from the previous year. The data suggests that rather than managing numerous illicit havens, cybercriminals make use of a small group of purpose built centralized exchanges for sending and receiving illicit cryptocurrency. In 2021, those exchanges received 47% of funds sent by crime linked addresses. Almost $2.2bn worth of cryptocurrencies was embezzled from DeFi protocols in 2021, which represents 72% of all cryptocurrency theft in 2021.\n",
      "According to Bloomberg and the New York Times, Federation Tower, a two skyscraper complex in the heart of Moscow City, is home to many cryptocurrency businesses under suspicion of facilitating extensive money laundering, including accepting illicit cryptocurrency funds obtained through scams, darknet markets, and ransomware. Notable businesses include Garantex, Eggchange, Cashbank, Buy-Bitcoin, Tetchange, Bitzlato, and Suex, which was sanctioned by the U.S. in 2021. Bitzlato founder and owner Anatoly Legkodymov was arrested following money-laundering charges by the United States Department of Justice.Dark money has also been flowing into Russia through a dark web marketplace called Hydra, which is powered by cryptocurrency, and enjoyed more than $1 billion in sales in 2020, according to Chainalysis. The platform demands that sellers liquidate cryptocurrency only through certain regional exchanges, which has made it difficult for investigators to trace the money.\n",
      "Almost 74% of ransomware revenue in 2021 — over $400 million worth of cryptocurrency — went to software strains likely affiliated with Russia, where oversight is notoriously limited. However, Russians are also leaders in the benign adoption of cryptocurrencies, as the ruble is unreliable, and President Putin favours the idea of \"overcoming the excessive domination of the limited number of reserve currencies.\"In 2022, RenBridge - an unregulated alternative to exchanges for transferring value between blockchains - was found to be responsible for the laundering of at least $540 million since 2020. It is especially popular with people attempting to launder money from theft. This includes a cyberattack on Japanese crypto exchange Liquid that has been linked to North Korea.\n",
      "\n",
      "Darknet markets\n",
      "Properties of cryptocurrencies gave them popularity in applications such as a safe haven in banking crises and means of payment, which also led to the cryptocurrency use in controversial settings in the form of online black markets, such as Silk Road. The original Silk Road was shut down in October 2013 and there have been two more versions in use since then. In the year following the initial shutdown of Silk Road, the number of prominent dark markets increased from four to twelve, while the amount of drug listings increased from 18,000 to 32,000.Darknet markets present challenges in regard to legality. Cryptocurrency used in dark markets are not clearly or legally classified in almost all parts of the world. In the U.S., Bitcoins are labelled as \"virtual assets\". This type of ambiguous classification puts pressure on law enforcement agencies around the world to adapt to the shifting drug trade of dark markets.\n",
      "\n",
      "Wash trades\n",
      "Various studies have found that crypto-trading is rife with wash trading. Wash trading is a process, illegal in some jurisdictions, involving buyers and sellers being the same person or group, and may be used to manipulate the price of a cryptocurrency or inflate volume artificially. Exchanges with higher volumes can demand higher premiums from token issuers. A study from 2019 concluded that up to 80% of trades on unregulated cryptocurrency exchanges could be wash trades. A 2019 report by Bitwise Asset Management claimed that 95% of all Bitcoin trading volume reported on major website CoinMarketCap had been artificially generated, and of 81 exchanges studied, only 10 provided legitimate volume figures.\n",
      "\n",
      "As a tool to evade sanctions\n",
      "In 2022, cryptocurrencies attracted attention when Western nations imposed severe economic sanctions on Russia in the aftermath of its invasion of Ukraine in February. However, American sources warned in March that some crypto-transactions could potentially be used to evade economic sanctions against Russia and Belarus.In April 2022, the computer programmer Virgil Griffith received a five-year prison sentence in the US for attending a Pyongyang cryptocurrency conference, where he gave a presentation on blockchains which might be used for sanctions evasion.\n",
      "\n",
      "Impacts and analysis\n",
      "The Bank for International Settlements summarized several criticisms of cryptocurrencies in Chapter V of their 2018 annual report. The criticisms include the lack of stability in their price, the high energy consumption, high and variable transactions costs, the poor security and fraud at cryptocurrency exchanges, vulnerability to debasement (from forking), and the influence of miners.\n",
      "\n",
      "Speculation, fraud, and adoption\n",
      "Cryptocurrencies have been compared to Ponzi schemes, pyramid schemes and economic bubbles, such as housing market bubbles. Howard Marks of Oaktree Capital Management stated in 2017 that digital currencies were \"nothing but an unfounded fad (or perhaps even a pyramid scheme), based on a willingness to ascribe value to something that has little or none beyond what people will pay for it\", and compared them to the tulip mania (1637), South Sea Bubble (1720), and dot-com bubble (1999), which all experienced profound price booms and busts.Regulators in several countries have warned against cryptocurrency and some have taken measures to dissuade users. However, research in 2021 by the UK's financial regulator suggests such warnings either went unheard, or were ignored. Fewer than one in 10 potential cryptocurrency buyers were aware of consumer warnings on the FCA website, and 12% of crypto users were not aware that their holdings were not protected by statutory compensation. Of 1,000 respondents between the ages of eighteen and forty, almost 70% falsely assumed cryptocurrencies were regulated, 75% of younger crypto investors claimed to be driven by competition with friends and family, 58% said that social media enticed them to make high risk investments. The FCA recommends making use of its warning list, which flags unauthorized financial firms.Many banks do not offer virtual currency services themselves and can refuse to do business with virtual currency companies. In 2014, Gareth Murphy, a senior banking officer, suggested that the widespread adoption of cryptocurrencies may lead to too much money being obfuscated, blinding economists who would use such information to better steer the economy. While traditional financial products have strong consumer protections in place, there is no intermediary with the power to limit consumer losses if Bitcoins are lost or stolen. One of the features cryptocurrency lacks in comparison to credit cards, for example, is consumer protection against fraud, such as chargebacks.\n",
      "The French regulator Autorité des marchés financiers (AMF) lists 16 websites of companies that solicit investment in cryptocurrency without being authorized to do so in France.An October 2021 paper by the National Bureau of Economic Research found that Bitcoin suffers from systemic risk as the top 10,000 addresses control about one-third of all Bitcoin in circulation. It is even worse for Bitcoin miners, with 0.01% controlling 50% of the capacity. According to researcher Flipside Crypto, less than 2% of anonymous accounts control 95% of all available Bitcoin supply. This is considered risky as a great deal of the market is in the hands of a few entities.\n",
      "A paper by John Griffin, a finance professor at the University of Texas, and Amin Shams, a graduate student found that in 2017 the price of Bitcoin had been substantially inflated using another cryptocurrency, Tether.Roger Lowenstein, author of \"Bank of America: The Epic Struggle to Create the Federal Reserve,\" says in a New York Times story that FTX will face over $8 billion in claims.\n",
      "\n",
      "Non-fungible tokens\n",
      "Non-fungible tokens (NFTs) are digital assets that represent art, collectibles, gaming, etc. Like crypto, their data is stored on the blockchain. NFTs are bought and traded using cryptocurrency. The Ethereum blockchain was the first place where NFTs were implemented, but now many other blockchains have created their own versions of NFTs.\n",
      "\n",
      "Banks\n",
      "As the first big Wall Street bank to embrace cryptocurrencies, Morgan Stanley announced on 17 March 2021 that they will be offering access to Bitcoin funds for their wealthy clients through three funds which enable Bitcoin ownership for investors with an aggressive risk tolerance. BNY Mellon on 11 February 2021 announced that it would begin offering cryptocurrency services to its clients.On 20 April 2021, Venmo added support to its platform to enable customers to buy, hold and sell cryptocurrencies.In October 2021, financial services company Mastercard announced it is working with digital asset manager Bakkt on a platform that would allow any bank or merchant on the Mastercard network to offer cryptocurrency services.\n",
      "\n",
      "Environmental effects\n",
      "Mining for proof-of-work cryptocurrencies requires enormous amounts of electricity and consequently comes with a large carbon footprint due to causing greenhouse gas emissions. Proof-of-work blockchains such as Bitcoin, Ethereum, Litecoin, and Monero were estimated to have added between 3 million and 15 million tons of carbon dioxide (CO2) to the atmosphere in the period from 1 January 2016 to 30 June 2017. By November 2018, Bitcoin was estimated to have an annual energy consumption of 45.8TWh, generating 22.0 to 22.9 million tons of CO2, rivalling nations like Jordan and Sri Lanka. By the end of 2021, Bitcoin was estimated to produce 65.4 million tons of CO2, as much as Greece, and consume between 91 and 177 terawatt-hours annually.Critics have also identified a large electronic waste problem in disposing of mining rigs. Mining hardware is improving at a fast rate, quickly resulting in older generations of hardware.Bitcoin is the least energy-efficient cryptocurrency, using 707.6 kilowatt-hours of electricity per transaction.Before June 2021, China was the primary location for Bitcoin mining. However, due to concerns over power usage and other factors, China forced out Bitcoin operations, at least temporarily. As a result, the United States promptly emerged as the top global leader in the industry. An example of a gross amount of electronic waste associated with Bitcoin mining operations in the US is a facility that located in Dalton, Georgia which is consuming nearly the same amount of electricity as the combined power usage of 97,000 households in its vicinity. Another example is that Riot Platforms operates a Bitcoin mining facility in Rockdale, Texas, which consumes approximately as much electricity as the nearby 300,000 households. This makes it the most energy-intensive Bitcoin mining operation in the United States.The world's second-largest cryptocurrency, Ethereum, uses 62.56 kilowatt-hours of electricity per transaction. XRP is the world's most energy efficient cryptocurrency, using 0.0079 kilowatt-hours of electricity per transaction.Although the biggest PoW blockchains consume energy on the scale of medium-sized countries, the annual power demand from proof-of-stake (PoS) blockchains is on a scale equivalent to a housing estate. The Times identified six \"environmentally friendly\" cryptocurrencies: Chia, IOTA, Cardano, Nano, Solarcoin and Bitgreen. Academics and researchers have used various methods for estimating the energy use and energy efficiency of blockchains. A study of the six largest proof-of-stake networks in May 2021 concluded:\n",
      "\n",
      "Cardano has the lowest electricity use per node;\n",
      "Polkadot has the lowest electricity use overall; and\n",
      "Solana has the lowest electricity use per transaction.In terms of annual consumption (kWh/yr), the figures were: Polkadot (70,237), Tezos (113,249), Avalanche (489,311), Algorand (512,671), Cardano (598,755) and Solana (1,967,930). This equates to Polkadot consuming 7 times the electricity of an average U.S. home, Cardano 57 homes and Solana 200 times as much. The research concluded that PoS networks consumed 0.001% the electricity of the Bitcoin network. University College London researchers reached a similar conclusion.Variable renewable energy power stations could invest in Bitcoin mining to reduce curtailment, hedge electricity price risk, stabilize the grid, increase the profitability of renewable energy power stations and therefore accelerate transition to sustainable energy.\n",
      "\n",
      "Technological limitations\n",
      "There are also purely technical elements to consider. For example, technological advancement in cryptocurrencies such as Bitcoin result in high up-front costs to miners in the form of specialized hardware and software. Cryptocurrency transactions are normally irreversible after a number of blocks confirm the transaction. Additionally, cryptocurrency private keys can be permanently lost from local storage due to malware, data loss or the destruction of the physical media. This precludes the cryptocurrency from being spent, resulting in its effective removal from the markets.\n",
      "\n",
      "Academic studies\n",
      "In September 2015, the establishment of the peer-reviewed academic journal Ledger (ISSN 2379-5980) was announced. It covers studies of cryptocurrencies and related technologies, and is published by the University of Pittsburgh.The journal encourages authors to digitally sign a file hash of submitted papers, which will then be timestamped into the Bitcoin blockchain. Authors are also asked to include a personal Bitcoin address in the first page of their papers.\n",
      "\n",
      "Aid agencies\n",
      "A number of aid agencies have started accepting donations in cryptocurrencies, including UNICEF. Christopher Fabian, principal adviser at UNICEF Innovation, said the children's fund would uphold donor protocols, meaning that people making donations online would have to pass checks before they were allowed to deposit funds.However, in 2021, there was a backlash against donations in Bitcoin because of the environmental emissions it caused. Some agencies stopped accepting Bitcoin and others turned to \"greener\" cryptocurrencies. The U.S. arm of Greenpeace stopped accepting bitcoin donations after seven years. It said: \"As the amount of energy needed to run Bitcoin became clearer, this policy became no longer tenable.\"In 2022, the Ukrainian government raised over US$10,000,000 worth of aid through cryptocurrency following the 2022 Russian invasion of Ukraine.\n",
      "\n",
      "Criticism\n",
      "Bitcoin has been characterized as a speculative bubble by eight winners of the Nobel Memorial Prize in Economic Sciences: Paul Krugman, Robert J. Shiller, Joseph Stiglitz, Richard Thaler, James Heckman, Thomas Sargent, Angus Deaton, and Oliver Hart; and by central bank officials including Alan Greenspan, Agustín Carstens, Vítor Constâncio, and Nout Wellink.Investors Warren Buffett and George Soros have respectively characterized it as a \"mirage\" and a \"bubble\"; while business executives Jack Ma and JP Morgan Chase CEO Jamie Dimon have called it a \"bubble\" and a \"fraud\", respectively, although Jamie Dimon later said he regretted dubbing Bitcoin a fraud. BlackRock CEO Laurence D. Fink called Bitcoin an \"index of money laundering\".In June 2022, business magnate Bill Gates said that cryptocurrencies are \"100% based on greater fool theory\".Legal scholars criticize the lack of regulation, which hinders conflict resolution when crypto assets are at the center of a legal dispute, for example a divorce or an inheritance. In Switzerland, jurists generally deny that cryptocurrencies are objects that fall under property law, as cryptocurrencies do not belong to any class of legally defined objects (Typenzwang, the legal numerus clausus). Therefore, it is debated whether anybody could even be sued for embezzlement of cryptocurrency if he/she had access to someone's wallet. However, in the law of obligations and contract law, any kind of object would be legally valid, but the object would have to be tied to an identified counterparty. However, as the more popular cryptocurrencies can be freely and quickly exchanged into legal tender, they are financial assets and have to be taxed and accounted for as such.In 2018, an increase in crypto-related suicides was noticed after the cryptocurrency market crashed in August. The situation was particularly critical in Korea as crypto traders were on \"suicide watch\". A cryptocurrency forum on Reddit even started providing suicide prevention support to affected investors. The May 2022 collapse of the Luna currency operated by Terra also led to reports of suicidal investors in crypto-related subreddits.\n",
      "\n",
      "See also\n",
      "Notes\n",
      "References\n",
      "Further reading\n",
      "Chayka, Kyle (2 July 2013). \"What Comes After Bitcoin?\". Pacific Standard. Retrieved 18 January 2014.\n",
      "Guadamuz, Andres; Marsden, Chris (2015). \"Blockchains and Bitcoin: Regulatory responses to cryptocurrencies\" (PDF). First Monday. 20 (12). doi:10.5210/fm.v20i12.6198. S2CID 811921.\n",
      "\n",
      "External links\n",
      " Media related to Cryptocurrency at Wikimedia Commons\n",
      " Quotations related to Cryptocurrency at Wikiquote\n",
      " Learning materials related to Should cryptocurrencies be banned? at WikiversityRome (Italian and Latin: Roma [ˈroːma] ) is the capital city of Italy. It is also the capital of the Lazio region, the centre of the Metropolitan City of Rome Capital, and a special comune (municipality) named Comune di Roma Capitale. With 2,860,009 residents in 1,285 km2 (496.1 sq mi), Rome is the country's most populated comune and the third most populous city in the European Union by population within city limits. The Metropolitan City of Rome, with a population of 4,355,725 residents, is the most populous metropolitan city in Italy. Its metropolitan area is the third-most populous within Italy. Rome is located in the central-western portion of the Italian Peninsula, within Lazio (Latium), along the shores of the Tiber. Vatican City (the smallest country in the world) is an independent country inside the city boundaries of Rome, the only existing example of a country within a city. Rome is often referred to as the City of Seven Hills due to its geographic location, and also as the \"Eternal City\". Rome is generally considered to be the cradle of Western civilization and Western Christian culture, and the centre of the Catholic Church.Rome's history spans 28 centuries. While Roman mythology dates the founding of Rome at around 753 BC, the site has been inhabited for much longer, making it a major human settlement for almost three millennia and one of the oldest continuously occupied cities in Europe. The city's early population originated from a mix of Latins, Etruscans, and Sabines. Eventually, the city successively became the capital of the Roman Kingdom, the Roman Republic and the Roman Empire, and is regarded by many as the first-ever Imperial city and metropolis. It was first called The Eternal City (Latin: Urbs Aeterna; Italian: La Città Eterna) by the Roman poet Tibullus in the 1st century BC, and the expression was also taken up by Ovid, Virgil, and Livy. Rome is also called \"Caput Mundi\" (Capital of the World).\n",
      "After the fall of the Empire in the west, which marked the beginning of the Middle Ages, Rome slowly fell under the political control of the Papacy, and in the 8th century, it became the capital of the Papal States, which lasted until 1870. Beginning with the Renaissance, almost all popes since Nicholas V (1447–1455) pursued a coherent architectural and urban programme over four hundred years, aimed at making the city the artistic and cultural centre of the world. In this way, Rome first became one of the major centres of the Renaissance and then became the birthplace of both the Baroque style and Neoclassicism. Famous artists, painters, sculptors, and architects made Rome the centre of their activity, creating masterpieces throughout the city. In 1871, Rome became the capital of the Kingdom of Italy, which, in 1946, became the Italian Republic.\n",
      "In 2019, Rome was the 14th most visited city in the world, with 8.6 million tourists, the third most visited city in the European Union, and the most popular tourist destination in Italy. Its historic centre is listed by UNESCO as a World Heritage Site. The host city for the 1960 Summer Olympics, Rome is also the seat of several specialised agencies of the United Nations, such as the Food and Agriculture Organization (FAO), the World Food Programme (WFP) and the International Fund for Agricultural Development (IFAD). The city also hosts the Secretariat of the Parliamentary Assembly of the Union for the Mediterranean (UfM) as well as the headquarters of many multinational companies, such as Eni, Enel, TIM, Leonardo, and banks such as BNL. Numerous companies are based within Rome's EUR business district, such as the luxury fashion house Fendi located in the Palazzo della Civiltà Italiana. The presence of renowned international brands in the city has made Rome an important centre of fashion and design, and the Cinecittà Studios have been the set of many Academy Award–winning movies.\n",
      "\n",
      "Name and symbol\n",
      "Etymology\n",
      "According to the Ancient Romans' founding myth, the name Roma came from the city's founder and first king, Romulus.However, it is possible that the name Romulus was actually derived from Rome itself. As early as the 4th century, there have been alternative theories proposed on the origin of the name Roma. Several hypotheses have been advanced focusing on its linguistic roots which however remain uncertain:\n",
      "From Rumon or Rumen, archaic name of the Tiber, which in turn is supposedly related to the Greek verb ῥέω (rhéō) 'to flow, stream' and the Latin verb ruō 'to hurry, rush';\n",
      "From the Etruscan word 𐌓𐌖𐌌𐌀 (ruma), whose root is *rum- \"teat\", with possible reference either to the totem wolf that adopted and suckled the cognately named twins Romulus and Remus, or to the shape of the Palatine and Aventine Hills;\n",
      "From the Greek word ῥώμη (rhṓmē), which means strength.\n",
      "\n",
      "Other names and symbols\n",
      "Rome has also been called in ancient times simply \"Urbs\" (central city), from urbs roma, or identified with its ancient Roman initialism of SPQR, the symbol of Rome's constituted republican government. Furthermore, Rome has been called Urbs Aeterna (The Eternal City), Caput Mundi (The Capital of the world), Throne of St. Peter and Roma Capitale.\n",
      "\n",
      "History\n",
      "Earliest history\n",
      "While there have been discoveries of archaeological evidence of human occupation of the Rome area from approximately 14,000 years ago, the dense layer of much younger debris obscures Palaeolithic and Neolithic sites. Evidence of stone tools, pottery, and stone weapons attest to about 10,000 years of human presence. Several excavations support the view that Rome grew from pastoral settlements on the Palatine Hill built above the area of the future Roman Forum. Between the end of the Bronze Age and the beginning of the Iron Age, each hill between the sea and the Capitoline Hill was topped by a village (on the Capitoline, a village is attested since the end of the 14th century BC). However, none of them yet had an urban quality. Nowadays, there is a wide consensus that the city developed gradually through the aggregation (\"synoecism\") of several villages around the largest one, placed above the Palatine. This aggregation was facilitated by the increase of agricultural productivity above the subsistence level, which also allowed the establishment of secondary and tertiary activities. These, in turn, boosted the development of trade with the Greek colonies of southern Italy (mainly Ischia and Cumae). These developments, which according to archaeological evidence took place during the mid-eighth century BC, can be considered as the \"birth\" of the city. Despite recent excavations at the Palatine hill, the view that Rome was founded deliberately in the middle of the eighth century BC, as the legend of Romulus suggests, remains a fringe hypothesis.\n",
      "\n",
      "Legend of the founding of Rome\n",
      "Traditional stories handed down by the ancient Romans themselves explain the earliest history of their city in terms of legend and myth. The most familiar of these myths, and perhaps the most famous of all Roman myths, is the story of Romulus and Remus, the twins who were suckled by a she-wolf. They decided to build a city, but after an argument, Romulus killed his brother and the city took his name. According to the Roman annalists, this happened on 21 April 753 BC. This legend had to be reconciled with a dual tradition, set earlier in time, that had the Trojan refugee Aeneas escape to Italy and found the line of Romans through his son Iulus, the namesake of the Julio-Claudian dynasty.\n",
      "This was accomplished by the Roman poet Virgil in the first century BC. In addition, Strabo mentions an older story, that the city was an Arcadian colony founded by Evander. Strabo also writes that Lucius Coelius Antipater believed that Rome was founded by Greeks.\n",
      "\n",
      "Monarchy and republic\n",
      "After the foundation by Romulus according to a legend, Rome was ruled for a period of 244 years by a monarchical system, initially with sovereigns of Latin and Sabine origin, later by Etruscan kings. The tradition handed down seven kings: Romulus, Numa Pompilius, Tullus Hostilius, Ancus Marcius, Tarquinius Priscus, Servius Tullius and Lucius Tarquinius Superbus.In 509 BC, the Romans expelled the last king from their city and established an oligarchic republic. Rome then began a period characterised by internal struggles between patricians (aristocrats) and plebeians (small landowners), and by constant warfare against the populations of central Italy: Etruscans, Latins, Volsci, Aequi, and Marsi. After becoming master of Latium, Rome led several wars (against the Gauls, Osci-Samnites and the Greek colony of Taranto, allied with Pyrrhus, king of Epirus) whose result was the conquest of the Italian peninsula, from the central area up to Magna Graecia.The third and second century BC saw the establishment of Roman hegemony over the Mediterranean and the Balkans, through the three Punic Wars (264–146 BC) fought against the city of Carthage and the three Macedonian Wars (212–168 BC) against Macedonia. The first Roman provinces were established at this time: Sicily, Sardinia and Corsica, Hispania, Macedonia, Achaea and Africa.From the beginning of the 2nd century BC, power was contested between two groups of aristocrats: the optimates, representing the conservative part of the Senate, and the populares, which relied on the help of the plebs (urban lower class) to gain power. In the same period, the bankruptcy of the small farmers and the establishment of large slave estates caused large-scale migration to the city. The continuous warfare led to the establishment of a professional army, which turned out to be more loyal to its generals than to the republic. Because of this, in the second half of the second century and during the first century BC there were conflicts both abroad and internally: after the failed attempt of social reform of the populares Tiberius and Gaius Gracchus, and the war against Jugurtha, there was a civil war from which the general Sulla emerged victorious. A major slave revolt under Spartacus followed, and then the establishment of the first Triumvirate with Caesar, Pompey and Crassus.The conquest of Gaul made Caesar immensely powerful and popular, which led to a second civil war against the Senate and Pompey. After his victory, Caesar established himself as dictator for life. His assassination led to a second Triumvirate among Octavian (Caesar's grandnephew and heir), Mark Antony and Lepidus, and to another civil war between Octavian and Antony.\n",
      "\n",
      "Empire\n",
      "In 27 BC, Octavian became princeps civitatis and took the title of Augustus, founding the principate, a diarchy between the princeps and the senate. During the reign of Nero, two thirds of the city was ruined after the Great Fire of Rome, and the persecution of Christians commenced. Rome was established as a de facto empire, which reached its greatest expansion in the second century under the Emperor Trajan. Rome was confirmed as caput Mundi, i.e. the capital of the known world, an expression which had already been used in the Republican period. During its first two centuries, the empire was ruled by emperors of the Julio-Claudian, Flavian (who also built an eponymous amphitheatre, known as the Colosseum), and Antonine dynasties. This time was also characterised by the spread of the Christian religion, preached by Jesus Christ in Judea in the first half of the first century (under Tiberius) and popularised by his apostles through the empire and beyond. The Antonine age is considered the zenith of the Empire, whose territory ranged from the Atlantic Ocean to the Euphrates and from Britain to Egypt.\n",
      "After the end of the Severan Dynasty in 235, the Empire entered into a 50-year period known as the Crisis of the Third Century during which there were numerous putsches by generals, who sought to secure the region of the empire they were entrusted with due to the weakness of central authority in Rome. There was the so-called Gallic Empire from 260 to 274 and the revolts of Zenobia and her father from the mid-260s which sought to fend off Persian incursions. Some regions – Britain, Spain, and North Africa – were hardly affected. Instability caused economic deterioration, and there was a rapid rise in inflation as the government debased the currency in order to meet expenses. The Germanic tribes along the Rhine and north of the Balkans made serious, uncoordinated incursions from the 250s–280s that were more like giant raiding parties rather than attempts to settle. The Persian Empire invaded from the east several times during the 230s to 260s but were eventually defeated. Emperor Diocletian (284) undertook the restoration of the State. He ended the Principate and introduced the Tetrarchy which sought to increase state power. The most marked feature was the unprecedented intervention of the State down to the city level: whereas the State had submitted a tax demand to a city and allowed it to allocate the charges, from his reign the State did this down to the village level. In a vain attempt to control inflation, he imposed price controls which did not last. He or Constantine regionalised the administration of the empire which fundamentally changed the way it was governed by creating regional dioceses (the consensus seems to have shifted from 297 to 313/14 as the date of creation due to the argument of Constantin Zuckerman in 2002 \"Sur la liste de Vérone et la province de Grande-Arménie, Mélanges Gilber Dagron). The existence of regional fiscal units from 286 served as the model for this unprecedented innovation. The emperor quickened the process of removing military command from governors. Henceforth, civilian administration and military command would be separate. He gave governors more fiscal duties and placed them in charge of the army logistical support system as an attempt to control it by removing the support system from its control. Diocletian ruled the eastern half, residing in Nicomedia. In 296, he elevated Maximian to Augustus of the western half, where he ruled mostly from Mediolanum when not on the move. In 292, he created two 'junior' emperors, the Caesars, one for each Augustus, Constantius for Britain, Gaul, and Spain whose seat of power was in Trier and Galerius in Sirmium in the Balkans. The appointment of a Caesar was not unknown: Diocletian tried to turn into a system of non-dynastic succession. Upon abdication in 305, the Caesars succeeded and they, in turn, appointed two colleagues for themselves.After the abdication of Diocletian and Maximian in 305 and a series of civil wars between rival claimants to imperial power, during the years 306–313, the Tetrarchy was abandoned. Constantine the Great undertook a major reform of the bureaucracy, not by changing the structure but by rationalising the competencies of the several ministries during the years 325–330, after he defeated Licinius, emperor in the East, at the end of 324. The so-called Edict of Milan of 313, actually a fragment of a letter from Licinius to the governors of the eastern provinces, granted freedom of worship to everyone, including Christians, and ordered the restoration of confiscated church properties upon petition to the newly created vicars of dioceses. He funded the building of several churches and allowed clergy to act as arbitrators in civil suits (a measure that did not outlast him but which was restored in part much later). He transformed the town of Byzantium into his new residence, which, however, was not officially anything more than an imperial residence like Milan or Trier or Nicomedia until given a city prefect in May 359 by Constantius II; Constantinople.Christianity in the form of the Nicene Creed became the official religion of the empire in 380, via the Edict of Thessalonica issued in the name of three emperors – Gratian, Valentinian II, and Theodosius I – with Theodosius clearly the driving force behind it. He was the last emperor of a unified empire: after his death in 395, his sons, Arcadius and Honorius divided the empire into a western and an eastern part. The seat of government in the Western Roman Empire was transferred to Ravenna in 408, but from 450 the emperors mostly resided in the capital city, Rome.\n",
      "Rome, which had lost its central role in the administration of the empire, was sacked in 410 by the Visigoths led by Alaric I, but very little physical damage was done, most of which was repaired. What could not be so easily replaced were portable items such as artwork in precious metals and items for domestic use (loot). The popes embellished the city with large basilicas, such as Santa Maria Maggiore (with the collaboration of the emperors). The population of the city had fallen from 800,000 to 450–500,000 by the time the city was sacked in 455 by Genseric, king of the Vandals. The weak emperors of the fifth century could not stop the decay, leading to the deposition of Romulus Augustus on 22 August 476, which marked the end of the Western Roman Empire and, for many historians, the beginning of the Middle Ages.The decline of the city's population was caused by the loss of grain shipments from North Africa, from 440 onward, and the unwillingness of the senatorial class to maintain donations to support a population that was too large for the resources available. Even so, strenuous efforts were made to maintain the monumental centre, the palatine, and the largest baths, which continued to function until the Gothic siege of 537. The large baths of Constantine on the Quirinale were even repaired in 443, and the extent of the damage exaggerated and dramatised.However, the city gave an appearance overall of shabbiness and decay because of the large abandoned areas due to population decline. The population declined to 500,000 by 452 and 100,000 by 500 AD (perhaps larger, though no certain figure can be known). After the Gothic siege of 537, the population dropped to 30,000 but had risen to 90,000 by the papacy of Gregory the Great. The population decline coincided with the general collapse of urban life in the West in the fifth and sixth centuries, with few exceptions. Subsidized state grain distributions to the poorer members of society continued right through the sixth century and probably prevented the population from falling further. The figure of 450,000–500,000 is based on the amount of pork, 3,629,000 lbs. distributed to poorer Romans during five winter months at the rate of five Roman lbs per person per month, enough for 145,000 persons or 1/4 or 1/3 of the total population. Grain distribution to 80,000 ticket holders at the same time suggests 400,000 (Augustus set the number at 200,000 or one-fifth of the population).\n",
      "\n",
      "Middle Ages\n",
      "After the fall of the Western Roman Empire in 476 AD, Rome was first under the control of Odoacer and then became part of the Ostrogothic Kingdom before returning to East Roman control after the Gothic War, which devastated the city in 546 and 550. Its population declined from more than a million in 210 AD to 500,000 in 273 to 35,000 after the Gothic War (535–554), reducing the sprawling city to groups of inhabited buildings interspersed among large areas of ruins, vegetation, vineyards and market gardens. It is generally thought the population of the city until 300 AD was 1 million (estimates range from 2 million to 750,000) declining to 750–800,000 in 400 AD, 450–500,000 in 450 AD and down to 80–100,000 in 500 AD (though it may have been twice this).The Bishop of Rome, called the Pope, was important since the early days of Christianity because of the martyrdom of both the apostles Peter and Paul there. The Bishops of Rome were also seen (and still are seen by Catholics) as the successors of Peter, who is considered the first Bishop of Rome. The city thus became of increasing importance as the centre of the Catholic Church.\n",
      "After the Lombard invasion of Italy (569–572), the city remained nominally Byzantine, but in reality, the popes pursued a policy of equilibrium between the Byzantines, the Franks, and the Lombards. In 729, the Lombard king Liutprand donated the north Latium town of Sutri to the Church, starting its temporal power. In 756, Pepin the Short, after having defeated the Lombards, gave the Pope temporal jurisdiction over the Roman Duchy and the Exarchate of Ravenna, thus creating the Papal States. Since this period, three powers tried to rule the city: the pope, the nobility (together with the chiefs of militias, the judges, the Senate and the populace), and the Frankish king, as king of the Lombards, patricius, and Emperor. These three parties (theocratic, republican, and imperial) were a characteristic of Roman life during the entire Middle Ages. On Christmas night of 800, Charlemagne was crowned in Rome as emperor of the Holy Roman Empire by Pope Leo III: on that occasion, the city hosted for the first time the two powers whose struggle for control was to be a constant of the Middle Ages.\n",
      "In 846, Muslim Arabs unsuccessfully stormed the city's walls, but managed to loot St. Peter's and St. Paul's basilica, both outside the city wall. After the decay of Carolingian power, Rome fell prey to feudal chaos: several noble families fought against the pope, the emperor, and each other. These were the times of Theodora and her daughter Marozia, concubines and mothers of several popes, and of Crescentius, a powerful feudal lord, who fought against the Emperors Otto II and Otto III. The scandals of this period forced the papacy to reform itself: the election of the pope was reserved to the cardinals, and reform of the clergy was attempted. The driving force behind this renewal was the monk Ildebrando da Soana, who once elected pope under the name of Gregory VII became involved into the Investiture Controversy against Emperor Henry IV. Subsequently, Rome was sacked and burned by the Normans under Robert Guiscard who had entered the city in support of the Pope, then besieged in Castel Sant'Angelo.During this period, the city was autonomously ruled by a senatore or patrizio. In the 12th century, this administration, like other European cities, evolved into the commune, a new form of social organisation controlled by the new wealthy classes. Pope Lucius II fought against the Roman commune, and the struggle was continued by his successor Pope Eugenius III: by this stage, the commune, allied with the aristocracy, was supported by Arnaldo da Brescia, a monk who was a religious and social reformer. After the pope's death, Arnaldo was taken prisoner by Adrianus IV, which marked the end of the commune's autonomy. Under Pope Innocent III, whose reign marked the apogee of the papacy, the commune liquidated the senate, and replaced it with a Senatore, who was subject to the pope.In this period, the papacy played a role of secular importance in Western Europe, often acting as arbitrators between Christian monarchs and exercising additional political powers.In 1266, Charles of Anjou, who was heading south to fight the Hohenstaufen on behalf of the pope, was appointed Senator. Charles founded the Sapienza, the university of Rome. In that period the pope died, and the cardinals, summoned in Viterbo, could not agree on his successor. This angered the people of the city, who then unroofed the building where they met and imprisoned them until they had nominated the new pope; this marked the birth of the conclave. In this period the city was also shattered by continuous fights between the aristocratic families: Annibaldi, Caetani, Colonna, Orsini, Conti, nested in their fortresses built above ancient Roman edifices, fought each other to control the papacy.\n",
      "Pope Boniface VIII, born Caetani, was the last pope to fight for the church's universal domain; he proclaimed a crusade against the Colonna family and, in 1300, called for the first Jubilee of Christianity, which brought millions of pilgrims to Rome. However, his hopes were crushed by the French king Philip the Fair, who took him prisoner and killed him in Anagni. Afterwards, a new pope faithful to the French was elected, and the papacy was briefly relocated to Avignon (1309–1377). During this period Rome was neglected, until a plebeian man, Cola di Rienzo, came to power. An idealist and a lover of ancient Rome, Cola dreamed about a rebirth of the Roman Empire: after assuming power with the title of Tribuno, his reforms were rejected by the populace. Forced to flee, Cola returned as part of the entourage of Cardinal Albornoz, who was charged with restoring the Church's power in Italy. Back in power for a short time, Cola was soon lynched by the populace, and Albornoz took possession of the city. In 1377, Rome became the seat of the papacy again under Gregory XI. The return of the pope to Rome in that year unleashed the Western Schism (1377–1418), and for the next forty years, the city was affected by the divisions which rocked the Church.\n",
      "\n",
      "Early modern history\n",
      "In 1418, the Council of Constance settled the Western Schism, and a Roman pope, Martin V, was elected. This brought to Rome a century of internal peace, which marked the beginning of the Renaissance. The ruling popes until the first half of the 16th century, from Nicholas V, founder of the Vatican Library, to Pius II, humanist and literate, from Sixtus IV, a warrior pope, to Alexander VI, immoral and nepotist, from Julius II, soldier and patron, to Leo X, who gave his name to this period (\"the century of Leo X\"), all devoted their energy to the greatness and the beauty of the Eternal City and to the patronage of the arts.During those years, the centre of the Italian Renaissance moved to Rome from Florence. Majestic works, as the new Saint Peter's Basilica, the Sistine Chapel and Ponte Sisto (the first bridge to be built across the Tiber since antiquity, although on Roman foundations) were created. To accomplish that, the Popes engaged the best artists of the time, including Michelangelo, Perugino, Raphael, Ghirlandaio, Luca Signorelli, Botticelli, and Cosimo Rosselli.\n",
      "The period was also infamous for papal corruption, with many Popes fathering children, and engaging in nepotism and simony. The corruption of the Popes and the huge expenses for their building projects led, in part, to the Reformation and, in turn, the Counter-Reformation. Under extravagant and rich popes, Rome was transformed into a centre of art, poetry, music, literature, education and culture. Rome became able to compete with other major European cities of the time in terms of wealth, grandeur, the arts, learning and architecture.\n",
      "The Renaissance period changed the face of Rome dramatically, with works like the Pietà by Michelangelo and the frescoes of the Borgia Apartments. Rome reached the highest point of splendour under Pope Julius II (1503–1513) and his successors Leo X and Clement VII, both members of the Medici family.\n",
      "\n",
      "In this twenty-year period, Rome became one of the greatest centres of art in the world. The old St. Peter's Basilica built by Emperor Constantine the Great (which by then was in a dilapidated state) was demolished and a new one begun. The city hosted artists like Ghirlandaio, Perugino, Botticelli and Bramante, who built the temple of San Pietro in Montorio and planned a great project to renovate the Vatican. Raphael, who in Rome became one of the most famous painters of Italy, created frescoes in the Villa Farnesina, the Raphael's Rooms, plus many other famous paintings. Michelangelo started the decoration of the ceiling of the Sistine Chapel and executed the famous statue of the Moses for the tomb of Julius II.\n",
      "Its economy was rich, with the presence of several Tuscan bankers, including Agostino Chigi, who was a friend of Raphael and a patron of arts. Before his early death, Raphael also promoted for the first time the preservation of the ancient ruins. The War of the League of Cognac caused the first plunder of the city in more than five hundred years since the previous sack; in 1527, the Landsknechts of Emperor Charles V sacked the city, bringing an abrupt end to the golden age of the Renaissance in Rome.Beginning with the Council of Trent in 1545, the Church began the Counter-Reformation in response to the Reformation, a large-scale questioning of the Church's authority on spiritual matters and governmental affairs. This loss of confidence led to major shifts of power away from the Church. Under the popes from Pius IV to Sixtus V, Rome became the centre of a reformed Catholicism and saw the building of new monuments which celebrated the papacy. The popes and cardinals of the 17th and early 18th centuries continued the movement by having the city's landscape enriched with baroque buildings.This was another nepotistic age; the new aristocratic families (Barberini, Pamphili, Chigi, Rospigliosi, Altieri, Odescalchi) were protected by their respective popes, who built huge baroque buildings for their relatives. During the Age of Enlightenment, new ideas reached the Eternal City, where the papacy supported archaeological studies and improved the people's welfare. But not everything went well for the Church during the Counter-Reformation. There were setbacks in the attempts to assert the Church's power, a notable example being in 1773 when Pope Clement XIV was forced by secular powers to have the Jesuit order suppressed.\n",
      "\n",
      "Late modern and contemporary\n",
      "The rule of the Popes was interrupted by the short-lived Roman Republic (1798–1800), which was established under the influence of the French Revolution. The Papal States were restored in June 1800, but during Napoleon's reign Rome was annexed as a Département of the French Empire: first as Département du Tibre (1808–1810) and then as Département Rome (1810–1814). After the fall of Napoleon, the Papal States were reconstituted by a decision of the Congress of Vienna of 1814.\n",
      "In 1849, a second Roman Republic was proclaimed during a year of revolutions in 1848. Two of the most influential figures of the Italian unification, Giuseppe Mazzini and Giuseppe Garibaldi, fought for the short-lived republic.\n",
      "Rome then became the focus of hopes of Italian reunification after the rest of Italy was united as the Kingdom of Italy in 1861 with the temporary capital in Florence. That year Rome was declared the capital of Italy even though it was still under the Pope's control. During the 1860s, the last vestiges of the Papal States were under French protection thanks to the foreign policy of Napoleon III. French troops were stationed in the region under Papal control. In 1870 the French troops were withdrawn due to the outbreak of the Franco-Prussian War. Italian troops were able to capture Rome entering the city through a breach near Porta Pia. Pope Pius IX declared himself a prisoner in the Vatican. In 1871 the capital of Italy was moved from Florence to Rome. In 1870 the population of the city was 212,000, all of whom lived with the area circumscribed by the ancient city, and in 1920, the population was 660,000. A significant portion lived outside the walls in the north and across the Tiber in the Vatican area.\n",
      "\n",
      "Soon after World War I in late 1922 Rome witnessed the rise of Italian Fascism led by Benito Mussolini, who led a march on the city. He did away with democracy by 1926, eventually declaring a new Italian Empire and allying Italy with Nazi Germany in 1938. Mussolini demolished fairly large parts of the city centre in order to build wide avenues and squares which were supposed to celebrate the fascist regime and the resurgence and glorification of classical Rome. The interwar period saw a rapid growth in the city's population which surpassed one million inhabitants soon after 1930. During World War II, due to the art treasuries and the presence of the Vatican, Rome largely escaped the tragic destiny of other European cities. However, on 19 July 1943, the San Lorenzo district was subject to Allied bombing raids, resulting in about 3,000 fatalities and 11,000 injuries, of whom another 1,500 died. Mussolini was arrested on 25 July 1943. On the date of the Italian Armistice 8 September 1943 the city was occupied by the Germans. The Pope declared Rome an open city. It was liberated on 4 June 1944.\n",
      "Rome developed greatly after the war as part of the \"Italian economic miracle\" of post-war reconstruction and modernisation in the 1950s and early 1960s. During this period, the years of la dolce vita (\"the sweet life\"), Rome became a fashionable city, with popular classic films such as Ben Hur, Quo Vadis, Roman Holiday and La Dolce Vita filmed in the city's iconic Cinecittà Studios. The rising trend in population growth continued until the mid-1980s when the comune had more than 2.8 million residents. After this, the population declined slowly as people began to move to nearby suburbs.\n",
      "\n",
      "Geography\n",
      "Location\n",
      "Rome is in the Lazio region of central Italy on the Tiber (Italian: Tevere) river. The original settlement developed on hills that faced onto a ford beside the Tiber Island, the only natural ford of the river in this area. The Rome of the Kings was built on seven hills: the Aventine Hill, the Caelian Hill, the Capitoline Hill, the Esquiline Hill, the Palatine Hill, the Quirinal Hill, and the Viminal Hill. Modern Rome is also crossed by another river, the Aniene, which flows into the Tiber north of the historic centre.\n",
      "Although the city centre is about 24 km (15 mi) inland from the Tyrrhenian Sea, the city territory extends to the shore, where the south-western district of Ostia is located. The altitude of the central part of Rome ranges from 13 m (43 ft) above sea level (at the base of the Pantheon) to 139 m (456 ft) above sea level (the peak of Monte Mario). The Comune of Rome covers an overall area of about 1,285 km2 (496 sq mi), including many green areas.\n",
      "\n",
      "Parks and gardens\n",
      "Public parks and nature reserves cover a large area in Rome, and the city has one of the largest areas of green space among European capitals. The most notable part of this green space is represented by the large number of villas and landscaped gardens created by the Italian aristocracy. While most of the parks surrounding the villas were destroyed during the building boom of the late 19th century, some of them remain. The most notable of these are the Villa Borghese, Villa Ada, and Villa Doria Pamphili. Villa Doria Pamphili is west of the Gianicolo hill, comprising some 1.8 km2 (0.7 sq mi). The Villa Sciarra is on the hill, with playgrounds for children and shaded walking areas. In the nearby area of Trastevere, the Orto Botanico (Botanical Garden) is a cool and shady green space. The old Roman hippodrome (Circus Maximus) is another large green space: it has few trees but is overlooked by the Palatine and the Rose Garden ('roseto comunale'). Nearby is the lush Villa Celimontana, close to the gardens surrounding the Baths of Caracalla. The Villa Borghese garden is the best known large green space in Rome, with famous art galleries among its shaded walks. Overlooking Piazza del Popolo and the Spanish Steps are the gardens of Pincio and Villa Medici. There is also a notable pine wood at Castelfusano, near Ostia. Rome also has a number of regional parks of much more recent origin, including the Pineto Regional Park and the Appian Way Regional Park. There are also nature reserves at Marcigliana and at Tenuta di Castelporziano.\n",
      "\n",
      "Climate\n",
      "Rome has a Mediterranean climate (Köppen climate classification: Csa), with hot, dry summers and mild, humid winters.\n",
      "Its average annual temperature is above 21 °C (70 °F) during the day and 9 °C (48 °F) at night. In the coldest month, January, the average temperature is 12.6 °C (54.7 °F) during the day and 2.1 °C (35.8 °F) at night. In the warmest month, August, the average temperature is 31.7 °C (89.1 °F) during the day and 17.3 °C (63.1 °F) at night.\n",
      "December, January and February are the coldest months, with a daily mean temperature of approximately 8 °C (46 °F). Temperatures during these months generally vary between 10 and 15 °C (50 and 59 °F) during the day and between 3 and 5 °C (37 and 41 °F) at night, with colder or warmer spells occurring frequently. Snowfall is rare but not unheard of, with light snow or flurries occurring on some winters, generally without accumulation, and major snowfalls on a very rare occurrence (the most recent ones were in 2018, 2012 and 1986).The average relative humidity is 75%, varying from 72% in July to 77% in November. Sea temperatures vary from a low of 13.9 °C (57.0 °F) in February to a high of 25.0 °C (77.0 °F) in August.The highest temperature ever recorded in Rome was 42.9 °C (109.2 °F) on 18 July 2023.\n",
      "\n",
      "Demographics\n",
      "In 550 BC, Rome was the second largest city in Italy, with Tarentum being the largest. It had an area of about 285 ha (700 acres) and an estimated population of 35,000. Other sources suggest the population was just under 100,000 from 600 to 500 BC. When the Republic was founded in 509 BC the census recorded a population of 130,000. The republic included the city itself and the immediate surroundings. Other sources suggest a population of 150,000 in 500 BC. It surpassed 300,000 in 150 BC.The size of the city at the time of the Emperor Augustus is a matter of speculation, with estimates based on grain distribution, grain imports, aqueduct capacity, city limits, population density, census reports, and assumptions about the number of unreported women, children and slaves providing a very wide range. Glenn Storey estimates 450,000 people, Whitney Oates estimates 1.2 million, Neville Morely provides a rough estimate of 800,000 and excludes earlier suggestions of 2 million. Estimates of the city's population towards and after the end of the Roman empire also vary. A.H.M. Jones estimated the population at 650,000 in the mid-fifth century. The damage caused by the sackings may have been overestimated. The population had already started to decline from the late fourth century onward, although around the middle of the fifth century it seems that Rome continued to be the most populous city of the two parts of the Empire. According to Krautheimer it was still close to 800,000 in 400 AD; had declined to 500,000 by 452, and dwindled to perhaps 100,000 in 500 AD. After the Gothic Wars, 535–552, the population may have dwindled temporarily to 30,000. During the pontificate of Pope Gregory I (590–604), it may have reached 90,000, augmented by refugees. Lancon estimates 500,000 based on the number of 'incisi' enrolled as eligible to receive bread, oil and wine rations; the number fell to 120,000 in the reform of 419. Neil Christie, citing free rations for the poorest, estimated 500,000 in the mid-fifth century and still a quarter of a million at the end of the century. Novel 36 of Emperor Valentinian III records 3.629 million pounds of pork to be distributed to the needy at 5 lbs. per month for the five winter months, sufficient for 145,000 recipients. This has been used to suggest a population of just under 500,000. Supplies of grain remained steady until the seizure of the remaining provinces of North Africa in 439 by the Vandals, and may have continued to some degree afterwards for a while. The city's population declined to less than 50,000 people in the Early Middle Ages from 700 AD onward. It continued to stagnate or shrink until the Renaissance.When the Kingdom of Italy annexed Rome in 1870, the city had a population of about 225,000. Less than half the city within the walls was built up in 1881 when the population recorded was 275,000. This increased to 600,000 by the eve of World War I. The Fascist regime of Mussolini tried to block an excessive demographic rise of the city but failed to prevent it from reaching one million people by the early 1930s. Population growth continued after the Second World War, helped by a post-war economic boom. A construction boom also created many suburbs during the 1950s and 1960s.\n",
      "In mid-2010, there were 2,754,440 residents in the city proper, while some 4.2 million people lived in the greater Rome area (which can be approximately identified with its administrative metropolitan city, with a population density of about 800 inhabitants/km2 stretching over more than 5,000 km2 (1,900 sq mi)). Minors (children ages 18 and younger) totalled 17.00% of the population compared to pensioners who number 20.76%. This compares with the Italian average of 18.06% (minors) and 19.94% (pensioners). The average age of a Roman resident is 43 compared to the Italian average of 42. In the five years between 2002 and 2007, the population of Rome grew by 6.54%, while Italy as a whole grew by 3.56%. The current birth rate of Rome is 9.10 births per 1,000 inhabitants compared to the Italian average of 9.45 births.The urban area of Rome extends beyond the administrative city limits with a population of around 3.9 million. Between 3.2 and 4.2 million people live in the Rome metropolitan area.\n",
      "\n",
      "Origin groups\n",
      "According to the latest statistics conducted by ISTAT, approximately 9.5% of the population consists of non-Italians. About half of the immigrant population consists of those of various other European origins (chiefly Romanian, Polish, Ukrainian, and Albanian) numbering a combined total of 131,118 or 4.7% of the population. The remaining 4.8% are those with non-European origins, chiefly Filipinos (26,933), Bangladeshis (12,154), and Chinese (10,283).\n",
      "The Esquilino rione, off Termini Railway Station, has evolved into a largely immigrant neighbourhood. It is perceived as Rome's Chinatown. Immigrants from more than a hundred different countries reside there. A commercial district, Esquilino contains restaurants featuring many kinds of international cuisine. There are wholesale clothes shops. Of the 1,300 or so commercial premises operating in the district 800 are Chinese-owned; around 300 are run by immigrants from other countries around the world; 200 are owned by Italians.\n",
      "\n",
      "Language\n",
      "Rome's historic contribution to language in a worldwide sense is much more extensive, however. Through the process of Romanization, the peoples of Italy, Gallia, the Iberian Peninsula and Dacia developed languages which derive directly from Latin and were adopted in large areas of the world, all through cultural influence, colonisation and migration. Moreover, also modern English, because of the Norman Conquest, borrowed a large percentage of its vocabulary from the Latin language. The Roman or Latin alphabet is the most widely used writing system in the world used by the greatest number of languages.The medieval Roman dialect belonged to the southern family of Italian dialects, and was thus much closer to the Neapolitan language than to the Florentine. A typical example of Romanesco of that period is Vita di Cola di Rienzo (\"Life of Cola di Rienzo\"), written by an anonymous Roman during the 14th century. Starting with the 16th century, the Roman dialect underwent a stronger and stronger influence from the Tuscan dialect (from which modern Italian derives) starting with the reigns of the two Medici popes (Leo X and Clement VII) and with the Sack of Rome in 1527, two events which provoked a large immigration from Tuscany. Therefore, current Romanesco has grammar and roots that are rather different from other dialects in Central Italy.\n",
      "\n",
      "Religion\n",
      "Much like the rest of Italy, Rome is predominantly Christian, and the city has been an important centre of religion and pilgrimage for centuries, the base of the ancient Roman religion with the pontifex maximus and later the seat of the Vatican and the pope. Before the arrival of the Christians in Rome, the Religio Romana (literally, the \"Roman Religion\") was the major religion of the city in classical antiquity. The first gods held sacred by the Romans were Jupiter, the Most High, and Mars, the god of war, and father of Rome's twin founders, Romulus and Remus, according to tradition. Other deities such as Vesta and Minerva were honoured. Rome was also the base of several mystery cults, such as Mithraism. Later, after St Peter and St Paul were martyred in the city, and the first Christians began to arrive, Rome became Christian, and the Old St. Peter's Basilica was constructed in 313 AD. Despite some interruptions (such as the Avignon papacy), Rome has for centuries been the home of the Roman Catholic Church and the Bishop of Rome, otherwise known as the Pope.\n",
      "Despite the fact that Rome is home to the Vatican City and St. Peter's Basilica, Rome's cathedral is the Archbasilica of Saint John Lateran, in the south-east of the city centre. There are around 900 churches in Rome in total. Aside from the cathedral itself, some others of note include the Basilica di Santa Maria Maggiore, the Basilica of Saint Paul Outside the Walls, the Basilica di San Clemente, San Carlo alle Quattro Fontane and the Church of the Gesù. There are also the ancient Catacombs of Rome underneath the city. Numerous highly important religious educational institutions are also in Rome, such as the Pontifical Lateran University, Pontifical Biblical Institute, Pontifical Gregorian University, and Pontifical Oriental Institute.\n",
      "Since the end of the Roman Republic, Rome is also the centre of an important Jewish community, which was once based in Trastevere, and later in the Roman Ghetto. There lies also the major synagogue in Rome, the Tempio Maggiore.\n",
      "The territory of Vatican City is part of the Mons Vaticanus (Vatican Hill), and of the adjacent former Vatican Fields, where St. Peter's Basilica, the Apostolic Palace, the Sistine Chapel, and museums were built, along with various other buildings. The area was part of the Roman rione of Borgo until 1929. Being separated from the city on the west bank of the Tiber, the area was a suburb that was protected by being included within the walls of Leo IV, later expanded by the current fortification walls of Paul III, Pius IV, and Urban VIII. When the Lateran Treaty of 1929 that created the Vatican state was being prepared, the boundaries of the proposed territory were influenced by the fact that much of it was all but enclosed by this loop.\n",
      "Rome has been a major Christian pilgrimage site since the Middle Ages. People from all over the Christian world visit Vatican City, within the city of Rome, the seat of the papacy. The city became a major pilgrimage site during the Middle Ages. Apart from brief periods as an independent city during the Middle Ages, Rome kept its status as Papal capital and holy city for centuries, even when the Papacy briefly relocated to Avignon (1309–1377). Catholics believe that the Vatican is the last resting place of St. Peter. Pilgrimages to Rome can involve visits to many sites, both within Vatican City and in Italian territory. A popular stopping point is the Pilate's stairs: these are, according to the Christian tradition, the steps that led up to the praetorium of Pontius Pilate in Jerusalem, which Jesus Christ stood on during his Passion on his way to trial.\n",
      "\n",
      "Government\n",
      "Rome constitutes a comune speciale, named \"Roma Capitale\", and is the largest both in terms of land area and population among the 8,101 comuni of Italy. It is governed by a mayor and a city council. The seat of the comune is the Palazzo Senatorio on the Capitoline Hill, the historic seat of the city government. The local administration in Rome is commonly referred to as \"Campidoglio\", the Italian name of the hill.\n",
      "Since 1972, the city has been divided into administrative areas, called municipi (sing. municipio) (until 2001 named circoscrizioni). They were created for administrative reasons to increase decentralisation in the city. Each municipio is governed by a president and a council of twenty-five members who are elected by its residents every five years. The municipi frequently cross the boundaries of the traditional, non-administrative divisions of the city. The municipi were originally 20, then 19, and in 2013, their number was reduced to 15.Rome is also divided into differing types of non-administrative units. The historic centre is divided into 22 rioni, all of which are located within the Aurelian Walls except Prati and Borgo. These originate from the 14 regions of Augustan Rome, which evolved in the Middle Ages into the medieval rioni. In the Renaissance, under Pope Sixtus V, they again reached fourteen, and their boundaries were finally defined under Pope Benedict XIV in 1743.\n",
      "Rome is the principal town of the Metropolitan City of Rome, operative since 1 January 2015. The Metropolitan City replaced the old provincia di Roma, which included the city's metropolitan area and extends further north until Civitavecchia. The Metropolitan City of Rome is the largest by area in Italy. At 5,352 km2 (2,066 sq mi), its dimensions are comparable to the region of Liguria. Moreover, the city is also the capital of the Lazio region.Rome is the national capital of Italy and is the seat of the Italian Government. The official residences of the President of the Italian Republic and the Italian Prime Minister, the seats of both houses of the Italian Parliament and that of the Italian Constitutional Court are located in the historic centre. The state ministries are spread out around the city; these include the Ministry of Foreign Affairs, which is located in Palazzo della Farnesina near the Olympic stadium.\n",
      "\n",
      "International relations\n",
      "Among the global cities, Rome is unique in having two sovereign entities located entirely within its city limits, the Holy See, represented by the Vatican City State, and the territorially smaller Sovereign Military Order of Malta. The Vatican is an enclave of the Italian capital city and a sovereign possession of the Holy See, which is the Diocese of Rome and the supreme government of the Roman Catholic Church. For this reason, Rome has sometimes been described as the capital of two states. Rome is the seat of the so-called \"Polo Romano\" made up by three main international agencies of the United Nations: the Food and Agriculture Organization (FAO), the World Food Programme (WFP) and the International Fund for Agricultural Development (IFAD).Rome has traditionally been involved in the process of European political integration. The Treaties of the EU are located in Palazzo della Farnesina. In 1957 the city hosted the signing of the Treaty of Rome, which established the European Economic Community (predecessor to the European Union), and also played host to the official signing of the proposed European Constitution in July 2004. Rome is the seat of the European Olympic Committee and of the NATO Defense College. The city is the place where the Statute of the International Criminal Court and the European Convention on Human Rights were formulated. The city hosts also other important international entities such as the IDLO (International Development Law Organisation), the ICCROM (International Centre for the Study of the Preservation and Restoration of Cultural Property) and the UNIDROIT (International Institute for the Unification of Private Law).\n",
      "\n",
      "Twin towns and sister cities\n",
      "Since 9 April 1956, Rome is exclusively and reciprocally twinned only with:\n",
      "\n",
      " Paris, France, 1956Solo Parigi è degna di Roma; solo Roma è degna di Parigi. (in Italian)\n",
      "Seule Paris est digne de Rome; seule Rome est digne de Paris. (in French)\n",
      "\"Only Paris is worthy of Rome; only Rome is worthy of Paris.\"Rome's other partner cities are:\n",
      "\n",
      "Economy\n",
      "As the capital of Italy, Rome hosts all the principal institutions of the nation, including the Presidency of the Republic, the government (and its single Ministeri), the Parliament, the main judicial Courts, and the diplomatic representatives of all the countries for the states of Italy and Vatican City. Many international institutions are located in Rome, notably cultural and scientific ones, such as the American Institute, the British School, the French Academy, the Scandinavian Institutes, and the German Archaeological Institute. There are also specialised agencies of the United Nations, such as the Food and Agriculture Organization (FAO). Rome also hosts major international and worldwide political and cultural organisations, such as the International Fund for Agricultural Development (IFAD), World Food Programme (WFP), the NATO Defence College, and the International Centre for the Study of the Preservation and Restoration of Cultural Property (ICCROM).\n",
      "According to the GaWC study of world cities, Rome is a \"Beta +\" city. The city was ranked in 2014 as 32nd in the Global Cities Index, the highest in Italy. With a 2005 GDP of €94.376 billion (US$121.5 billion), the city produces 6.7% of the national GDP (more than any other single city in Italy), and its unemployment rate, lowered from 11.1% to 6.5% between 2001 and 2005, is now one of the lowest rates of all the European Union capital cities. Rome's economy grows at around 4.4% annually and continues to grow at a higher rate in comparison to any other city in the rest of the country. This means that were Rome a country, it would be the world's 52nd richest country by GDP, near to the size to that of Egypt. Rome also had a 2003 GDP per capita of €29,153 (US$37,412), which was second in Italy (after Milan), and is more than 134.1% of the EU average GDP per capita. Rome, on the whole, has the highest total earnings in Italy, reaching €47,076,890,463 in 2008, yet, in terms of average workers' incomes, the city places itself 9th in Italy, with €24,509. On a global level, Rome's workers receive the 30th highest wages in 2009, coming three places higher than in 2008, in which the city ranked 33rd. The Rome area had a GDP amounting to $167.8 billion, and $38,765 per capita.Although the economy of Rome is characterised by the absence of heavy industry, and it is largely dominated by services, high-technology companies (IT, aerospace, defence, telecommunications), research, construction and commercial activities (especially banking), and the huge development of tourism are very dynamic and extremely important to its economy. Rome's international airport, Fiumicino, is the largest in Italy, and the city hosts the head offices of the vast majority of the major Italian companies, as well as the headquarters of three of the world's 100 largest companies: Enel, Eni, and Telecom Italia.Universities, national radio and television and the movie industry in Rome are also important parts of the economy: Rome is also the hub of the Italian film industry, thanks to the Cinecittà studios, working since the 1930s. The city is also a centre for banking and insurance as well as electronics, energy, transport, and aerospace industries. Numerous international companies and agencies headquarters, government ministries, conference centres, sports venues, and museums are located in Rome's principal business districts: the Esposizione Universale Roma (EUR); the Torrino (further south from the EUR); the Magliana; the Parco de' Medici-Laurentina and the so-called Tiburtina-valley along the ancient Via Tiburtina.\n",
      "\n",
      "Tourism\n",
      "Rome today is one of the most important tourist destinations of the world, due to the incalculable immensity of its archaeological and artistic treasures, as well as for the charm of its unique traditions, the beauty of its panoramic views, and the majesty of its magnificent \"villas\" (parks). Among the most significant resources are the many museums – Capitoline Museums, the Vatican Museums and the Galleria Borghese and others dedicated to modern and contemporary art – aqueducts, fountains, churches, palaces, historical buildings, the monuments and ruins of the Roman Forum, and the Catacombs. Rome is the third most visited city in the EU, after London and Paris, and receives an average of 7–10 million tourists a year, which sometimes doubles on holy years. The Colosseum (4 million tourists) and the Vatican Museums (4.2 million tourists) are the 39th and 37th (respectively) most visited places in the world, according to a recent study.Rome is a major archaeological hub, and one of the world's main centres of archaeological research. There are numerous cultural and research institutes located in the city, such as the American Academy in Rome, and The Swedish Institute at Rome. Rome contains numerous ancient sites, including the Forum Romanum, Trajan's Market, Trajan's Forum, the Colosseum, and the Pantheon, to name but a few. The Colosseum, arguably one of Rome's most iconic archaeological sites, is regarded as a wonder of the world.Rome contains a vast collection of art, sculpture, fountains, mosaics, frescos, and paintings, from all different periods. Rome first became a major artistic centre during ancient Rome, with forms of important Roman art such as architecture, painting, sculpture and mosaic work. Metal-work, coin die and gem engraving, ivory carvings, figurine glass, pottery, and book illustrations are considered to be 'minor' forms of Roman artwork. Rome later became a major centre of Renaissance art, since the popes spent vast sums of money for the constructions of grandiose basilicas, palaces, piazzas and public buildings in general. Rome became one of Europe's major centres of Renaissance artwork, second only to Florence, and able to compare to other major cities and cultural centres, such as Paris and Venice. The city was affected greatly by the baroque, and Rome became the home of numerous artists and architects, such as Bernini, Caravaggio, Carracci, Borromini and Cortona. In the late 18th century and early 19th century, the city was one of the centres of the Grand Tour, when wealthy, young English and other European aristocrats visited the city to learn about ancient Roman culture, art, philosophy, and architecture. Rome hosted a great number of neoclassical and rococo artists, such as Pannini and Bernardo Bellotto. Today, the city is a major artistic centre, with numerous art institutes and museums.\n",
      "Rome has a growing stock of contemporary and modern art and architecture. The National Gallery of Modern Art has works by Balla, Morandi, Pirandello, Carrà, De Chirico, De Pisis, Guttuso, Fontana, Burri, Mastroianni, Turcato, Kandisky, and Cézanne on permanent exhibition. 2010 saw the opening of Rome's newest arts foundation, a contemporary art and architecture gallery designed by acclaimed Iraqi architect Zaha Hadid. Known as MAXXI – National Museum of the 21st Century Arts it restores a dilapidated area with striking modern architecture. Maxxi features a campus dedicated to culture, experimental research laboratories, international exchange and study and research. It is one of Rome's most ambitious modern architecture projects alongside Renzo Piano's Auditorium Parco della Musica and Massimiliano Fuksas' Rome Convention Center, Centro Congressi Italia EUR, in the EUR district, due to open in 2016. The convention centre features a huge translucent container inside which is suspended a steel and teflon structure resembling a cloud and which contains meeting rooms and an auditorium with two piazzas open to the neighbourhood on either side.\n",
      "\n",
      "Education\n",
      "Rome is a nationwide and major international centre for higher education, containing numerous academies, colleges and universities. It boasts a large variety of academies and colleges, and has always been a major worldwide intellectual and educational centre, especially during Ancient Rome and the Renaissance, along with Florence. According to the City Brands Index, Rome is considered the world's second most historically, educationally and culturally interesting and beautiful city.Rome has many universities and colleges. Its first university, La Sapienza (founded in 1303), is one of the largest in the world, with more than 140,000 students attending; in 2005 it ranked as Europe's 33rd best university and in 2013 the Sapienza University of Rome ranked as the 62nd in the world and the top in Italy in its World University Rankings. and has been ranked among Europe's 50 and the world's 150 best colleges. In order to decrease the overcrowding of La Sapienza, two new public universities were founded during the last decades: Tor Vergata in 1982, and Roma Tre in 1992. Rome hosts also the LUISS School of Government, Italy's most important graduate university in the areas of international affairs and European studies as well as LUISS Business School, Italy's most important business school. Rome ISIA was founded in 1973 by Giulio Carlo Argan and is Italy's oldest institution in the field of industrial design.\n",
      "\n",
      "Rome contains many pontifical universities and other institutes, including the British School at Rome, the French School in Rome, the Pontifical Gregorian University (the oldest Jesuit university in the world, founded in 1551), Istituto Europeo di Design, the Scuola Lorenzo de' Medici, the Link Campus of Malta, and the Università Campus Bio-Medico. Rome is also the location of two American Universities; The American University of Rome and John Cabot University as well as St. John's University branch campus, John Felice Rome Center, a campus of Loyola University Chicago and Temple University Rome, a campus of Temple University. The Roman Colleges are several seminaries for students from foreign countries studying for the priesthood at the Pontifical Universities. Examples include the Venerable English College, the Pontifical North American College, the Scots College, and the Pontifical Croatian College of St. Jerome.\n",
      "Rome's major libraries include: the Biblioteca Angelica, opened in 1604, making it Italy's first public library; the Biblioteca Vallicelliana, established in 1565; the Biblioteca Casanatense, opened in 1701; the National Central Library, one of the two national libraries in Italy, which contains 4,126,002 volumes; The Biblioteca del Ministero degli Affari Esteri, specialised in diplomacy, foreign affairs and modern history; the Biblioteca dell'Istituto dell'Enciclopedia Italiana; the Biblioteca Don Bosco, one of the largest and most modern of all Salesian libraries; the Biblioteca e Museo teatrale del Burcardo, a museum-library specialised in history of drama and theatre; the Biblioteca della Società Geografica Italiana, which is based in the Villa Celimontana and is the most important geographical library in Italy, and one of Europe's most important; and the Vatican Library, one of the oldest and most important libraries in the world, which was formally established in 1475, though in fact much older and has 75,000 codices, as well as 1.1 million printed books, which include some 8,500 incunabula. There are also many specialist libraries attached to various foreign cultural institutes in Rome, among them that of the American Academy in Rome, the French Academy in Rome and the Bibliotheca Hertziana – Max Planck Institute of Art History, a German library, often noted for excellence in the arts and sciences.\n",
      "\n",
      "Culture\n",
      "Architecture\n",
      "Fountains and aqueducts\n",
      "Rome is a city known for its numerous fountains, built-in all different styles, from Classical and Medieval, to Baroque and Neoclassical. The city has had fountains for more than two thousand years, and they have provided drinking water and decorated the piazzas of Rome. During the Roman Empire, in 98 AD, according to Sextus Julius Frontinus, the Roman consul who was named curator aquarum or guardian of the water of the city, Rome had nine aqueducts which fed 39 monumental fountains and 591 public basins, not counting the water supplied to the Imperial household, baths, and owners of private villas. Each of the major fountains was connected to two different aqueducts, in case one was shut down for service.During the 17th and 18th century, the Roman popes reconstructed other degraded Roman aqueducts and built new display fountains to mark their termini, launching the golden age of the Roman fountain. The fountains of Rome, like the paintings of Rubens, were expressions of the new style of Baroque art. In these fountains, sculpture became the principal element, and the water was used simply to animate and decorate the sculptures. They, like baroque gardens, were \"a visual representation of confidence and power\".\n",
      "\n",
      "Statues\n",
      "Rome is well known for its statues but, in particular, the talking statues of Rome. These are usually ancient statues which have become popular soapboxes for political and social discussion, and places for people to (often satirically) voice their opinions. There are two main talking statues: the Pasquino and the Marforio, yet there are four other noted ones: il Babuino, Madama Lucrezia, il Facchino and Abbot Luigi. Most of these statues are ancient Roman or classical, and most of them also depict mythical gods, ancient people or legendary figures; il Pasquino represents Menelaus, Abbot Luigi is an unknown Roman magistrate, il Babuino is supposed to be Silenus, Marforio represents Oceanus, Madama Lucrezia is a bust of Isis, and il Facchino is the only non-Roman statue, created in 1580, and not representing anyone in particular. They are often, due to their status, covered with placards or graffiti expressing political ideas and points of view. Other statues in the city, which are not related to the talking statues, include those of the Ponte Sant'Angelo, or several monuments scattered across the city, such as that to Giordano Bruno in the Campo de'Fiori.\n",
      "\n",
      "Obelisks and columns\n",
      "The city hosts eight ancient Egyptian and five ancient Roman obelisks, together with a number of more modern obelisks; there was also formerly (until 2005) an ancient Ethiopian obelisk in Rome. The city contains some of obelisks in piazzas, such as in Piazza Navona, St Peter's Square, Piazza Montecitorio, and Piazza del Popolo, and others in villas, thermae parks and gardens, such as in Villa Celimontana, the Baths of Diocletian, and the Pincian Hill. Moreover, the centre of Rome hosts also Trajan's and Antonine Column, two ancient Roman columns with spiral relief. The Column of Marcus Aurelius is located in Piazza Colonna and it was built around 180 AD by Commodus in memory of his parents. The Column of Marcus Aurelius was inspired by Trajan's Column at Trajan's Forum, which is part of the Imperial Fora.\n",
      "\n",
      "Bridges\n",
      "The city of Rome contains numerous famous bridges which cross the Tiber. The only bridge to remain unaltered until today from the classical age is Ponte dei Quattro Capi, which connects the Isola Tiberina with the left bank. The other surviving – albeit modified – ancient Roman bridges crossing the Tiber are Ponte Cestio, Ponte Sant'Angelo and Ponte Milvio. Considering Ponte Nomentano, also built during ancient Rome, which crosses the Aniene, currently there are five ancient Roman bridges still remaining in the city. Other noteworthy bridges are Ponte Sisto, the first bridge built in the Renaissance above Roman foundations; Ponte Rotto, actually the only remaining arch of the ancient Pons Aemilius, collapsed during the flood of 1598 and demolished at the end of the 19th century; and Ponte Vittorio Emanuele II, a modern bridge connecting Corso Vittorio Emanuele and Borgo. Most of the city's public bridges were built in Classical or Renaissance style, but also in Baroque, Neoclassical and Modern styles. According to the Encyclopædia Britannica, the finest ancient bridge remaining in Rome is the Ponte Sant'Angelo, which was completed in 135 AD, and was decorated with ten statues of the angels, designed by Bernini in 1688.\n",
      "\n",
      "Catacombs\n",
      "Rome has an extensive amount of ancient catacombs, or underground burial places under or near the city, of which there are at least forty, some discovered only in recent decades. Though most famous for Christian burials, they include pagan and Jewish burials, either in separate catacombs or mixed together. The first large-scale catacombs were excavated from the 2nd century onwards. Originally they were carved through tuff, a soft volcanic rock, outside the boundaries of the city, because Roman law forbade burial places within city limits. Currently, maintenance of the catacombs is in the hands of the Papacy which has invested in the Salesians of Don Bosco the supervision of the Catacombs of St. Callixtus on the outskirts of Rome.\n",
      "\n",
      "Entertainment and performing arts\n",
      "Rome is an important centre for music, and it has an intense musical scene, including several prestigious music conservatories and theatres. It hosts the Accademia Nazionale di Santa Cecilia (founded in 1585), for which new concert halls have been built in the new Parco della Musica, one of the largest musical venues in the world. Rome also has an opera house, the Teatro dell'Opera di Roma, as well as several minor musical institutions. The city also played host to the Eurovision Song Contest in 1991 and the MTV Europe Music Awards in 2004.\n",
      "Rome has also had a major impact on music history. The Roman School was a group of composers of predominantly church music, which were active in the city during the 16th and 17th centuries, therefore spanning the late Renaissance and early Baroque eras. The term also refers to the music they produced. Many of the composers had a direct connection to the Vatican and the papal chapel, though they worked at several churches; stylistically they are often contrasted with the Venetian School of composers, a concurrent movement which was much more progressive. By far the most famous composer of the Roman School is Giovanni Pierluigi da Palestrina, whose name has been associated for four hundred years with smooth, clear, polyphonic perfection. However, there were other composers working in Rome, and in a variety of styles and forms.\n",
      "Between 1960 and 1970 Rome was considered to be as a \"new Hollywood\" because of the many actors and directors who worked there; Via Vittorio Veneto had transformed into a glamour place where you could meet famous people.\n",
      "\n",
      "Fashion\n",
      "Rome is also widely recognised as a world fashion capital. Although not as important as Milan, Rome is the fourth most important centre for fashion in the world, according to the 2009 Global Language Monitor after Milan, New York, and Paris, and beating London.Major luxury fashion houses and jewellery chains, such as Valentino, Bulgari, Fendi, Laura Biagiotti, Brioni, and Renato Balestra, are headquartered or were founded in the city. Also, other major labels, such as Gucci, Chanel, Prada, Dolce & Gabbana, Armani, and Versace have luxury boutiques in Rome, primarily along its prestigious and upscale Via dei Condotti.\n",
      "\n",
      "Cuisine\n",
      "Rome's cuisine has evolved through centuries and periods of social, cultural, and political changes. Rome became a major gastronomical centre during the ancient age. Ancient Roman cuisine was highly influenced by Ancient Greek culture, and after, the empire's enormous expansion exposed Romans to many new, provincial culinary habits and cooking techniques.Later, during the Renaissance, Rome became well known as a centre of high-cuisine, since some of the best chefs of the time worked for the popes. An example of this was Bartolomeo Scappi, who was a chef working for Pius IV; he acquired fame in 1570 when his cookbook Opera dell'arte del cucinare was published. In the book he lists approximately 1,000 recipes of the Renaissance cuisine and describes cooking techniques and tools, giving the first known picture of a fork.\n",
      "The Testaccio, Rome's trade and slaughterhouse area, was often known as the \"belly\" or \"slaughterhouse\" of Rome, and was inhabited by butchers, or vaccinari. The most common or ancient Roman cuisine included the \"fifth quarter\". The old-fashioned coda alla vaccinara (oxtail cooked in the way of butchers) is still one of the city's most popular meals and is part of most of Rome's restaurants' menus. Lamb is also a very popular part of Roman cuisine, and is often roasted with spices and herbs.In the modern age, the city developed its own peculiar cuisine, based on products of the nearby Campagna, as lamb and vegetables (globe artichokes are common). In parallel, Roman Jews – present in the city since the 1st century BC – developed their own cuisine, the cucina giudaico-romanesca.\n",
      "Examples of Roman dishes include saltimbocca alla romana – a veal cutlet, Roman-style, topped with raw ham and sage and simmered with white wine and butter; carciofi alla romana – artichokes Roman-style, outer leaves removed, stuffed with mint, garlic, breadcrumbs and braised; carciofi alla giudia – artichokes fried in olive oil, typical of Roman Jewish cooking, outer leaves removed, stuffed with mint, garlic, breadcrumbs and braised; spaghetti alla carbonara – spaghetti with bacon, eggs and pecorino; and gnocchi di semolino alla romana – semolina dumpling, Roman-style.\n",
      "\n",
      "Cinema\n",
      "Rome hosts the Cinecittà Studios, the largest film and television production facility in continental Europe and the centre of the Italian cinema, where many of today's biggest box office hits are filmed. The 99-acre (40 ha) studio complex is 9.0 km (5.6 mi) from the centre of Rome and is part of one of the biggest production communities in the world, second only to Hollywood, with well over 5,000 professionals – from period costume makers to visual effects specialists. More than 3,000 productions have been made on its lot.Founded in 1937 by Benito Mussolini, the studios were bombed by the Western Allies during the Second World War. In the 1950s, Cinecittà was the filming location for several large American film productions, and subsequently became the studio most closely associated with Federico Fellini. Today, Cinecittà is the only studio in the world with pre-production, production, and full post-production facilities on one lot, allowing directors and producers to walk in with their script and \"walkout\" with a completed film.\n",
      "\n",
      "Sports\n",
      "Association football is the most popular sport in Rome, as in the rest of the country.\n",
      "The city hosted the final games of the 1934 and 1990 FIFA World Cup.\n",
      "The latter took place in the Stadio Olimpico, which is also the shared home stadium for local Serie A clubs SS Lazio, founded in 1900, and AS Roma, founded in 1927, whose rivalry in the Derby della Capitale has become a staple of Roman sports culture.\n",
      "Footballers who play for these teams and are also born in the city tend to become especially popular, as has been the case with players such as Francesco Totti and Daniele De Rossi (both for AS Roma), and Alessandro Nesta (for SS Lazio).\n",
      "\n",
      "Rome hosted the 1960 Summer Olympics, with great success, using many ancient sites such as the Villa Borghese and the Thermae of Caracalla as venues. For the Olympic Games many new facilities were built, notably the new large Olympic Stadium (which was then enlarged and renewed to host several matches and the final of the 1990 FIFA World Cup), the Stadio Flaminio, the Villaggio Olimpico (Olympic Village, created to host the athletes and redeveloped after the games as a residential district), ecc. Rome made a bid to host the 2020 Summer Olympics but it was withdrawn.Further, Rome hosted the EuroBasket 1991 and is home to the internationally recognised basketball team Virtus Roma. Rugby union is gaining wider acceptance. Until 2011 the Stadio Flaminio was the home stadium for the Italy national rugby union team, which has been playing in the Six Nations Championship since 2000. The team now plays home games at the Stadio Olimpico because the Stadio Flaminio needs works of renovation in order to improve both its capacity and safety. Rome is home to local rugby union teams such as Rugby Roma (winner of five Italian championships), Unione Rugby Capitolina and S.S. Lazio Rugby 1927 (rugby union branch of the multisport club S.S. Lazio).\n",
      "Every May, Rome hosts the ATP Masters Series tennis tournament on the clay courts of the Foro Italico. Cycling was popular in the post-World War II period, although its popularity has faded. Rome has hosted the final portion of the Giro d'Italia three times, in 1911, 1950, and 2009. Other local sports teams include volleyball (M. Roma Volley), handball or waterpolo.\n",
      "\n",
      "Transport\n",
      "Rome is at the centre of the radial network of roads that roughly follow the lines of the ancient Roman roads which began at the Capitoline Hill and connected Rome with its empire. Today Rome is circled, at a distance of about 10 km (6 mi) from the Capitol, by the ring-road (the Grande Raccordo Anulare or GRA).\n",
      "Due to its location in the centre of the Italian peninsula, Rome is the principal railway node for central Italy. Rome's main railway station, Termini, is one of the largest railway stations in Europe and the most heavily used in Italy, with around 400 thousand travellers passing through every day. The second-largest station in the city, Roma Tiburtina, has been redeveloped as a high-speed rail terminus. As well as frequent high-speed day trains to all major Italian cities, Rome is linked nightly by 'boat train' sleeper services to Sicily, and internationally by overnight sleeper services to Munich and Vienna.\n",
      "Rome is served by three airports. The intercontinental Leonardo da Vinci International Airport, Italy's chief airport is located in the nearby Fiumicino, south-west of Rome. The older Rome Ciampino Airport is a joint civilian and military airport. It is commonly referred to as \"Ciampino Airport\", as it is located beside Ciampino, south-east of Rome. A third airport, the Rome Urbe Airport, is a small, low-traffic airport located about 6 km (4 mi) north of the city centre, which handles most helicopter and private flights. The main airport system of the city (composed of Fiumicino and Ciampino), with 32.8 million passengers transported in 2022, is the second busiest airport system in Italy.Although the city has its own quarter on the Mediterranean Sea (Lido di Ostia), this has only a marina and a small channel-harbour for fishing boats. The main harbour which serves Rome is Port of Civitavecchia, located about 62 km (39 mi) northwest of the city.The city suffers from traffic problems largely due to this radial street pattern, making it difficult for Romans to move easily from the vicinity of one of the radial roads to another without going into the historic centre or using the ring-road. These problems are not helped by the limited size of Rome's metro system when compared to other cities of similar size. Rome has only 21 taxis for every 10,000 inhabitants, far below other major European cities. Chronic congestion caused by cars during the 1970s and 1980s led to restrictions being placed on vehicle access to the inner city-centre during daylight hours. Areas, where these restrictions apply, are known as Limited Traffic Zones (Zona a Traffico Limitato (ZTL)). More recently, heavy night-time traffic in Trastevere, Testaccio and San Lorenzo has led to the creation of night-time ZTLs in those districts.\n",
      "\n",
      "A three-line metro system called the Metropolitana operates in Rome. Construction on the first branch started in the 1930s. The line had been planned to quickly connect the main railway station with the newly planned E42 area in the southern suburbs, where 1942 the World Fair was supposed to be held. The event never took place because of war, but the area was later partly redesigned and renamed Esposizione Universale Roma in the 1950s to serve as a modern business district. The line was finally opened in 1955, and it is now the south part of the B Line.\n",
      "The A line opened in 1980 from Ottaviano to Anagnina stations, later extended in stages (1999–2000) to Battistini. In the 1990s, an extension of the B line was opened from Termini to Rebibbia. The A and B lines intersect at Roma Termini station. A new branch of the B line (B1) opened on 13 June 2012 after an estimated building cost of €500 million. B1 connects to line B at Piazza Bologna and has four stations over a distance of 3.9 km (2 mi).\n",
      "A third line, the C line, is under construction with an estimated cost of €3 billion and will have 30 stations over a distance of 25.5 km (16 mi). It will partly replace the existing Termini-Pantano rail line. It will feature full automated, driverless trains. The first section with 15 stations connecting Pantano with the quarter of Centocelle in the eastern part of the city, opened on 9 November 2014. The end of the work was scheduled in 2015, but archaeological findings often delay underground construction work.\n",
      "A fourth line, D line, is also planned. It will have 22 stations over a distance of 20 km (12 mi). The first section was projected to open in 2015 and the final sections before 2035, but due to the city's financial crisis, the project has been put on hold.\n",
      "Above-ground public transport in Rome is made up of a bus, tram and urban train network (FR lines). The bus network has in excess of 350 bus lines and over eight thousand bus stops, whereas the more-limited tram system has 39 km (24 mi) of track and 192 stops. There are also trolleybuses.\n",
      "\n",
      "See also\n",
      "Outline of Rome\n",
      "SPQR\n",
      "Tourism in Italy\n",
      "\n",
      "Notes\n",
      "References\n",
      "Bibliography\n",
      "External links\n",
      "\n",
      "Comune of Rome (in Italian)\n",
      "APT (official Tourist Office) of the City of Rome (in English)\n",
      "Rome Museums – official site. Archived 1 June 2017 at the Wayback Machine (in English).\n",
      "Capitoline Museums (in English)\n",
      " Geographic data related to Rome at OpenStreetMap Media related to Roma at Wikimedia CommonsRenewable energy is energy from renewable resources that are naturally replenished on a human timescale. Renewable resources include sunlight, wind, the movement of water, and geothermal heat. Although most renewable energy sources are sustainable, some are not. For example, some biomass sources are considered unsustainable at current rates of exploitation. Renewable energy is often used for electricity generation, heating and cooling. Renewable energy projects are typically large-scale, but they are also suited to rural and remote areas and developing countries, where energy is often crucial in human development.Renewable energy is often deployed together with further electrification, which has several benefits: electricity can move heat or objects efficiently, and is clean at the point of consumption. From 2011 to 2021, renewable energy grew from 20% to 28% of global electricity supply. Use of fossil energy shrank from 68% to 62%, and nuclear from 12% to 10%. The share of hydropower decreased from 16% to 15% while power from sun and wind increased from 2% to 10%. Biomass and geothermal energy grew from 2% to 3%. There are 3,146 gigawatts installed in 135 countries, while 156 countries have laws regulating the renewable energy sector.  In 2021, China accounted for almost half of the global increase in renewable electricity.Globally there are over 10 million jobs associated with the renewable energy industries, with solar photovoltaics being the largest renewable employer. Renewable energy systems are rapidly becoming more efficient and cheaper and their share of total energy consumption is increasing, with a large majority of worldwide newly installed electricity capacity being renewable. In most countries, photovoltaic solar or onshore wind are the cheapest new-build electricity.Many nations around the world already have renewable energy contributing more than 20% of their total energy supply, with some generating over half their electricity from renewables. A few countries generate all their electricity using renewable energy. National renewable energy markets are projected to continue to grow strongly in the 2020s and beyond. According to the IEA, to achieve net zero emissions by 2050, 90% of global electricity generation will need to be produced from renewable sources. Some studies have shown that a global transition to 100% renewable energy across all sectors – power, heat, transport and industry – is feasible and economically viable.Renewable energy resources exist over wide geographical areas, in contrast to fossil fuels, which are concentrated in a limited number of countries. Deployment of renewable energy and energy efficiency technologies is resulting in significant energy security, climate change mitigation, and economic benefits. However renewables are being hindered by hundreds of billions of dollars of fossil fuel subsidies. In international public opinion surveys there is strong support for renewables such as solar power and wind power. In 2022 the International Energy Agency asked countries to solve policy, regulatory, permitting and financing obstacles to adding more renewables, to have a better chance of reaching net zero carbon emissions by 2050.\n",
      "\n",
      "Overview\n",
      "Definition\n",
      "Renewable energy flows involve natural phenomena such as sunlight, wind, tides, plant growth, and geothermal heat, as the International Energy Agency explains:\n",
      "Renewable energy is derived from natural processes that are replenished constantly. In its various forms, it derives directly from the sun, or from heat generated deep within the earth. Included in the definition is electricity and heat generated from solar, wind, ocean, hydropower, biomass, geothermal resources, and biofuels and hydrogen derived from renewable resources.\n",
      "\n",
      "Drivers and benefits\n",
      "Renewable energy stands in contrast to fossil fuels, which are being used far more quickly than they are being replenished. Renewable energy resources and significant opportunities for energy efficiency exist over wide geographical areas, in contrast to other energy sources, which are concentrated in a limited number of countries. Rapid deployment of renewable energy and energy efficiency, and technological diversification of energy sources, would result in significant energy security and economic benefits. Solar and wind power have got much cheaper. In some cases it will be cheaper to transition to these sources as opposed to continuing to use the current, inefficient, fossil fuels. In addition, electrification with renewable energy is more efficient and therefore leads to significant reductions in primary energy requirements.It would also reduce environmental pollution such as air pollution caused by the burning of fossil fuels, and improve public health, reduce premature mortalities due to pollution and save associated health costs that could amount to trillions of dollars annually. Multiple analyses of decarbonization strategies have found that quantified health benefits can significantly offset the costs of implementing these strategies.Climate change concerns, coupled with the continuing fall in the costs of some renewable energy equipment, such as wind turbines and solar panels, are driving increased use of renewables. New government spending, regulation and policies helped the industry weather the global financial crisis better than many other sectors. As of 2019, however, according to the International Renewable Energy Agency, renewables overall share in the energy mix (including power, heat and transport) needs to grow six times faster, in order to keep the rise in average global temperatures \"well below\" 2.0 °C (3.6 °F) during the present century, compared to pre-industrial levels.\n",
      "\n",
      "Scale\n",
      "A household's solar panels, and batteries if they have them, can often either be used for just that household or if connected to an electrical grid can be aggregated with millions of others. Over 44 million households use biogas made in household-scale digesters for lighting and/or cooking, and more than 166 million households rely on a new generation of more-efficient biomass cookstoves.According to the research, a nation must reach a certain point in its growth before it can take use of more renewable energy. In our words, its addition changed how crucial input factors (labor and capital) connect to one another, lowering their overall elasticity and increasing the apparent economies of scale. United Nations' eighth Secretary-General Ban Ki-moon has said that renewable energy has the ability to lift the poorest nations to new levels of prosperity. At the national level, at least 30 nations around the world already have renewable energy contributing more than 20% of energy supply. Although many countries have various policy targets for longer-term shares of renewable energy these tend to be only for the power sector, including a 40% target of all electricity generated for the European Union by 2030.\n",
      "\n",
      "Uses\n",
      "Renewable energy often displaces conventional fuels in four areas: electricity generation, hot water/space heating, transportation, and rural (off-grid) energy services.More than a quarter of electricity is generated from renewables as of 2021. One of the efforts to decarbonize transportation is the increased use of electric vehicles (EVs). Despite that and the use of biofuels, such as biojet, less than 4% of transport energy is from renewables. Occasionally hydrogen fuel cells are used for heavy transport. Meanwhile, in the future electrofuels may also play a greater role in decarbonizing hard-to-abate sectors like aviation and maritime shipping.Solar water heating makes an important contribution to renewable heat in many countries, most notably in China, which now has 70% of the global total (180  GWth). Most of these systems are installed on multi-family apartment buildings and meet a portion of the hot water needs of an estimated 50–60 million households in China. Worldwide, total installed solar water heating systems meet a portion of the water heating needs of over 70 million households. \n",
      "Heat pumps provide both heating and cooling, and also flatten the electric demand curve and are thus an increasing priority. Renewable thermal energy is also growing rapidly. About 10% of heating and cooling energy is from renewables.\n",
      "\n",
      "Mainstream technologies\n",
      "Solar energy\n",
      "Solar energy, radiant light and heat from the sun, is harnessed using a range of ever-evolving technologies such as solar heating, photovoltaics, concentrated solar power (CSP), concentrator photovoltaics (CPV), solar architecture and artificial photosynthesis. Most new renewable energy is solar. Solar technologies are broadly characterized as either passive solar or active solar depending on the way they capture, convert, and distribute solar energy. Passive solar techniques include orienting a building to the Sun, selecting materials with favorable thermal mass or light dispersing properties, and designing spaces that naturally circulate air. Active solar technologies encompass solar thermal energy, using solar collectors for heating, and solar power, converting sunlight into electricity either directly using photovoltaics (PV), or indirectly using concentrated solar power (CSP).\n",
      "A photovoltaic system converts light into electrical direct current (DC) by taking advantage of the photoelectric effect. Solar PV has turned into a multi-billion, fast-growing industry, continues to improve its cost-effectiveness, and has the most potential of any renewable technologies together with CSP. Concentrated solar power (CSP) systems use lenses or mirrors and tracking systems to focus a large area of sunlight into a small beam. Commercial concentrated solar power plants were first developed in the 1980s. CSP-Stirling has by far the highest efficiency among all solar energy technologies.\n",
      "In 2011, the International Energy Agency said that \"the development of affordable, inexhaustible and clean solar energy technologies will have huge longer-term benefits. It will increase countries' energy security through reliance on an indigenous, inexhaustible and mostly import-independent resource, enhance sustainability, reduce pollution, lower the costs of mitigating climate change, and keep fossil fuel prices lower than otherwise. These advantages are global. Hence the additional costs of the incentives for early deployment should be considered learning investments; they must be wisely spent and need to be widely shared\". Solar power accounts for 505 GW annually, which is about 2% of the world's electricity. Solar energy can be harnessed anywhere that receives sunlight; however, the amount of solar energy that can be harnessed for electricity generation is influenced by weather conditions, geographic location and time of day.According to chapter 6 of the IPCC 2022 climate mitigation report, the global potential of direct solar energy far exceeds that of any other renewable energy resource. It is well beyond the total amount of energy needed in order to support mitigation over the current century. Australia has the largest proportion of solar electricity in the world, supplying 9.9% of the country's electrical demand in 2020. More than 30 per cent of Australian households now have rooftop solar PV, with a combined capacity exceeding 11 GW.There are, however, environmental implications of scaling up solar energy. In particular, the demand for raw materials such as aluminum poses concerns over the carbon footprint that will result from harvesting raw materials needed to implement solar energy.\n",
      "\n",
      "Photovoltaic development\n",
      "Photovoltaics (PV) is rapidly-growing with global capacity increasing from 230 GW at the end of 2015 to 890 GW in 2021.PV uses solar cells assembled into solar panels to convert sunlight into electricity. PV systems range from small, residential and commercial rooftop or building integrated installations, to large utility-scale photovoltaic power station. The predominant PV technology is crystalline silicon, while thin-film solar cell technology accounts for about 10 percent of global photovoltaic deployment. In recent years, PV technology has improved its electricity generating efficiency, reduced the installation cost per watt as well as its energy payback time, and reached grid parity.Building-integrated photovoltaics or \"onsite\" PV systems use existing land and structures and generate power close to where it is consumed.Photovoltaics grew fastest in China between 2016 and 2021 adding 560 GW, more than all advanced economies combined. Solar PV's installed power capacity is poised to surpass that of coal by 2027, becoming the largest in the world. This requires an increase of installed PV capacity to 4,600 GW, of which more than half is expected to be deployed in China and India.Commercial concentrated solar power plants were first developed in the 1980s. As the cost of solar electricity has fallen, the number of grid-connected solar PV systems has grown into the millions and gigawatt-scale solar power stations are being built. Many solar photovoltaic power stations have been built, mainly in Europe, China and the United States. The 1.5 GW Tengger Desert Solar Park, in China is the world's largest PV power station. Many of these plants are integrated with agriculture and some use tracking systems that follow the sun's daily path across the sky to generate more electricity than fixed-mounted systems.\n",
      "\n",
      "Solar thermal\n",
      "Wind power\n",
      "Air flow can be used to run wind turbines. Modern utility-scale wind turbines range from around 600 kW to 9 MW of rated power. The power available from the wind is a function of the cube of the wind speed, so as wind speed increases, power output increases up to the maximum output for the particular turbine. Areas where winds are stronger and more constant, such as offshore and high-altitude sites, are preferred locations for wind farms.\n",
      "Wind-generated electricity met nearly 4% of global electricity demand in 2015, with nearly 63 GW of new wind power capacity installed. Wind energy was the leading source of new capacity in Europe, the US and Canada, and the second largest in China. In Denmark, wind energy met more than 40% of its electricity demand while Ireland, Portugal and Spain each met nearly 20%.Globally, the long-term technical potential of wind energy is believed to be five times total current global energy production, or 40 times current electricity demand, assuming all practical barriers needed were overcome. This would require wind turbines to be installed over large areas, particularly in areas of higher wind resources, such as offshore, and likely also industrial use of new types of VAWT turbines in addition to the horizontal axis units currently in use. As offshore wind speeds average ~90% greater than that of land, offshore resources can contribute substantially more energy than land-stationed turbines.\n",
      "\n",
      "Hydropower\n",
      "Since water is about 800 times denser than air, even a slow flowing stream of water, or moderate sea swell, can yield considerable amounts of energy. Water can generate electricity with a conversion efficiency of about 90%, which is the highest rate in renewable energy. There are many forms of water energy:\n",
      "\n",
      "Historically, hydroelectric power came from constructing large hydroelectric dams and reservoirs, which are still popular in developing countries. The largest of them are the Three Gorges Dam (2003) in China and the Itaipu Dam (1984) built by Brazil and Paraguay.\n",
      "Small hydro systems are hydroelectric power installations that typically produce up to 50 MW of power. They are often used on small rivers or as a low-impact development on larger rivers. China is the largest producer of hydroelectricity in the world and has more than 45,000 small hydro installations.\n",
      "Run-of-the-river hydroelectricity plants derive energy from rivers without the creation of a large reservoir. The water is typically conveyed along the side of the river valley (using channels, pipes and/or tunnels) until it is high above the valley floor, whereupon it can be allowed to fall through a penstock to drive a turbine. A run-of-river plant may still produce a large amount of electricity, such as the Chief Joseph Dam on the Columbia River in the United States. However many run-of-the-river hydro power plants are micro hydro or pico hydro plants.Hydropower is produced in 150 countries, with the Asia-Pacific region generating 32 percent of global hydropower in 2010. Of the top 50 countries by percentage of electricity generated from renewables, 46 are primarily hydroelectric. There are now seven hydroelectricity stations larger than 10 GW (10,000 MW) worldwide, see table below.\n",
      "\n",
      "Much hydropower is flexible, thus complementing wind and solar. Wave power, which captures the energy of ocean surface waves, and tidal power, converting the energy of tides, are two forms of hydropower with future potential; however, they are not yet widely employed commercially. A demonstration project operated by the Ocean Renewable Power Company on the coast of Maine, and connected to the grid, harnesses tidal power from the Bay of Fundy, location of the world's highest tidal flow. Ocean thermal energy conversion, which uses the temperature difference between cooler deep and warmer surface waters, currently has no economic feasibility.In 2021, the world renewable hydropower capacity was 1,360 GW. Only a third of the world's estimated hydroelectric potential of 14,000 TWh/year has been developed. New hydropower projects face opposition from local communities due to their large impact, including relocation of communities and flooding of wildlife habitats and farming land. High cost and lead times from permission process, including environmental and risk assessments, with lack of environmental and social acceptance are therefore the primary challenges for new developments. It is popular to repower old dams thereby increasing their efficiency and capacity as well as quicker responsiveness on the grid. Where circumstances permit existing dams such as the Russell Dam built in 1985 may be updated with \"pump back\" facilities for pumped-storage which is useful for peak loads or to support intermittent wind and solar power. Because dispatchable power is more valuable than VRE countries with large hydroelectric developments such as Canada and Norway are spending billions to expand their grids to trade with neighboring countries having limited hydro.\n",
      "\n",
      "Bioenergy\n",
      "Biomass is biological material derived from living, or recently living organisms. It commonly refers to plants or plant-derived materials. As an energy source, biomass can either be used directly via combustion to produce heat, or indirectly after converting it to various forms of biofuel in solid, liquid or gaseous form. Conversion of biomass to biofuel can be achieved by different methods which are broadly classified into: thermal, chemical, and biochemical methods. Wood was the largest biomass energy source as of 2012; examples include forest residues – such as dead trees, branches and tree stumps, yard clippings, wood chips and even municipal solid waste. Industrial biomass can be grown from numerous types of plants, including miscanthus, switchgrass, hemp, corn, poplar, willow, sorghum, sugarcane, bamboo, and a variety of tree species, ranging from eucalyptus to oil palm (palm oil).\n",
      "Plant energy is produced by crops specifically grown for use as fuel that offer high biomass output per hectare with low input energy. The grain can be used for liquid transportation fuels while the straw can be burned to produce heat or electricity. Plant biomass can also be degraded from cellulose to glucose through a series of chemical treatments, and the resulting sugar can then be used as a first-generation biofuel.\n",
      "Biomass can be converted to other usable forms of energy such as methane gas or transportation fuels such as ethanol and biodiesel. Rotting garbage, and agricultural and human waste, all release methane gas – also called landfill gas or biogas. Crops, such as corn and sugarcane, can be fermented to produce the transportation fuel, ethanol. Biodiesel, another transportation fuel, can be produced from left-over food products such as vegetable oils and animal fats. There is a great deal of research involving algal fuel or algae-derived biomass due to the fact that it is a non-food resource, grows around 20 times faster than other types of food crops, such as corn and soy, and can be grown almost anywhere. Once harvested, it can be fermented to produce biofuels such as ethanol, butanol, and methane, as well as biodiesel and hydrogen. The biomass used for electricity generation varies by region. Forest by-products, such as wood residues, are common in the United States. Agricultural waste is common in Mauritius (sugar cane residue) and Southeast Asia (rice husks). \n",
      "Biomass, biogas and biofuels are burned to produce heat/power and in doing so can harm the environment. Pollutants such as sulphurous oxides (SOx), nitrous oxides (NOx), and particulate matter (PM) are produced from the combustion of biomass. With regards to traditional use of biomass for heating and cooking, the World Health Organization estimates that 3.7 million prematurely died from outdoor air pollution in 2012 while indoor pollution from biomass burning effects over 3 billion people worldwide.Bioenergy global capacity in 2021 was 158 GW. Biofuels avoided 4.4% of global transport fuel demand in 2021.\n",
      "\n",
      "Biofuel\n",
      "Biofuels include a wide range of fuels which are derived from biomass. The term covers solid, liquid, and gaseous fuels. Liquid biofuels include bioalcohols, such as bioethanol, and oils, such as biodiesel. Gaseous biofuels include biogas, landfill gas and synthetic gas. Bioethanol is an alcohol made by fermenting the sugar components of plant materials and it is made mostly from sugar and starch crops. These include maize, sugarcane and, more recently, sweet sorghum. The latter crop is particularly suitable for growing in dryland conditions, and is being investigated by International Crops Research Institute for the Semi-Arid Tropics for its potential to provide fuel, along with food and animal feed, in arid parts of Asia and Africa.With advanced technology being developed, cellulosic biomass, such as trees and grasses, are also used as feedstocks for ethanol production. Ethanol can be used as a fuel for vehicles in its pure form, but it is usually used as a gasoline additive to increase octane and improve vehicle emissions. Bioethanol is widely used in the United States and in Brazil. The energy costs for producing bio-ethanol are almost equal to, the energy yields from bio-ethanol. However, according to the European Environment Agency, biofuels do not address global warming concerns. Biodiesel is made from vegetable oils, animal fats or recycled greases. It can be used as a fuel for vehicles in its pure form, or more commonly as a diesel additive to reduce levels of particulates, carbon monoxide, and hydrocarbons from diesel-powered vehicles. Biodiesel is produced from oils or fats using transesterification and is the most common biofuel in Europe. Biofuels provided 2.7% of the world's transport fuel in 2010.Policies in more than 80 countries support biofuels demand. Since the 1970s, Brazil has had an ethanol fuel program which has allowed the country to become the world's second largest producer of ethanol (after the United States) and the world's largest exporter. Brazil's ethanol fuel program uses modern equipment and cheap sugarcane as feedstock, and the residual cane-waste (bagasse) is used to produce heat and power. There are no longer light vehicles in Brazil running on pure gasoline.Biojet is expected to be important for short-term reduction of carbon dioxide emissions from long-haul flights.\n",
      "\n",
      "Geothermal energy\n",
      "High temperature geothermal energy is from thermal energy generated and stored in the Earth. Thermal energy is the energy that determines the temperature of matter. Earth's geothermal energy originates from the original formation of the planet and from radioactive decay of minerals (in currently uncertain but possibly roughly equal proportions). The geothermal gradient, which is the difference in temperature between the core of the planet and its surface, drives a continuous conduction of thermal energy in the form of heat from the core to the surface. The adjective geothermal originates from the Greek roots geo, meaning earth, and thermos, meaning heat.\n",
      "The heat that is used for geothermal energy can be from deep within the Earth, all the way down to Earth's core – 6,400 kilometres (4,000 mi) down. At the core, temperatures may reach over 5,000 °C (9,030 °F). Heat conducts from the core to the surrounding rock. Extremely high temperature and pressure cause some rock to melt, which is commonly known as magma. Magma convects upward since it is lighter than the solid rock. This magma then heats rock and water in the crust, sometimes up to 371 °C (700 °F).Low temperature geothermal refers to the use of the outer crust of the Earth as a thermal battery to facilitate renewable thermal energy for heating and cooling buildings, and other refrigeration and industrial uses. In this form of geothermal, a geothermal heat pump and ground-coupled heat exchanger are used together to move heat energy into the Earth (for cooling) and out of the Earth (for heating) on a varying seasonal basis. Low-temperature geothermal (generally referred to as \"GHP\") is an increasingly important renewable technology because it both reduces total annual energy loads associated with heating and cooling, and it also flattens the electric demand curve eliminating the extreme summer and winter peak electric supply requirements. Thus low temperature geothermal/GHP is becoming an increasing national priority with multiple tax credit support and focus as part of the ongoing movement toward net zero energy.Geothermal power is cost effective, reliable, sustainable, and environmentally friendly, but has historically been limited to areas near tectonic plate boundaries. Recent technological advances have expanded the range and size of viable resources, especially for applications such as home heating, opening a potential for widespread exploitation. Geothermal wells release greenhouse gases trapped deep within the earth, but these emissions are usually much lower per energy unit than those of fossil fuels. As a result, geothermal power has the potential to help mitigate global warming if widely deployed in place of fossil fuels.\n",
      "In 2017, the United States led the world in geothermal electricity production with 12.9 GW of installed capacity. The largest group of geothermal power plants in the world is located at The Geysers, a geothermal field in California. The Philippines follows the US as the second highest producer of geothermal power in the world, with 1.9 GW of capacity online.Global geothermal capacity in 2021 was 15 GW.\n",
      "\n",
      "Emerging technologies\n",
      "There are also other renewable energy technologies that are still under development, including cellulosic ethanol, hot-dry-rock geothermal power, and marine energy. These technologies are not yet widely demonstrated or have limited commercialization. Many are on the horizon and may have potential comparable to other renewable energy technologies, but still depend on attracting sufficient attention and research, development and demonstration (RD&D) funding.There are numerous organizations within the academic, federal, and commercial sectors conducting large-scale advanced research in the field of renewable energy. This research spans several areas of focus across the renewable energy spectrum. Most of the research is targeted at improving efficiency and increasing overall energy yields.\n",
      "Multiple government supported research organizations have focused on renewable energy in recent years. Two of the most prominent of these labs are Sandia National Laboratories and the National Renewable Energy Laboratory (NREL), both of which are funded by the United States Department of Energy and supported by various corporate partners.\n",
      "\n",
      "Enhanced geothermal system\n",
      "Enhanced geothermal systems (EGS) are a new type of geothermal power technology that does not require natural convective hydrothermal resources. The vast majority of geothermal energy within drilling reach is in dry and non-porous rock. EGS technologies \"enhance\" and/or create geothermal resources in this \"hot dry rock (HDR)\" through hydraulic fracturing. EGS and HDR technologies, such as hydrothermal geothermal, are expected to be baseload resources that produce power 24 hours a day like a fossil plant. Distinct from hydrothermal, HDR and EGS may be feasible anywhere in the world, depending on the economic limits of drill depth. Good locations are over deep granite covered by a thick (3–5 km or 1.9–3.1 mi) layer of insulating sediments which slow heat loss. There are HDR and EGS systems currently being developed and tested in France, Australia, Japan, Germany, the U.S., and Switzerland. The largest EGS project in the world is a 25 megawatt demonstration plant currently being developed in the Cooper Basin, Australia. The Cooper Basin has the potential to generate 5,000–10,000 MW.\n",
      "\n",
      "Hydrogen\n",
      "Marine energy\n",
      "Marine energy (also sometimes referred to as ocean energy) is the energy carried by ocean waves, tides, salinity, and ocean temperature differences. The movement of water in the world's oceans creates a vast store of kinetic energy, or energy in motion. This energy can be harnessed to generate electricity to power homes, transport and industries. The term marine energy encompasses wave power – power from surface waves, marine current power - power from marine hydrokinetic streams (e.g., the Gulf Stream), and tidal power – obtained from the kinetic energy of large bodies of moving water. Reverse electrodialysis (RED) is a technology for generating electricity by mixing fresh river water and salty sea water in large power cells designed for this purpose; as of 2016, it is being tested at a small scale (50 kW). Offshore wind power is not a form of marine energy, as wind power is derived from the wind, even if the wind turbines are placed over water. The oceans have a tremendous amount of energy and are close to many if not most concentrated populations. Ocean energy has the potential of providing a substantial amount of new renewable energy around the world.\n",
      "\n",
      "Passive daytime radiative cooling\n",
      "Passive daytime radiative cooling (PDRC) uses the coldness of outer space as a renewable energy source to achieve daytime cooling that can be used in many applications, such as indoor space cooling, outdoor urban heat island mitigation, and solar cell efficiency. PDRC surfaces are designed to be high in solar reflectance to minimize heat gain and strong in longwave infrared (LWIR) thermal radiation heat transfer. On a planetary scale, it has been proposed as a way to slow and reverse global warming. PDRC applications are deployed as sky-facing surfaces, similar to other renewable energy sources such as photovoltaic systems and solar thermal collectors. PDRC became possible with the ability to suppress solar heating using photonic metamaterials, first published in a study by Raman et al. to the scientific community in 2014. PDRC applications for indoor space cooling is growing with an estimated \"market size of ~$27 billion in 2025.\"\n",
      "\n",
      "Artificial photosynthesis\n",
      "Artificial photosynthesis uses techniques including nanotechnology to store solar electromagnetic energy in chemical bonds by splitting water to produce hydrogen and then using carbon dioxide to make methanol. Researchers in this field strived to design molecular mimics of photosynthesis that use a wider region of the solar spectrum, employ catalytic systems made from abundant, inexpensive materials that are robust, readily repaired, non-toxic, stable in a variety of environmental conditions and perform more efficiently allowing a greater proportion of photon energy to end up in the storage compounds, i.e., carbohydrates (rather than building and sustaining living cells). However, prominent research faces hurdles, Sun Catalytix a MIT spin-off stopped scaling up their prototype fuel-cell in 2012 because it offers few savings over other ways to make hydrogen from sunlight.\n",
      "\n",
      "Earth infrared thermal radiation\n",
      "Earth emits roughly 1017 W of infrared thermal radiation that flows toward the cold outer space. Solar energy hits the surface and atmosphere of the earth and produces heat. Using various theorized devices like emissive energy harvester (EEH) or thermoradiative diode, this energy flow can be converted into electricity. In theory, this technology can be used during nighttime.\n",
      "\n",
      "Others\n",
      "Algae fuels\n",
      "Producing liquid fuels from oil-rich (fat-rich) varieties of algae is an ongoing research topic. Various microalgae grown in open or closed systems are being tried including some systems that can be set up in brownfield and desert lands.\n",
      "\n",
      "Water vapor\n",
      "Collection of static electricity charges from water droplets on metal surfaces is an experimental technology that would be especially useful in low-income countries with relative air humidity over 60%.\n",
      "\n",
      "Nuclear energy\n",
      "Breeder reactors could, in principle, extract almost all of the energy contained in uranium or thorium, decreasing fuel requirements by a factor of 100 compared to widely used once-through light water reactors, which extract less than 1% of the energy in the actinide metal (uranium or thorium) mined from the earth. The high fuel-efficiency of breeder reactors could greatly reduce concerns about fuel supply, energy used in mining, and storage of radioactive waste. With seawater uranium extraction (currently too expensive to be economical), there is enough fuel for breeder reactors to satisfy the world's energy needs for 5 billion years at 1983's total energy consumption rate, thus making nuclear energy effectively a renewable energy. In addition to seawater the average crustal granite rocks contain significant quantities of uranium and thorium that with breeder reactors can supply abundant energy for the remaining lifespan of the sun on the main sequence of stellar evolution.\n",
      "\n",
      "Integration into the energy system and sector coupling\n",
      "Renewable energy production from some sources such as wind and solar is more variable and more geographically spread than technology based on fossil fuels and nuclear. While integrating it into the wider energy system is feasible, it does lead to some additional challenges such as increased production volatility and decreased system inertia. Implementation of energy storage, using a wide variety of renewable energy technologies, and implementing a smart grid in which energy is automatically used at the moment it is produced can reduce risks and costs of renewable energy implementation.: 15–16 Sector coupling of the power generation sector with other sectors may increase flexibility: for example the transport sector can be coupled by charging electric vehicles and sending electricity from vehicle to grid. Similarly the industry sector can be coupled by hydrogen produced by electrolysis, and the buildings sector by thermal energy storage for space heating and cooling.\n",
      "\n",
      "Electrical energy storage\n",
      "Electrical energy storage is a collection of methods used to store electrical energy. Electrical energy is stored during times when production (especially from intermittent sources such as wind power, tidal power, solar power) exceeds consumption, and returned to the grid when production falls below consumption. Pumped-storage hydroelectricity accounts for more than 85% of all grid power storage. Batteries are increasingly being deployed for storage and grid ancillary services and for domestic storage. Green hydrogen is a more economical means of long-term renewable energy storage, in terms of capital expenditures compared to pumped hydroelectric or batteries.\n",
      "\n",
      "Market and industry trends\n",
      "Most new renewables are solar, followed by wind then hydro then bioenergy. Investment in renewables, especially solar, tends to be more effective in creating jobs than coal, gas or oil. Worldwide, renewables employ about 12 million people as of 2020, with solar PV being the technology employing the most at almost 4 million.\n",
      "\n",
      "Cost comparison\n",
      "The International Renewable Energy Agency (IRENA) stated that ~86% (187 GW) of renewable capacity added in 2022 had lower costs than electricity generated from fossil fuels. IRENA also stated that capacity added since 2000 reduced electricity bills in 2022 by at least $520 billion, and that in non-OECD countries, the lifetime savings of 2022 capacity additions will reduce costs by up to $580 billion.\n",
      "* = 2018. All other values for 2019.\n",
      "\n",
      "Growth of renewables\n",
      "The results of a recent review of the literature concluded that as greenhouse gas (GHG) emitters begin to be held liable for damages resulting from GHG emissions resulting in climate change, a high value for liability mitigation would provide powerful incentives for deployment of renewable energy technologies.In the decade of 2010–2019, worldwide investment in renewable energy capacity excluding large hydropower amounted to US$2.7 trillion, of which the top countries China contributed US$818 billion, the United States contributed US$392.3 billion, Japan contributed US$210.9 billion, Germany contributed US$183.4 billion, and the United Kingdom contributed US$126.5 billion. This was an increase of over three and possibly four times the equivalent amount invested in the decade of 2000–2009 (no data is available for 2000–2003).As of 2022, an estimated 28% of the world's electricity was generated by renewables. This is up from 19% in 1990.\n",
      "\n",
      "Future projections\n",
      "A December 2022 report by the IEA forecasts that over 2022-2027, renewables are seen growing by almost 2 400 GW in its main forecast, equal to the entire installed power capacity of China in 2021. This is an 85% acceleration from the previous five years, and almost 30% higher than what the IEA forecast in its 2021 report, making its largest ever upward revision. Renewables are set to account for over 90% of global electricity capacity expansion over the forecast period. To achieve net zero emissions by 2050, IEA believes that 90% of global electricity generation will need to be produced from renewable sources.In June 2022 IEA Executive Director Fatih Birol said that countries should invest more in renewables to \"ease the pressure on consumers from high fossil fuel prices, make our energy systems more secure, and get the world on track to reach our climate goals.”China's five year plan to 2025 includes increasing direct heating by renewables such as geothermal and solar thermal.REPowerEU, the EU plan to escape dependence on fossil Russian gas, is expected to call for much more green hydrogen.After a transitional period, renewable energy production is expected to make up most of the world's energy production. In 2018, the risk management firm, DNV GL, forecasts that the world's primary energy mix will be split equally between fossil and non-fossil sources by 2050.\n",
      "\n",
      "Demand\n",
      "In July 2014, WWF and the World Resources Institute convened a discussion among a number of major US companies who had declared their intention to increase their use of renewable energy. These discussions identified a number of \"principles\" which companies seeking greater access to renewable energy considered important market deliverables. These principles included choice (between suppliers and between products), cost competitiveness, longer term fixed price supplies, access to third-party financing vehicles, and collaboration.UK statistics released in September 2020 noted that \"the proportion of demand met from renewables varies from a low of 3.4 per cent (for transport, mainly from biofuels) to highs of over 20 per cent for 'other final users', which is largely the service and commercial sectors that consume relatively large quantities of electricity, and industry\".In some locations, individual households can opt to purchase renewable energy through a consumer green energy program.\n",
      "\n",
      "Developing countries\n",
      "In Kenya, the Olkaria V Geothermal Power Station is one of the largest in the world. The Grand Ethiopia Renaissance Dam project incorporates wind turbines. Once completed, Morocco's Ouarzazate Solar Power Station is projected to provide power to over a million people.\n",
      "\n",
      "Policy\n",
      "Policies to support renewable energy have been vital in their expansion. Where Europe dominated in establishing energy policy in the early 2000s, most countries around the world now have some form of energy policy.\n",
      "\n",
      "Policy trends\n",
      "The International Renewable Energy Agency (IRENA) is an intergovernmental organization for promoting the adoption of renewable energy worldwide. It aims to provide concrete policy advice and facilitate capacity building and technology transfer. IRENA was formed in 2009, with 75 countries signing the charter of IRENA. As of April 2019, IRENA has 160 member states. The then United Nations Secretary-General Ban Ki-moon has said that renewable energy can lift the poorest nations to new levels of prosperity, and in September 2011 he launched the UN Sustainable Energy for All initiative to improve energy access, efficiency and the deployment of renewable energy.The 2015 Paris Agreement on climate change motivated many countries to develop or improve renewable energy policies. In 2017, a total of 121 countries adopted some form of renewable energy policy. National targets that year existed in 176 countries. In addition, there is also a wide range of policies at the state/provincial, and local levels. Some public utilities help plan or install residential energy upgrades.\n",
      "Many national, state and local governments have created green banks. A green bank is a quasi-public financial institution that uses public capital to leverage private investment in clean energy technologies. Green banks use a variety of financial tools to bridge market gaps that hinder the deployment of clean energy.\n",
      "Climate neutrality by the year 2050 is the main goal of the European Green Deal. For the European Union to reach their target of climate neutrality, one goal is to decarbonise its energy system by aiming to achieve \"net-zero greenhouse gas emissions by 2050.\"\n",
      "\n",
      "Full renewable energy\n",
      "Debates\n",
      "Renewable electricity generation by wind and solar is variable. This results in reduced capacity factor and may require keeping some gas-fired power plants or other dispatchable generation on standby until there is enough energy storage, demand response, grid improvement, and/or base load power from non-intermittent sources like hydropower, nuclear power or bioenergy.\n",
      "The market for renewable energy technologies has continued to grow. Climate change concerns and increasing in green jobs, coupled with high oil prices, peak oil, oil wars, oil spills, promotion of electric vehicles and renewable electricity, nuclear disasters and increasing government support, are driving increasing renewable energy legislation, incentives and commercialization.The International Energy Agency has stated that deployment of renewable technologies usually increases the diversity of electricity sources and, through local generation, contributes to the flexibility of the system and its resistance to central shocks.\n",
      "\n",
      "Public support\n",
      "Solar power plants may compete with arable land, while on-shore wind farms face opposition due to aesthetic concerns and noise, which is impacting both humans and wildlife.In the United States, the Massachusetts Cape Wind project was delayed for years partly because of aesthetic concerns. However, residents in other areas have been more positive. According to a town councilor, the overwhelming majority of locals believe that the Ardrossan Wind Farm in Scotland has enhanced the area. These concerns, when directed against renewable energy, are sometimes described as \"not in my back yard\" attitude (NIMBY).\n",
      "A 2011 UK Government document states that \"projects are generally more likely to succeed if they have broad public support and the consent of local communities. This means giving communities both a say and a stake\". In countries such as Germany and Denmark many renewable projects are owned by communities, particularly through cooperative structures, and contribute significantly to overall levels of renewable energy deployment.\n",
      "\n",
      "Nuclear power proposed as renewable energy\n",
      "Geopolitics\n",
      "From around 2010 onwards, the geopolitical impact of the growing use of renewable energy has been discussed. Some argue that former fossil fuels exporters will experience a weakening of their position in international affairs, while countries with abundant renewable energy resources will be strengthened. Also some countries rich in critical materials for renewable energy technologies are expected to rise in importance in international affairs.The GeGaLo index of geopolitical gains and losses assesses how the geopolitical position of 156 countries may change if the world fully transitions to renewable energy resources. Former fossil fuels exporters are expected to lose power, while the positions of former fossil fuel importers and countries rich in renewable energy resources is expected to strengthen. Sourcing of required materials, ownership of key infrastructure assets and the design of grids all require geopolitics consideration.Transitions to renewable energy have many geopolitical implications such as the potential of revenue losses leading to political instability in insufficiently prepared fossil-fuel-exporting economies, albeit it is unclear whether the transition will increase or reduce conflict overall. In particular, a study hypothesizes that a \"configuration emerges in which fossil fuel importers are better off decarbonizing, competitive fossil fuel exporters are better off flooding markets and uncompetitive fossil fuel producers—rather than benefitting from 'free-riding'—suffer from their exposure to stranded assets and lack of investment in decarbonization technologies\".A study found that transition from fossil fuels to renewable energy systems reduces risks from mining, trade and political dependence because renewable energy systems don't need fuel – they depend on trade only for the acquisition of materials and components during construction.Nations rich in solar and wind energy could become major energy exporters.Trade in hydrogen could fundamentally redraw the geography of the global energy trade, and international governance and investments that seek to scale up the hydrogen economy could reduce \"the risk of market fragmentation, carbon lock-in, and intensified geo-economic rivalry\". Electricity will overtake other energy carriers by 2050, accounting for almost 50% of total energy consumption (up from 22% in 2015). Given the limitations of using solely electricity, clean hydrogen has significant potential in a number of industries. Hydrogen has the potential to be long-term stored in the electricity and heating industries.In 2019, oil and gas companies were listed by Forbes with sales of US$4.8 trillion, about 5% of the global GDP. Net importers such as China and the EU would gain advantages from a transition to low-carbon technologies driven by technological development, energy efficiency or climate change policy, while Russia, the USA or Canada could see their fossil fuel industries nearly shut down. On the other hand, countries with large areas such as Australia, Russia, China, the US, Canada and Brazil and also Africa and the Middle East have a potential for huge installations of renewable energy. The production of renewable energy technologies requires rare-earth elements with new supply chains.In October 2021, European Commissioner for Climate Action Frans Timmermans suggested \"the best answer\" to the 2021 global energy crisis is \"to reduce our reliance on fossil fuels.\" He said those blaming the European Green Deal were doing so \"for perhaps ideological reasons or sometimes economic reasons in protecting their vested interests.\" Some critics blamed the European Union Emissions Trading System (EU ETS) and closure of nuclear plants for contributing to the energy crisis. European Commission President Ursula von der Leyen said that Europe is \"too reliant\" on natural gas and too dependent on natural gas imports. According to Von der Leyen, \"The answer has to do with diversifying our suppliers ... and, crucially, with speeding up the transition to clean energy.\"\n",
      "\n",
      "Metal and mineral extraction\n",
      "The renewable energy transition requires increased extraction of certain metals and minerals. This impacts the environment and can lead to environmental conflict.The International Energy Agency does not recognise shortages of resources but states that supply could struggle to keep pace with the world's climate ambitions. Electric vehicles (EV) and battery storage are expected to cause the most demand. Wind farms and solar PV are less consuming. The extension of electrical grids requires large amounts of copper and aluminium. The IEA recommends to scale up recycling. By 2040, quantities of copper, lithium, cobalt, and nickel from spent batteries could reduce combined primary supply requirements for these minerals by around 10%.The demand for lithium by 2040 is expected to grow by the factor of 42. Graphite and nickel exploration is predicted to grow about 20-fold. For each of the most relevant minerals and metals, a significant share of resources are concentrated in only one country: copper in Chile, nickel in Indonesia, rare earths in China, cobalt in the Democratic Republic of the Congo (DRC), and lithium in Australia. China dominates processing of them all. A controversial approach is deep sea mining. Minerals can be collected from new sources like polymetallic nodules lying on the seabed, but this could damage biodiversity.\n",
      "\n",
      "Health and environmental impact\n",
      "Moving to modern renewable energy has very large health benefits due to reducing air pollution from fossil fuels.Renewable sources other than biomass such as wind power, photovoltaics, and hydroelectricity have the advantage of being able to conserve water, lower pollution and reduce CO2 emissions.\n",
      "Solar panels change the albedo of the surface, so if used on a very large scale (such as covering 20% of the Sahara Desert), could change global weather patterns.\n",
      "\n",
      "Conservation areas, recycling and rare-earth elements\n",
      "Installations used to produce wind, solar and hydropower are an increasing threat to key conservation areas, with facilities built in areas set aside for nature conservation and other environmentally sensitive areas. They are often much larger than fossil fuel power plants, needing areas of land up to 10 times greater than coal or gas to produce equivalent energy amounts. More than 2000 renewable energy facilities are built, and more are under construction, in areas of environmental importance and threaten the habitats of plant and animal species across the globe. The authors' team emphasized that their work should not be interpreted as anti-renewables because renewable energy is crucial for reducing carbon emissions. The key is ensuring that renewable energy facilities are built in places where they do not damage biodiversity.The transition to renewable energy depends on non-renewable resources, such as mined metals. Manufacturing of photovoltaic panels, wind turbines and batteries requires significant amounts of rare-earth elements which has significant social and environmental impact if mined in forests and protected areas. Due to co-occurrence of rare-earth and radioactive elements (thorium, uranium and radium), rare-earth mining results in production of low-level radioactive waste.In 2020 scientists published a world map of areas that contain renewable energy materials as well as estimations of their overlaps with \"Key Biodiversity Areas\", \"Remaining Wilderness\" and \"Protected Areas\". The authors assessed that careful strategic planning is needed. Solar panels are recycled to reduce electronic waste and create a source for materials that would otherwise need to be mined, but such business is still small and work is ongoing to improve and scale-up the process.\n",
      "\n",
      "History\n",
      "Prior to the development of coal in the mid 19th century, nearly all energy used was renewable. The oldest known use of renewable energy, in the form of traditional biomass to fuel fires, dates from more than a million years ago. The use of biomass for fire did not become commonplace until many hundreds of thousands of years later. Probably the second oldest usage of renewable energy is harnessing the wind in order to drive ships over water. This practice can be traced back some 7000 years, to ships in the Persian Gulf and on the Nile. From hot springs, geothermal energy has been used for bathing since Paleolithic times and for space heating since ancient Roman times. Moving into the time of recorded history, the primary sources of traditional renewable energy were human labor, animal power, water power, wind, in grain crushing windmills, and firewood, a traditional biomass.\n",
      "In 1885, Werner Siemens, commenting on the discovery of the photovoltaic effect in the solid state, wrote:\n",
      "\n",
      "In conclusion, I would say that however great the scientific importance of this discovery may be, its practical value will be no less obvious when we reflect that the supply of solar energy is both without limit and without cost, and that it will continue to pour down upon us for countless ages after all the coal deposits of the earth have been exhausted and forgotten.\n",
      "Max Weber mentioned the end of fossil fuel in the concluding paragraphs of his Die protestantische Ethik und der Geist des Kapitalismus (The Protestant Ethic and the Spirit of Capitalism), published in 1905. Development of solar engines continued until the outbreak of World War I. The importance of solar energy was recognized in a 1911 Scientific American article: \"in the far distant future, natural fuels having been exhausted [solar power] will remain as the only means of existence of the human race\".The theory of peak oil was published in 1956. In the 1970s environmentalists promoted the development of renewable energy both as a replacement for the eventual depletion of oil, as well as for an escape from dependence on oil, and the first electricity-generating wind turbines appeared. Solar had long been used for heating and cooling, but solar panels were too costly to build solar farms until 1980.New government spending, regulation and policies helped the industry weather the 2009 economic crisis better than many other sectors.\n",
      "\n",
      "See also\n",
      "References\n",
      "Sources\n",
      "\"Renewable Power Generation Costs in 2019\" (PDF). IRENA. 2020.\n",
      "\"Renewable Capacity Statistics 2020\". IRENA. 2020.\n",
      "\"Renewable Energy Statistics 2020\". IRENA. 2020.\n",
      "\n",
      "External links\n",
      "\n",
      "\"Renewable Power Generation Costs in 2022\" (PDF). IRENA.org. International Renewable Energy Agency (IRENA). 2022. Archived (PDF) from the original on 30 August 2023. ISBN 978-92-9260-544-5.\n",
      "Overview of clean energy from the United States Department of Energy\n",
      "Energypedia – a wiki platform for collaborative knowledge exchange on renewable energy in developing countries\n",
      "Countries not on track to reach 100% renewable energy systemsHawaii (  hə-WY-ee; Hawaiian: Hawaiʻi [həˈvɐjʔi, həˈwɐjʔi]) is an island state in the Western United States, about 2,000 miles (3,200 km) from the U.S. mainland in the Pacific Ocean. It is the only U.S. state outside North America, the only one which is an archipelago, and the only one in the tropics.\n",
      "Hawaii consists of 137 volcanic islands that comprise almost the entire Hawaiian archipelago (the exception, which is outside the state, is Midway Atoll). Spanning 1,500 miles (2,400 km), the state is physiographically and ethnologically part of the Polynesian subregion of Oceania. Hawaii's ocean coastline is consequently the fourth-longest in the U.S., at about 750 miles (1,210 km). The eight main islands, from northwest to southeast, are Niʻihau, Kauaʻi, Oʻahu, Molokaʻi, Lānaʻi, Kahoʻolawe, Maui, and Hawaiʻi, after which the state is named; the latter is often called the \"Big Island\" or \"Hawaii Island\" to avoid confusion with the state or archipelago. The uninhabited Northwestern Hawaiian Islands make up most of the Papahānaumokuākea Marine National Monument, the largest protected area in the U.S. and the fourth-largest in the world.\n",
      "Of the 50 U.S. states, Hawaii is the eighth-smallest in land area and the 11th-least populous; but with 1.4 million residents, it ranks 13th in population density. Two-thirds of Hawaiians live on O'ahu, home to the state's capital and largest city, Honolulu. Hawaii is among the country's most diverse states, owing to its central location in the Pacific and over two centuries of migration. As one of only six majority-minority states, it has the only Asian American plurality, the largest Buddhist community, and largest proportion of multiracial people in the U.S. Consequently, Hawaii is a unique melting pot of North American and East Asian cultures, in addition to its indigenous Hawaiian heritage.\n",
      "Settled by Polynesians sometime between 1000 and 1200 CE, Hawaii was home to numerous independent chiefdoms. In 1778, British explorer James Cook was the first known non-Polynesian to arrive at the archipelago; early British influence is reflected in the state flag, which bears a Union Jack. An influx of European and American explorers, traders, and whalers soon arrived, leading to the decimation of the once-isolated indigenous community through the introduction of diseases such as syphilis, tuberculosis, smallpox, and measles; the native Hawaiian population declined from between 300,000 and one million to less than 40,000 by 1890. Hawaii became a unified, internationally recognized kingdom in 1810, remaining independent until American and European businessmen overthrew the monarchy in 1893; this led to annexation by the U.S. in 1898. As a strategically valuable U.S. territory, Hawaii was attacked by Japan on December 7, 1941, which brought it global and historical significance, and contributed to America's entry into World War II. Hawaii is the most recent state to join the union, on August 21, 1959. In 1993, the U.S. government formally apologized for its role in the overthrow of Hawaii's government, which had spurred the Hawaiian sovereignty movement and has led to ongoing efforts to obtain redress for the indigenous population.\n",
      "\n",
      "Historically dominated by a plantation economy, Hawaii remains a major agricultural exporter due to its fertile soil and uniquely tropical climate in the U.S. Its economy has gradually diversified since the mid-20th century, with tourism and military defense becoming the two largest sectors. The state attracts visitors, surfers, and scientists with its diverse natural scenery, warm tropical climate, abundant public beaches, oceanic surroundings, active volcanoes, and clear skies on the Big Island. Hawaii hosts the United States Pacific Fleet, the world's largest naval command, as well as 75,000 employees of the Defense Department. Hawaii's relative isolation results in one of the highest costs of living in the U.S. However, Hawaii is the third-wealthiest state, and residents have the longest life expectancy of any U.S. state, at 80.7 years.\n",
      "\n",
      "Etymology\n",
      "The State of Hawaii derives its name from the name of its largest island, Hawaiʻi. A common explanation of the name of Hawaiʻi is that it was named for Hawaiʻiloa, a figure from Hawaiian oral tradition. He is said to have discovered the islands when they were first settled.The Hawaiian language word Hawaiʻi is very similar to Proto-Polynesian Sawaiki, with the reconstructed meaning \"homeland\". Cognates of Hawaiʻi are found in other Polynesian languages, including Māori (Hawaiki), Rarotongan (ʻAvaiki) and Samoan (Savaiʻi). According to linguists Pukui and Elbert, \"elsewhere in Polynesia, Hawaiʻi or a cognate is the name of the underworld or of the ancestral home, but in Hawaii, the name has no meaning\".\n",
      "\n",
      "Spelling of state name\n",
      "In 1978, Hawaiian was added to the Constitution of the State of Hawaii as an official state language alongside English. The title of the state constitution is The Constitution of the State of Hawaii. Article XV, Section 1 of the Constitution uses The State of Hawaii. Diacritics were not used because the document, drafted in 1949, predates the use of the ʻokina ⟨ʻ⟩ and the kahakō in modern Hawaiian orthography. The exact spelling of the state's name in the Hawaiian language is Hawaiʻi. In the Hawaii Admission Act that granted Hawaiian statehood, the federal government used Hawaii for the state name. Official government publications, department and office titles, and the Seal of Hawaii use the traditional spelling with no symbols for glottal stops or vowel length.\n",
      "\n",
      "Geography and environment\n",
      "There are eight main Hawaiian islands. Seven are inhabited, but only six are open to tourists and locals. Niʻihau is privately managed by brothers Bruce and Keith Robinson; access is restricted to those who have their permission. This island is also home to native Hawaiians. Access to uninhabited Kahoʻolawe island is also restricted and anyone who enters without permission will be arrested. This island may also be dangerous since it was a military base during the world wars and could still have unexploded ordnance.\n",
      "\n",
      "Topography\n",
      "The Hawaiian archipelago is 2,000 mi (3,200 km) southwest of the contiguous United States. Hawaii is the southernmost U.S. state and the second westernmost after Alaska. Like Alaska, Hawaii borders no other U.S. state. It is the only U.S. state not in North America, and the only one completely surrounded by water and entirely an archipelago.\n",
      "In addition to the eight main islands, the state has many smaller islands and islets. Kaʻula is a small island near Niʻihau. The Northwestern Hawaiian Islands is a group of nine small, older islands northwest of Kauaʻi that extends from Nihoa to Kure Atoll; these are remnants of once much larger volcanic mountains. Across the archipelago are around 130 small rocks and islets, such as Molokini, which are made up of either volcanic or marine sedimentary rock.Hawaiʻi's tallest mountain Mauna Kea is 13,796 ft (4,205 m) above mean sea level; it is taller than Mount Everest if measured from the base of the mountain, which lies on the floor of the Pacific Ocean and rises about 33,500 feet (10,200 m).\n",
      "\n",
      "Geology\n",
      "The Hawaiian islands were formed by volcanic activity initiated at an undersea magma source called the Hawaiʻi hotspot. The process is continuing to build islands; the tectonic plate beneath much of the Pacific Ocean continually moves northwest and the hotspot remains stationary, slowly creating new volcanoes. Because of the hotspot's location, all active land volcanoes are on the southern half of Hawaiʻi Island. The newest volcano, Kamaʻehuakanaloa (formerly Lōʻihi), is south of the coast of Hawaiʻi Island.\n",
      "The last volcanic eruption outside Hawaiʻi Island occurred at Haleakalā on Maui before the late 18th century, possibly hundreds of years earlier. In 1790, Kīlauea exploded; it is the deadliest eruption known to have occurred in the modern era in what is now the United States. Up to 5,405 warriors and their families marching on Kīlauea were killed by the eruption. Volcanic activity and subsequent erosion have created impressive geological features. Hawaii Island has the second-highest point among the world's islands.On the volcanoes' flanks, slope instability has generated damaging earthquakes and related tsunamis, particularly in 1868 and 1975. Catastrophic debris avalanches on the ocean island volcanoes' submerged flanks have created steep cliffs.Kīlauea erupted in May 2018, opening 22 fissure vents on its eastern rift zone. The Leilani Estates and Lanipuna Gardens are within this territory. The eruption destroyed at least 36 buildings and this, coupled with the lava flows and the sulfur dioxide fumes, necessitated the evacuation of more than 2,000 inhabitants from their neighborhoods.\n",
      "\n",
      "Flora and fauna\n",
      "The islands of Hawaiʻi are distant from other land habitats, and life is thought to have arrived there by wind, waves (i.e., by ocean currents), and wings (i.e., birds, insects, and any seeds that they may have carried on their feathers). Hawaiʻi has more endangered species and has lost a higher percentage of its endemic species than any other U.S. state. The endemic plant Brighamia now requires hand pollination because its natural pollinator is presumed to be extinct. The two species of Brighamia—B. rockii and B. insignis—are represented in the wild by around 120 individual plants. To ensure that these plants set seed, biologists rappel down 3,000-foot (910 m) cliffs to brush pollen onto their stigmas.\n",
      "\n",
      "Terrestrial ecology\n",
      "The archipelago's extant main islands have been above the surface of the ocean for less than 10 million years, a fraction of the time biological colonization and evolution have occurred there. The islands are well known for the environmental diversity that occurs on high mountains within a trade winds field. Native Hawaiians developed complex horticultural practices to utilize the surrounding ecosystem for agriculture. Cultural practices developed to enshrine values of environmental stewardship and reciprocity with the natural world, resulting in widespread biodiversity and intricate social and environmental relationships that persist to this day. On a single island, the climate around the coasts can range from dry tropical (less than 20 inches or 510 millimeters annual rainfall) to wet tropical; on the slopes, environments range from tropical rainforest (more than 200 inches or 5,100 millimeters per year), through a temperate climate, to alpine conditions with a cold, dry climate. The rainy climate impacts soil development, which largely determines ground permeability, affecting the distribution of streams and wetlands.\n",
      "\n",
      "Protected areas\n",
      "Several areas in Hawaiʻi are under the National Park Service's protection. Hawaii has two national parks: Haleakalā National Park, near Kula on Maui, which features the dormant volcano Haleakalā that formed east Maui; and Hawaii Volcanoes National Park, in the southeast region of Hawaiʻi Island, which includes the active volcano Kīlauea and its rift zones.\n",
      "There are three national historical parks: Kalaupapa National Historical Park in Kalaupapa, Molokaʻi, the site of a former leper colony; Kaloko-Honokōhau National Historical Park in Kailua-Kona on Hawaiʻi Island; and Puʻuhonua o Hōnaunau National Historical Park, an ancient place of refuge on Hawaiʻi Island's west coast. Other areas under the National Park Service's control include Ala Kahakai National Historic Trail on Hawaiʻi Island and the USS Arizona Memorial at Pearl Harbor on Oʻahu.\n",
      "President George W. Bush proclaimed the Papahānaumokuākea Marine National Monument on June 15, 2006. The monument covers roughly 140,000 square miles (360,000 km2) of reefs, atolls, and shallow and deep sea out to 50 miles (80 km) offshore in the Pacific Ocean—an area larger than all the national parks in the U.S. combined.\n",
      "\n",
      "Climate\n",
      "Hawaiʻi has a tropical climate. Temperatures and humidity tend to be less extreme because of near-constant trade winds from the east. Summer highs reach around 88 °F (31 °C) during the day, with lows of 75 °F (24 °C) at night. Winter day temperatures are usually around 83 °F (28 °C); at low elevation they seldom dip below 65 °F (18 °C) at night. Snow, not usually associated with the tropics, falls at 13,800 feet (4,200 m) on Mauna Kea and Mauna Loa on Hawaii Island in some winter months. Snow rarely falls on Haleakalā. Mount Waiʻaleʻale on Kauaʻi has the second-highest average annual rainfall on Earth, about 460 inches (12,000 mm) per year. Most of Hawaii experiences only two seasons; the dry season runs from May to October and the wet season is from October to April.Overall with climate change, Hawaiʻi is getting drier and hotter. The warmest temperature recorded in the state, in Pahala on April 27, 1931, is 100 °F (38 °C), tied with Alaska as the lowest record high temperature observed in a U.S. state. Hawaiʻi's record low temperature is 12 °F (−11 °C) observed in May 1979, on the summit of Mauna Kea. Hawaiʻi is the only state to have never recorded subzero Fahrenheit temperatures.Climates vary considerably on each island; they can be divided into windward and leeward (koʻolau and kona, respectively) areas based upon location relative to the higher mountains. Windward sides face cloud cover.\n",
      "\n",
      "Environmental issues\n",
      "Hawaii has a decades-long history of hosting more military space for the United States than any other territory or state. This record of military activity has taken a sharp toll on the environmental health of the Hawaiian archipelago, degrading its beaches and soil, and making some places entirely unsafe due to unexploded ordnance. According to scholar Winona LaDuke: \"The vast militarization of Hawaii has profoundly damaged the land. According to the Environmental Protection Agency, there are more federal hazardous waste sites in Hawaii – 31 – than in any other U.S. state.\" Hawaii State Representative Roy Takumi writes in \"Challenging U.S. Militarism in Hawai'i and Okinawa\" that these military bases and hazardous waste sites have meant \"the confiscation of large tracts of land from native peoples\" and quotes late Hawaiian activist George Helm as asking: \"What is national defense when what is being destroyed is the very thing the military is entrusted to defend, the sacred land of Hawaiʻi?\" Contemporary Indigenous Hawaiians are still protesting the occupation of their homelands and environmental degradation due to increased militarization in the wake of 9/11.After the rise of sugarcane plantations in the mid 19th century, island ecology changed dramatically. Plantations require massive quantities of water, and European and American plantation owners transformed the land in order to access it, primarily by building tunnels to divert water from the mountains to the plantations, constructing reservoirs, and digging wells. These changes have made lasting impacts on the land and continue to contribute to resource scarcity for Native Hawaiians today.According to Stanford scientist and scholar Sibyl Diver, Indigenous Hawaiians engage in a reciprocal relationship with the land, \"based on principles of mutual caretaking, reciprocity and sharing\". This relationship ensures the longevity, sustainability, and natural cycles of growth and decay, as well as cultivating a sense of respect for the land and humility towards one's place in an ecosystem.The tourism industry's ongoing expansion and its pressure on local systems of ecology, cultural tradition and infrastructure is creating a conflict between economic and environmental health. In 2020, the Center for Biological Diversity reported on the plastic pollution of Hawaii's Kamilo beach, citing \"massive piles of plastic waste\". Invasive species are spreading, and chemical and pathogenic runoff is contaminating groundwater and coastal waters.\n",
      "\n",
      "History\n",
      "Hawaiʻi is one of two U.S. states that were widely recognized independent nations before becoming U.S. states. The Kingdom of Hawaiʻi was sovereign from 1810 until 1893, when resident American and European capitalists and landholders overthrew the monarchy. Hawaiʻi was an independent republic from 1894 until August 12, 1898, when it officially became a U.S. territory. Hawaiʻi was admitted as a U.S. state on August 21, 1959.\n",
      "\n",
      "First human settlement – Ancient Hawaiʻi (1000–1778)\n",
      "Based on archaeological evidence, the earliest habitation of the Hawaiian Islands appears to date between 1000 and 1200 CE. The first wave was probably by Polynesian settlers from the Marquesas Islands, and a second wave of migration from Raiatea and Bora Bora took place in the 11th century. The date of the human discovery and habitation of the Hawaiian Islands is the subject of academic debate. Some archaeologists and historians think it was a later wave of immigrants from Tahiti around 1000 CE who introduced a new line of high chiefs, the kapu system, the practice of human sacrifice, and the building of heiau. This later immigration is detailed in Hawaiian mythology (moʻolelo) about Paʻao. Other authors say there is no archaeological or linguistic evidence of a later influx of Tahitian settlers and that Paʻao must be regarded as a myth.The islands' history is marked by a slow, steady growth in population and the size of the chiefdoms, which grew to encompass whole islands. Local chiefs, called aliʻi, ruled their settlements, and launched wars to extend their influence and defend their communities from predatory rivals. Ancient Hawaiʻi was a caste-based society, much like that of Hindus in India. Population growth was facilitated by ecological and agricultural practices that combined upland agriculture (manuka), ocean fishing (makai), fishponds and gardening systems. These systems were upheld by spiritual and religious beliefs, like the lokahi, that linked cultural continuity with the health of the natural world. According to Hawaiian scholar Mililani Trask, the lokahi symbolizes the \"greatest of the traditions, values, and practices of our people ... There are three points in the triangle—the Creator, Akua; the peoples of the earth, Kanaka Maoli; and the land, the ʻaina. These three things all have a reciprocal relationship.\"\n",
      "\n",
      "European arrival\n",
      "The 1778 arrival of British explorer Captain James Cook marked the first documented contact by a European explorer with Hawaiʻi; early British influence can be seen in the design of the flag of Hawaiʻi, which bears the Union Jack in the top-left corner. Cook named the archipelago \"the Sandwich Islands\" in honor of his sponsor John Montagu, 4th Earl of Sandwich, publishing the islands' location and rendering the native name as Owyhee. The form \"Owyhee\" or \"Owhyhee\" is preserved in the names of certain locations in the American part of the Pacific Northwest, among them Owyhee County and Owyhee Mountains in Idaho, named after three native Hawaiian members of a trapping party who went missing in the area.Spanish explorers may have arrived in the Hawaiian Islands in the 16th century, 200 years before Cook's first documented visit in 1778. Ruy López de Villalobos commanded a fleet of six ships that left Acapulco in 1542 bound for the Philippines, with a Spanish sailor named Juan Gaetano aboard as pilot. Gaetano's reports describe an encounter with either Hawaiʻi or the Marshall Islands. If López de Villalobos's crew spotted Hawaiʻi, Gaetano would thus be the first European to see the islands. Most scholars have dismissed these claims due to a lack of credibility.Nonetheless, Spanish archives contain a chart that depicts islands at the same latitude as Hawaiʻi, but with a longitude ten degrees east of the islands. In this manuscript, Maui is named La Desgraciada (The Unfortunate Island), and what appears to be Hawaiʻi Island is named La Mesa (The Table). Islands resembling Kahoʻolawe', Lānaʻi, and Molokaʻi are named Los Monjes (The Monks). For two and a half centuries, Spanish galleons crossed the Pacific from Mexico along a route that passed south of Hawaiʻi on their way to Manila. The exact route was kept secret to protect the Spanish trade monopoly against competing powers. Hawaiʻi thus maintained independence, despite being on a sea route east–west between nations that were subjects of the Viceroyalty of New Spain, an empire that exercised jurisdiction over many subject civilizations and kingdoms on both sides of the Pacific.\n",
      "Despite such contested claims, Cook is generally considered the first European to land at Hawaiʻi, having visited the Hawaiian Islands twice. As he prepared for departure after his second visit in 1779, a quarrel ensued as he took temple idols and fencing as \"firewood\", and a minor chief and his group stole a boat from his ship. Cook abducted the King of Hawaiʻi Island, Kalaniʻōpuʻu, and held him for ransom aboard his ship to gain return of Cook's boat, as this tactic had previously worked in Tahiti and other islands. Instead, the supporters of Kalaniʻōpuʻu attacked, killing Cook and four sailors as Cook's party retreated along the beach to their ship. The ship departed without retrieving the stolen boat.\n",
      "After Cook's visit and the publication of several books relating his voyages, the Hawaiian Islands attracted many European and American explorers, traders, and whalers, who found the islands to be a convenient harbor and source of supplies. These visitors introduced diseases to the once-isolated islands, causing the Hawaiian population to drop precipitously. Native Hawaiians had no resistance to Eurasian diseases, such as influenza, smallpox and measles. By 1820, disease, famine and wars between the chiefs killed more than half of the Native Hawaiian population. During the 1850s, measles killed a fifth of Hawaiʻi's people.Historical records indicate the earliest Chinese immigrants to Hawaiʻi originated from Guangdong Province; a few sailors arrived in 1778 with Cook's journey, and more in 1789 with an American trader who settled in Hawaiʻi in the late 18th century. It is said that Chinese workers introduced leprosy by 1830, and as with the other new infectious diseases, it proved damaging to the Hawaiians.\n",
      "\n",
      "Kingdom of Hawaiʻi\n",
      "House of Kamehameha\n",
      "During the 1780s, and 1790s, chiefs often fought for power. After a series of battles that ended in 1795, all inhabited islands were subjugated under a single ruler, who became known as King Kamehameha the Great. He established the House of Kamehameha, a dynasty that ruled the kingdom until 1872.After Kamehameha II inherited the throne in 1819, American Protestant missionaries to Hawaiʻi converted many Hawaiians to Christianity. Missionaries have argued that one function of missionary work was to \"civilize\" and \"purify\" perceived heathenism in the New World. This carried into Hawaiʻi. According to historical archaeologist James L. Flexner, \"missionaries provided the moral means to rationalize conquest and wholesale conversion to Christianity\". But rather than abandon traditional beliefs entirely, most native Hawaiians merged their Indigenous religion with Christianity. Missionaries used their influence to end many traditional practices, including the kapu system, the prevailing legal system before European contact, and heiau, or \"temples\" to religious figures. Kapu, which typically translates to \"the sacred\", refers to social regulations (like gender and class restrictions) that were based upon spiritual beliefs. Under the missionaries' guidance, laws against gambling, consuming alcohol, dancing the hula, breaking the Sabbath, and polygamy were enacted. Without the kapu system, many temples and priestly statuses were jeopardized, idols were burned, and participation in Christianity increased. When Kamehameha III inherited the throne at age 12, his advisors pressured him to merge Christianity with traditional Hawaiian ways. Under the guidance of his kuhina nui (his mother and coregent Elizabeth Kaʻahumanu) and British allies, Hawaiʻi turned into a Christian monarchy with the signing of the 1840 Constitution. Hiram Bingham I, a prominent Protestant missionary, was a trusted adviser to the monarchy during this period. Other missionaries and their descendants became active in commercial and political affairs, leading to conflicts between the monarchy and its restive American subjects. Catholic and Mormon missionaries were also active in the kingdom, but they converted a minority of the Native Hawaiian population. Missionaries from each major group administered to the leper colony at Kalaupapa on Molokaʻi, which was established in 1866 and operated well into the 20th century. The best known were Father Damien and Mother Marianne Cope, both of whom were canonized in the early 21st century as Roman Catholic saints.\n",
      "The death of the bachelor King Kamehameha V—who did not name an heir—resulted in the popular election of Lunalilo over Kalākaua. Lunalilo died the next year, also without naming an heir. In 1874, the election was contested within the legislature between Kalākaua and Emma, Queen Consort of Kamehameha IV. After riots broke out, the U.S. and Britain landed troops on the islands to restore order. The Legislative Assembly chose King Kalākaua as monarch by a vote of 39 to 6 on February 12, 1874.\n",
      "\n",
      "1887 Constitution and overthrow preparations\n",
      "In 1887, Kalākaua was forced to sign the 1887 Constitution of the Kingdom of Hawaiʻi. Drafted by white businessmen and lawyers, the document stripped the king of much of his authority. It established a property qualification for voting that effectively disenfranchised most Hawaiians and immigrant laborers and favored the wealthier, white elite. Resident whites were allowed to vote but resident Asians were not. As the 1887 Constitution was signed under threat of violence, it is known as the Bayonet Constitution. King Kalākaua, reduced to a figurehead, reigned until his death in 1891. His sister, Queen Liliʻuokalani, succeeded him; she was the last monarch of Hawaiʻi.\n",
      "In 1893, Liliʻuokalani announced plans for a new constitution to proclaim herself an absolute monarch. On January 14, 1893, a group of mostly Euro-American business leaders and residents formed the Committee of Safety to stage a coup d'état against the kingdom and seek annexation by the United States. U.S. Government Minister John L. Stevens, responding to a request from the Committee of Safety, summoned a company of U.S. Marines. The queen's soldiers did not resist. According to historian William Russ, the monarchy was unable to protect itself. In Hawaiian Autonomy, Liliʻuokalani states: If we did not by force resist their final outrage, it was because we could not do so without striking at the military force of the United States. Whatever constraint the executive of this great country may be under to recognize the present government at Honolulu has been forced upon it by no act of ours, but by the unlawful acts of its own agents. Attempts to repudiate those acts are vain.In a message to Sanford B. Dole, Liliʻuokalani states:Now to avoid any collision of armed forces and perhaps the loss of life, I do under this protest, and impelled by said force, yield my authority until such time as the Government of the United States shall, upon the facts being presented to it, undo the action of its representatives and reinstate me in the authority which I claim as the constitutional sovereign of the Hawaiian Islands.\n",
      "\n",
      "Overthrow of 1893 – Republic of Hawaiʻi (1894–1898)\n",
      "The treason trials of 1892 brought together the main players in the 1893 overthrow. American Minister John L. Stevens voiced support for Native Hawaiian revolutionaries; William R. Castle, a Committee of Safety member, served as a defense counsel in the treason trials; Alfred Stedman Hartwell, the 1893 annexation commissioner, led the defense effort; and Sanford B. Dole ruled as a supreme court justice against acts of conspiracy and treason.On January 17, 1893, a small group of sugar and pineapple-growing businessmen, aided by the American minister to Hawaii and backed by heavily armed U.S. soldiers and marines, deposed Queen Liliʻuokalani and installed a provisional government composed of members of the Committee of Safety. According to scholar Lydia Kualapai and Hawaii State Representative Roy Takumi, this committee was formed against the will of Indigenous Hawaiian voters, who constituted the majority of voters at the time, and consisted of \"thirteen white men\" according to scholar J Kehaulani Kauanui. The United States Minister to the Kingdom of Hawaii (John L. Stevens) conspired with U.S. citizens to overthrow the monarchy. After the overthrow, Sanford B. Dole, a citizen of Hawaii and cousin to James Dole, owner of Hawaiian Fruit Company, a company that benefited from the annexation of Hawaii, became president of the republic when the Provisional Government of Hawaiʻi ended on July 4, 1894.Controversy ensued in the following years as the queen tried to regain her throne. Scholar Lydia Kualapai writes that Liliʻuokalani had \"yielded under protest not to the counterfeit Provisional Government of Hawaii but to the superior force of the United States of America\" and wrote letters of protest to the president requesting a recognizance of allyship and a reinstatement of her sovereignty against the recent actions of the Provisional Government of Hawaii. Following the January 1893 coup that deposed Liliʻuokalani, many royalists were preparing to overthrow the white-led Republic of Hawaiʻi oligarchy. Hundreds of rifles were covertly shipped to Hawaii and hidden in caves nearby. As armed troops came and went, a Republic of Hawaiʻi patrol discovered the rebel group. On January 6, 1895, gunfire began on both sides and later the rebels were surrounded and captured. Over the next 10 days several skirmishes occurred, until the last armed opposition surrendered or were captured. The Republic of Hawaiʻi took 123 troops into custody as prisoners of war. The mass arrest of nearly 300 more men and women, including Queen Liliʻuokalani, as political prisoners was intended to incapacitate the political resistance against the ruling oligarchy. In March 1895, a military tribunal convicted 170 prisoners of treason and sentenced six troops to be \"hung by the neck\" until dead, according to historian Ronald Williams Jr. The other prisoners were variously sentenced to from five to thirty-five years' imprisonment at hard labor, while those convicted of lesser charges received sentences from six months' to six years' imprisonment at hard labor. The queen was sentenced to five years in prison, but spent eight months under house arrest until she was released on parole. The total number of arrests related to the 1895 Kaua Kūloko was 406 people on a summary list of statistics, published by the government of the Republic of Hawaiʻi.\n",
      "The administration of President Grover Cleveland commissioned the Blount Report, which concluded that the removal of Liliʻuokalani had been illegal. Commissioner Blount found the U.S. and its minister guilty on all counts including the overthrow, the landing of the marines, and the recognition of the provisional government. In a message to Congress, Cleveland wrote:And finally, but for the lawless occupation of Honolulu under false pretexts by the United States forces, and but for Minister Stevens' recognition of the provisional government when the United States forces were its sole support and constituted its only military strength, the Queen and her Government would never have yielded to the provisional government, even for a time and for the sole purpose of submitting her case to the enlightened justice of the United States. By an act of war, committed with the participation of a diplomatic representative of the United States and without authority of Congress, the Government of a feeble but friendly and confiding people has been overthrown. A substantial wrong has thus been done which a due regard for our national character as well as the rights of the injured people requires we should endeavor to repair. The provisional government has not assumed a republican or other constitutional form, but has remained a mere executive council or oligarchy, set up without the assent of the people. It has not sought to find a permanent basis of popular support and has given no evidence of an intention to do so.The U.S. government first demanded that Queen Liliʻuokalani be reinstated, but the Provisional Government refused. On December 23, 1893, the response from the Provisional Government of Hawaii, authored by President Sanford B. Dole, was received by Cleveland's representative Minister Albert S. Willis and emphasized that the Provisional Government of Hawaii \"unhesitatingly\" rejected the demand from the Cleveland Administration.Congress conducted an independent investigation, and on February 26, 1894, submitted the Morgan Report, which found all parties, including Minister Stevens—with the exception of the queen—\"not guilty\" and not responsible for the coup. Partisans on both sides of the debate questioned the accuracy and impartiality of both the Blount and Morgan reports over the events of 1893.In 1993, Congress passed a joint Apology Resolution regarding the overthrow; it was signed by President Bill Clinton. The resolution apologized and said that the overthrow was illegal in the following phrase: \"The Congress—on the occasion of the 100th anniversary of the illegal overthrow of the Kingdom of Hawaiʻi on January 17, 1893, acknowledges the historical significance of this event which resulted in the suppression of the inherent sovereignty of the Native Hawaiian people.\" The Apology Resolution also \"acknowledges that the overthrow of the Kingdom of Hawaiʻi occurred with the active participation of agents and citizens of the United States and further acknowledges that the Native Hawaiian people never directly relinquished to the United States their claims to their inherent sovereignty as a people over their national lands, either through the Kingdom of Hawaiʻi or through a plebiscite or referendum\".\n",
      "\n",
      "Annexation – Territory of Hawaiʻi (1898–1959)\n",
      "After William McKinley won the 1896 U.S. presidential election, advocates pressed to annex the Republic of Hawaiʻi. The previous president, Grover Cleveland, was a friend of Queen Liliʻuokalani. McKinley was open to persuasion by U.S. expansionists and by annexationists from Hawaiʻi. He met with three non-native annexationists: Lorrin A. Thurston, Francis March Hatch and William Ansel Kinney. After negotiations in June 1897, Secretary of State John Sherman agreed to a treaty of annexation with these representatives of the Republic of Hawaiʻi. The U.S. Senate never ratified the treaty. Despite the opposition of most native Hawaiians, the Newlands Resolution was used to annex the republic to the U.S.; it became the Territory of Hawaiʻi. The Newlands Resolution was passed by the House on June 15, 1898, by 209 votes in favor to 91 against, and by the Senate on July 6, 1898, by a vote of 42 to 21.A majority of Native Hawaiians opposed annexation, voiced chiefly by Liliʻuokalani, whom Hawaiian Haunani-Kay Trask described as beloved and respected by her people. Liliʻuokalani wrote, \"it had not entered into our hearts to believe that these friends and allies from the United States ... would ever go so far as to absolutely overthrow our form of government, seize our nation by the throat, and pass it over to an alien power\" in her retelling of the overthrow of her government. According to Trask, newspapers at the time argued Hawaiians would suffer \"virtual enslavement under annexation\", including further loss of lands and liberties, in particular to sugar plantation owners. These plantations were protected by the U.S. Navy as economic interests, justifying a continued military presence in the islands.In 1900, Hawaiʻi was granted self-governance and retained ʻIolani Palace as the territorial capitol building. Despite several attempts to become a state, Hawaii remained a territory for 60 years. Plantation owners and capitalists, who maintained control through financial institutions such as the Big Five, found territorial status convenient because they remained able to import cheap, foreign labor. Such immigration and labor practices were prohibited in many states.\n",
      "Puerto Rican immigration to Hawaiʻi began in 1899, when Puerto Rico's sugar industry was devastated by a hurricane, causing a worldwide shortage of sugar and a huge demand for sugar from Hawaiʻi. Hawaiian sugarcane plantation owners began to recruit experienced, unemployed laborers in Puerto Rico. Two waves of Korean immigration to Hawaiʻi occurred in the 20th century. The first wave arrived between 1903 and 1924; the second wave began in 1965 after President Lyndon B. Johnson signed the Immigration and Nationality Act of 1965, which removed racial and national barriers and resulted in significantly altering the demographic mix in the U.S.Oʻahu was the target of a surprise attack on Pearl Harbor by Imperial Japan on December 7, 1941. The attack on Pearl Harbor and other military and naval installations, carried out by aircraft and by midget submarines, brought the United States into World War II.\n",
      "\n",
      "Political changes of 1954 – State of Hawaiʻi (1959–present)\n",
      "In the 1950s, the plantation owners' power was broken by the descendants of immigrant laborers, who were born in Hawaiʻi and were U.S. citizens. They voted against the Hawaiʻi Republican Party, strongly supported by plantation owners. The new majority voted for the Democratic Party of Hawaiʻi, which dominated territorial and state politics for more than 40 years. Eager to gain full representation in Congress and the Electoral College, residents actively campaigned for statehood. In Washington there was talk that Hawaiʻi would be a Republican Party stronghold so it was matched with the admission of Alaska, seen as a Democratic Party stronghold. These predictions proved inaccurate; today, Hawaiʻi votes Democratic predominantly, while Alaska votes Republican.In March 1959, Congress passed the Hawaiʻi Admissions Act, which U.S. President Dwight D. Eisenhower signed into law. The act excluded Palmyra Atoll from statehood; it had been part of the Kingdom and Territory of Hawaiʻi. On June 27, 1959, a referendum asked residents of Hawaiʻi to vote on the statehood bill; 94.3% voted in favor of statehood and 5.7% opposed it. The referendum asked voters to choose between accepting the Act and remaining a U.S. territory. The United Nations' Special Committee on Decolonization later removed Hawaiʻi from its list of non-self-governing territories.\n",
      "After attaining statehood, Hawaiʻi quickly modernized through construction and a rapidly growing tourism economy. Later, state programs promoted Hawaiian culture. The Hawaiʻi State Constitutional Convention of 1978 created institutions such as the Office of Hawaiian Affairs to promote indigenous language and culture.\n",
      "\n",
      "Legacy of annexation on Hawaiian land\n",
      "In 1897, over 21,000 Natives, representing the overwhelming majority of adult Hawaiians, signed anti-annexation petitions in one of the first examples of protest against the overthrow of Queen Liliʻuokalaniʻs government. Nearly 100 years later, in 1993, 17,000 Hawaiians marched to demand access and control over Hawaiian trust lands and as part of the modern Hawaiian sovereignty movement. Hawaiian trust land ownership and use is still widely contested as a consequence of annexation. According to scholar Winona LaDuke, as of 2015, 95% of Hawaiʻiʻs land was owned or controlled by just 82 landholders, including over 50% by federal and state governments, as well as the established sugar and pineapple companies. The Thirty Meter Telescope is planned to be built on Hawaiian trust land, but has faced resistance as the project interferes with Kanaka indigeneity.\n",
      "\n",
      "Demographics\n",
      "Population\n",
      "After Europeans and mainland Americans first arrived during the Kingdom of Hawaii period, the overall population of Hawaii—which until that time composed solely of Indigenous Hawaiians—fell dramatically. Many people of the Indigenous Hawaiian population died to foreign diseases, declining from 300,000 in the 1770s, to 60,000 in the 1850s, to 24,000 in 1920. Other estimates for the pre-contact population range from 150,000 to 1.5 million. The population of Hawaii began to finally increase after an influx of primarily Asian settlers that arrived as migrant laborers at the end of the 19th century. In 1923, 42% of the population was of Japanese descent, 9% was of Chinese descent, and 16% was native descent.The unmixed indigenous Hawaiian population has still not restored itself to its 300,000 pre-contact level. As of 2010, only 156,000 persons declared themselves to be of Native Hawaiian-only ancestry, just over half the pre-contact level Native Hawaiian population, although an additional 371,000 persons declared themselves to possess Native Hawaiian ancestry in combination with one or more other races (including other Polynesian groups, but mostly Asian or Caucasian).\n",
      "As of 2018, the United States Census Bureau estimates the population of Hawaii at 1,420,491, a decrease of 7,047 from the previous year and an increase of 60,190 (4.42%) since 2010. This includes a natural increase of 48,111 (96,028 births minus 47,917 deaths) and an increase due to net migration of 16,956 people into the state. Immigration from outside the United States resulted in a net increase of 30,068; migration within the country produced a net loss of 13,112 people.The center of population of Hawaii is located on the island of O'ahu. Large numbers of Native Hawaiians have moved to Las Vegas, which has been called the \"ninth island\" of Hawaii.Hawaii has a de facto population of over 1.4 million, due in part to a large number of military personnel and tourist residents. O'ahu is the most populous island; it has the highest population density with a resident population of just under one million in 597 square miles (1,546 km2), approximately 1,650 people per square mile. Hawaii's 1.4 million residents, spread across 6,000 square miles (15,500 km2) of land, result in an average population density of 188.6 persons per square mile. The state has a lower population density than Ohio and Illinois.The average projected lifespan of people born in Hawaii in 2000 is 79.8 years; 77.1 years if male, 82.5 if female—longer than the average lifespan of any other U.S. state. As of 2011 the U.S. military reported it had 42,371 personnel on the islands.According to HUD's 2022 Annual Homeless Assessment Report, there were an estimated 5,967 homeless people in Hawaii.\n",
      "\n",
      "Ancestry\n",
      "According to the 2020 United States Census, Hawaii had a population of 1,455,271. The state's population identified as 37.2% Asian; 25.3% Multiracial; 22.9% White; 10.8% Native Hawaiians and other Pacific Islanders; 9.5% Hispanic and Latinos of any race; 1.6% Black or African American; 1.8% from some other race; and 0.3% Native American and Alaskan Native.\n",
      "Hawaii has the highest percentage of Asian Americans and multiracial Americans and the lowest percentage of White Americans of any state. It is the only state where people who identify as Asian Americans are the largest ethnic group. In 2012, 14.5% of the resident population under age 1 was non-Hispanic white. Hawaii's Asian population consists mainly of 198,000 (14.6%) Filipino Americans, 185,000 (13.6%) Japanese Americans, roughly 55,000 (4.0%) Chinese Americans, and 24,000 (1.8%) Korean Americans.Over 120,000 (8.8%) Hispanic and Latino Americans live in Hawaii. Mexican Americans number over 35,000 (2.6%); Puerto Ricans exceed 44,000 (3.2%). Multiracial Americans constitute almost 25% of Hawaii's population, exceeding 320,000 people. Hawaii is the only state to have a tri-racial group as its largest multiracial group, one that includes white, Asian and Native Hawaiian/Pacific Islander (22% of all mutiracial population). The non-Hispanic White population numbers around 310,000—just over 20% of the population. The multi-racial population outnumbers the non-Hispanic white population by about 10,000 people. In 1970, the Census Bureau reported Hawaii's population was 38.8% white and 57.7% Asian and Pacific Islander.There are more than 80,000 Indigenous Hawaiians—5.9% of the population. Including those with partial ancestry, Samoan Americans constitute 2.8% of Hawaii's population, and Tongan Americans constitute 0.6%.The five largest European ancestries in Hawaii are German (7.4%), Irish (5.2%), English (4.6%), Portuguese (4.3%) and Italian (2.7%). About 82.2% of the state's residents were born in the United States. Roughly 75% of foreign-born residents originate from Asia. Hawaii is a majority-minority state. It was expected to be one of three states that would not have a non-Hispanic white plurality in 2014; the other two are California and New Mexico.\n",
      "The third group of foreigners to arrive in Hawaii were from China. Chinese workers on Western trading ships settled in Hawaii starting in 1789. In 1820, the first American missionaries arrived to preach Christianity and teach the Hawaiians Western ways. As of 2015, a large proportion of Hawaii's population have Asian ancestry—especially Filipino, Japanese and Chinese. Many are descendants of immigrants brought to work on the sugarcane plantations in the mid-to-late 19th century. The first 153 Japanese immigrants arrived in Hawaii on June 19, 1868. They were not approved by the then-current Japanese government because the contract was between a broker and the Tokugawa shogunate—by then replaced by the Meiji Restoration. The first Japanese current-government-approved immigrants arrived on February 9, 1885, after Kalākaua's petition to Emperor Meiji when Kalākaua visited Japan in 1881.Almost 13,000 Portuguese migrants had arrived by 1899; they also worked on the sugarcane plantations. By 1901, more than 5,000 Puerto Ricans were living in Hawaii.\n",
      "\n",
      "Languages\n",
      "English and Hawaiian are listed as Hawaii's official languages in the state's 1978 constitution, in Article XV, Section 4. However, the use of Hawaiian is limited because the constitution specifies that \"Hawaiian shall be required for public acts and transactions only as provided by law\". Hawaiʻi Creole English, locally referred to as \"Pidgin\", is the native language of many native residents and is a second language for many others.As of the 2000 Census, 73.4% of Hawaii residents age 5 and older exclusively speak English at home. According to the 2008 American Community Survey, 74.6% of Hawaii's residents older than 5 speak only English at home. In their homes, 21.0% of state residents speak an additional Asian language, 2.6% speak Spanish, 1.6% speak other Indo-European languages and 0.2% speak another language.After English, other languages popularly spoken in the state are Tagalog, Ilocano, and Japanese. 5.4% of residents speak Tagalog, which includes non-native speakers of Filipino, a Tagalog-based national and co-official language of the Philippines; 5.0% speak Japanese and 4.0% speak Ilocano; 1.2% speak Chinese, 1.7% speak Hawaiian; 1.7% speak Spanish; 1.6% speak Korean; and 1.0% speak Samoan.\n",
      "\n",
      "Hawaiian\n",
      "The Hawaiian language has about 2,000 native speakers, about 0.15% of the total population. According to the United States Census, there were more than 24,000 total speakers of the language in Hawaii in 2006–2008. Hawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.According to Schütz, the Marquesans colonized the archipelago in roughly 300 CE and were later followed by waves of seafarers from the Society Islands, Samoa and Tonga. These Polynesians remained in the islands; they eventually became the Hawaiian people and their languages evolved into the Hawaiian language. Kimura and Wilson say: \"[l]inguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands\".Before the arrival of Captain James Cook, the Hawaiian language had no written form. That form was developed mainly by American Protestant missionaries between 1820 and 1826 who assigned to the Hawaiian phonemes letters from the Latin alphabet. Interest in Hawaiian increased significantly in the late 20th century. With the help of the Office of Hawaiian Affairs, specially designated immersion schools in which all subjects would be taught in Hawaiian were established. The University of Hawaiʻi developed a Hawaiian-language graduate studies program. Municipal codes were altered to favor Hawaiian place and street names for new civic developments.Hawaiian distinguishes between long and short vowel sounds. In modern practice, vowel length is indicated with a macron (kahakō). Hawaiian-language newspapers (nūpepa) published from 1834 to 1948 and traditional native speakers of Hawaiian generally omit the marks in their own writing. The ʻokina and kahakō are intended to capture the proper pronunciation of Hawaiian words. The Hawaiian language uses the glottal stop (ʻOkina) as a consonant. It is written as a symbol similar to the apostrophe or left-hanging (opening) single quotation mark.The keyboard layout used for Hawaiian is QWERTY.\n",
      "\n",
      "Hawaiian Pidgin\n",
      "Some residents of Hawaii speak Hawaiʻi Creole English (HCE), endonymically called pidgin or pidgin English. The lexicon of HCE derives mainly from English but also uses words that have derived from Hawaiian, Chinese, Japanese, Portuguese, Ilocano and Tagalog. During the 19th century, the increase in immigration—mainly from China, Japan, Portugal—especially from the Azores and Madeira, and Spain—catalyzed the development of a hybrid variant of English known to its speakers as pidgin. By the early 20th century, pidgin speakers had children who acquired it as their first language. HCE speakers use some Hawaiian words without those words being considered archaic. Most place names are retained from Hawaiian, as are some names for plants and animals. For example, tuna fish is often called by its Hawaiian name, ahi.HCE speakers have modified the meanings of some English words. For example, \"aunty\" and \"uncle\" may either refer to any adult who is a friend or be used to show respect to an elder. Syntax and grammar follow distinctive rules different from those of General American English. For example, instead of \"it is hot today, isn't it?\", an HCE speaker would say simply \"stay hot, eh?\" The term da kine is used as a filler; a substitute for virtually any word or phrase. During the surfing boom in Hawaii, HCE was influenced by surfer slang. Some HCE expressions, such as brah and da kine, have found their ways elsewhere through surfing communities.\n",
      "\n",
      "Hawaiʻi Sign Language\n",
      "Hawaiʻi Sign Language, a sign language for the Deaf based on the Hawaiian language, has been in use in the islands since the early 1800s. It is dwindling in numbers due to American Sign Language supplanting HSL through schooling and various other domains.\n",
      "\n",
      "Religion\n",
      "Hawaii is among the most religiously diverse states in the U.S., with one in ten residents practicing a non-Christian faith. Roughly one-quarter to half the population identify as unaffiliated and nonreligious, making Hawaii one of the most secular states as well.\n",
      "Christianity remains the majority religion, represented mainly by various Protestant groups and Roman Catholicism. The second-largest religion is Buddhism, which comprises a larger proportion of the population than in any other state; it is concentrated in the Japanese community. Native Hawaiians continue to engage in traditional religious and spiritual practices today, often adhering to Christian and traditional beliefs at the same time.The Cathedral Church of Saint Andrew in Honolulu was formally the seat of the Hawaiian Reformed Catholic Church, a province of the Anglican Communion that had been the state church of the Kingdom of Hawaii; it subsequently merged into the Episcopal Church in the 1890s following the overthrow of the Kingdom of Hawaii, becoming the seat of the Episcopal Diocese of Hawaii. The Cathedral Basilica of Our Lady of Peace and the Co-Cathedral of Saint Theresa of the Child Jesus serve as seats of the Roman Catholic Diocese of Honolulu. The Eastern Orthodox community is centered around the Saints Constantine and Helen Greek Orthodox Cathedral of the Pacific.\n",
      "The largest religious denominations by membership were the Roman Catholic Church with 249,619 adherents in 2010; the Church of Jesus Christ of Latter-day Saints with 68,128 adherents in 2009; the United Church of Christ with 115 congregations and 20,000 members; and the Southern Baptist Convention with 108 congregations and 18,000 members. Nondenominational churches collectively have 128 congregations and 32,000 members.\n",
      "According to data provided by religious establishments, religion in Hawaii in 2000 was distributed as follows:\n",
      "\n",
      "However, a Pew poll found that the religious composition was as follows:\n",
      "\n",
      "Birth data\n",
      "Note: Births in this table do not add up, because Hispanic peoples are counted both by their ethnicity and by their race, giving a higher overall number.\n",
      "\n",
      "1) Until 2016, data for births of Asian origin, included also births of the Pacific Islander group.\n",
      "2) Since 2016, data for births of White Hispanic origin are not collected, but included in one Hispanic group; persons of Hispanic origin may be of any race.\n",
      "\n",
      "LGBTQ\n",
      "Hawaii has had a long history of LGBTQIA+ identities. Māhū (\"in the middle\") were a precolonial third gender with traditional spiritual and social roles, widely respected as healers. Homosexual relationships known as aikāne were widespread and normal in ancient Hawaiian society. Among men, aikāne relationships often began as teens and continued throughout their adult lives, even if they also maintained heterosexual partners. While aikāne usually refers to male homosexuality, some stories also refer to women, implying that women may have been involved in aikāne relationships as well. Journals written by Captain Cook's crew record that many aliʻi (hereditary nobles) also engaged in aikāne relationships, and Kamehameha the Great, the founder and first ruler of the Kingdom of Hawaii, was also known to participate. Cook's second lieutenant and co-astronomer James King observed that \"all the chiefs had them\", and recounts that Cook was actually asked by one chief to leave King behind, considering the role a great honor.\n",
      "Hawaiian scholar Lilikalā Kameʻeleihiwa notes that aikāne served a practical purpose of building mutual trust and cohesion; \"If you didn't sleep with a man, how could you trust him when you went into battle? How would you know if he was going to be the warrior that would protect you at all costs, if he wasn't your lover?\"As Western colonial influences intensified in the late 19th and early 20th century, the word aikāne was expurgated of its original sexual meaning, and in print simply meant \"friend\". Nonetheless, in Hawaiian language publications its metaphorical meaning can still mean either \"friend\" or \"lover\" without stigmatization.A 2012 Gallup poll found that Hawaii had the largest proportion of LGBTQIA+ adults in the U.S., at 5.1%, an estimated 53,966 individuals. The number of same-sex couple households in 2010 was 3,239, representing a 35.5% increase from a decade earlier. In 2013, Hawaii became the fifteenth U.S. state to legalize same-sex marriage; this reportedly boosted tourism by $217 million.\n",
      "\n",
      "Economy\n",
      "The history of Hawaii's economy can be traced through a succession of dominant industries: sandalwood, whaling, sugarcane, pineapple, the military, tourism and education. By the 1840s, sugar plantations had gained a strong foothold in the Hawaiian economy, due to a high demand of sugar in the United States and rapid transport via steamships. Sugarcane plantations were tightly controlled by American missionary families and businessmen known as \"the Big Five\", who monopolized control of the sugar industry's profits. By the time Hawaiian annexation was being considered in 1898, sugarcane producers turned to cultivating tropical fruits like pineapple, which became the principal export for Hawaiʻi's plantation economy. Since statehood in 1959, tourism has been the largest industry, contributing 24.3% of the gross state product (GSP) in 1997, despite efforts to diversify. The state's gross output for 2003 was US$47 billion; per capita income for Hawaii residents in 2014 was US$54,516. Hawaiian exports include food and clothing. These industries play a small role in the Hawaiian economy, due to the shipping distance to viable markets, such as the West Coast of the United States. The state's food exports include coffee, macadamia nuts, pineapple, livestock, sugarcane and honey.By weight, honey bees may be the state's most valuable export. According to the Hawaii Agricultural Statistics Service, agricultural sales were US$370.9 million from diversified agriculture, US$100.6 million from pineapple, and US$64.3 million from sugarcane. Hawaii's relatively consistent climate has attracted the seed industry, which is able to test three generations of crops per year on the islands, compared with one or two on the mainland. Seeds yielded US$264 million in 2012, supporting 1,400 workers.As of December 2015, the state's unemployment rate was 3.2%. In 2009, the United States military spent US$12.2 billion in Hawaii, accounting for 18% of spending in the state for that year. 75,000 United States Department of Defense personnel live in Hawaii. According to a 2013 study by Phoenix Marketing International, Hawaii at that time had the fourth-largest number of millionaires per capita in the United States, with a ratio of 7.2%.\n",
      "\n",
      "Taxation\n",
      "Tax is collected by the Hawaii Department of Taxation. Most government revenue comes from personal income taxes and a general excise tax (GET) levied primarily on businesses; there is no statewide tax on sales, personal property, or stock transfers, while the effective property tax rate is among the lowest in the country. The high rate of tourism means that millions of visitors generate public revenue through GET and the hotel room tax. However, Hawaii residents generally pay among the most state taxes per person in the U.S.The Tax Foundation of Hawaii considers the state's tax burden too high, claiming that it contributes to higher prices and the perception of an unfriendly business climate. The nonprofit Tax Foundation ranks Hawaii third in income tax burden and second in its overall tax burden, though notes that a significant portion of taxes are borne by tourists. Former State Senator Sam Slom attributed Hawaii's comparatively high tax rate to the fact that the state government is responsible for education, health care, and social services that are usually handled at a county or municipal level in most other states.\n",
      "\n",
      "Cost of living\n",
      "The cost of living in Hawaii, specifically Honolulu, is high compared to that of most major U.S. cities, although it is 6.7% lower than in New York City and 3.6% lower than in San Francisco. These numbers may not take into account some costs, such as increased travel costs for flights, additional shipping fees, and the loss of promotional participation opportunities for customers outside the contiguous U.S. While some online stores offer free shipping on orders to Hawaii, many merchants exclude Hawaii, Alaska, Puerto Rico and certain other U.S. territories.Hawaiian Electric Industries, a privately owned company, provides 95% of the state's population with electricity, mostly from fossil-fuel power stations. Average electricity prices in October 2014 (36.41 cents per kilowatt-hour) were nearly three times the national average (12.58 cents per kilowatt-hour) and 80% higher than the second-highest state, Connecticut.The median home value in Hawaii in the 2000 U.S. Census was US$272,700, while the national median home value was US$119,600. Hawaii home values were the highest of all states, including California with a median home value of US$211,500. Research from the National Association of Realtors places the 2010 median sale price of a single family home in Honolulu, Hawaii, at US$607,600 and the U.S. median sales price at US$173,200. The sale price of single family homes in Hawaii was the highest of any U.S. city in 2010, just above that of the Silicon Valley area of California (US$602,000).Hawaii's very high cost of living is the result of several interwoven factors of the global economy in addition to domestic U.S. government trade policy. Like other regions with desirable weather year-round, such as California, Arizona and Florida, Hawaii's residents can be considered to be subject to a \"sunshine tax\". This situation is further exacerbated by the natural factors of geography and world distribution that lead to higher prices for goods due to increased shipping costs, a problem which many island states and territories suffer from as well.\n",
      "The higher costs to ship goods across an ocean may be further increased by the requirements of the Jones Act, which generally requires that goods be transported between places within the U.S., including between the mainland U.S. west coast and Hawaii, using only U.S.-owned, built, and crewed ships. Jones Act-compliant vessels are often more expensive to build and operate than foreign equivalents, which can drive up shipping costs. While the Jones Act does not affect transportation of goods to Hawaii directly from Asia, this type of trade is nonetheless not common; this is a result of other primarily economic reasons including additional costs associated with stopping over in Hawaii (e.g. pilot and port fees), the market size of Hawaii, and the economics of using ever-larger ships that cannot be handled in Hawaii for transoceanic voyages. Therefore, Hawaii relies on receiving most inbound goods on Jones Act-qualified vessels originating from the U.S. west coast, which may contribute to the increased cost of some consumer goods and therefore the overall cost of living. Critics of the Jones Act contend that Hawaii consumers ultimately bear the expense of transporting goods imposed by the Jones Act.\n",
      "\n",
      "Culture\n",
      "The aboriginal culture of Hawaii is Polynesian. Hawaii represents the northernmost extension of the vast Polynesian Triangle of the south and central Pacific Ocean. While traditional Hawaiian culture remains as vestiges in modern Hawaiian society, there are re-enactments of the ceremonies and traditions throughout the islands. Some of these cultural influences, including the popularity (in greatly modified form) of lūʻau and hula, are strong enough to affect the wider United States.\n",
      "\n",
      "Cuisine\n",
      "The cuisine of Hawaii is a fusion of many foods brought by immigrants to the Hawaiian Islands, including the earliest Polynesians and Native Hawaiian cuisine, and American, Chinese, Filipino, Japanese, Korean, Polynesian, Puerto Rican, and Portuguese origins. Plant and animal food sources are imported from around the world for agricultural use in Hawaii. Poi, a starch made by pounding taro, is one of the traditional foods of the islands. Many local restaurants serve the ubiquitous plate lunch, which features two scoops of rice, a simplified version of American macaroni salad and a variety of toppings including hamburger patties, a fried egg, and gravy of a loco moco, Japanese style tonkatsu or the traditional lūʻau favorites, including kālua pork and laulau. Spam musubi is an example of the fusion of ethnic cuisine that developed on the islands among the mix of immigrant groups and military personnel. In the 1990s, a group of chefs developed Hawaii regional cuisine as a contemporary fusion cuisine.\n",
      "\n",
      "Customs and etiquette\n",
      "Some key customs and etiquette in Hawaii are as follows: when visiting a home, it is considered good manners to bring a small gift for one's host (for example, a dessert). Thus, parties are usually in the form of potlucks. Most locals take their shoes off before entering a home. It is customary for Hawaiian families, regardless of ethnicity, to hold a luau to celebrate a child's first birthday. It is also customary at Hawaiian weddings, especially at Filipino weddings, for the bride and groom to do a money dance (also called the pandanggo). Print media and local residents recommend that one refer to non-Hawaiians as \"locals of Hawaii\" or \"people of Hawaii\".\n",
      "\n",
      "Hawaiian mythology\n",
      "Hawaiian mythology includes the legends, historical tales, and sayings of the ancient Hawaiian people. It is considered a variant of a more general Polynesian mythology that developed a unique character for several centuries before c. 1800. It is associated with the Hawaiian religion, which was officially suppressed in the 19th century but was kept alive by some practitioners to the modern day. Prominent figures and terms include Aumakua, the spirit of an ancestor or family god and Kāne, the highest of the four major Hawaiian deities.\n",
      "\n",
      "Polynesian mythology\n",
      "Polynesian mythology is the oral traditions of the people of Polynesia, a grouping of Central and South Pacific Ocean island archipelagos in the Polynesian triangle together with the scattered cultures known as the Polynesian outliers. Polynesians speak languages that descend from a language reconstructed as Proto-Polynesian that was probably spoken in the area around Tonga and Samoa in around 1000 BC.Prior to the 15th century, Polynesian people migrated east to the Cook Islands, and from there to other island groups such as Tahiti and the Marquesas. Their descendants later discovered the islands Tahiti, Rapa Nui, and later the Hawaiian Islands and New Zealand.The Polynesian languages are part of the Austronesian language family. Many are close enough in terms of vocabulary and grammar to be mutually intelligible. There are also substantial cultural similarities between the various groups, especially in terms of social organization, childrearing, horticulture, building and textile technologies. Their mythologies in particular demonstrate local reworkings of commonly shared tales. The Polynesian cultures each have distinct but related oral traditions; legends or myths are traditionally considered to recount ancient history (the time of \"pō\") and the adventures of gods (\"atua\") and deified ancestors.\n",
      "\n",
      "List of state parks\n",
      "There are many Hawaiian state parks.\n",
      "\n",
      "The Island of Hawaiʻi has state parks, recreation areas, and historical parks.\n",
      "Kauaʻi has the Ahukini State Recreation Pier, six state parks, and the Russian Fort Elizabeth State Historical Park.\n",
      "Maui has two state monuments, several state parks, and the Polipoli Spring State Recreation Area. Moloka'i has the Pala'au State Park.\n",
      "Oʻahu has several state parks, a number of state recreation areas, and a number of monuments, including the Ulu Pō Heiau State Monument.\n",
      "\n",
      "Literature\n",
      "The literature of Hawaii is diverse and includes authors Kiana Davenport, Lois-Ann Yamanaka, and Kaui Hart Hemmings. Hawaiian magazines include Hana Hou!, Hawaii Business and Honolulu, among others.\n",
      "\n",
      "Music\n",
      "The music of Hawaii includes traditional and popular styles, ranging from native Hawaiian folk music to modern rock and hip hop.\n",
      "Styles such as slack-key guitar are well known worldwide, while Hawaiian-tinged music is a frequent part of Hollywood soundtracks. Hawaii also made a major contribution to country music with the introduction of the steel guitar.Traditional Hawaiian folk music is a major part of the state's musical heritage. The Hawaiian people have inhabited the islands for centuries and have retained much of their traditional musical knowledge. Their music is largely religious in nature, and includes chanting and dance music.\n",
      "Hawaiian music has had an enormous impact on the music of other Polynesian islands; according to Peter Manuel, the influence of Hawaiian music is a \"unifying factor in the development of modern Pacific musics\". Native Hawaiian musician and Hawaiian sovereignty activist Israel Kamakawiwoʻole, famous for his medley of \"Somewhere Over the Rainbow/What a Wonderful World\", was named \"The Voice of Hawaii\" by NPR in 2010 in its 50 great voices series.\n",
      "\n",
      "Sports\n",
      "Due to its distance from the continental United States, team sports in Hawaii are characterised by youth, collegial and amateur teams over professional teams, although some professional teams sports teams have at one time played in the state. Notable professional teams include The Hawaiians, which played at the World Football League in 1974 and 1975; the Hawaii Islanders, a Triple-A minor league baseball team that played at the Pacific Coast League from 1961 to 1987; and Team Hawaii, a North American Soccer League team that played in 1977.\n",
      "Notable college sports events in Hawaii include the Maui Invitational Tournament, Diamond Head Classic (basketball) and Hawaii Bowl (football). The only NCAA Division I team in Hawaii is the Hawaii Rainbow Warriors and Rainbow Wahine, which competes at the Big West Conference (major sports), Mountain West Conference (football) and Mountain Pacific Sports Federation (minor sports). There are three teams in NCAA Division II: Chaminade Silverswords, Hawaii Pacific Sharks and Hawaii-Hilo Vulcans, all of which compete at the Pacific West Conference.\n",
      "\n",
      "Surfing has been a central part of Polynesian culture for centuries. Since the late 19th century, Hawaii has become a major site for surfists from around the world. Notable competitions include the Triple Crown of Surfing and The Eddie. Likewise, Hawaii has produced elite-level swimmers, including five-time Olympic medalist Duke Kahanamoku and Buster Crabbe, who set 16 swimming\n",
      "world records.\n",
      "Hawaii has hosted the Sony Open in Hawaii golf tournament since 1965, the Tournament of Champions golf tournament since 1999, the Lotte Championship golf tournament since 2012, the Honolulu Marathon since 1973, the Ironman World Championship triathlon race since 1978, the Ultraman triathlon since 1983, the National Football League's Pro Bowl from 1980 to 2016, the 2000 FINA World Open Water Swimming Championships, and the 2008 Pan-Pacific Championship and 2012 Hawaiian Islands Invitational soccer tournaments.\n",
      "Hawaii has produced a number of notable Mixed Martial Arts fighters, such as former UFC Lightweight Champion and UFC Welterweight Champion B.J. Penn, and former UFC Featherweight Champion Max Holloway. Other notable Hawaiian Martial Artists include Travis Browne, K. J. Noons, Brad Tavares and Wesley Correira.\n",
      "Hawaiians have found success in the world of sumo wrestling. Takamiyama Daigorō was the first foreigner to ever win a sumo title in Japan, while his protege Akebono Tarō became a top-level sumo wrestler in Japan during the 1990s before transitioning into a successful professional wrestling career in the 2000s. Akebono was the first foreign-born Sumo to reach Yokozuna in history and helped fuel a boom in interest in Sumo during his career.\n",
      "\n",
      "Tourism\n",
      "Tourism is an important part of the Hawaiian economy as it represents ¼ of the economy. According to the Hawaii Tourism: 2019 Annual Visitor Research Report, a total of 10,386,673 visitors arrived in 2019 which increased 5% from the previous year, with expenditures of almost $18 billion. In 2019, tourism provided over 216,000 jobs statewide and contributed more than $2 billion in tax revenue. Due to mild year-round weather, tourist travel is popular throughout the year. Tourists across the globe visited Hawaii in 2019 with over 1 million tourists from the U.S. East, almost 2 million Japanese tourists, and almost 500,000 Canadian tourists.\n",
      "It was with statehood in 1959 that the Hawaii tourism industry began to grow.According to Hawaiian scholar Haunani-Kay Trask, tourism in Hawaii has led to the commodification and exploitation of Hawaiian culture resulting in insidious forms of \"cultural prostitution\". Hawaii has been used to fuel ideas of escapism yet tourism in Hawaii ignores the harm Kanaka and locals experience. Cultural traditions such as the hula have been made \"ornamental ... a form of exotica\" for tourists as a way for large corporations and land owners to gain profit over the exploitation of Hawaiian people and culture.Tourism in Hawaiʻi has been considered as an escape from reality resulting in the dismissal of violence faced by Native Hawaiians and locals living on the land. According to scholar Winona LaDuke, native Hawaiians have been forced to gather \"shrimp and fish from ponds sitting on resort property\". Tourism has also had damaging effects on the environment such as water shortages, overcrowding, sea level rising, elevated sea surface temperatures and micro plastics on beaches.Due to the COVID-19 pandemic, tourism in Hawaiʻi came to a halt, which allowed the land, water, and animals to began to heal. Fish like the baby akule and big ulua have returned after years of not being around the bay. The coral reefs, fish, water growth, and limu (algae) growth was able to flourish without the heavy toll of tourism.There has been pushback against tourism by Native Hawaiians, urging people to not visit the islands. A survey by the Hawaii Tourism Authority indicated over ⅔ of Hawaiians did not want tourists to return to Hawaii. Tourism had \"become extractive and hurtful, with tourists coming here and taking, taking, taking, taking, without any reciprocation with locals\".Hawaii hosts numerous cultural events. The annual Merrie Monarch Festival is an international Hula competition. The Hawaii International Film Festival is the premier film festival for Pacific rim cinema. Honolulu hosts the state's long-running LGBT film festival, the Rainbow Film Festival.\n",
      "\n",
      "Health\n",
      "As of 2009, Hawaii's health care system insures 92% of residents. Under the state's plan, businesses are required to provide insurance to employees who work more than twenty hours per week. Heavy regulation of insurance companies helps reduce the cost to employers. Due in part to heavy emphasis on preventive care, Hawaiians require hospital treatment less frequently than the rest of the United States, while total health care expenses measured as a percentage of state GDP are substantially lower. Proponents of universal health care elsewhere in the U.S. sometimes use Hawaii as a model for proposed federal and state health care plans.\n",
      "\n",
      "Education\n",
      "Public schools\n",
      "Hawaii has the only school system within the U.S. that is unified statewide. Policy decisions are made by the fourteen-member state Board of Education, which sets policy and hires the superintendent of schools, who oversees the Hawaii Department of Education. The Department of Education is divided into seven districts; four on Oʻahu and one for each of the other three counties.\n",
      "Public elementary, middle and high school test scores in Hawaii are below national averages on tests mandated under the No Child Left Behind Act. The Hawaii Board of Education requires all eligible students to take these tests and report all student test scores. This may have unbalanced the results that reported in August 2005 that of 282 schools across the state, 185 failed to reach federal minimum performance standards in mathematics and reading. The ACT college placement tests show that in 2005, seniors scored slightly above the national average (21.9 compared with 20.9), but in the widely accepted SAT examinations, Hawaii's college-bound seniors tend to score below the national average in all categories except mathematics.\n",
      "The first native controlled public charter school was the Kanu O Ka Aina New Century Charter School.\n",
      "\n",
      "Private schools\n",
      "Hawaii has the highest rates of private school attendance in the nation. During the 2011–2012 school year, Hawaii public and charter schools had an enrollment of 181,213, while private schools had 37,695. Private schools educated over 17% of students in Hawaii that school year, nearly three times the approximate national average of 6%. According to Alia Wong of Honolulu Civil Beat, this is due to private schools being relatively inexpensive compared to ones on the mainland as well as the overall reputations of private schools.It has four of the largest independent schools; ʻIolani School, Kamehameha Schools, Mid-Pacific Institute and Punahou School. Pacific Buddhist Academy, the second Buddhist high school in the U.S. and first such school in Hawaii, was founded in 2003.\n",
      "Independent schools can select their students, while most public schools of HIDOE are open to all students in their attendance zones. The Kamehameha Schools are the only schools in the U.S. that openly grant admission to students based on ancestry; collectively, they are one of the wealthiest schools in the United States, if not the world, having over eleven billion US dollars in estate assets. In 2005, Kamehameha enrolled 5,398 students, 8.4% of the Native Hawaiian children in the state.\n",
      "\n",
      "Colleges and universities\n",
      "The largest institution of higher learning in Hawaii is the University of Hawaiʻi System, which consists of the research university at Mānoa, two comprehensive campuses at Hilo and West Oʻahu, and seven community colleges. Private universities include Brigham Young University–Hawaii, Chaminade University of Honolulu, Hawaii Pacific University, and Wayland Baptist University. Saint Stephen Diocesan Center is a seminary of the Roman Catholic Diocese of Honolulu. Kona hosts the University of the Nations, which is not an accredited university.\n",
      "\n",
      "Transportation\n",
      "A system of state highways encircles each main island. Only Oʻahu has federal highways, and is the only area outside the contiguous 48 states to have signed Interstate highways. Narrow, winding roads and congestion in populated places can slow traffic. Each major island has a public bus system.\n",
      "Honolulu International Airport (IATA: HNL), which shares runways with the adjacent Hickam Field (IATA: HIK), is the major commercial aviation hub of Hawaii. The commercial aviation airport offers intercontinental service to North America, Asia, Australia and Oceania. Hawaiian Airlines and Mokulele Airlines use jets to provide services between the large airports in Honolulu, Līhuʻe, Kahului, Kona and Hilo. These airlines also provide air freight services between the islands. On May 30, 2017, the airport was officially renamed as the Daniel K. Inouye International Airport (HNL), after U.S. Senator Daniel K. Inouye.Until air passenger services began in the 1920s, private boats were the sole means of traveling between the islands. Seaflite operated hydrofoils between the major islands in the mid-1970s.The Hawaii Superferry operated between Oʻahu and Maui between December 2007 and March 2009, with additional routes planned for other islands. Protests and legal problems over environmental impact statements ended the service, though the company operating Superferry has expressed a wish to recommence ferry services in the future. Currently there is a passenger ferry service in Maui County between Lanaʻi and Maui, which does not take vehicles; a passenger ferry to Molokai ended in 2016. Currently Norwegian Cruise Lines and Princess Cruises provide passenger cruise ship services between the larger islands.\n",
      "\n",
      "Rail\n",
      "At one time Hawaii had a network of railroads on each of the larger islands that transported farm commodities and passengers. Most were 3 ft (914 mm) narrow gauge systems but there were some 2 ft 6 in (762 mm) gauge on some of the smaller islands. The standard gauge in the U.S. is 4 ft 8+1⁄2 in (1,435 mm). By far the largest railroad was the Oahu Railway and Land Company (OR&L) that ran lines from Honolulu across the western and northern part of Oahu.The OR&L was important for moving troops and goods during World War II. Traffic on this line was busy enough for signals to be used to facilitate movement of trains and to require wigwag signals at some railroad crossings for the protection of motorists. The main line was officially abandoned in 1947, although part of it was bought by the U.S. Navy and operated until 1970. Thirteen miles (21 km) of track remain; preservationists occasionally run trains over a portion of this line.Skyline is an elevated passenger rail line on Oahu which was built to relieve highway congestion. It opened for service in 2023.\n",
      "\n",
      "Governance\n",
      "Political subdivisions and local government\n",
      "The movement of the Hawaiian royal family from Hawaiʻi Island to Maui, and subsequently to Oʻahu, explains the modern-day distribution of population centers. Kamehameha III chose the largest city, Honolulu, as his capital because of its natural harbor—the present-day Honolulu Harbor. Now the state capital, Honolulu is located along the southeast coast of Oʻahu. The previous capital was Lahaina, Maui, and before that Kailua-Kona, Hawaiʻi. Some major towns are Hilo; Kaneohe; Kailua; Pearl City; Waipahu; Kahului; Kailua-Kona. Kīhei; and Līhuʻe.\n",
      "Hawaii has five counties: the City and County of Honolulu, Hawaii County, Maui County, Kauai County, and Kalawao County.\n",
      "Hawaii has the fewest local governments among U.S. states. Unique to this state is the lack of municipal governments. All local governments are generally administered at the county level. The only incorporated area in the state is Honolulu County, a consolidated city–county that governs the entire island of Oahu. County executives are referred to as mayors; these are the Mayor of Hawaii County, Mayor of Honolulu, Mayor of Kauaʻi, and the Mayor of Maui. The mayors are all elected in nonpartisan elections. Kalawao County has no elected government, and as mentioned above there are no local school districts; instead, all local public education is administered at the state level by the Hawaii Department of Education. The remaining local governments are special districts.\n",
      "\n",
      "State government\n",
      "The state government of Hawaii is modeled after the federal government with adaptations originating from the kingdom era of Hawaiian history. As codified in the Constitution of Hawaii, there are three branches of government: executive, legislative and judicial. The executive branch is led by the Governor of Hawaii, who is assisted by the Lieutenant Governor of Hawaii, both of whom are elected on the same ticket. The governor is the only state public official elected statewide; all others are appointed by the governor. The lieutenant governor acts as the Secretary of State. The governor and lieutenant governor oversee twenty agencies and departments from offices in the State Capitol. The official residence of the governor is Washington Place.\n",
      "The legislative branch consists of the bicameral Hawaii State Legislature, which is composed of the 51-member Hawaii House of Representatives led by the Speaker of the House, and the 25-member Hawaii Senate led by the President of the Senate. The Legislature meets at the State Capitol. The unified judicial branch of Hawaii is the Hawaii State Judiciary. The state's highest court is the Supreme Court of Hawaii, which uses Aliʻiōlani Hale as its chambers.\n",
      "\n",
      "Federal government\n",
      "Congressional delegation for the 118th United States Congress\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "Hawaii is represented in the United States Congress by two senators and two representatives. As of 2023, all four seats are held by Democrats. Former representative Ed Case was elected in 2018 to the 1st congressional district. Jill Tokuda represents the 2nd congressional district, representing the rest of the state, which is largely rural and semi-rural.Brian Schatz is the senior United States senator from Hawaii. He was appointed to the office on December 26, 2012, by Governor Neil Abercrombie, following the death of former senator Daniel Inouye. The state's junior senator is Mazie Hirono, the former representative from the second congressional district. Hirono is the first female Asian American senator and the first Buddhist senator. Hawaii incurred the biggest seniority shift between the 112th and 113th Congresses. The state went from a delegation consisting of senators who were first and twenty-first in seniority to their respective replacements, relative newcomers Schatz and Hirono.Federal officials in Hawaii are based at the Prince Kūhiō Federal Building near the Aloha Tower and Honolulu Harbor. The Federal Bureau of Investigation, Internal Revenue Service and the Secret Service maintain their offices there; the building is also the site of the federal District Court for the District of Hawaii and the United States Attorney for the District of Hawaii.\n",
      "\n",
      "Politics\n",
      "Since gaining statehood and participating in its first election in 1960, Hawaii has supported Democrats in all but two presidential elections: 1972 and 1984, both of which were landslide reelection victories for Republicans Richard Nixon and Ronald Reagan respectively. In Hawaii's statehood tenure, only Minnesota has supported Republican candidates fewer times in presidential elections. The 2016 Cook Partisan Voting Index ranks Hawaii as the most heavily Democratic state in the nation.Hawaii has not elected a Republican to represent the state in the U.S. Senate since Hiram Fong in 1970; since 1977, both of the state's U.S. Senators have been Democrats.In 2004, John Kerry won the state's four electoral votes by a margin of nine percentage points with 54% of the vote. Every county supported the Democratic candidate. In 1964, favorite son candidate senator Hiram Fong of Hawaii sought the Republican presidential nomination, while Patsy Mink ran in the Oregon primary in 1972.\n",
      "\n",
      "Honolulu-born Barack Obama, then serving as a United States senator from Illinois, was elected the 44th president of the United States on November 4, 2008, and was re-elected for a second term on November 6, 2012. Obama had won the Hawaii Democratic caucus on February 19, 2008, with 76% of the vote. He was the third Hawaii-born candidate to seek the nomination of a major party, the first presidential nominee and first president from Hawaii.In a 2020 study, Hawaii was ranked as the 6th easiest state for citizens to vote in.\n",
      "\n",
      "Law enforcement\n",
      "Hawaii has a statewide sheriff department under its Department of Public Safety that provides law enforcement protection to government buildings and Daniel K. Inouye International Airport as well as correction services to all correctional facilities owned by the state.\n",
      "Counties have their own respective police departments with their own jurisdictions:\n",
      "\n",
      "Kauai County Police Department for the island of Kauai\n",
      "Honolulu Police Department for Oahu\n",
      "Maui County Police Department for Molokai, Maui and Lanai\n",
      "Hawaii County Police Department for the Big IslandForensic services for all agencies in the state are provided by the Honolulu Police Department.In January 2022, state officials proposed legislation that would split the sheriff department from the Department of Public Safety and consolidate it with the criminal investigation division from the Department of the Attorney General to create a new Department of Law Enforcement that would create a statewide police agency with the ability to investigate crimes.\n",
      "\n",
      "Hawaiian sovereignty movement\n",
      "While Hawaii is internationally recognized as a state of the United States while also being broadly accepted as such in mainstream understanding, the legality of this status has been questioned in U.S. District Court, the U.N., and other international forums. Domestically, the debate is a topic covered in the Kamehameha Schools curriculum, and in classes at the University of Hawaiʻi at Mānoa.Political organizations seeking some form of sovereignty for Hawaii have been active since the late 19th century. Generally, their focus is on self-determination and self-governance, either for Hawaii as an independent nation (in many proposals, for \"Hawaiian nationals\" descended from subjects of the Hawaiian Kingdom or declaring themselves as such by choice), or for people of whole or part native Hawaiian ancestry in an indigenous \"nation to nation\" relationship akin to tribal sovereignty with US federal recognition of Native Hawaiians. The pro-federal recognition Akaka Bill drew substantial opposition among Hawaiian residents in the 2000s. Opponents to the tribal approach argue it is not a legitimate path to Hawaiian nationhood; they also argue that the U.S. government should not be involved in re-establishing Hawaiian sovereignty.The Hawaiian sovereignty movement views the overthrow of the Kingdom of Hawaii in 1893 as illegal, and views the subsequent annexation of Hawaii by the United States as illegal as well; the movement seeks some form of greater autonomy for Hawaii, such as free association or independence from the United States.Some groups also advocate some form of redress from the United States for the 1893 overthrow of Queen Liliʻuokalani, and for what is described as a prolonged military occupation beginning with the 1898 annexation. The Apology Resolution passed by US Congress in 1993 is cited as a major impetus by the movement for Hawaiian sovereignty. The sovereignty movement considers Hawaii to be an illegally occupied nation.\n",
      "\n",
      "International sister relationships\n",
      "Ehime, Japan\n",
      " Fukuoka, Japan\n",
      " Hiroshima, Japan\n",
      " Hokkaido, Japan\n",
      " Okinawa, Japan\n",
      " Guangdong, China\n",
      " Hainan, China\n",
      " Jeju, South Korea\n",
      " Taiwan, Republic of China\n",
      " Cebu, Philippines\n",
      " Isabela, Philippines\n",
      " Pangasinan, Philippines\n",
      " Ilocos Sur, Philippines\n",
      " Ilocos Norte, Philippines\n",
      " Rabat-Salé-Zemmour-Zaër, Morocco\n",
      " Azores Islands, Portugal\n",
      " Bali, Indonesia\n",
      " Goa, India\n",
      "\n",
      "See also\n",
      "Index of Hawaii-related articles\n",
      "List of cemeteries in Hawaii\n",
      "Outline of Hawaii\n",
      "USS Hawaii, 2 ships\n",
      "\n",
      "References\n",
      "Informational notes\n",
      "Citations\n",
      "Bibliography\n",
      "Beechert, Edward D. Working in Hawaii: A Labor History (University of Hawaii Press, 1985).\n",
      "Bushnell, Oswald A. (1993). The Gifts of Civilization: Germs and Genocide in Hawai?i. University of Hawaii Press. ISBN 978-0-8248-1457-1.\n",
      "Kuykendall, Ralph S. A History of Hawaii (Macmillan, 1926) online.\n",
      "Russ Jr., William Adam (1961) The Hawaiian Republic (1894–98) and Its Struggle to Win Annexation. Selinsgrove, Pennsylvania: Susquehanna University Press.\n",
      "Schmitt, Robert C. Historical Statistics of Hawaii. (University Press of Hawaii, 1977).\n",
      "Schmitt, Robert C. \"Religious statistics of Hawaii, 1825–1972\".  Hawaiian Journal of History (1973), vol. 7, pp 41–47.\n",
      "Schmitt, Robert C. Demographic Statistics of Hawaii. (University of Hawaii Press, 2021).\n",
      "Tabrah, Ruth M. Hawaii: a history (WW Norton & Company, 1984).\n",
      "\n",
      "Guides\n",
      "Cooperm, Jeanne, and Natalie Schack.  Frommer's Hawaii (2022) excerpt\n",
      "Doughty, Andrew. Hawaii the Big Island Revealed: The Ultimate Guidebook (2021) excerpt\n",
      "FODOR. Fodor's Essential Hawaii (2020) excerpt\n",
      "\n",
      "External links\n",
      "\n",
      "Official website\n",
      "Hawaii State Guide from the Library of Congress\n",
      "Hawaii at Curlie\n",
      "Hawaiʻi State Fact Sheet from the U.S. Department of Agriculture\n",
      "USGS real-time, geographic, and other scientific resources of Hawaii\n",
      "Energy Data & Statistics for Hawaii\n",
      "Satellite image of Hawaiian Islands at NASA's Earth Observatory\n",
      "Documents relating to Hawaii Statehood, Dwight D. Eisenhower Presidential Library\n",
      "Happily a State, Forever an Island by The New York Times\n",
      "\"Hawaiʻi Then and Now\"—slideshow by Life magazine (Archived from the original Archived November 3, 2010, at the Wayback Machine on November 3, 2010)\n",
      " Geographic data related to Hawaii at OpenStreetMap\n",
      "Hawaiian Imprint Collection From the Rare Book and Special Collections Division at the Library of CongressSynthetic biology (SynBio) is a multidisciplinary field of science that focuses on living systems and organisms, and it applies engineering principles to develop new biological parts, devices, and systems or to redesign existing systems found in nature.It is a branch of science that encompasses a broad range of methodologies from various disciplines, such as biotechnology, biomaterials, material science/engineering, genetic engineering, molecular biology, molecular engineering, systems biology, membrane science, biophysics, chemical and biological engineering, electrical and computer engineering, control engineering and evolutionary biology.\n",
      "It includes designing and constructing biological modules, biological systems, and biological machines, or re-designing existing biological systems for useful purposes.Additionally, it is the branch of science that focuses on the new abilities of engineering into existing organisms to redesign them for useful purposes.In order to produce predictable and robust systems with novel functionalities that do not already exist in nature, it is also necessary to apply the engineering paradigm of systems design to biological systems. According to the European Commission, this possibly involves a molecular assembler based on biomolecular systems such as the ribosome.\n",
      "\n",
      "History\n",
      "1910: First identifiable use of the term synthetic biology in Stéphane Leduc's publication Théorie physico-chimique de la vie et générations spontanées. He also noted this term in another publication, La Biologie Synthétique in 1912.1944: Canadian-American scientist Oswald Avery shows that DNA is the material of which genes and chromosomes are made. This becomes the bedrock on which all subsequent genetic research is built.1953: Francis Crick and James Watson publish the structure of the DNA in Nature.\n",
      "1961: Jacob and Monod postulate cellular regulation by molecular networks from their study of the lac operon in E. coli and envisioned the ability to assemble new systems from molecular components.1973: First molecular cloning and amplification of DNA in a plasmid is published in P.N.A.S. by Cohen, Boyer et al. constituting the dawn of synthetic biology.1978: Arber, Nathans and Smith win the Nobel Prize in Physiology or Medicine for the discovery of restriction enzymes, leading Szybalski to offer an editorial comment in the journal Gene:\n",
      "\n",
      "The work on restriction nucleases not only permits us easily to construct recombinant DNA molecules and to analyze individual genes, but also has led us into the new era of synthetic biology where not only existing genes are described and analyzed but also new gene arrangements can be constructed and evaluated.\n",
      "1988: First DNA amplification by the polymerase chain reaction (PCR) using a thermostable DNA polymerase is published in Science by Mullis et al. This obviated adding new DNA polymerase after each PCR cycle, thus greatly simplifying DNA mutagenesis and assembly.\n",
      "2000: Two papers in Nature report synthetic biological circuits, a genetic toggle switch and a biological clock, by combining genes within E. coli cells.2003: The most widely used standardized DNA parts, BioBrick plasmids, are invented by Tom Knight. These parts will become central to the International Genetically Engineered Machine (iGEM) competition founded at MIT in the following year.\n",
      "\n",
      "2003: Researchers engineer an artemisinin precursor pathway in E. coli.2004: First international conference for synthetic biology, Synthetic Biology 1.0 (SB1.0) is held at MIT.\n",
      "2005: Researchers develop a light-sensing circuit in E. coli. Another group designs circuits capable of multicellular pattern formation.2006: Researchers engineer a synthetic circuit that promotes bacterial invasion of tumour cells.2010: Researchers publish in Science the first synthetic bacterial genome, called M. mycoides JCVI-syn1.0. The genome is made from chemically-synthesized DNA using yeast recombination.\n",
      "2011: Functional synthetic chromosome arms are engineered in yeast.2012: Charpentier and Doudna labs publish in Science the programming of CRISPR-Cas9 bacterial immunity for targeting DNA cleavage. This technology greatly simplified and expanded eukaryotic gene editing.\n",
      "2019: Scientists at ETH Zurich report the creation of the first bacterial genome, named Caulobacter ethensis-2.0, made entirely by a computer, although a related viable form of C. ethensis-2.0 does not yet exist.2019: Researchers report the production of a new synthetic (possibly artificial) form of viable life, a variant of the bacteria Escherichia coli, by reducing the natural number of 64 codons in the bacterial genome to 59 codons instead, in order to encode 20 amino acids.2020: Scientists created the first xenobot, a programmable synthetic organism derived from frog cells and designed by AI.2021: Scientists reported that xenobots are able to self-replicate by gathering loose cells in the environment and then forming new xenobot.\n",
      "\n",
      "Perspectives\n",
      "It is a field whose scope is expanding in terms of systems integration, engineered organisms, and practical findings.Engineers view biology as technology (in other words, a given system includes biotechnology or its biological engineering). Synthetic biology includes the broad redefinition and expansion of biotechnology, with the ultimate goal of being able to design and build engineered live biological systems that process information, manipulate chemicals, fabricate materials and structures, produce energy, provide food, and maintain and enhance human health, as well as advance fundamental knowledge of biological systems (see Biomedical engineering) and our environment.Researchers and companies working in synthetic biology are using nature's power to solve issues in agriculture, manufacturing, and medicine.Due to more powerful genetic engineering capabilities and decreased DNA synthesis and sequencing costs, the field of synthetic biology is rapidly growing. In 2016, more than 350 companies across 40 countries were actively engaged in synthetic biology applications; all these companies had an estimated net worth of $3.9 billion in the global market. Synthetic biology currently has no generally accepted definition. Here are a few examples:\n",
      "It is the science of emerging genetic and physical engineering to produce new (and, therefore, synthetic) life forms. To develop organisms with novel or enhanced characteristics, this emerging field of study combines biology, engineering, and related disciplines' knowledge and techniques to design chemically synthesised DNA.Biomolecular engineering includes approaches that aim to create a toolkit of functional units that can be introduced to present new technological functions in living cells. Genetic engineering includes approaches to construct synthetic chromosomes or minimal organisms like Mycoplasma laboratorium.\n",
      "Biomolecular design refers to the general idea of de novo design and additive combination of biomolecular components. Each of these approaches shares a similar task: to develop a more synthetic entity at a higher level of complexity by inventively manipulating a simpler part at the preceding level. Optimizing these exogenous pathways in unnatural systems takes iterative fine-tuning of the individual biomolecular components to select the highest concentrations of the desired product.On the other hand, \"re-writers\" are synthetic biologists interested in testing the irreducibility of biological systems. Due to the complexity of natural biological systems, it would be simpler to rebuild the natural systems of interest from the ground up; to provide engineered surrogates that are easier to comprehend, control and manipulate. Re-writers draw inspiration from refactoring, a process sometimes used to improve computer software.\n",
      "\n",
      "Categories of synthetic biology\n",
      "Bioengineering, synthetic genomics, protocell synthetic biology, unconventional molecular biology, and in silico techniques are the five categories of synthetic biology.It is necessary to review the distinctions and analogies between the categories of synthetic biology for its social and ethical assessment, to distinguish between issues affecting the whole field and particular to a specific one.\n",
      "\n",
      "Bioengineering\n",
      "The subfield of bioengineering concentrates on creating novel metabolic and regulatory pathways, and is currently the one that likely draws the attention of most researchers and funding. It is primarily motivated by the desire to establish biotechnology as a legitimate engineering discipline. When referring to this area of synthetic biology, the word \"bioengineering\" should not be confused with \"traditional genetic engineering,\" which involves introducing a single transgene into the intended organism. Bioengineers adapted synthetic biology to provide a substantially more integrated perspective on how to alter organisms or metabolic systems.A typical example of single-gene genetic engineering is the insertion of the human insulin gene into bacteria to create transgenic proteins. The creation of whole new signalling pathways, containing numerous genes and regulatory components (such as an oscillator circuit to initiate the periodic production of green fluorescent protein (GFP) in mammalian cells), is known as bioengineering as part of synthetic biology.By utilising simplified and abstracted metabolic and regulatory modules as well as other standardized parts that may be freely combined to create new pathways or creatures, bioengineering aims to create innovative biological systems. In addition to creating infinite opportunities for novel applications, this strategy is anticipated to make bioengineering more predictable and controllable than traditional biotechnology.\n",
      "\n",
      "Synthetic genomics\n",
      "The formation of animals with a chemically manufactured (minimal) genome is another facet of synthetic biology that is highlighted by synthetic genomics. This area of synthetic biology has been made possible by ongoing advancements in DNA synthesis technology, which now makes it feasible to produce DNA molecules with thousands of base pairs at a reasonable cost. The goal is to combine these molecules into complete genomes and transplant them into living cells, replacing the host cell's genome and reprogramming its metabolism to perform different functions.Scientists have previously demonstrated the potential of this approach by creating infectious viruses by synthesising the genomes of multiple viruses. These significant advances in science and technology triggered the initial public concerns concerning the risks associated with this technology.A simple genome might also work as a \"chassis genome\" that could be enlarged quickly by gene inclusion created for particular tasks. Such \"chassis creatures\" would be more suited for the insertion of new functions than wild organisms since they would have fewer biological pathways that could potentially conflict with the new functionalities in addition to having specific insertion sites. Synthetic genomics strives to create creatures with novel \"architectures,\" much like the bioengineering method. It adopts an integrative or holistic perspective of the organism. In this case, the objective is the creation of chassis genomes based on necessary genes and other required DNA sequences rather than the design of metabolic or regulatory pathways based on abstract criteria.\n",
      "\n",
      "Protocell synthetic biology\n",
      "The in vitro generation of synthetic cells is the protocell branch of synthetic biology. Lipid vesicles, which have all the necessary components to function as a complete system, can be used to create these artificial cells. In the end, these synthetic cells should meet the requirements for being deemed alive, namely the capacity for self-replication, self-maintenance, and evolution. The protocell technique has this as its end aim, however there are other intermediary steps that fall short of meeting all the criteria for a living cell. In order to carry out a specific function, these lipid vesicles contain cell extracts or more specific sets of biological macromolecules and complex structures, such as enzymes, nucleic acids, or ribosomes. For instance, liposomes may carry out particular polymerase chain reactions or synthesise a particular protein.Protocell synthetic biology takes artificial life one step closer to reality by eventually synthesizing not only the genome but also every component of the cell in vitro, as opposed to the synthetic genomics approach, which relies on coercing a natural cell to carry out the instructions encoded by the introduced synthetic genome. Synthetic biologists in this field view their work as basic study into the conditions necessary for life to exist and its origin more than in any of the other techniques. The protocell technique, however, also lends itself well to applications; similar to other synthetic biology byproducts, protocells could be employed for the manufacture of biopolymers and medicines.\n",
      "\n",
      "Unconventional molecular biology\n",
      "The objective of the \"unnatural molecular biology\" strategy is to create new varieties of life that are based on a different kind of molecular biology, such as new types of nucleic acids or a new genetic code. The creation of new types of nucleotides that can be built into unique nucleic acids could be accomplished by changing certain DNA or RNA constituents, such as the bases or the backbone sugars.The normal genetic code is being altered by inserting quadruplet codons or changing some codons to encode new amino acids, which would subsequently permit the use of non-natural amino acids with unique features in protein production. It is a scientific and technological problem to adjust the enzymatic machinery of the cell for both approaches.A new sort of life would be formed by organisms with a genome built on synthetic nucleic acids or on a totally new coding system for synthetic amino acids. This new style of life would have some benefits but also some new dangers. On release into the environment, there would be no horizontal gene transfer or outcrossing of genes with natural species. Furthermore, these kinds of synthetic organisms might be created to require non-natural materials for protein or nucleic acid synthesis, rendering them unable to thrive in the wild if they accidentally escaped.On the other hand, if these organisms ultimately were able to survive outside of controlled space, they might have a particular benefit over natural organisms because they would be resistant to predatory living organisms or natural viruses, that could lead to an unmanaged spread of the synthetic organisms.\n",
      "\n",
      "In silico technique\n",
      "Synthetic biology in silico and the various strategies are interconnected. The development of complex designs, whether they are metabolic pathways, fundamental cellular processes, or chassis genomes, is one of the major difficulties faced by the four synthetic-biology methods outlined above. Because of this, synthetic biology has a robust in silico branch, similar to systems biology, that aims to create computational models for the design of common biological components or synthetic circuits, which are essentially simulations of synthetic organisms.The practical application of simulations and models through bioengineering or other fields of synthetic biology is the long-term goal of in silico synthetic biology. Many of the computational simulations of synthetic organisms up to this point possess little to no direct analogy to living things. Due to this, in silico synthetic biology is regarded as a separate group in this article.It is sensible to integrate the five areas under the umbrella of synthetic biology as an unified area of study. Even though they focus on various facets of life, such as metabolic regulation, essential elements, or biochemical makeup, these five strategies all work toward the same end: creating new types of living organisms. Additionally, the varied methodologies begin with numerous methodological approaches, which leads to the diversity of synthetic biology approaches.Synthetic biology is an interdisciplinary field that draws from and is inspired by many different scientific disciplines, not one single field or technique. Synthetic biologists all have the same underlying objective of designing and producing new forms of life, despite the fact that they may employ various methodologies, techniques, and research instruments. Any evaluation of synthetic biology, whether it examines ethical, legal, or safety considerations, must take into account the fact that while some questions, risks, and issues are unique to each technique, in other circumstances, synthetic biology as a whole must be taken into consideration.\n",
      "\n",
      "Four engineering approaches\n",
      "Synthetic biology has traditionally been divided into four different engineering approaches: top down, parallel, orthogonal and bottom up.To replicate emergent behaviours from natural biology and build artificial life, unnatural chemicals are used. The other looks for interchangeable components from biological systems to put together and create systems that do not work naturally. In either case, a synthetic objective compels researchers to venture into new area in order to engage and resolve issues that cannot be readily resolved by analysis. Due to this, new paradigms are driven to arise in ways that analysis cannot easily do. In addition to equipments that oscillate, creep, and play tic-tac-toe, synthetic biology has produced diagnostic instruments that enhance the treatment of patients with infectious diseases.\n",
      "\n",
      "Top-down approach\n",
      "It involves using metabolic and genetic engineering techniques to impart new functions to living cells. By comparing universal genes and eliminating non-essential ones to create a basic genome, this method seeks to lessen the complexity of existing cells. These initiatives are founded on the hypothesis of a single genesis for cellular life, the so-called Last Universal Common Ancestor, which supports the presence of a universal minimal genome that gave rise to all living things. Recent studies, however, raise the possibility that the eukaryotic and prokaryotic cells that make up the tree of life may have evolved from a group of primordial cells rather than from a single cell. As a result, even while the Holy Grail-like pursuit of the \"minimum genome\" has grown elusive, cutting out a number of non-essential functions impairs an organism's fitness and leads to \"fragile\" genomes.\n",
      "\n",
      "Bottom-up approach\n",
      "This approach involves creating new biological systems in vitro by bringing together 'non-living' biomolecular components, often with the aim of constructing an artificial cell.\n",
      "Reproduction, replication, and assembly are three crucial self-organizational principles that are taken into account in order to accomplish this. Cells, which are made up of a container and a metabolism, are considered \"hardware\" in the definition of reproduction, whereas replication occurs when a system duplicates a perfect copy of itself, as in the case of DNA, which is considered \"software.\" When vesicles or containers (such as Oparin's coacervates) formed of tiny droplets of molecules that are organic like lipids or liposomes, membrane-like structures comprising phospholipids, aggregate, assembly occur.The study of protocells exists along with other in vitro synthetic biology initiatives that seek to produce minimum cells, metabolic pathways, or \"never-born proteins\" as well as to mimic physiological functions including cell division and growth. The in vitro enhancement of synthetic pathways does have the potential to have an effect on some other synthetic biology sectors, including metabolic engineering, despite the fact that it no longer classified as synthetic biology research. This research, which is primarily essential, deserves proper recognition as synthetic biology research.\n",
      "\n",
      "Parallel approach\n",
      "Parallel engineering is also known as bioengineering. The basic genetic code is the foundation for parallel engineering research, which uses conventional biomolecules like nucleic acids and the 20 amino acids to construct biological systems. For a variety of applications in biocomputing, bioenergy, biofuels, bioremediation, optogenetics, and medicine, it involves the standardisation of DNA components, engineering of switches, biosensors, genetic circuits, logic gates, and cellular communication operators. For directing the expression of two or more genes and/or proteins, the majority of these applications often rely on the use of one or more vectors (or plasmids). Small, circular, double-strand DNA units known as plasmids, which are primarily found in prokaryotic but can also occasionally be detected in eukaryotic cells, may replicate autonomously of chromosomal DNA.\n",
      "\n",
      "Orthogonal approach\n",
      "It is also known as perpendicular engineering. This strategy, also referred to as \"chemical synthetic biology,\" principally seeks to alter or enlarge the genetic codes of living systems utilising artificial DNA bases and/or amino acids. This subfield is also connected to xenobiology, a newly developed field that combines systems chemistry, synthetic biology, exobiology, and research into the origins of life. In recent decades, researchers have created compounds that are structurally similar to the DNA canonical bases to see if those \"alien\" or xeno (XNA) molecules may be employed as genetic information carriers. Similar to this, noncanonical moieties have taken the place of the DNA sugar (deoxyribose). In order to express information other than the 20 conventional amino acids of proteins, the genetic code can be altered or enlarged. One method involves incorporating a specified unnatural, noncanonical, or xeno amino acid (XAA) into one or more proteins at one or more precise places using orthogonal enzymes and a transfer RNA adaptor from an other organism. By using \"directed evolution,\" which entails repeated cycles of gene mutagenesis (genotypic diversity production), screening or selection (of a specific phenotypic trait), and amplification of a better variant for the following iterative round, orthogonal enzymes are produced Numerous XAAs have been effectively incorporated into proteins in more complex creatures like worms and flies as well as in bacteria, yeast, and human cell lines. As a result of canonical DNA sequence changes, directed evolution also enables the development of orthogonal ribosomes, which make it easier to incorporate XAAs into proteins or create \"mirror life,\" or biological systems that contain biomolecules made up of enantiomers with different chiral orientations.\n",
      "\n",
      "Enabling technologies\n",
      "Several novel enabling technologies were critical to the success of synthetic biology. Concepts include standardization of biological parts and hierarchical abstraction to permit using those parts in synthetic systems. DNA serves as the guide for how biological processes should function, like the score to a complex symphony of life. Our ability to comprehend and design biological systems has undergone significant modifications as a result of developments in the previous few decades in both reading (sequencing) and writing (synthesis) DNA sequences. These developments have produced ground-breaking techniques for designing, assembling, and modifying DNA-encoded genes, materials, circuits, and metabolic pathways, enabling an ever-increasing amount of control over biological systems and even entire organisms.Basic technologies include reading and writing DNA (sequencing and fabrication). Measurements under multiple conditions are needed for accurate modeling and computer-aided design (CAD).\n",
      "\n",
      "DNA and gene synthesis\n",
      "Driven by dramatic decreases in costs of oligonucleotide (\"oligos\") synthesis and the advent of PCR, the sizes of DNA constructions from oligos have increased to the genomic level. In 2000, researchers reported synthesis of the 9.6 kbp (kilo bp) Hepatitis C virus genome from chemically synthesized 60 to 80-mers. In 2002, researchers at Stony Brook University succeeded in synthesizing the 7741 bp poliovirus genome from its published sequence, producing the second synthetic genome, spanning two years. In 2003, the 5386 bp genome of the bacteriophage Phi X 174 was assembled in about two weeks. In 2006, the same team, at the J. Craig Venter Institute, constructed and patented a synthetic genome of a novel minimal bacterium, Mycoplasma laboratorium and were working on getting it functioning in a living cell.In 2007, it was reported that several companies were offering synthesis of genetic sequences up to 2000 base pairs (bp) long, for a price of about $1 per bp and a turnaround time of less than two weeks. Oligonucleotides harvested from a photolithographic- or inkjet-manufactured DNA chip combined with PCR and DNA mismatch error-correction allows inexpensive large-scale changes of codons in genetic systems to improve gene expression or incorporate novel amino-acids (see George M. Church's and Anthony Forster's synthetic cell projects.). This favors a synthesis-from-scratch approach.\n",
      "Additionally, the CRISPR/Cas system has emerged as a promising technique for gene editing. It was described as \"the most important innovation in the synthetic biology space in nearly 30 years\". While other methods take months or years to edit gene sequences, CRISPR speeds that time up to weeks. Due to its ease of use and accessibility, however, it has raised ethical concerns, especially surrounding its use in biohacking.\n",
      "\n",
      "Sequencing\n",
      "DNA sequencing determines the order of nucleotide bases in a DNA molecule. Synthetic biologists use DNA sequencing in their work in several ways. First, large-scale genome sequencing efforts continue to provide information on naturally occurring organisms. This information provides a rich substrate from which synthetic biologists can construct parts and devices. Second, sequencing can verify that the fabricated system is as intended. Third, fast, cheap, and reliable sequencing can facilitate rapid detection and identification of synthetic systems and organisms.\n",
      "\n",
      "Modularity\n",
      "This is the ability of a system or component to operate without reference to its context.The most used: 22–23  standardized DNA parts are BioBrick plasmids, invented by Tom Knight in 2003. Biobricks are stored at the Registry of Standard Biological Parts in Cambridge, Massachusetts. The BioBrick standard has been used by tens of thousands of students worldwide in the international Genetically Engineered Machine (iGEM) competition. BioBrick Assembly Standard 10 promotes modularity by allowing BioBrick coding sequences to be spliced out and exchanged using restriction enzymes EcoRI or XbaI (BioBrick prefix) and SpeI and PstI (BioBrick suffix).: 22–23 Sequence overlap between two genetic elements (genes or coding sequences), called overlapping genes, can prevent their individual manipulation. To increase genome modularity, the practice of genome refactoring or improving \"the internal structure of an existing system for future use, while simultaneously maintaining external system function\" has been adopted across synthetic biology disciplines. Some notable examples of refactoring including the nitrogen fixation cluster and type III secretion system along with bacteriophages T7 and ΦX174.While DNA is most important for information storage, a large fraction of the cell's activities are carried out by proteins. Tools can send proteins to specific regions of the cell and to link different proteins together. The interaction strength between protein partners should be tunable between a lifetime of seconds (desirable for dynamic signaling events) up to an irreversible interaction (desirable for device stability or resilient to harsh conditions). Interactions such as coiled coils, SH3 domain-peptide binding or SpyTag/SpyCatcher offer such control. In addition, it is necessary to regulate protein-protein interactions in cells, such as with light (using light-oxygen-voltage-sensing domains) or cell-permeable small molecules by chemically induced dimerization.In a living cell, molecular motifs are embedded in a bigger network with upstream and downstream components. These components may alter the signaling capability of the modeling module. In the case of ultrasensitive modules, the sensitivity contribution of a module can differ from the sensitivity that the module sustains in isolation.\n",
      "\n",
      "Modeling\n",
      "Models inform the design of engineered biological systems by better predicting system behavior prior to fabrication. Synthetic biology benefits from better models of how biological molecules bind substrates and catalyze reactions, how DNA encodes the information needed to specify the cell and how multi-component integrated systems behave. Multiscale models of gene regulatory networks focus on synthetic biology applications. Simulations can model all biomolecular interactions in transcription, translation, regulation and induction of gene regulatory networks.Only extensive modelling can enable the exploration of dynamic gene expression in a form suitable for research and design due to the numerous involved species and the intricacy of their relationships. Dynamic simulations of the entire biomolecular interconnection involved in regulation, transport, transcription, induction, and translation enable the molecular level detailing of designs. As opposed to modelling artificial networks a posteriori, this is contrasted.\n",
      "\n",
      "Microfluidics\n",
      "Microfluidics, in particular droplet microfluidics, is an emerging tool used to construct new components, and to analyze and characterize them. It is widely employed in screening assays.\n",
      "\n",
      "Synthetic transcription factors\n",
      "Studies have considered the components of the DNA transcription mechanism. One desire of scientists creating synthetic biological circuits is to be able to control the transcription of synthetic DNA in unicellular organisms (prokaryotes) and in multicellular organisms (eukaryotes). One study tested the adjustability of synthetic transcription factors (sTFs) in areas of transcription output and cooperative ability among multiple transcription factor complexes. Researchers were able to mutate functional regions called zinc fingers, the DNA specific component of sTFs, to decrease their affinity for specific operator DNA sequence sites, and thus decrease the associated site-specific activity of the sTF (usually transcriptional regulation). They further used the zinc fingers as components of complex-forming sTFs, which are the eukaryotic translation mechanisms.\n",
      "\n",
      "Applications\n",
      "Synthetic biology initiatives frequently aim to redesign organisms so that they can create a material, such as a drug or fuel, or acquire a new function, such as the ability to sense something in the environment. Examples of what researchers are creating using synthetic biology include:\n",
      "\n",
      "Utilizing microorganisms for bioremediation to remove contaminants from our water, soil, and air.\n",
      "Production of complex natural products that are usually extracted from plants but cannot be obtained in sufficient amounts, e.g. drugs of natural origin, such as artemisinin and paclitaxel.\n",
      "Beta-carotene, a substance typically associated with carrots that prevents vitamin A deficiency, is produced by rice that has been modified. Every year, between 250,000 and 500,000 children lose their vision due to vitamin A deficiency, which also significantly raises their chance of dying from infectious infections.\n",
      "As a sustainable and environmentally benign alternative to the fresh roses that perfumers use to create expensive smells, yeast has been created to produce rose oil.\n",
      "\n",
      "Biosensors\n",
      "A biosensor refers to an engineered organism, usually a bacterium, that is capable of reporting some ambient phenomenon such as the presence of heavy metals or toxins. One such system is the Lux operon of Aliivibrio fischeri, which codes for the enzyme that is the source of bacterial bioluminescence, and can be placed after a respondent promoter to express the luminescence genes in response to a specific environmental stimulus. One such sensor created, consisted of a bioluminescent bacterial coating on a photosensitive computer chip to detect certain petroleum pollutants. When the bacteria sense the pollutant, they luminesce. Another example of a similar mechanism is the detection of landmines by an engineered E.coli reporter strain capable of detecting TNT and its main degradation product DNT, and consequently producing a green fluorescent protein (GFP).Modified organisms can sense environmental signals and send output signals that can be detected and serve diagnostic purposes. Microbe cohorts have been used.Biosensors could also be used to detect pathogenic signatures—such as of SARS-CoV-2—and can be wearable.For the purpose of detecting and reacting to various and temporary environmental factors, cells have developed a wide range of regulatory circuits, ranging from transcriptional to post-translational. These circuits are made up of transducer modules that filter the signals and activate a biological response, as well as carefully designed sensitive sections that attach analytes and regulate signal-detection thresholds. Modularity and selectivity are programmed to biosensor circuits at the transcriptional, translational, and post-translational levels, to achieve the delicate balancing of the two basic sensing modules.\n",
      "\n",
      "Food and drink\n",
      "However, not all synthetic nutrition products are animal food products – for instance, as of 2021, there are also products of synthetic coffee that are reported to be close to commercialization. Similar fields of research and production based on synthetic biology that can be used for the production of food and drink are:\n",
      "\n",
      "Genetically engineered microbial food cultures (e.g. for solar-energy-based protein powder)\n",
      "Cell-free artificial synthesis (e.g. synthetic starch; see Biobased economy#Agriculture)\n",
      "\n",
      "Materials\n",
      "Photosynthetic microbial cells have been used as a step to synthetic production of spider silk.\n",
      "\n",
      "Biological computers\n",
      "A biological computer refers to an engineered biological system that can perform computer-like operations, which is a dominant paradigm in synthetic biology. Researchers built and characterized a variety of logic gates in a number of organisms, and demonstrated both analog and digital computation in living cells. They demonstrated that bacteria can be engineered to perform both analog and/or digital computation. In 2007, in human cells, research demonstrated a universal logic evaluator that operates in mammalian cells. Subsequently, researchers utilized this paradigm to demonstrate a proof-of-concept therapy that uses biological digital computation to detect and kill human cancer cells in 2011. In 2016, another group of researchers demonstrated that principles of computer engineering can be used to automate digital circuit design in bacterial cells. In 2017, researchers demonstrated the 'Boolean logic and arithmetic through DNA excision' (BLADE) system to engineer digital computation in human cells. In 2019, researchers implemented a perceptron in biological systems opening the way for machine learning in these systems.\n",
      "\n",
      "Cell transformation\n",
      "Cells use interacting genes and proteins, which are called gene circuits, to implement diverse function, such as responding to environmental signals, decision making and communication. Three key components are involved: DNA, RNA and Synthetic biologist designed gene circuits that can control gene expression from several levels including transcriptional, post-transcriptional and translational levels.\n",
      "Traditional metabolic engineering has been bolstered by the introduction of combinations of foreign genes and optimization by directed evolution. This includes engineering E. coli and yeast for commercial production of a precursor of the antimalarial drug, Artemisinin.Entire organisms have yet to be created from scratch, although living cells can be transformed with new DNA. Several ways allow constructing synthetic DNA components and even entire synthetic genomes, but once the desired genetic code is obtained, it is integrated into a living cell that is expected to manifest the desired new capabilities or phenotypes while growing and thriving. Cell transformation is used to create biological circuits, which can be manipulated to yield desired outputs.By integrating synthetic biology with materials science, it would be possible to use cells as microscopic molecular foundries to produce materials whose properties were genetically encoded. Re-engineering has produced Curli fibers, the amyloid component of extracellular material of biofilms, as a platform for programmable nanomaterial. These nanofibers were genetically constructed for specific functions, including adhesion to substrates, nanoparticle templating and protein immobilization.\n",
      "\n",
      "Designed proteins\n",
      "Natural proteins can be engineered, for example, by directed evolution, novel protein structures that match or improve on the functionality of existing proteins can be produced. One group generated a helix bundle that was capable of binding oxygen with similar properties as hemoglobin, yet did not bind carbon monoxide. A similar protein structure was generated to support a variety of oxidoreductase activities while another formed a structurally and sequentially novel ATPase. Another group generated a family of G-protein coupled receptors that could be activated by the inert small molecule clozapine N-oxide but insensitive to the native ligand, acetylcholine; these receptors are known as DREADDs. Novel functionalities or protein specificity can also be engineered using computational approaches. One study was able to use two different computational methods: a bioinformatics and molecular modeling method to mine sequence databases, and a computational enzyme design method to reprogram enzyme specificity. Both methods resulted in designed enzymes with greater than 100 fold specificity for production of longer chain alcohols from sugar.Another common investigation is expansion of the natural set of 20 amino acids. Excluding stop codons, 61 codons have been identified, but only 20 amino acids are coded generally in all organisms. Certain codons are engineered to code for alternative amino acids including: nonstandard amino acids such as O-methyl tyrosine; or exogenous amino acids such as 4-fluorophenylalanine. Typically, these projects make use of re-coded nonsense suppressor tRNA-Aminoacyl tRNA synthetase pairs from other organisms, though in most cases substantial engineering is required.Other researchers investigated protein structure and function by reducing the normal set of 20 amino acids. Limited protein sequence libraries are made by generating proteins where groups of amino acids may be replaced by a single amino acid. For instance, several non-polar amino acids within a protein can all be replaced with a single non-polar amino acid. One project demonstrated that an engineered version of Chorismate mutase still had catalytic activity when only nine amino acids were used.Researchers and companies practice synthetic biology to synthesize industrial enzymes with high activity, optimal yields and effectiveness. These synthesized enzymes aim to improve products such as detergents and lactose-free dairy products, as well as make them more cost effective. The improvements of metabolic engineering by synthetic biology is an example of a biotechnological technique utilized in industry to discover pharmaceuticals and fermentive chemicals. Synthetic biology may investigate modular pathway systems in biochemical production and increase yields of metabolic production. Artificial enzymatic activity and subsequent effects on metabolic reaction rates and yields may develop \"efficient new strategies for improving cellular properties ... for industrially important biochemical production\".\n",
      "\n",
      "Designed nucleic acid systems\n",
      "Scientists can encode digital information onto a single strand of synthetic DNA. In 2012, George M. Church encoded one of his books about synthetic biology in DNA. The 5.3 Mb of data was more than 1000 times greater than the previous largest amount of information to be stored in synthesized DNA. A similar project encoded the complete sonnets of William Shakespeare in DNA. More generally, algorithms such as NUPACK, ViennaRNA, Ribosome Binding Site Calculator, Cello, and Non-Repetitive Parts Calculator enables the design of new genetic systems.\n",
      "Many technologies have been developed for incorporating unnatural nucleotides and amino acids into nucleic acids and proteins, both in vitro and in vivo. For example, in May 2014, researchers announced that they had successfully introduced two new artificial nucleotides into bacterial DNA. By including individual artificial nucleotides in the culture media, they were able to exchange the bacteria 24 times; they did not generate mRNA or proteins able to use the artificial nucleotides.\n",
      "\n",
      "Space exploration\n",
      "Synthetic biology raised NASA's interest as it could help to produce resources for astronauts from a restricted portfolio of compounds sent from Earth. On Mars, in particular, synthetic biology could lead to production processes based on local resources, making it a powerful tool in the development of occupied outposts with less dependence on Earth. Work has gone into developing plant strains that are able to cope with the harsh Martian environment, using similar techniques to those employed to increase resilience to certain environmental factors in agricultural crops.\n",
      "\n",
      "Synthetic life\n",
      "One important topic in synthetic biology is synthetic life, that is concerned with hypothetical organisms created in vitro from biomolecules and/or chemical analogues thereof. Synthetic life experiments attempt to either probe the origins of life, study some of the properties of life, or more ambitiously to recreate life from non-living (abiotic) components. Synthetic life biology attempts to create living organisms capable of carrying out important functions, from manufacturing pharmaceuticals to detoxifying polluted land and water. In medicine, it offers prospects of using designer biological parts as a starting point for new classes of therapies and diagnostic tools.A living \"artificial cell\" has been defined as a completely synthetic cell that can capture energy, maintain ion gradients, contain macromolecules as well as store information and have the ability to mutate. Nobody has been able to create such a cell.A completely synthetic bacterial chromosome was produced in 2010 by Craig Venter, and his team introduced it to genomically emptied bacterial host cells. The host cells were able to grow and replicate. The Mycoplasma laboratorium is the only living organism with completely engineered genome.\n",
      "The first living organism with 'artificial' expanded DNA code was presented in 2014; the team used E. coli that had its genome extracted and replaced with a chromosome with an expanded genetic code. The nucleosides added are d5SICS and dNaM.In May 2019, in a milestone effort, researchers reported the creation of a new synthetic (possibly artificial) form of viable life, a variant of the bacteria Escherichia coli, by reducing the natural number of 64 codons in the bacterial genome to 59 codons instead, in order to encode 20 amino acids.In 2017, the international Build-a-Cell large-scale open-source research collaboration for the construction of synthetic living cells was started, followed by national synthetic cell organizations in several countries, including FabriCell, MaxSynBio and BaSyC. The European synthetic cell efforts were unified in 2019 as SynCellEU initiative.In 2023, researchers were able to create the first synthetically made human embryos derived from stem cells.\n",
      "\n",
      "Drug delivery platforms\n",
      "In therapeutics, synthetic biology has achieved significant advancements in altering and simplifying the therapeutics scope in a relatively short period of time. In fact, new therapeutic platforms, from the discovery of disease mechanisms and drug targets to the manufacture and transport of small molecules, are made possible by the logical and model-guided design construction of biological components.Synthetic biology devices have been designed to act as therapies in therapeutic treatment. It is possible to control complete created viruses and organisms to target particular pathogens and diseased pathways. Thus, in two independent studies 91,92, researchers utilised genetically modified bacteriophages to fight antibiotic-resistant bacteria by giving them genetic features that specifically target and hinder bacterial defences against antibiotic activity.In the therapy of cancer, since conventional medicines frequently indiscriminately target tumours and normal tissues, artificially created viruses and organisms that can identify and connect their therapeutic action to pathological signals may be helpful. For example, p53 pathway activity in human cells was put into adenoviruses to control how they replicated.\n",
      "\n",
      "Engineered bacteria-based platform\n",
      "Bacteria have long been used in cancer treatment. Bifidobacterium and Clostridium selectively colonize tumors and reduce their size. Recently synthetic biologists reprogrammed bacteria to sense and respond to a particular cancer state. Most often bacteria are used to deliver a therapeutic molecule directly to the tumor to minimize off-target effects. To target the tumor cells, peptides that can specifically recognize a tumor were expressed on the surfaces of bacteria. Peptides used include an affibody molecule that specifically targets human epidermal growth factor receptor 2 and a synthetic adhesin. The other way is to allow bacteria to sense the tumor microenvironment, for example hypoxia, by building an AND logic gate into bacteria. Then the bacteria only release target therapeutic molecules to the tumor through either lysis or the bacterial secretion system. Lysis has the advantage that it can stimulate the immune system and control growth. Multiple types of secretion systems can be used and other strategies as well. The system is inducible by external signals. Inducers include chemicals, electromagnetic or light waves.\n",
      "Multiple species and strains are applied in these therapeutics. Most commonly used bacteria are Salmonella typhimurium, Escherichia coli, Bifidobacteria, Streptococcus, Lactobacillus, Listeria and Bacillus subtilis. Each of these species have their own property and are unique to cancer therapy in terms of tissue colonization, interaction with immune system and ease of application.\n",
      "Engineered yeast-based platform\n",
      "Synthetic biologists are developing genetically modified live yeast that can deliver therapeutic biologic medicines. When orally delivered, these live yeast act like micro-factories and will make therapeutic molecules directly in the gastrointestinal tract. Because yeast are eukaryotic, a key benefit is that they can be administered together with antibiotics. Probiotic yeast expressing human P2Y2 purinergic receptor suppressed intestinal inflammation in mouse models of inflammatory bowel disease. A live S. boulardii yeast delivering a tetra-specific anti-toxin that potently neutralizes Toxin A and Toxin B of Clostridioides difficile has been developed. This therapeutic anti-toxin is a fusion of four single-domain antibodies (nanobodies) that potently and broadly neutralize the two major virulence factors of C. difficile at the site of infection in preclinical models.  The first in human clinical trial of engineered live yeast for the treatment of Clostridium difficile infection is anticipated in 2024 and will be sponsored by the developer Fzata, Inc.\n",
      "\n",
      "Cell-based platform\n",
      "The immune system plays an important role in cancer and can be harnessed to attack cancer cells. Cell-based therapies focus on immunotherapies, mostly by engineering T cells.\n",
      "T cell receptors were engineered and 'trained' to detect cancer epitopes. Chimeric antigen receptors (CARs) are composed of a fragment of an antibody fused to intracellular T cell signaling domains that can activate and trigger proliferation of the cell. Multiple second generation CAR-based therapies have been approved by FDA.Gene switches were designed to enhance safety of the treatment. Kill switches were developed to terminate the therapy should the patient show severe side effects. Mechanisms can more finely control the system and stop and reactivate it. Since the number of T-cells are important for therapy persistence and severity, growth of T-cells is also controlled to dial the effectiveness and safety of therapeutics.Although several mechanisms can improve safety and control, limitations include the difficulty of inducing large DNA circuits into the cells and risks associated with introducing foreign components, especially proteins, into cells.\n",
      "\n",
      "Biofuels, pharmaceuticals and biomaterials\n",
      "The most popular biofuel is ethanol produced from corn or sugar cane, but this method of producing biofuels is troublesome and constrained due to the high agricultural cost and inadequate fuel characteristics of ethanol. An substitute and potential source of renewable energy is microbes that have had their metabolic pathways altered to be more efficient at converting biomass into biofuels. Only if their production costs could be made to match or even exceed those of present fuel production can these techniques be expected to be successful. Related to this, there are several medicines whose pricey manufacturing procedures prevent them from having a larger therapeutic range. The creation of new materials and the microbiological manufacturing of biomaterials would both benefit substantially from novel artificial biology tools.\n",
      "\n",
      "CRISPR/Cas9\n",
      "The clustered frequently interspaced short palindromic repetitions (CRISPR)/CRISPR associated (Cas) system is a powerful method of genome engineering in a range of organisms because of its simplicity, modularity, and scalability. In this technique, a guide RNA (gRNA) attracts the CRISPR nuclease Cas9 to a particular spot in the genome, causing a double strand break. Several DNA repair processes, including homology-directed recombination and non-homology end joining, can be used to accomplish the desired genome change (i.e., gene deletion or insertion). Additionally, dCas9 (dead Cas9 or nuclease-deficient Cas9), a Cas9 double mutant (H840A, D10A), has been utilised to control gene expression in bacteria or when linked to a stimulation of suppression site in yeast.\n",
      "\n",
      "Regulatory elements\n",
      "To build and develop biological systems, regulating components including regulators, ribosome-binding sites (RBSs), and terminators are crucial. Despite years of study, there are many various varieties and numbers of promoters and terminators for Escherichia coli, but also for the well-researched model organism Saccharomyces cerevisiae, as well as for other organisms of interest, these tools are quite scarce. Numerous techniques have been invented for the finding and identification of promoters and terminators in order to overcome this constraint, including genome mining, random mutagenesis, hybrid engineering, biophysical modelling, combinatorial design, and rational design.\n",
      "\n",
      "Organoids\n",
      "Synthetic biology has been used for organoids, which are lab-grown organs with application to medical research and transplantation.\n",
      "\n",
      "Bioprinted organs\n",
      "3D bioprinting can be used to reconstruct tissue from various regions of the body. The precursor to the adoption of 3D printing in healthcare was a series of trials conducted by researchers at Boston Children's Hospital. The team built replacement urinary bladders by hand for seven patients by constructing scaffolds, then layering the scaffolds with cells from the patients and allowing them to grow. The trials were a success as the patients remained in good health 7 years after implantation, which led a research fellow named Anthony Atala, MD, to search or ways to automate the process. Patients with end-stage bladder disease can now be treated by using bio-engineered bladder tissues to rebuild the damaged organ. This technology can also potentially be applied to bone, skin, cartilage and muscle tissue. Though one long-term goal of 3D bioprinting technology is to reconstruct an entire organ as well as minimize the problem of the lack of organs for transplantation. There has been little success in bioprinting of fully functional organs e.g. liver, skin, meniscus or pancreas. Unlike implantable stents, organs have complex shapes and are significantly harder to bioprint. A bioprinted heart, for example, must not only meet structural requirements, but also vascularization, mechanical load, and electrical signal propagation requirements.In 2022, first success of a clinical trial for a 3D bioprinted transplant that is made from the patient's own cells, an external ear to treat microtia, was reported.For bioprinted food like meat see #Food and drink.\n",
      "\n",
      "Other transplants and induced regeneration\n",
      "There is ongoing research and development into synthetic biology based methods for inducing regeneration in humans as well the creation of transplantable artificial organs.\n",
      "\n",
      "Nanoparticles, artificial cells and micro-droplets\n",
      "Synthetic biology can be used for creating nanoparticles which can be used for drug-delivery as well as for other purposes. Complementing research and development seeks to and has created synthetic cells that mimics functions of biological cells. Applications include medicine such as designer-nanoparticles that make blood cells eat away—from the inside out—portions of atherosclerotic plaque that cause heart attacks. Synthetic micro-droplets for algal cells or synergistic algal-bacterial multicellular spheroid microbial reactors, for example, could be used to produce hydrogen as hydrogen economy biotechnology.\n",
      "\n",
      "Ethics\n",
      "The creation of new life and the tampering of existing life has raised ethical concerns in the field of synthetic biology and are actively being discussed.Common ethical questions include:\n",
      "\n",
      "Is it morally right to tamper with nature?\n",
      "Is one playing God when creating new life?\n",
      "What happens if a synthetic organism accidentally escapes?\n",
      "What if an individual misuses synthetic biology and creates a harmful entity (e.g., a biological weapon)?\n",
      "Who will have control of and access to the products of synthetic biology?\n",
      "Who will gain from these innovations? Investors? Medical patients? Industrial farmers?\n",
      "Does the patent system allow patents on living organisms? What about parts of organisms, like HIV resistance genes in humans?\n",
      "What if a new creation is deserving of moral or legal status?The ethical aspects of synthetic biology has three main features: biosafety, biosecurity, and the creation of new life forms. Other ethical issues mentioned include the regulation of new creations, patent management of new creations, benefit distribution, and research integrity.Ethical issues have surfaced for recombinant DNA and genetically modified organism (GMO) technologies and extensive regulations of genetic engineering and pathogen research were in place in many jurisdictions. Amy Gutmann, former head of the Presidential Bioethics Commission, argued that we should avoid the temptation to over-regulate synthetic biology in general, and genetic engineering in particular. According to Gutmann, \"Regulatory parsimony is especially important in emerging technologies...where the temptation to stifle innovation on the basis of uncertainty and fear of the unknown is particularly great. The blunt instruments of statutory and regulatory restraint may not only inhibit the distribution of new benefits, but can be counterproductive to security and safety by preventing researchers from developing effective safeguards.\".\n",
      "\n",
      "The \"creation\" of life\n",
      "One ethical question is whether or not it is acceptable to create new life forms, sometimes known as \"playing God\". Currently, the creation of new life forms not present in nature is at small-scale, the potential benefits and dangers remain unknown, and careful consideration and oversight are ensured for most studies. Many advocates express the great potential value—to agriculture, medicine, and academic knowledge, among other fields—of creating artificial life forms. Creation of new entities could expand scientific knowledge well beyond what is currently known from studying natural phenomena. Yet there is concern that artificial life forms may reduce nature's \"purity\" (i.e., nature could be somehow corrupted by human intervention and manipulation) and potentially influence the adoption of more engineering-like principles instead of biodiversity- and nature-focused ideals. Some are also concerned that if an artificial life form were to be released into nature, it could hamper biodiversity by beating out natural species for resources (similar to how algal blooms kill marine species). Another concern involves the ethical treatment of newly created entities if they happen to sense pain, sentience, and self-perception. There is an ongoing debate as to whether such life forms should be granted moral or legal rights, though no consensus exists as to how these rights would be administered or enforced.\n",
      "\n",
      "Ethical support for synthetic biology\n",
      "Ethics and moral rationales that support certain applications of synthetic biology include their potential mitigation of substantial global problems of detrimental environmental impacts of conventional agriculture (including meat production), animal welfare, food security, and human health, as well as potential reduction of human labor needs and, via therapies of diseases, reduction of human suffering and prolonged life.\n",
      "\n",
      "Biosafety and biocontainment\n",
      "What is most ethically appropriate when considering biosafety measures? How can accidental introduction of synthetic life in the natural environment be avoided? Much ethical consideration and critical thought has been given to these questions. Biosafety not only refers to biological containment; it also refers to strides taken to protect the public from potentially hazardous biological agents. Even though such concerns are important and remain unanswered, not all products of synthetic biology present concern for biological safety or negative consequences for the environment. It is argued that most synthetic technologies are benign and are incapable of flourishing in the outside world due to their \"unnatural\" characteristics as there is yet to be an example of a transgenic microbe conferred with a fitness advantage in the wild.\n",
      "In general, existing hazard controls, risk assessment methodologies, and regulations developed for traditional genetically modified organisms (GMOs) are considered to be sufficient for synthetic organisms. \"Extrinsic\" biocontainment methods in a laboratory context include physical containment through biosafety cabinets and gloveboxes, as well as personal protective equipment. In an agricultural context, they include isolation distances and pollen barriers, similar to methods for biocontainment of GMOs. Synthetic organisms may offer increased hazard control because they can be engineered with \"intrinsic\" biocontainment methods that limit their growth in an uncontained environment, or prevent horizontal gene transfer to natural organisms. Examples of intrinsic biocontainment include auxotrophy, biological kill switches, inability of the organism to replicate or to pass modified or synthetic genes to offspring, and the use of xenobiological organisms using alternative biochemistry, for example using artificial xeno nucleic acids (XNA) instead of DNA. Regarding auxotrophy, bacteria and yeast can be engineered to be unable to produce histidine, an important amino acid for all life. Such organisms can thus only be grown on histidine-rich media in laboratory conditions, nullifying fears that they could spread into undesirable areas.\n",
      "\n",
      "Biosecurity and bioterrorism\n",
      "Some ethical issues relate to biosecurity, where biosynthetic technologies could be deliberately used to cause harm to society and/or the environment. Since synthetic biology raises ethical issues and biosecurity issues, humanity must consider and plan on how to deal with potentially harmful creations, and what kinds of ethical measures could possibly be employed to deter nefarious biosynthetic technologies. With the exception of regulating synthetic biology and biotechnology companies, however, the issues are not seen as new because they were raised during the earlier recombinant DNA and genetically modified organism (GMO) debates, and extensive regulations of genetic engineering and pathogen research are already in place in many jurisdictions.Additionally, the development of synthetic biology tools has made it easier for individuals with less education, training, and access to equipment to modify and use pathogenic organisms as bioweapons. This increases the threat of bioterrorism, especially as terrorist groups become aware of the significant social, economic, and political disruption caused by pandemics like COVID-19. As new techniques are developed in the field of synthetic biology, the risk of bioterrorism is likely to continue to grow. Juan Zarate, who served as Deputy National Security Advisor for Combating Terrorism from 2005 to 2009, noted that \"the severity and extreme disruption of a novel coronavirus will likely spur the imagination of the most creative and dangerous groups and individuals to reconsider bioterrorist attacks.\"\n",
      "\n",
      "European Union\n",
      "The European Union-funded project SYNBIOSAFE has issued reports on how to manage synthetic biology. A 2007 paper identified key issues in safety, security, ethics, and the science-society interface, which the project defined as public education and ongoing dialogue among scientists, businesses, government and ethicists. The key security issues that SYNBIOSAFE identified involved engaging companies that sell synthetic DNA and the biohacking community of amateur biologists. Key ethical issues concerned the creation of new life forms.\n",
      "A subsequent report focused on biosecurity, especially the so-called dual-use challenge. For example, while synthetic biology may lead to more efficient production of medical treatments, it may also lead to synthesis or modification of harmful pathogens (e.g., smallpox). The biohacking community remains a source of special concern, as the distributed and diffuse nature of open-source biotechnology makes it difficult to track, regulate or mitigate potential concerns over biosafety and biosecurity.COSY, another European initiative, focuses on public perception and communication. To better communicate synthetic biology and its societal ramifications to a broader public, COSY and SYNBIOSAFE published SYNBIOSAFE, a 38-minute documentary film, in October 2009.The International Association Synthetic Biology has proposed self-regulation. This proposes specific measures that the synthetic biology industry, especially DNA synthesis companies, should implement. In 2007, a group led by scientists from leading DNA-synthesis companies published a \"practical plan for developing an effective oversight framework for the DNA-synthesis industry\".\n",
      "\n",
      "United States\n",
      "In January 2009, the Alfred P. Sloan Foundation funded the Woodrow Wilson Center, the Hastings Center, and the J. Craig Venter Institute to examine the public perception, ethics and policy implications of synthetic biology.On July 9–10, 2009, the National Academies' Committee of Science, Technology & Law convened a symposium on \"Opportunities and Challenges in the Emerging Field of Synthetic Biology\".After the publication of the first synthetic genome and the accompanying media coverage about \"life\" being created, President Barack Obama established the Presidential Commission for the Study of Bioethical Issues to study synthetic biology. The commission convened a series of meetings, and issued a report in December 2010 titled \"New Directions: The Ethics of Synthetic Biology and Emerging Technologies.\" The commission stated that \"while Venter's achievement marked a significant technical advance in demonstrating that a relatively large genome could be accurately synthesized and substituted for another, it did not amount to the \"creation of life\". It noted that synthetic biology is an emerging field, which creates potential risks and rewards. The commission did not recommend policy or oversight changes and called for continued funding of the research and new funding for monitoring, study of emerging ethical issues and public education.Synthetic biology, as a major tool for biological advances, results in the \"potential for developing biological weapons, possible unforeseen negative impacts on human health ... and any potential environmental impact\". The proliferation of such technology could also make the production of biological and chemical weapons available to a wider array of state and non-state actors. These security issues may be avoided by regulating industry uses of biotechnology through policy legislation. Federal guidelines on genetic manipulation are being proposed by \"the President's Bioethics Commission ... in response to the announced creation of a self-replicating cell from a chemically synthesized genome, put forward 18 recommendations not only for regulating the science ... for educating the public\".\n",
      "\n",
      "Opposition\n",
      "On March 13, 2012, over 100 environmental and civil society groups, including Friends of the Earth, the International Center for Technology Assessment, and the ETC Group, issued the manifesto The Principles for the Oversight of Synthetic Biology. This manifesto calls for a worldwide moratorium on the release and commercial use of synthetic organisms until more robust regulations and rigorous biosafety measures are established. The groups specifically call for an outright ban on the use of synthetic biology on the human genome or human microbiome. Richard Lewontin wrote that some of the safety tenets for oversight discussed in The Principles for the Oversight of Synthetic Biology are reasonable, but that the main problem with the recommendations in the manifesto is that \"the public at large lacks the ability to enforce any meaningful realization of those recommendations\".\n",
      "\n",
      "Health and safety\n",
      "The hazards of synthetic biology include biosafety hazards to workers and the public, biosecurity hazards stemming from deliberate engineering of organisms to cause harm, and environmental hazards. The biosafety hazards are similar to those for existing fields of biotechnology, mainly exposure to pathogens and toxic chemicals, although novel synthetic organisms may have novel risks. For biosecurity, there is concern that synthetic or redesigned organisms could theoretically be used for bioterrorism. Potential risks include recreating known pathogens from scratch, engineering existing pathogens to be more dangerous, and engineering microbes to produce harmful biochemicals. Lastly, environmental hazards include adverse effects on biodiversity and ecosystem services, including potential changes to land use resulting from agricultural use of synthetic organisms. Synthetic biology is an example of a dual-use technology with the potential to be used in ways that could intentionally or unintentionally harm humans and/or damage the environment. Often \"scientists, their host institutions and funding bodies\" consider whether the planned research could be misused and sometimes implement measures to reduce the likelihood of misuse.Existing risk analysis systems for GMOs are generally considered sufficient for synthetic organisms, although there may be difficulties for an organism built \"bottom-up\" from individual genetic sequences. Synthetic biology generally falls under existing regulations for GMOs and biotechnology in general, and any regulations that exist for downstream commercial products, although there are generally no regulations in any jurisdiction that are specific to synthetic biology.\n",
      "\n",
      "See also\n",
      "References\n",
      "NHGRI. (2019, March 13). Synthetic Biology. Genome.gov. https://www.genome.gov/about-genomics/policy-issues/Synthetic-Biology\n",
      "\n",
      "Bibliography\n",
      "Church G, Regis E (2012). How Synthetic Biology will Reinvent Nature and Ourselves. New York, NY: Basic Books. ISBN 978-0465021758.\n",
      "Synthetic biology and biodiversity ; Science for Environment Policy (PDF). Future Brief 15. Produced for the European Commission DG Environment by the Science Communication Unit, UWE, Bristol (Report). European Commission. 2016.\n",
      "Venter C (2013). Life at the Speed of Light: The Double Helix and the Dawn of Digital Life. New York, NY: Penguin Books. ISBN 978-0670025404.\n",
      "\n",
      "External links\n",
      "\n",
      "Engineered Pathogens and Unnatural Biological Weapons: The Future Threat of Synthetic Biology . Threats and considerations\n",
      "Synthetic biology books popular science book and textbooks\n",
      "Introductory Summary of Synthetic Biology Archived 2018-04-02 at the Wayback Machine. Concise overview of synthetic biology concepts, developments and applications\n",
      "Collaborative overview article on Synthetic Biology\n",
      "Controversial DNA startup wants to let customers create creatures (2015-01-03), San Francisco Chronicle\n",
      "It's Alive, But Is It Life: Synthetic Biology and the Future of Creation (28 September 2016), World Science FestivalCleopatra VII Thea Philopator (Koinē Greek: Κλεοπάτρα Θεά Φιλοπάτωρ lit. Cleopatra \"father-loving goddess\"; 70/69 BC – 10 August 30 BC) was Queen of the Ptolemaic Kingdom of Egypt from 51 to 30 BC, and its last active ruler. A member of the Ptolemaic dynasty, she was a descendant of its founder Ptolemy I Soter, a Macedonian Greek general and companion of Alexander the Great. After the death of Cleopatra, Egypt became a province of the Roman Empire, marking the end of the last Hellenistic-period state in the Mediterranean and of the age that had lasted since the reign of Alexander (336–323 BC). Her first language was Koine Greek and she is the only known Ptolemaic ruler to learn the Egyptian language.In 58 BC, Cleopatra presumably accompanied her father, Ptolemy XII Auletes, during his exile to Rome after a revolt in Egypt (a Roman client state) allowed his rival daughter Berenice IV to claim his throne. Berenice was killed in 55 BC when Ptolemy returned to Egypt with Roman military assistance. When he died in 51 BC, the joint reign of Cleopatra and her brother Ptolemy XIII began, but a falling-out between them led to open civil war. After losing the 48 BC Battle of Pharsalus in Greece against his rival Julius Caesar (a Roman dictator and consul) in Caesar's civil war, the Roman statesman Pompey fled to Egypt. Pompey had been a political ally of Ptolemy XII, but Ptolemy XIII, at the urging of his court eunuchs, had Pompey ambushed and killed before Caesar arrived and occupied Alexandria. Caesar then attempted to reconcile the rival Ptolemaic siblings, but Ptolemy's chief adviser, Potheinos, viewed Caesar's terms as favoring Cleopatra, so his forces besieged her and Caesar at the palace. Shortly after the siege was lifted by reinforcements, Ptolemy XIII died in the Battle of the Nile; Cleopatra's half-sister Arsinoe IV was eventually exiled to Ephesus for her role in carrying out the siege. Caesar declared Cleopatra and her brother Ptolemy XIV joint rulers but maintained a private affair with Cleopatra that produced a son, Caesarion. Cleopatra traveled to Rome as a client queen in 46 and 44 BC, where she stayed at Caesar's villa. After Caesar's assassination, followed shortly afterwards by that of Ptolemy XIV (on Cleopatra's orders), she named Caesarion co-ruler as Ptolemy XV.\n",
      "In the Liberators' civil war of 43–42 BC, Cleopatra sided with the Roman Second Triumvirate formed by Caesar's grandnephew and heir Octavian, Mark Antony, and Marcus Aemilius Lepidus. After their meeting at Tarsos in 41 BC, the queen had an affair with Antony which produced three children. He carried out the execution of Arsinoe at her request, and became increasingly reliant on Cleopatra for both funding and military aid during his invasions of the Parthian Empire and the Kingdom of Armenia. The Donations of Alexandria declared their children rulers over various erstwhile territories under Antony's triumviral authority. This event, their marriage, and Antony's divorce of Octavian's sister Octavia Minor led to the final war of the Roman Republic. Octavian engaged in a war of propaganda, forced Antony's allies in the Roman Senate to flee Rome in 32 BC, and declared war on Cleopatra. After defeating Antony and Cleopatra's naval fleet at the 31 BC Battle of Actium, Octavian's forces invaded Egypt in 30 BC and defeated Antony, leading to Antony's suicide. When Cleopatra learned that Octavian planned to bring her to his Roman triumphal procession, she killed herself by poisoning, contrary to the popular belief that she was bitten by an asp.\n",
      "Cleopatra's legacy survives in ancient and modern works of art. Roman historiography and Latin poetry produced a generally critical view of the queen that pervaded later Medieval and Renaissance literature. In the visual arts, her ancient depictions include Roman busts, paintings, and sculptures, cameo carvings and glass, Ptolemaic and Roman coinage, and reliefs. In Renaissance and Baroque art, she was the subject of many works including operas, paintings, poetry, sculptures, and theatrical dramas. She has become a pop culture icon of Egyptomania since the Victorian era, and in modern times, Cleopatra has appeared in the applied and fine arts, burlesque satire, Hollywood films, and brand images for commercial products.\n",
      "\n",
      "Etymology\n",
      "The Latinized form Cleopatra comes from the Ancient Greek Kleopátra (Κλεοπάτρα), meaning \"glory of her father\", from κλέος (kléos, \"glory\") and πατήρ (patḗr, \"father\"). The masculine form would have been written either as Kleópatros (Κλεόπατρος) or Pátroklos (Πάτροκλος). Cleopatra was the name of Alexander the Great's sister, as well as Cleopatra Alcyone, wife of Meleager in Greek mythology. Through the marriage of Ptolemy V Epiphanes and Cleopatra I Syra (a Seleucid princess), the name entered the Ptolemaic dynasty. Cleopatra's adopted title Theā́ Philopátōra (Θεᾱ́ Φιλοπάτωρα) means \"goddess who loves her father\".\n",
      "\n",
      "Background\n",
      "Ptolemaic pharaohs were crowned by the Egyptian high priest of Ptah at Memphis, but resided in the multicultural and largely Greek city of Alexandria, established by Alexander the Great. They spoke Greek]and governed Egypt as Hellenistic Greek monarchs, refusing to learn the native Egyptian language. In contrast, Cleopatra could speak multiple languages by adulthood and was the first Ptolemaic ruler known to learn the Egyptian language. Plutarch implies that she also spoke Ethiopian, the language of the \"Troglodytes\", Hebrew (or Aramaic), Arabic, the Syrian language (perhaps Syriac), Median, and Parthian, and she could apparently also speak Latin, although her Roman contemporaries would have preferred to speak with her in her native Koine Greek. Aside from Greek, Egyptian, and Latin, these languages reflected Cleopatra's desire to restore North African and West Asian territories that once belonged to the Ptolemaic Kingdom.Roman interventionism in Egypt predated the reign of Cleopatra. When Ptolemy IX Lathyros died in late 81 BC, he was succeeded by his daughter Berenice III. With opposition building at the royal court against the idea of a sole reigning female monarch, Berenice III accepted joint rule and marriage with her cousin and stepson Ptolemy XI Alexander II, an arrangement made by the Roman dictator Sulla. Ptolemy XI had his wife killed shortly after their marriage in 80 BC, and was lynched soon after in the resulting riot over the assassination. Ptolemy XI, and perhaps his uncle Ptolemy IX or father Ptolemy X Alexander I, willed the Ptolemaic Kingdom to Rome as collateral for loans, so that the Romans had legal grounds to take over Egypt, their client state, after the assassination of Ptolemy XI. The Romans chose instead to divide the Ptolemaic realm among the illegitimate sons of Ptolemy IX, bestowing Cyprus on Ptolemy of Cyprus and Egypt on Ptolemy XII Auletes.\n",
      "\n",
      "Biography\n",
      "Early childhood\n",
      "Cleopatra VII was born in early 69 BC to the ruling Ptolemaic pharaoh Ptolemy XII and an uncertain mother, presumably Ptolemy XII's wife Cleopatra V Tryphaena (who may have been the same person as Cleopatra VI Tryphaena), the mother of Cleopatra's older sister, Berenice IV Epiphaneia. Cleopatra Tryphaena disappears from official records a few months after the birth of Cleopatra in 69 BC. The three younger children of Ptolemy XII, Cleopatra's sister Arsinoe IV and brothers Ptolemy XIII Theos Philopator and Ptolemy XIV, were born in the absence of his wife. Cleopatra's childhood tutor was Philostratos, from whom she learned the Greek arts of oration and philosophy. During her youth Cleopatra presumably studied at the Musaeum, including the Library of Alexandria.\n",
      "\n",
      "Reign and exile of Ptolemy XII\n",
      "In 65 BC the Roman censor Marcus Licinius Crassus argued before the Roman Senate that Rome should annex Ptolemaic Egypt, but his proposed bill and the similar bill of tribune Servilius Rullus in 63 BC were rejected. Ptolemy XII responded to the threat of possible annexation by offering remuneration and lavish gifts to powerful Roman statesmen, such as Pompey during his campaign against Mithridates VI of Pontus, and eventually Julius Caesar after he became Roman consul in 59 BC. However, Ptolemy XII's profligate behavior bankrupted him, and he was forced to acquire loans from the Roman banker Gaius Rabirius Postumus.In 58 BC the Romans annexed Cyprus and on accusations of piracy drove Ptolemy of Cyprus, Ptolemy XII's brother, to commit suicide instead of enduring exile to Paphos. Ptolemy XII remained publicly silent on the death of his brother, a decision which, along with ceding traditional Ptolemaic territory to the Romans, damaged his credibility among subjects already enraged by his economic policies. Ptolemy XII was then exiled from Egypt by force, traveling first to Rhodes, then Athens, and finally the villa of triumvir Pompey in the Alban Hills, near Praeneste, Italy.Ptolemy XII spent nearly a year there on the outskirts of Rome, ostensibly accompanied by his daughter Cleopatra, then about 11. Berenice IV sent an embassy to Rome to advocate for her rule and oppose the reinstatement of her father Ptolemy XII. Ptolemy had assassins kill the leaders of the embassy, an incident that was covered up by his powerful Roman supporters. When the Roman Senate denied Ptolemy XII the offer of an armed escort and provisions for a return to Egypt, he decided to leave Rome in late 57 BC and reside at the Temple of Artemis in Ephesus.The Roman financiers of Ptolemy XII remained determined to restore him to power. Pompey persuaded Aulus Gabinius, the Roman governor of Syria, to invade Egypt and restore Ptolemy XII, offering him 10,000 talents for the proposed mission. Although it put him at odds with Roman law, Gabinius invaded Egypt in the spring of 55 BC by way of Hasmonean Judea, where Hyrcanus II had Antipater the Idumaean, father of Herod the Great, furnish the Roman-led army with supplies. As a young cavalry officer, Mark Antony was under Gabinius's command. He distinguished himself by preventing Ptolemy XII from massacring the inhabitants of Pelousion, and for rescuing the body of Archelaos, the husband of Berenice IV, after he was killed in battle, ensuring him a proper royal burial. Cleopatra, then 14 years of age, would have traveled with the Roman expedition into Egypt; years later, Antony would profess that he had fallen in love with her at this time.\n",
      "Gabinius was put on trial in Rome for abusing his authority, for which he was acquitted, but his second trial for accepting bribes led to his exile, from which he was recalled seven years later in 48 BC by Caesar. Crassus replaced him as governor of Syria and extended his provincial command to Egypt, but he was killed by the Parthians at the Battle of Carrhae in 53 BC. Ptolemy XII had Berenice IV and her wealthy supporters executed, seizing their properties. He allowed Gabinius's largely Germanic and Gallic Roman garrison, the Gabiniani, to harass people in the streets of Alexandria and installed his longtime Roman financier Rabirius as his chief financial officer.Within a year Rabirius was placed under protective custody and sent back to Rome after his life was endangered for draining Egypt of its resources. Despite these problems, Ptolemy XII created a will designating Cleopatra and Ptolemy XIII as his joint heirs, oversaw major construction projects such as the Temple of Edfu and a temple at Dendera, and stabilized the economy. On 31 May 52 BC, Cleopatra was made a regent of Ptolemy XII, as indicated by an inscription in the Temple of Hathor at Dendera. Rabirius was unable to collect the entirety of Ptolemy XII's debt by the time of the latter's death, and so it was passed on to his successors Cleopatra and Ptolemy XIII.\n",
      "\n",
      "Accession to the throne\n",
      "Ptolemy XII died sometime before 22 March 51 BC, when Cleopatra, in her first act as queen, began her voyage to Hermonthis, near Thebes, to install a new sacred Buchis bull, worshiped as an intermediary for the god Montu in the Ancient Egyptian religion. Cleopatra faced several pressing issues and emergencies shortly after taking the throne. These included famine caused by drought and a low level of the annual flooding of the Nile, and lawless behavior instigated by the Gabiniani, the now unemployed and assimilated Roman soldiers left by Gabinius to garrison Egypt. Inheriting her father's debts, Cleopatra also owed the Roman Republic 17.5 million drachmas.In 50 BC Marcus Calpurnius Bibulus, proconsul of Syria, sent his two eldest sons to Egypt, most likely to negotiate with the Gabiniani and recruit them as soldiers in the desperate defense of Syria against the Parthians. The Gabiniani tortured and murdered these two, perhaps with secret encouragement by rogue senior administrators in Cleopatra's court. Cleopatra sent the Gabiniani culprits to Bibulus as prisoners awaiting his judgment, but he sent them back to Cleopatra and chastised her for interfering in their adjudication, which was the prerogative of the Roman Senate. Bibulus, siding with Pompey in Caesar's Civil War, failed to prevent Caesar from landing a naval fleet in Greece, which ultimately allowed Caesar to reach Egypt in pursuit of Pompey.By 29 August 51 BC, official documents started listing Cleopatra as the sole ruler, evidence that she had rejected her brother Ptolemy XIII as a co-ruler. She had probably married him, but there is no record of this. The Ptolemaic practice of sibling marriage was introduced by Ptolemy II and his sister Arsinoe II. A long-held royal Egyptian practice, it was loathed by contemporary Greeks. By the reign of Cleopatra, however, it was considered a normal arrangement for Ptolemaic rulers.Despite Cleopatra's rejection of him, Ptolemy XIII still retained powerful allies, notably the eunuch Potheinos, his childhood tutor, regent, and administrator of his properties. Others involved in the cabal against Cleopatra included Achillas, a prominent military commander, and Theodotus of Chios, another tutor of Ptolemy XIII. Cleopatra seems to have attempted a short-lived alliance with her brother Ptolemy XIV, but by the autumn of 50 BC Ptolemy XIII had the upper hand in their conflict and began signing documents with his name before that of his sister, followed by the establishment of his first regnal date in 49 BC.\n",
      "\n",
      "Assassination of Pompey\n",
      "In the summer of 49 BC, Cleopatra and her forces were still fighting against Ptolemy XIII within Alexandria when Pompey's son Gnaeus Pompeius arrived, seeking military aid on behalf of his father. After returning to Italy from the wars in Gaul and crossing the Rubicon in January of 49 BC, Caesar had forced Pompey and his supporters to flee to Greece. In perhaps their last joint decree, both Cleopatra and Ptolemy XIII agreed to Gnaeus Pompeius's request and sent his father 60 ships and 500 troops, including the Gabiniani, a move that helped erase some of the debt owed to Rome. Losing the fight against her brother, Cleopatra was then forced to flee Alexandria and withdraw to the region of Thebes. By the spring of 48 BC Cleopatra had traveled to Roman Syria with her younger sister, Arsinoe IV, to gather an invasion force that would head to Egypt. She returned with an army, but her advance to Alexandria was blocked by her brother's forces, including some Gabiniani mobilized to fight against her, so she camped outside Pelousion in the eastern Nile Delta.In Greece, Caesar and Pompey's forces engaged each other at the decisive Battle of Pharsalus on 9 August 48 BC, leading to the destruction of most of Pompey's army and his forced flight to Tyre, Lebanon. Given his close relationship with the Ptolemies, Pompey ultimately decided that Egypt would be his place of refuge, where he could replenish his forces. Ptolemy XIII's advisers, however, feared the idea of Pompey using Egypt as his base in a protracted Roman civil war. In a scheme devised by Theodotus, Pompey arrived by ship near Pelousion after being invited by a written message, only to be ambushed and stabbed to death on 28 September 48 BC. Ptolemy XIII believed he had demonstrated his power and simultaneously defused the situation by having Pompey's head, severed and embalmed, sent to Caesar, who arrived in Alexandria by early October and took up residence at the royal palace. Caesar expressed grief and outrage over the killing of Pompey and called on both Ptolemy XIII and Cleopatra to disband their forces and reconcile with each other.\n",
      "\n",
      "Relationship with Julius Caesar\n",
      "Ptolemy XIII arrived at Alexandria at the head of his army, in clear defiance of Caesar's demand that he disband and leave his army before his arrival. Cleopatra initially sent emissaries to Caesar, but upon allegedly hearing that Caesar was inclined to having affairs with royal women, she came to Alexandria to see him personally. Historian Cassius Dio records that she did so without informing her brother, dressed in an attractive manner, and charmed Caesar with her wit. Plutarch provides an entirely different account that alleges she was bound inside a bed sack to be smuggled into the palace to meet Caesar.When Ptolemy XIII realized that his sister was in the palace consorting directly with Caesar, he attempted to rouse the populace of Alexandria into a riot, but he was arrested by Caesar, who used his oratorical skills to calm the frenzied crowd. Caesar then brought Cleopatra and Ptolemy XIII before the assembly of Alexandria, where Caesar revealed the written will of Ptolemy XII—previously possessed by Pompey—naming Cleopatra and Ptolemy XIII as his joint heirs. Caesar then attempted to arrange for the other two siblings, Arsinoe IV and Ptolemy XIV, to rule together over Cyprus, thus removing potential rival claimants to the Egyptian throne while also appeasing the Ptolemaic subjects still bitter over the loss of Cyprus to the Romans in 58 BC.Judging that this agreement favored Cleopatra over Ptolemy XIII and that the latter's army of 20,000, including the Gabiniani, could most likely defeat Caesar's army of 4,000 unsupported troops, Potheinos decided to have Achillas lead their forces to Alexandria to attack both Caesar and Cleopatra. After Caesar managed to execute Potheinos, Arsinoe IV joined forces with Achillas and was declared queen, but soon afterward had her tutor Ganymedes kill Achillas and take his position as commander of her army. Ganymedes then tricked Caesar into requesting the presence of the erstwhile captive Ptolemy XIII as a negotiator, only to have him join the army of Arsinoe IV. The resulting siege of the palace, with Caesar and Cleopatra trapped together inside, lasted into the following year of 47 BC.Sometime between January and March of 47 BC, Caesar's reinforcements arrived, including those led by Mithridates of Pergamon and Antipater the Idumaean. Ptolemy XIII and Arsinoe IV withdrew their forces to the Nile, where Caesar attacked them. Ptolemy XIII tried to flee by boat, but it capsized, and he drowned. Ganymedes may have been killed in the battle. Theodotus was found years later in Asia, by Marcus Junius Brutus, and executed. Arsinoe IV was forcefully paraded in Caesar's triumph in Rome before being exiled to the Temple of Artemis at Ephesus. Cleopatra was conspicuously absent from these events and resided in the palace, most likely because she had been pregnant with Caesar's child since September 48 BC.Caesar's term as consul had expired at the end of 48 BC. However, Antony, an officer of his, helped to secure Caesar's appointment as dictator lasting for a year, until October 47 BC, providing Caesar with the legal authority to settle the dynastic dispute in Egypt. Wary of repeating the mistake of Cleopatra's sister Berenice IV in having a female monarch as sole ruler, Caesar appointed Cleopatra's 12-year-old brother, Ptolemy XIV, as joint ruler with the 22-year-old Cleopatra in a nominal sibling marriage, but Cleopatra continued living privately with Caesar. The exact date at which Cyprus was returned to her control is not known, although she had a governor there by 42 BC.Caesar is alleged to have joined Cleopatra for a cruise of the Nile and sightseeing of Egyptian monuments, although this may be a romantic tale reflecting later well-to-do Roman proclivities and not a real historical event. The historian Suetonius provided considerable details about the voyage, including use of Thalamegos, the pleasure barge constructed by Ptolemy IV, which during his reign measured 90 metres (300 ft) in length and 24 metres (80 ft) in height and was complete with dining rooms, state rooms, holy shrines, and promenades along its two decks, resembling a floating villa. Caesar could have had an interest in the Nile cruise owing to his fascination with geography; he was well-read in the works of Eratosthenes and Pytheas, and perhaps wanted to discover the source of the river, but turned back before reaching Ethiopia.Caesar departed from Egypt around April 47 BC, allegedly to confront Pharnaces II of Pontus, the son of Mithridates VI of Pontus, who was stirring up trouble for Rome in Anatolia. It is possible that Caesar, married to the prominent Roman woman Calpurnia, also wanted to avoid being seen together with Cleopatra when she had their son. He left three legions in Egypt, later increased to four, under the command of the freedman Rufio, to secure Cleopatra's tenuous position, but also perhaps to keep her activities in check.Caesarion, Cleopatra's alleged child with Caesar, was born 23 June 47 BC and was originally named \"Pharaoh Caesar\", as preserved on a stele at the Serapeum of Saqqara. Perhaps owing to his still childless marriage with Calpurnia, Caesar remained publicly silent about Caesarion (but perhaps accepted his parentage in private). Cleopatra, on the other hand, made repeated official declarations about Caesarion's parentage, naming Caesar as the father.Cleopatra and her nominal joint ruler Ptolemy XIV visited Rome sometime in late 46 BC, presumably without Caesarion, and were given lodging in Caesar's villa within the Horti Caesaris. As with their father Ptolemy XII, Caesar awarded both Cleopatra and Ptolemy XIV the legal status of \"friend and ally of the Roman people\" (Latin: socius et amicus populi Romani), in effect client rulers loyal to Rome. Cleopatra's visitors at Caesar's villa across the Tiber included the senator Cicero, who found her arrogant. Sosigenes of Alexandria, one of the members of Cleopatra's court, aided Caesar in the calculations for the new Julian calendar, put into effect 1 January 45 BC. The Temple of Venus Genetrix, established in the Forum of Caesar on 25 September 46 BC, contained a golden statue of Cleopatra (which stood there at least until the 3rd century AD), associating the mother of Caesar's child directly with the goddess Venus, mother of the Romans. The statue also subtly linked the Egyptian goddess Isis with the Roman religion.Cleopatra's presence in Rome most likely had an effect on the events at the Lupercalia festival a month before Caesar's assassination. Antony attempted to place a royal diadem on Caesar's head, but the latter refused in what was most likely a staged performance, perhaps to gauge the Roman public's mood about accepting Hellenistic-style kingship. Cicero, who was present at the festival, mockingly asked where the diadem came from, an obvious reference to the Ptolemaic queen whom he abhorred. Caesar was assassinated on the Ides of March (15 March 44 BC), but Cleopatra stayed in Rome until about mid-April, in the vain hope of having Caesarion recognized as Caesar's heir. However, Caesar's will named his grandnephew Octavian as the primary heir, and Octavian arrived in Italy around the same time Cleopatra decided to depart for Egypt. A few months later, Cleopatra had Ptolemy XIV killed by poisoning, elevating her son Caesarion as her co-ruler.\n",
      "\n",
      "Cleopatra in the Liberators' civil war\n",
      "Octavian, Antony, and Marcus Aemilius Lepidus formed the Second Triumvirate in 43 BC, in which they were each elected for five-year terms to restore order in the Republic and bring Caesar's assassins to justice. Cleopatra received messages from both Gaius Cassius Longinus, one of Caesar's assassins, and Publius Cornelius Dolabella, proconsul of Syria and Caesarian loyalist, requesting military aid. She decided to write Cassius an excuse that her kingdom faced too many internal problems, while sending the four legions left by Caesar in Egypt to Dolabella. These troops were captured by Cassius in Palestine.While Serapion, Cleopatra's governor of Cyprus, defected to Cassius and provided him with ships, Cleopatra took her own fleet to Greece to personally assist Octavian and Antony. Her ships were heavily damaged in a Mediterranean storm and she arrived too late to aid in the fighting. By the autumn of 42 BC, Antony had defeated the forces of Caesar's assassins at the Battle of Philippi in Greece, leading to the suicide of Cassius and Brutus.By the end of 42 BC, Octavian had gained control over much of the western half of the Roman Republic and Antony the eastern half, with Lepidus largely marginalized. In the summer of 41 BC, Antony established his headquarters at Tarsos in Anatolia and summoned Cleopatra there in several letters, which she rebuffed until Antony's envoy Quintus Dellius convinced her to come. The meeting would allow Cleopatra to clear up the misconception that she had supported Cassius during the civil war and address territorial exchanges in the Levant, but Antony also undoubtedly desired to form a personal, romantic relationship with the queen. Cleopatra sailed up the Kydnos River to Tarsos in Thalamegos, hosting Antony and his officers for two nights of lavish banquets on board the ship. Cleopatra managed to clear her name as a supposed supporter of Cassius, arguing she had really attempted to help Dolabella in Syria, and convinced Antony to have her exiled sister, Arsinoe IV, executed at Ephesus. Cleopatra's former rebellious governor of Cyprus was also handed over to her for execution.\n",
      "\n",
      "Relationship with Mark Antony\n",
      "Cleopatra invited Antony to come to Egypt before departing from Tarsos, which led Antony to visit Alexandria by November 41 BC. Antony was well received by the populace of Alexandria, both for his heroic actions in restoring Ptolemy XII to power and coming to Egypt without an occupation force like Caesar had done. In Egypt, Antony continued to enjoy the lavish royal lifestyle he had witnessed aboard Cleopatra's ship docked at Tarsos. He also had his subordinates, such as Publius Ventidius Bassus, drive the Parthians out of Anatolia and Syria.Cleopatra carefully chose Antony as her partner for producing further heirs, as he was deemed to be the most powerful Roman figure following Caesar's demise. With his powers as a triumvir, Antony also had the broad authority to restore former Ptolemaic lands, which were currently in Roman hands, to Cleopatra. While it is clear that both Cilicia and Cyprus were under Cleopatra's control by 19 November 38 BC, the transfer probably occurred earlier in the winter of 41–40 BC, during her time spent with Antony.By the spring of 40 BC, Antony left Egypt due to troubles in Syria, where his governor Lucius Decidius Saxa was killed and his army taken by Quintus Labienus, a former officer under Cassius who now served the Parthian Empire. Cleopatra provided Antony with 200 ships for his campaign and as payment for her newly acquired territories. She would not see Antony again until 37 BC, but she maintained correspondence, and evidence suggests she kept a spy in his camp. By the end of 40 BC, Cleopatra had given birth to twins, a boy named Alexander Helios and a girl named Cleopatra Selene II, both of whom Antony acknowledged as his children. Helios (the Sun) and Selene (the Moon) were symbolic of a new era of societal rejuvenation, as well as an indication that Cleopatra hoped Antony would repeat the exploits of Alexander the Great by conquering the Parthians.\n",
      "Mark Antony's Parthian campaign in the east was disrupted by the events of the Perusine War (41–40 BC), initiated by his ambitious wife Fulvia against Octavian in the hopes of making her husband the undisputed leader of Rome. It has been suggested that Fulvia wanted to cleave Antony away from Cleopatra, but the conflict emerged in Italy even before Cleopatra's meeting with Antony at Tarsos. Fulvia and Antony's brother Lucius Antonius were eventually besieged by Octavian at Perusia (modern Perugia, Italy) and then exiled from Italy, after which Fulvia died at Sicyon in Greece while attempting to reach Antony. Her sudden death led to a reconciliation of Octavian and Antony at Brundisium in Italy in September 40 BC. Although the agreement struck at Brundisium solidified Antony's control of the Roman Republic's territories east of the Ionian Sea, it also stipulated that he concede Italia, Hispania, and Gaul, and marry Octavian's sister Octavia the Younger, a potential rival for Cleopatra.In December 40 BC Cleopatra received Herod in Alexandria as an unexpected guest and refugee who fled a turbulent situation in Judea. Herod had been installed as a tetrarch there by Antony, but he was soon at odds with Antigonus II Mattathias of the long-established Hasmonean dynasty. The latter had imprisoned Herod's brother and fellow tetrarch Phasael, who was executed while Herod was fleeing toward Cleopatra's court. Cleopatra attempted to provide him with a military assignment, but Herod declined and traveled to Rome, where the triumvirs Octavian and Antony named him king of Judea. This act put Herod on a collision course with Cleopatra, who would desire to reclaim the former Ptolemaic territories that comprised his new Herodian kingdom.\n",
      "\n",
      "Relations between Antony and Cleopatra perhaps soured when he not only married Octavia, but also sired her two children, Antonia the Elder in 39 BC and Antonia Minor in 36 BC, and moved his headquarters to Athens. However, Cleopatra's position in Egypt was secure. Her rival Herod was occupied with civil war in Judea that required heavy Roman military assistance, but received none from Cleopatra. Since the authority of Antony and Octavian as triumvirs had expired on 1 January 37 BC, Octavia arranged for a meeting at Tarentum, where the triumvirate was officially extended to 33 BC. With two legions granted by Octavian and a thousand soldiers lent by Octavia, Antony traveled to Antioch, where he made preparations for war against the Parthians.Antony summoned Cleopatra to Antioch to discuss pressing issues, such as Herod's kingdom and financial support for his Parthian campaign. Cleopatra brought her now three-year-old twins to Antioch, where Antony saw them for the first time and where they probably first received their surnames Helios and Selene as part of Antony and Cleopatra's ambitious plans for the future. In order to stabilize the east, Antony not only enlarged Cleopatra's domain, he also established new ruling dynasties and client rulers who would be loyal to him, yet would ultimately outlast him.In this arrangement Cleopatra gained significant former Ptolemaic territories in the Levant, including nearly all of Phoenicia (Lebanon) minus Tyre and Sidon, which remained in Roman hands. She also received Ptolemais Akko (modern Acre, Israel), a city that was established by Ptolemy II. Given her ancestral relations with the Seleucids, she was granted the region of Coele-Syria along the upper Orontes River. She was even given the region surrounding Jericho in Palestine, but she leased this territory back to Herod. At the expense of the Nabataean king Malichus I (a cousin of Herod), Cleopatra was also given a portion of the Nabataean Kingdom around the Gulf of Aqaba on the Red Sea, including Ailana (modern Aqaba, Jordan). To the west Cleopatra was handed Cyrene along the Libyan coast, as well as Itanos and Olous in Roman Crete. Although still administered by Roman officials, these territories nevertheless enriched her kingdom and led her to declare the inauguration of a new era by double-dating her coinage in 36 BC.\n",
      "Antony's enlargement of the Ptolemaic realm by relinquishing directly controlled Roman territory was exploited by his rival Octavian, who tapped into the public sentiment in Rome against the empowerment of a foreign queen at the expense of their Republic. Octavian, fostering the narrative that Antony was neglecting his virtuous Roman wife Octavia, granted both her and Livia, his own wife, extraordinary privileges of sacrosanctity. Some 50 years before, Cornelia Africana, daughter of Scipio Africanus, had been the first living Roman woman to have a statue dedicated to her. She was now followed by Octavia and Livia, whose statues were most likely erected in the Forum of Caesar to rival that of Cleopatra's, erected by Caesar.In 36 BC, Cleopatra accompanied Antony to the Euphrates in his journey toward invading the Parthian Empire. She then returned to Egypt, perhaps due to her advanced state of pregnancy. By the summer of 36 BC, she had given birth to Ptolemy Philadelphus, her second son with Antony.Antony's Parthian campaign in 36 BC turned into a complete debacle for a number of reasons, in particular the betrayal of Artavasdes II of Armenia, who defected to the Parthian side. After losing some 30,000 men, more than Crassus at Carrhae (an indignity he had hoped to avenge), Antony finally arrived at Leukokome near Berytus (modern Beirut, Lebanon) in December, engaged in heavy drinking before Cleopatra arrived to provide funds and clothing for his battered troops. Antony desired to avoid the risks involved in returning to Rome, and so he traveled with Cleopatra back to Alexandria to see his newborn son.\n",
      "\n",
      "Donations of Alexandria\n",
      "As Antony prepared for another Parthian expedition in 35 BC, this time aimed at their ally Armenia, Octavia traveled to Athens with 2,000 troops in alleged support of Antony, but most likely in a scheme devised by Octavian to embarrass him for his military losses. Antony received these troops but told Octavia not to stray east of Athens as he and Cleopatra traveled together to Antioch, only to suddenly and inexplicably abandon the military campaign and head back to Alexandria. When Octavia returned to Rome Octavian portrayed his sister as a victim wronged by Antony, although she refused to leave Antony's household. Octavian's confidence grew as he eliminated his rivals in the west, including Sextus Pompeius and even Lepidus, the third member of the triumvirate, who was placed under house arrest after revolting against Octavian in Sicily.Dellius was sent as Antony's envoy to Artavasdes II in 34 BC to negotiate a potential marriage alliance that would wed the Armenian king's daughter to Alexander Helios, the son of Antony and Cleopatra. When this was declined, Antony marched his army into Armenia, defeated their forces and captured the king and Armenian royal family. Antony then held a military parade in Alexandria as an imitation of a Roman triumph, dressed as Dionysus and riding into the city on a chariot to present the royal prisoners to Cleopatra, who was seated on a golden throne above a silver dais. News of this event was heavily criticized in Rome as a perversion of time-honored Roman rites and rituals to be enjoyed instead by an Egyptian queen.\n",
      "In an event held at the gymnasium soon after the triumph, Cleopatra dressed as Isis and declared that she was the Queen of Kings with her son Caesarion, King of Kings, while Alexander Helios was declared king of Armenia, Media, and Parthia, and two-year-old Ptolemy Philadelphos was declared king of Syria and Cilicia. Cleopatra Selene II was bestowed with Crete and Cyrene. Antony and Cleopatra may have been wed during this ceremony. Antony sent a report to Rome requesting ratification of these territorial claims, now known as the Donations of Alexandria. Octavian wanted to publicize it for propaganda purposes, but the two consuls, both supporters of Antony, had it censored from public view.In late 34 BC, Antony and Octavian engaged in a heated war of propaganda that would last for years. Antony claimed that his rival had illegally deposed Lepidus from their triumvirate and barred him from raising troops in Italy, while Octavian accused Antony of unlawfully detaining the king of Armenia, marrying Cleopatra despite still being married to his sister Octavia, and wrongfully claiming Caesarion as the heir of Caesar instead of Octavian. The litany of accusations and gossip associated with this propaganda war have shaped the popular perceptions about Cleopatra from Augustan-period literature through to various media in modern times. Cleopatra was said to have brainwashed Mark Antony with witchcraft and sorcery and was as dangerous as Homer's Helen of Troy in destroying civilization. Pliny the Elder claims in his Natural History that Cleopatra once dissolved a pearl worth tens of millions of sesterces in vinegar just to win a dinner-party bet. The accusation that Antony had stolen books from the Library of Pergamum to restock the Library of Alexandria later turned out to be an admitted fabrication by Gaius Calvisius Sabinus.A papyrus document dated to February 33 BC, later used to wrap a mummy, contains the signature of Cleopatra, probably written by an official authorized to sign for her. It concerns certain tax exemptions in Egypt granted to either Quintus Caecillius or Publius Canidius Crassus, a former Roman consul and Antony's confidant who would command his land forces at Actium. A subscript in a different handwriting at the bottom of the papyrus reads \"make it happen\" or \"so be it\" (Ancient Greek: γινέσθωι, romanized: ginésthōi); this is likely the autograph of the queen, as it was Ptolemaic practice to countersign documents to avoid forgery.\n",
      "\n",
      "Battle of Actium\n",
      "In a speech to the Roman Senate on the first day of his consulship on 1 January 33 BC, Octavian accused Antony of attempting to subvert Roman freedoms and territorial integrity as a slave to his Oriental queen. Before Antony and Octavian's joint imperium expired on 31 December 33 BC, Antony declared Caesarion as the true heir of Caesar in an attempt to undermine Octavian. In 32 BC, the Antonian loyalists Gaius Sosius and Gnaeus Domitius Ahenobarbus became consuls. The former gave a fiery speech condemning Octavian, now a private citizen without public office, and introduced pieces of legislation against him. During the next senatorial session, Octavian entered the Senate house with armed guards and levied his own accusations against the consuls. Intimidated by this act, the consuls and over 200 senators still in support of Antony fled Rome the next day to join the side of Antony.Antony and Cleopatra traveled together to Ephesus in 32 BC, where she provided him with 200 of the 800 naval ships he was able to acquire. Ahenobarbus, wary of having Octavian's propaganda confirmed to the public, attempted to persuade Antony to have Cleopatra excluded from the campaign against Octavian. Publius Canidius Crassus made the counterargument that Cleopatra was funding the war effort and was a competent monarch. Cleopatra refused Antony's requests that she return to Egypt, judging that by blocking Octavian in Greece she could more easily defend Egypt. Cleopatra's insistence that she be involved in the battle for Greece led to the defections of prominent Romans, such as Ahenobarbus and Lucius Munatius Plancus.During the spring of 32 BC Antony and Cleopatra traveled to Athens, where she persuaded Antony to send Octavia an official declaration of divorce. This encouraged Plancus to advise Octavian that he should seize Antony's will, invested with the Vestal Virgins. Although a violation of sacred and legal rights, Octavian forcefully acquired the document from the Temple of Vesta, and it became a useful tool in the propaganda war against Antony and Cleopatra. Octavian highlighted parts of the will, such as Caesarion being named heir to Caesar, that the Donations of Alexandria were legal, that Antony should be buried alongside Cleopatra in Egypt instead of Rome, and that Alexandria would be made the new capital of the Roman Republic. In a show of loyalty to Rome, Octavian decided to begin construction of his own mausoleum at the Campus Martius. Octavian's legal standing was also improved by being elected consul in 31 BC. With Antony's will made public, Octavian had his casus belli, and Rome declared war on Cleopatra, not Antony. The legal argument for war was based less on Cleopatra's territorial acquisitions, with former Roman territories ruled by her children with Antony, and more on the fact that she was providing military support to a private citizen now that Antony's triumviral authority had expired.\n",
      "\n",
      "Antony and Cleopatra had a larger fleet than Octavian, but the crews of Antony and Cleopatra's navy were not all well-trained, some of them perhaps from merchant vessels, whereas Octavian had a fully professional force. Antony wanted to cross the Adriatic Sea and blockade Octavian at either Tarentum or Brundisium, but Cleopatra, concerned primarily with defending Egypt, overrode the decision to attack Italy directly. Antony and Cleopatra set up their winter headquarters at Patrai in Greece, and by the spring of 31 BC they had moved to Actium, on the southern side of the Ambracian Gulf.Cleopatra and Antony had the support of various allied kings, but Cleopatra had already been in conflict with Herod, and an earthquake in Judea provided him with an excuse to be absent from the campaign. They also lost the support of Malichus I, which would prove to have strategic consequences. Antony and Cleopatra lost several skirmishes against Octavian around Actium during the summer of 31 BC, while defections to Octavian's camp continued, including Antony's long-time companion Dellius and the allied kings Amyntas of Galatia and Deiotaros of Paphlagonia. While some in Antony's camp suggested abandoning the naval conflict to retreat inland, Cleopatra urged for a naval confrontation, to keep Octavian's fleet away from Egypt.On 2 September 31 BC the naval forces of Octavian, led by Marcus Vipsanius Agrippa, met those of Antony and Cleopatra at the Battle of Actium. Cleopatra, aboard her flagship, the Antonias, commanded 60 ships at the mouth of the Ambracian Gulf, at the rear of the fleet, in what was likely a move by Antony's officers to marginalize her during the battle. Antony had ordered that their ships should have sails on board for a better chance to pursue or flee from the enemy, which Cleopatra, ever concerned about defending Egypt, used to swiftly move through the area of major combat in a strategic withdrawal to the Peloponnese.Burstein writes that partisan Roman writers would later accuse Cleopatra of cowardly deserting Antony, but their original intention of keeping their sails on board may have been to break the blockade and salvage as much of their fleet as possible. Antony followed Cleopatra and boarded her ship, identified by its distinctive purple sails, as the two escaped the battle and headed for Tainaron. Antony reportedly avoided Cleopatra during this three-day voyage, until her ladies in waiting at Tainaron urged him to speak with her. The Battle of Actium raged on without Cleopatra and Antony until the morning of 3 September, and was followed by massive defections of officers, troops, and allied kings to Octavian's side.\n",
      "\n",
      "Downfall and death\n",
      "While Octavian occupied Athens, Antony and Cleopatra landed at Paraitonion in Egypt. The couple then went their separate ways, Antony to Cyrene to raise more troops and Cleopatra to the harbor at Alexandria in an attempt to mislead the oppositional party and portray the activities in Greece as a victory. She was afraid that news about the outcome of the battle of Actium would lead to a rebellion. It is uncertain whether or not, at this time, she actually executed Artavasdes II and sent his head to his rival, Artavasdes I of Media Atropatene, in an attempt to strike an alliance with him.Lucius Pinarius, Mark Antony's appointed governor of Cyrene, received word that Octavian had won the Battle of Actium before Antony's messengers could arrive at his court. Pinarius had these messengers executed and then defected to Octavian's side, surrendering to him the four legions under his command that Antony desired to obtain. Antony nearly committed suicide after hearing news of this but was stopped by his staff officers. In Alexandria he built a reclusive cottage on the island of Pharos that he nicknamed the Timoneion, after the philosopher Timon of Athens, who was famous for his cynicism and misanthropy. Herod, who had personally advised Antony after the Battle of Actium that he should betray Cleopatra, traveled to Rhodes to meet Octavian and resign his kingship out of loyalty to Antony. Octavian was impressed by his speech and sense of loyalty, so he allowed him to maintain his position in Judea, further isolating Antony and Cleopatra.Cleopatra perhaps started to view Antony as a liability by the late summer of 31 BC, when she prepared to leave Egypt to her son Caesarion. Cleopatra planned to relinquish her throne to him, take her fleet from the Mediterranean into the Red Sea, and then set sail to a foreign port, perhaps in India, where she could spend time recuperating. However, these plans were ultimately abandoned when Malichus I, as advised by Octavian's governor of Syria, Quintus Didius, managed to burn Cleopatra's fleet in revenge for his losses in a war with Herod that Cleopatra had largely initiated. Cleopatra had no other option but to stay in Egypt and negotiate with Octavian. Although most likely later pro-Octavian propaganda, it was reported that at this time Cleopatra started testing the strengths of various poisons on prisoners and even her own servants.\n",
      "Cleopatra had Caesarion enter into the ranks of the ephebi, which, along with reliefs on a stele from Koptos dated 21 September 31 BC, demonstrated that Cleopatra was now grooming her son to become the sole ruler of Egypt. In a show of solidarity, Antony also had Marcus Antonius Antyllus, his son with Fulvia, enter the ephebi at the same time. Separate messages and envoys from Antony and Cleopatra were then sent to Octavian, still stationed at Rhodes, although Octavian seems to have replied only to Cleopatra. Cleopatra requested that her children should inherit Egypt and that Antony should be allowed to live in exile in Egypt, offered Octavian money in the future, and immediately sent him lavish gifts. Octavian sent his diplomat Thyrsos to Cleopatra after she threatened to burn herself and vast amounts of her treasure within a tomb already under construction. Thyrsos advised her to kill Antony so that her life would be spared, but when Antony suspected foul intent, he had this diplomat flogged and sent back to Octavian without a deal.After lengthy negotiations that ultimately produced no results, Octavian set out to invade Egypt in the spring of 30 BC, stopping at Ptolemais in Phoenicia, where his new ally Herod provided his army with fresh supplies. Octavian moved south and swiftly took Pelousion, while Cornelius Gallus, marching eastward from Cyrene, defeated Antony's forces near Paraitonion. Octavian advanced quickly to Alexandria, but Antony returned and won a small victory over Octavian's tired troops outside the city's hippodrome. However, on 1 August 30 BC, Antony's naval fleet surrendered to Octavian, followed by Antony's cavalry.Cleopatra hid herself in her tomb with her close attendants and sent a message to Antony that she had committed suicide. In despair, Antony responded to this by stabbing himself in the stomach and taking his own life at age 53. According to Plutarch, he was still dying when brought to Cleopatra at her tomb, telling her he had died honorably and that she could trust Octavian's companion Gaius Proculeius over anyone else in his entourage. It was Proculeius, however, who infiltrated her tomb using a ladder and detained the queen, denying her the ability to burn herself with her treasures. Cleopatra was then allowed to embalm and bury Antony within her tomb before she was escorted to the palace.\n",
      "Octavian entered Alexandria, occupied the palace, and seized Cleopatra's three youngest children. When she met with Octavian, Cleopatra told him bluntly, \"I will not be led in a triumph\" (Ancient Greek: οὑ θριαμβεύσομαι, romanized: ou thriambéusomai), according to Livy, a rare recording of her exact words. Octavian promised that he would keep her alive but offered no explanation about his future plans for her kingdom. When a spy informed her that Octavian planned to move her and her children to Rome in three days, she prepared for suicide as she had no intentions of being paraded in a Roman triumph like her sister Arsinoe IV. It is unclear if Cleopatra's suicide on 10 August 30 BC, at age 39, took place within the palace or her tomb. It is said she was accompanied by her servants Eiras and Charmion, who also took their own lives.Octavian was said to have been angered by this outcome but had Cleopatra buried in royal fashion next to Antony in her tomb. Cleopatra's physician Olympos did not explain her cause of death, although the popular belief is that she allowed an asp or Egyptian cobra to bite and poison her. Plutarch relates this tale, but then suggests an implement (κνῆστις, knêstis, lit. 'spine, cheese-grater') was used to introduce the toxin by scratching, while Dio says that she injected the poison with a needle (βελόνη, belónē), and Strabo argued for an ointment of some kind. No venomous snake was found with her body, but she did have tiny puncture wounds on her arm that could have been caused by a needle.Cleopatra decided in her last moments to send Caesarion away to Upper Egypt, perhaps with plans to flee to Kushite Nubia, Ethiopia, or India. Caesarion, now Ptolemy XV, would reign for a mere 18 days until executed on the orders of Octavian on 29 August 30 BC, after returning to Alexandria under the false pretense that Octavian would allow him to be king. Octavian was convinced by the advice of the philosopher Arius Didymus that there was room for only one Caesar in the world. With the fall of the Ptolemaic Kingdom, the Roman province of Egypt was established, marking the end of the Hellenistic period. In January of 27 BC Octavian was renamed Augustus (\"the revered\") and amassed constitutional powers that established him as the first Roman emperor, inaugurating the Principate era of the Roman Empire.\n",
      "\n",
      "Cleopatra's kingdom and role as a monarch\n",
      "Following the tradition of Macedonian rulers, Cleopatra ruled Egypt and other territories such as Cyprus as an absolute monarch, serving as the sole lawgiver of her kingdom. She was the chief religious authority in her realm, presiding over religious ceremonies dedicated to the deities of both the Egyptian and Greek polytheistic faiths. She oversaw the construction of various temples to Egyptian and Greek gods, a synagogue for the Jews in Egypt, and even built the Caesareum of Alexandria, dedicated to the cult worship of her patron and lover Julius Caesar.Cleopatra was directly involved in the administrative affairs of her domain, tackling crises such as famine by ordering royal granaries to distribute food to the starving populace during a drought at the beginning of her reign. Although the command economy that she managed was more of an ideal than a reality, the government attempted to impose price controls, tariffs, and state monopolies for certain goods, fixed exchange rates for foreign currencies, and rigid laws forcing peasant farmers to stay in their villages during planting and harvesting seasons. Apparent financial troubles led Cleopatra to debase her coinage, which included silver and bronze currencies but no gold coins like those of some of her distant Ptolemaic predecessors.\n",
      "\n",
      "Legacy\n",
      "Children and successors\n",
      "After her suicide, Cleopatra's three surviving children, Cleopatra Selene II, Alexander Helios, and Ptolemy Philadelphos, were sent to Rome with Octavian's sister Octavia the Younger, a former wife of their father, as their guardian. Cleopatra Selene II and Alexander Helios were present in the Roman triumph of Octavian in 29 BC. The fates of Alexander Helios and Ptolemy Philadelphus are unknown after this point. Octavia arranged the betrothal of Cleopatra Selene II to Juba II, son of Juba I, whose North African kingdom of Numidia had been turned into a Roman province in 46 BC by Julius Caesar due to Juba I's support of Pompey.The emperor Augustus installed Juba II and Cleopatra Selene II, after their wedding in 25 BC, as the new rulers of Mauretania, where they transformed the old Carthaginian city of Iol into their new capital, renamed Caesarea Mauretaniae (modern Cherchell, Algeria). Cleopatra Selene II imported many important scholars, artists, and advisers from her mother's royal court in Alexandria to serve her in Caesarea, now permeated in Hellenistic Greek culture. She also named her son Ptolemy of Mauretania, in honor of their Ptolemaic dynastic heritage.Cleopatra Selene II died c. 5 BC, and when Juba II died in 23/24 AD he was succeeded by his son Ptolemy. However, Ptolemy was eventually executed by the Roman emperor Caligula in 40 AD, perhaps under the pretense that Ptolemy had unlawfully minted his own royal coinage and utilized regalia reserved for the Roman emperor. Ptolemy of Mauretania was the last known monarch of the Ptolemaic dynasty, although Queen Zenobia, of the short-lived Palmyrene Empire during the Crisis of the Third Century, would claim descent from Cleopatra. A cult dedicated to Cleopatra still existed as late as 373 AD when Petesenufe, an Egyptian scribe of the book of Isis, explained that he \"overlaid the figure of Cleopatra with gold.\"\n",
      "\n",
      "Roman literature and historiography\n",
      "Although almost 50 ancient works of Roman historiography mention Cleopatra, these often include only terse accounts of the Battle of Actium, her suicide, and Augustan propaganda about her personal deficiencies. Despite not being a biography of Cleopatra, the Life of Antonius written by Plutarch in the 1st century AD provides the most thorough surviving account of Cleopatra's life. Plutarch lived a century after Cleopatra but relied on primary sources, such as Philotas of Amphissa, who had access to the Ptolemaic royal palace, Cleopatra's personal physician named Olympos, and Quintus Dellius, a close confidant of Mark Antony and Cleopatra. Plutarch's work included both the Augustan view of Cleopatra—which became canonical for his period—as well as sources outside of this tradition, such as eyewitness reports.The Jewish Roman historian Josephus, writing in the 1st century AD, provides valuable information on the life of Cleopatra via her diplomatic relationship with Herod the Great. However, this work relies largely on Herod's memoirs and the biased account of Nicolaus of Damascus, the tutor of Cleopatra's children in Alexandria before he moved to Judea to serve as an adviser and chronicler at Herod's court. The Roman History published by the official and historian Cassius Dio in the early 3rd century AD, while failing to fully comprehend the complexities of the late Hellenistic world, nevertheless provides a continuous history of the era of Cleopatra's reign.\n",
      "Cleopatra is barely mentioned in De Bello Alexandrino, the memoirs of an unknown staff officer who served under Caesar. The writings of Cicero, who knew her personally, provide an unflattering portrait of Cleopatra. The Augustan-period authors Virgil, Horace, Propertius, and Ovid perpetuated the negative views of Cleopatra approved by the ruling Roman regime, although Virgil established the idea of Cleopatra as a figure of romance and epic melodrama. Horace also viewed Cleopatra's suicide as a positive choice, an idea that found acceptance by the Late Middle Ages with Geoffrey Chaucer.The historians Strabo, Velleius, Valerius Maximus, Pliny the Elder, and Appian, while not offering accounts as full as Plutarch, Josephus, or Dio, provided some details of her life that had not survived in other historical records. Inscriptions on contemporary Ptolemaic coinage and some Egyptian papyrus documents demonstrate Cleopatra's point of view, but this material is very limited in comparison to Roman literary works. The fragmentary Libyka commissioned by Cleopatra's son-in-law Juba II provides a glimpse at a possible body of historiographic material that supported Cleopatra's perspective.Cleopatra's gender has perhaps led to her depiction as a minor if not insignificant figure in ancient, medieval, and even modern historiography about ancient Egypt and the Greco-Roman world. For instance, the historian Ronald Syme asserted that she was of little importance to Caesar and that the propaganda of Octavian magnified her importance to an excessive degree. Although the common view of Cleopatra was one of a prolific seductress, she had only two known sexual partners, Caesar and Antony, the two most prominent Romans of the time period, who were most likely to ensure the survival of her dynasty. Plutarch described Cleopatra as having had a stronger personality and charming wit than physical beauty.\n",
      "\n",
      "Cultural depictions\n",
      "Depictions in ancient art\n",
      "Statues\n",
      "Cleopatra was depicted in various ancient works of art, in the Egyptian as well as Hellenistic-Greek and Roman styles. Surviving works include statues, busts, reliefs, and minted coins, as well as ancient carved cameos, such as one depicting Cleopatra and Antony in Hellenistic style, now in the Altes Museum, Berlin. Contemporary images of Cleopatra were produced both in and outside of Ptolemaic Egypt. For instance, there was once a large gilded bronze statue of Cleopatra inside the Temple of Venus Genetrix in Rome, the first time that a living person had their statue placed next to that of a deity in a Roman temple. It was erected there by Caesar and remained in the temple at least until the 3rd century AD, its preservation perhaps owing to Caesar's patronage, although Augustus did not remove or destroy artworks in Alexandria depicting Cleopatra.A life-sized Roman-style statue of Cleopatra was found near the Tomba di Nerone, Rome, along the Via Cassia, and is now housed in the Museo Pio-Clementino, part of the Vatican Museums. Plutarch, in his Life of Antonius, said that the public statues of Antony were torn down by Augustus, but those of Cleopatra were preserved following her death thanks to her friend Archibius paying the emperor 2,000 talents to dissuade him from destroying hers.Since the 1950s scholars have debated whether or not the Esquiline Venus—discovered in 1874 on the Esquiline Hill in Rome and housed in the Palazzo dei Conservatori of the Capitoline Museums—is a depiction of Cleopatra, based on the statue's hairstyle and facial features, apparent royal diadem worn over the head, and the uraeus Egyptian cobra wrapped around the base. Detractors of this theory argue that the face in this statue is thinner than the face on the Berlin portrait and assert that it was unlikely she would be depicted as the naked goddess Venus (or the Greek Aphrodite). However, she was depicted in an Egyptian statue as the goddess Isis, while some of her coinage depicts her as Venus-Aphrodite. She also dressed as Aphrodite when meeting Antony at Tarsos. The Esquiline Venus is generally thought to be a mid-1st-century AD Roman copy of a 1st-century BC Greek original from the school of Pasiteles.\n",
      "\n",
      "Coinage portraits\n",
      "Surviving coinage of Cleopatra's reign include specimens from every regnal year, from 51 to 30 BC. Cleopatra, the only Ptolemaic queen to issue coins on her own behalf, almost certainly inspired her partner Caesar to become the first living Roman to present his portrait on his own coins. Cleopatra was the first foreign queen to have her image appear on Roman currency. Coins dated to the period of her marriage to Antony, which also bear his image, portray the queen as having a very similar aquiline nose and prominent chin as that of her husband. These similar facial features followed an artistic convention that represented the mutually-observed harmony of a royal couple.Her strong, almost masculine facial features in these particular coins are strikingly different from the smoother, softer, and perhaps idealized sculpted images of her in either the Egyptian or Hellenistic styles. Her masculine facial features on minted currency are similar to that of her father, Ptolemy XII Auletes, and perhaps also to those of her Ptolemaic ancestor Arsinoe II (316–260 BC) and even depictions of earlier queens such as Hatshepsut and Nefertiti. It is likely, due to political expediency, that Antony's visage was made to conform not only to hers but also to those of her Macedonian Greek ancestors who founded the Ptolemaic dynasty, to familiarize himself to her subjects as a legitimate member of the royal house.The inscriptions on the coins are written in Greek, but also in the nominative case of Roman coins rather than the genitive case of Greek coins, in addition to having the letters placed in a circular fashion along the edges of the coin instead of across it horizontally or vertically as was customary for Greek ones. These facets of their coinage represent the synthesis of Roman and Hellenistic culture, and perhaps also a statement to their subjects, however ambiguous to modern scholars, about the superiority of either Antony or Cleopatra over the other. Diana Kleiner argues that Cleopatra, in one of her coins minted with the dual image of her husband Antony, made herself more masculine-looking than other portraits and more like an acceptable Roman client queen than a Hellenistic ruler. Cleopatra had actually achieved this masculine look in coinage predating her affair with Antony, such as the coins struck at the Ascalon mint during her brief period of exile to Syria and the Levant, which Joann Fletcher explains as her attempt to appear like her father and as a legitimate successor to a male Ptolemaic ruler.Various coins, such as a silver tetradrachm minted sometime after Cleopatra's marriage with Antony in 37 BC, depict her wearing a royal diadem and a 'melon' hairstyle. The combination of this hairstyle with a diadem is also featured in two surviving sculpted marble heads. This hairstyle, with hair braided back into a bun, is the same as that worn by her Ptolemaic ancestors Arsinoe II and Berenice II in their own coinage. After her visit to Rome in 46–44 BC it became fashionable for Roman women to adopt it as one of their hairstyles, but it was abandoned for a more modest, austere look during the conservative rule of Augustus.\n",
      "\n",
      "Greco-Roman busts and heads\n",
      "Of the surviving Greco-Roman-style busts and heads of Cleopatra, the sculpture known as the \"Berlin Cleopatra\", located in the Antikensammlung Berlin collection at the Altes Museum, possesses her full nose, whereas the head known as the \"Vatican Cleopatra\", located in the Vatican Museums, is damaged with a missing nose. Both the Berlin Cleopatra and Vatican Cleopatra have royal diadems, similar facial features, and perhaps once resembled the face of her bronze statue housed in the Temple of Venus Genetrix.Both heads are dated to the mid-1st century BC and were found in Roman villas along the Via Appia in Italy, the Vatican Cleopatra having been unearthed in the Villa of the Quintilii. Francisco Pina Polo writes that Cleopatra's coinage present her image with certainty and asserts that the sculpted portrait of the Berlin head is confirmed as having a similar profile with her hair pulled back into a bun, a diadem, and a hooked nose.A third sculpted portrait of Cleopatra accepted by scholars as being authentic survives at the Archaeological Museum of Cherchell, Algeria. This portrait features the royal diadem and similar facial features as the Berlin and Vatican heads, but has a more unique hairstyle and may actually depict Cleopatra Selene II, daughter of Cleopatra. A possible Parian-marble sculpture of Cleopatra wearing a vulture headdress in Egyptian style is located at the Capitoline Museums. Discovered near a sanctuary of Isis in Rome and dated to the 1st century BC, it is either Roman or Hellenistic-Egyptian in origin.Other possible sculpted depictions of Cleopatra include one in the British Museum, London, made of limestone, which perhaps only depicts a woman in her entourage during her trip to Rome. The woman in this portrait has facial features similar to others (including the pronounced aquiline nose), but lacks a royal diadem and sports a different hairstyle. However, the British Museum head, once belonging to a full statue, could potentially represent Cleopatra at a different stage in her life and may also betray an effort by Cleopatra to discard the use of royal insignia (i.e. the diadem) to make herself more appealing to the citizens of Republican Rome. Duane W. Roller speculates that the British Museum head, along with those in the Egyptian Museum, Cairo, the Capitoline Museums, and in the private collection of Maurice Nahmen, while having similar facial features and hairstyles as the Berlin portrait but lacking a royal diadem, most likely represent members of the royal court or even Roman women imitating Cleopatra's popular hairstyle.\n",
      "\n",
      "Paintings\n",
      "In the House of Marcus Fabius Rufus at Pompeii, Italy, a mid-1st century BC Second Style wall painting of the goddess Venus holding a cupid near massive temple doors is most likely a depiction of Cleopatra as Venus Genetrix with her son Caesarion. The commission of the painting most likely coincides with the erection of the Temple of Venus Genetrix in the Forum of Caesar in September 46 BC, where Caesar had a gilded statue erected depicting Cleopatra. This statue likely formed the basis of her depictions in both sculpted art as well as this painting at Pompeii.The woman in the painting wears a royal diadem over her head and is strikingly similar in appearance to the Vatican Cleopatra, which bears possible marks on the marble of its left cheek where a cupid's arm may have been torn off. The room with the painting was walled off by its owner, perhaps in reaction to the execution of Caesarion in 30 BC by order of Octavian, when public depictions of Cleopatra's son would have been unfavorable with the new Roman regime.Behind her golden diadem, crowned with a red jewel, is a translucent veil with crinkles that suggest the \"melon\" hairstyle favored by the queen. Her ivory-white skin, round face, long aquiline nose, and large round eyes were features common in both Roman and Ptolemaic depictions of deities. Roller affirms that \"there seems little doubt that this is a depiction of Cleopatra and Caesarion before the doors of the Temple of Venus in the Forum Julium and, as such, it becomes the only extant contemporary painting of the queen.\"\n",
      "\n",
      "Another painting from Pompeii, dated to the early 1st century AD and located in the House of Giuseppe II, contains a possible depiction of Cleopatra with her son Caesarion, both wearing royal diadems while she reclines and consumes poison in an act of suicide. The painting was originally thought to depict the Carthaginian noblewoman Sophonisba, who toward the end of the Second Punic War (218–201 BC) drank poison and committed suicide at the behest of her lover Masinissa, King of Numidia. Arguments in favor of it depicting Cleopatra include the strong connection of her house with that of the Numidian royal family, Masinissa and Ptolemy VIII Physcon having been associates, and Cleopatra's own daughter marrying the Numidian prince Juba II.Sophonisba was also a more obscure figure when the painting was made, while Cleopatra's suicide was far more famous. An asp is absent from the painting, but many Romans held the view that she received poison in another manner than a venomous snakebite. A set of double doors on the rear wall of the painting, positioned very high above the people in it, suggests the described layout of Cleopatra's tomb in Alexandria. A male servant holds the mouth of an artificial Egyptian crocodile (possibly an elaborate tray handle), while another man standing by is dressed as a Roman.In 1818 a now lost encaustic painting was discovered in the Temple of Serapis at Hadrian's Villa, near Tivoli, Lazio, Italy, that depicted Cleopatra committing suicide with an asp biting her bare chest. A chemical analysis performed in 1822 confirmed that the medium for the painting was composed of one-third wax and two-thirds resin. The thickness of the painting over Cleopatra's bare flesh and her drapery were reportedly similar to the paintings of the Fayum mummy portraits. A steel engraving published by John Sartain in 1885 depicting the painting as described in the archaeological report shows Cleopatra wearing authentic clothing and jewelry of Egypt in the late Hellenistic period, as well as the radiant crown of the Ptolemaic rulers, as seen in their portraits on various coins minted during their respective reigns. After Cleopatra's suicide, Octavian commissioned a painting to be made depicting her being bitten by a snake, parading this image in her stead during his triumphal procession in Rome. The portrait painting of Cleopatra's death was perhaps among the great number of artworks and treasures taken from Rome by Emperor Hadrian to decorate his private villa, where it was found in an Egyptian temple.\n",
      "\n",
      "A Roman panel painting from Herculaneum, Italy, dated to the 1st century AD possibly depicts Cleopatra. In it she wears a royal diadem, red or reddish-brown hair pulled back into a bun, pearl-studded hairpins, and earrings with ball-shaped pendants, the white skin of her face and neck set against a stark black background. Her hair and facial features are similar to those in the sculpted Berlin and Vatican portraits as well as her coinage. A highly similar painted bust of a woman with a blue headband in the House of the Orchard at Pompeii features Egyptian-style imagery, such as a Greek-style sphinx, and may have been created by the same artist.\n",
      "\n",
      "Portland Vase\n",
      "The Portland Vase, a Roman cameo glass vase dated to the Augustan period and now in the British Museum, includes a possible depiction of Cleopatra with Antony. In this interpretation, Cleopatra can be seen grasping Antony and drawing him toward her while a serpent (i.e. the asp) rises between her legs, Eros floats above, and Anton, the alleged ancestor of the Antonian family, looks on in despair as his descendant Antony is led to his doom. The other side of the vase perhaps contains a scene of Octavia, abandoned by her husband Antony but watched over by her brother, the emperor Augustus. The vase would thus have been created no earlier than 35 BC, when Antony sent his wife Octavia back to Italy and stayed with Cleopatra in Alexandria.\n",
      "\n",
      "Native Egyptian art\n",
      "The Bust of Cleopatra in the Royal Ontario Museum represents a bust of Cleopatra in the Egyptian style. Dated to the mid-1st century BC, it is perhaps the earliest depiction of Cleopatra as both a goddess and ruling pharaoh of Egypt. The sculpture also has pronounced eyes that share similarities with Roman copies of Ptolemaic sculpted works of art. The Dendera Temple complex, near Dendera, Egypt, contains Egyptian-style carved relief images along the exterior walls of the Temple of Hathor depicting Cleopatra and her young son Caesarion as a grown adult and ruling pharaoh making offerings to the gods. Augustus had his name inscribed there following the death of Cleopatra.A large Ptolemaic black basalt statue measuring 104 centimetres (41 in) in height, now in the Hermitage Museum, Saint Petersburg, is thought to represent Arsinoe II, wife of Ptolemy II, but recent analysis has indicated that it could depict her descendant Cleopatra due to the three uraei adorning her headdress, an increase from the two used by Arsinoe II to symbolize her rule over Lower and Upper Egypt. The woman in the basalt statue also holds a divided, double cornucopia (dikeras), which can be seen on coins of both Arsinoe II and Cleopatra. In his Kleopatra und die Caesaren (2006), Bernard Andreae contends that this basalt statue, like other idealized Egyptian portraits of the queen, does not contain realistic facial features and hence adds little to the knowledge of her appearance. Adrian Goldsworthy writes that, despite these representations in the traditional Egyptian style, Cleopatra would have dressed as a native only \"perhaps for certain rites\" and instead would usually dress as a Greek monarch, which would include the Greek headband seen in her Greco-Roman busts.\n",
      "\n",
      "Medieval and Early Modern reception\n",
      "In modern times Cleopatra has become an icon of popular culture, a reputation shaped by theatrical representations dating back to the Renaissance as well as paintings and films. This material largely surpasses the scope and size of existent historiographic literature about her from classical antiquity and has made a greater impact on the general public's view of Cleopatra than the latter. The 14th-century English poet Geoffrey Chaucer, in The Legend of Good Women, contextualized Cleopatra for the Christian world of the Middle Ages. His depiction of Cleopatra and Antony, her shining knight engaged in courtly love, has been interpreted in modern times as being either playful or misogynistic satire.Chaucer highlighted Cleopatra's relationships with only two men as hardly the life of a seductress and wrote his works partly in reaction to the negative depiction of Cleopatra in De Mulieribus Claris and De Casibus Virorum Illustrium, Latin works by the 14th-century Italian poet Giovanni Boccaccio. The Renaissance humanist Bernardino Cacciante, in his 1504 Libretto apologetico delle donne, was the first Italian to defend the reputation of Cleopatra and criticize the perceived moralizing and misogyny in Boccaccio's works. Works of Islamic historiography written in Arabic covered the reign of Cleopatra, such as the 10th-century Meadows of Gold by Al-Masudi, although his work erroneously claimed that Octavian died soon after Cleopatra's suicide.Cleopatra appeared in miniatures for illuminated manuscripts, such as a depiction of her and Antony lying in a Gothic-style tomb by the Boucicaut Master in 1409. In the visual arts, the sculpted depiction of Cleopatra as a free-standing nude figure committing suicide began with the 16th-century sculptors Bartolommeo Bandinelli and Alessandro Vittoria. Early prints depicting Cleopatra include designs by the Renaissance artists Raphael and Michelangelo, as well as 15th-century woodcuts in illustrated editions of Boccaccio's works.In the performing arts, the death of Elizabeth I of England in 1603, and the German publication in 1606 of alleged letters of Cleopatra, inspired Samuel Daniel to alter and republish his 1594 play Cleopatra in 1607. He was followed by William Shakespeare, whose Antony and Cleopatra, largely based on Plutarch, was first performed in 1608 and provided a somewhat salacious view of Cleopatra in stark contrast to England's own Virgin Queen. Cleopatra was also featured in operas, such as George Frideric Handel's 1724 Giulio Cesare in Egitto, which portrayed the love affair of Caesar and Cleopatra; Domenico Cimarosa wrote Cleopatra on a similar subject in 1789.\n",
      "\n",
      "Modern depictions and brand imaging\n",
      "In Victorian Britain, Cleopatra was highly associated with many aspects of ancient Egyptian culture and her image was used to market various household products, including oil lamps, lithographs, postcards and cigarettes. Fictional novels such as H. Rider Haggard's Cleopatra (1889) and Théophile Gautier's One of Cleopatra's Nights (1838) depicted the queen as a sensual and mystic Easterner, while the Egyptologist Georg Ebers's Cleopatra (1894) was more grounded in historical accuracy. The French dramatist Victorien Sardou and Irish playwright George Bernard Shaw produced plays about Cleopatra, while burlesque shows such as F. C. Burnand's Antony and Cleopatra offered satirical depictions of the queen connecting her and the environment she lived in with the modern age.Shakespeare's Antony and Cleopatra was considered canonical by the Victorian era. Its popularity led to the perception that the 1885 painting by Lawrence Alma-Tadema depicted the meeting of Antony and Cleopatra on her pleasure barge in Tarsus, although Alma-Tadema revealed in a private letter that it depicts a subsequent meeting of theirs in Alexandria. Also based on Shakespeare's play was Samuel Barber's opera Antony and Cleopatra (1966), commissioned for the opening of the Metropolitan Opera House. In his unfinished 1825 short story The Egyptian Nights, Alexander Pushkin popularized the claims of the 4th-century Roman historian Aurelius Victor, previously largely ignored, that Cleopatra had prostituted herself to men who paid for sex with their lives. Cleopatra also became appreciated outside the Western world and Middle East, as the Qing-dynasty Chinese scholar Yan Fu wrote an extensive biography of her.Georges Méliès's Robbing Cleopatra's Tomb (French: Cléopâtre), an 1899 French silent horror film, was the first film to depict the character of Cleopatra. Hollywood films of the 20th century were influenced by earlier Victorian media, which helped to shape the character of Cleopatra played by Theda Bara in Cleopatra (1917), Claudette Colbert in Cleopatra (1934), and Elizabeth Taylor in Cleopatra (1963). In addition to her portrayal as a \"vampire\" queen, Bara's Cleopatra also incorporated tropes familiar from 19th-century Orientalist painting, such as despotic behavior, mixed with dangerous and overt female sexuality. Colbert's character of Cleopatra served as a glamour model for selling Egyptian-themed products in department stores in the 1930s, targeting female moviegoers. In preparation for the film starring Taylor as Cleopatra, women's magazines of the early 1960s advertised how to use makeup, clothes, jewelry, and hairstyles to achieve the \"Egyptian\" look similar to the queens Cleopatra and Nefertiti. By the end of the 20th century there were forty-three films, two hundred plays and novels, forty-five operas, and five ballets associated with Cleopatra.\n",
      "\n",
      "Written works\n",
      "Whereas myths about Cleopatra persist in popular media, important aspects of her career go largely unnoticed, such as her command of naval forces and administrative acts. Publications on ancient Greek medicine attributed to her are, likely to be the work of a physician by the same name writing in the late first century AD. Ingrid D. Rowland, who highlights that the \"Berenice called Cleopatra\" cited by the 3rd- or 4th-century female Roman physician Metrodora was likely conflated by medieval scholars as referring to Cleopatra. Only fragments exist of these medical and cosmetic writings, such as those preserved by Galen, including remedies for hair disease, baldness, and dandruff, along with a list of weights and measures for pharmacological purposes. Aëtius of Amida attributed a recipe for perfumed soap to Cleopatra, while Paul of Aegina preserved alleged instructions of hers for dyeing and curling hair.\n",
      "\n",
      "Ancestry\n",
      "Cleopatra belonged to the Macedonian Greek dynasty of the Ptolemies, their European origins tracing back to northern Greece. Through her father, Ptolemy XII Auletes, she was a descendant of two prominent companions of Alexander the Great of Macedon: the general Ptolemy I Soter, founder of the Ptolemaic Kingdom of Egypt, and Seleucus I Nicator, the Macedonian Greek founder of the Seleucid Empire of West Asia. While Cleopatra's paternal line can be traced, the identity of her mother is uncertain. She was presumably the daughter of Cleopatra V Tryphaena, the sister-wife of Ptolemy XII who had previously given birth to their daughter Berenice IV.Cleopatra I Syra was the only member of the Ptolemaic dynasty known for certain to have introduced some non-Greek ancestry. Her mother Laodice III was a daughter born to King Mithridates II of Pontus, a Persian of the Mithridatic dynasty, and his wife Laodice who had a mixed Greek-Persian heritage. Cleopatra I Syra's father Antiochus III the Great was a descendant of Queen Apama, the Sogdian Iranian wife of Seleucus I Nicator. It is generally believed that the Ptolemies did not intermarry with native Egyptians. Michael Grant asserts that there is only one known Egyptian mistress of a Ptolemy and no known Egyptian wife of a Ptolemy, further arguing that Cleopatra probably did not have any Egyptian ancestry and \"would have described herself as Greek.\"Stacy Schiff writes that Cleopatra was a Macedonian Greek with some Persian ancestry, arguing that it was rare for the Ptolemies to have an Egyptian mistress. Duane W. Roller speculates that Cleopatra could have been the daughter of a theoretical half-Macedonian-Greek, half-Egyptian woman from Memphis in northern Egypt belonging to a family of priests dedicated to Ptah (a hypothesis not generally accepted in scholarship), but contends that whatever Cleopatra's ancestry, she valued her Greek Ptolemaic heritage the most. Ernle Bradford writes that Cleopatra challenged Rome not as an Egyptian woman \"but as a civilized Greek.\"Claims that Cleopatra was an illegitimate child never appeared in Roman propaganda against her. Strabo was the only ancient historian who claimed that Ptolemy XII's children born after Berenice IV, including Cleopatra, were illegitimate. Cleopatra V (or VI) was expelled from the court of Ptolemy XII in late 69 BC, a few months after the birth of Cleopatra, while Ptolemy XII's three younger children were all born during the absence of his wife. The high degree of inbreeding among the Ptolemies is also illustrated by Cleopatra's immediate ancestry, of which a reconstruction is shown below.The family tree given below also lists Cleopatra V as a daughter of Ptolemy X Alexander I and Berenice III. This would make her a cousin of her husband, Ptolemy XII, but she could have been a daughter of Ptolemy IX Lathyros, which would have made her a sister-wife of Ptolemy XII instead. The confused accounts in ancient primary sources have also led scholars to number Ptolemy XII's wife as either Cleopatra V or Cleopatra VI; the latter may have actually been a daughter of Ptolemy XII. Fletcher and John Whitehorne assert that this is a possible indication Cleopatra V had died in 69 BC rather than reappearing as a co-ruler with Berenice IV in 58 BC (during Ptolemy XII's exile in Rome).\n",
      "\n",
      "See also\n",
      "List of female hereditary monarchs\n",
      "\n",
      "Notes\n",
      "References\n",
      "Sources\n",
      "Online\n",
      "Print\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "Ancient Roman depictions of Cleopatra VII of Egypt, at YouTube\n",
      "Cleopatra on In Our Time at the BBC\n",
      "Jacob Abbott (1852). Cleopatra at Project Gutenberg, a Victorian children's book\n",
      "\"Mysterious Death of Cleopatra\" at the Discovery Channel\n",
      "Cleopatra VII at BBC History\n",
      "Cleopatra VII at World History Encyclopedia\n",
      "Eubanks, W. Ralph. (1 November 2010). \"How History and Hollywood Got 'Cleopatra' Wrong\". National Public Radio (NPR) (a book review of Cleopatra: A Life, by Stacy Schiff).\n",
      "Jarus, Owen (13 March 2014). \"Cleopatra: Facts & Biography\". Live Science.\n",
      "Watkins, Thayer. \"The Timeline of the Life of Cleopatra Archived 13 August 2021 at the Wayback Machine.\" San Jose State University.\n",
      "Draycott, Jane (22 May 2018). \"Cleopatra's Daughter: While Antony and Cleopatra have been immortalised in history and in popular culture, their offspring have been all but forgotten. Their daughter, Cleopatra Selene, became an important ruler in her own right\". History Today.Artificial neural networks (ANNs, also shortened to neural networks (NNs) or neural nets) are a branch of machine learning models that are built using principles of neuronal organization discovered by connectionism in the biological neural networks constituting animal brains.An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The \"signal\" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold.\n",
      "Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times.\n",
      "\n",
      "A network is typically called a deep neural network if it has at least 2 hidden layers.\n",
      "\n",
      "Training\n",
      "Neural networks are typically trained through empirical risk minimization. This method is based on the idea of optimizing the network's parameters to minimize the difference, or empirical risk, between the predicted output and the actual target values in a given dataset. Gradient based methods such as backpropagation are usually used to estimate the parameters of the network. During the training phase, ANNs learn from labeled training data by iteratively updating their parameters to minimize a defined loss function. This method allows the network to generalize to unseen data.\n",
      "\n",
      "History\n",
      "The simplest kind of feedforward neural network (FNN) is a linear network, which consists of a single layer of output nodes; the inputs are fed directly to the outputs via a series of weights. The sum of the products of the weights and the inputs is calculated at each node. The mean squared errors between these calculated outputs and the given target values are minimized by creating an adjustment to the weights. This technique has been known for over two centuries as the method of least squares or linear regression. It was used as a means of finding a good rough linear fit to a set of points by Legendre (1805) and Gauss (1795) for the prediction of planetary movement.Wilhelm Lenz and Ernst Ising created and analyzed the Ising model (1925) which is essentially a non-learning artificial recurrent neural network (RNN) consisting of neuron-like threshold elements. In 1972, Shun'ichi Amari made this architecture adaptive. His learning RNN was popularised by John Hopfield in 1982.Warren McCulloch and Walter Pitts (1943) also considered a non-learning computational model for neural networks. In the late 1940s, D. O. Hebb created a learning hypothesis based on the mechanism of neural plasticity that became known as Hebbian learning. Farley and Wesley A. Clark (1954) first used computational machines, then called \"calculators\", to simulate a Hebbian network. In 1958, psychologist Frank Rosenblatt invented the perceptron, the first implemented artificial neural network, funded by the United States Office of Naval Research.\n",
      "The invention of the perceptron raised public excitement for research in Artificial Neural Networks, causing the US government to drastically increase funding into deep learning research. This led to \"the golden age of AI\" fueled by the optimistic claims made by computer scientists regarding the ability of perceptrons to emulate human intelligence. For example, in 1957 Herbert Simon famously said:It is not my aim to surprise or shock you—but the simplest way I can summarize is to say that there are now in the world machines that think, that learn and that create. Moreover, their ability to do these things is going to increase rapidly until—in a visible future—the range of problems they can handle will be coextensive with the range to which the human mind has been applied.However, this wasn't the case as research stagnated following the work of Minsky and Papert (1969), who discovered that basic perceptrons were incapable of processing the exclusive-or circuit and that computers lacked sufficient power to train useful neural networks. This, along with other factors such as the 1973 Lighthill report by James Lighthill stating that research in Artificial Intelligence has not \"produced the major impact that was then promised,\" shutting funding in research into the field of AI in all but two universities in the UK and in many major institutions across the world. This ushered an era called the AI Winter with reduced research into connectionism due to a decrease in government funding and an increased stress on symbolic artificial intelligence in the United States and other Western countries.During the AI Winter era, however, research outside the United States continued, especially in Eastern Europe. By the time Minsky and Papert's book on Perceptrons came out, methods for training multilayer perceptrons (MLPs) were already known. The first deep learning Multi Layer Perceptron (MLP) was published by Alexey Grigorevich Ivakhnenko and Valentin Lapa in 1965, as the Group Method of Data Handling. The first deep learning MLP trained by stochastic gradient descent was published in 1967 by Shun'ichi Amari. In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned useful internal representations to classify non-linearily separable pattern classes.Self-organizing maps (SOMs) were described by Teuvo Kohonen in 1982. SOMs are neurophysiologically inspired neural networks that learn low-dimensional representations of high-dimensional data while preserving the topological structure of the data. They are trained using competitive learning.The convolutional neural network (CNN) architecture with convolutional layers and downsampling layers was introduced by Kunihiko Fukushima in 1980. He called it the neocognitron. In 1969, he also introduced the ReLU (rectified linear unit) activation function. The rectifier has become the most popular activation function for CNNs and  deep neural networks in general. CNNs have become an essential tool for computer vision.\n",
      "The backpropagation algorithm is an efficient application of the Leibniz chain rule (1673) to networks of differentiable nodes. It is also known as \n",
      "the reverse mode of automatic differentiation or reverse accumulation, due to Seppo Linnainmaa (1970). The term \"back-propagating errors\" was introduced in 1962 by Frank Rosenblatt, but he did not have an implementation of this procedure, although Henry J. Kelley and Bryson had dynamic programming based continuous precursors of backpropagation already in 1960–61 in the context of control theory. \n",
      "In 1973, Dreyfus used backpropagation to adapt parameters of controllers in proportion to error gradients. \n",
      "In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard. In 1986 Rumelhart, Hinton and Williams showed that backpropagation learned interesting internal representations of words as feature vectors when trained to predict the next word in a sequence.The time delay neural network (TDNN) of Alex Waibel (1987) combined convolutions and weight sharing and backpropagation.  In 1988, Wei Zhang et al. applied backpropagation to a CNN (a simplified Neocognitron with convolutional interconnections between the image feature layers and the last fully connected layer) for alphabet recognition. In 1989, Yann LeCun et al. trained a CNN to recognize handwritten ZIP codes on mail. \n",
      "In 1992, max-pooling for CNNs was introduced by Juan Weng et al. to help with least-shift invariance and tolerance to deformation to aid 3D object recognition. \n",
      "LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks digitized in 32x32 pixel images.\n",
      "From 1988 onward, the use of neural networks transformed the field of protein structure prediction, in particular when the first cascading networks were trained on profiles (matrices) produced by multiple sequence alignments.In the 1980s, backpropagation did not work well for deep FNNs and RNNs. To overcome this problem, Juergen Schmidhuber (1992) proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning. It uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by distilling a higher level chunker network into a lower level automatizer network. In 1993, a chunker solved a deep learning task whose depth exceeded 1000.In 1992, Juergen Schmidhuber also published an alternative to RNNs which is now called a linear Transformer or a  Transformer with linearized self-attention (save for a normalization operator). It learns internal spotlights of attention: a slow feedforward neural network learns by gradient descent to control the fast weights of another neural network through outer products of self-generated activation patterns FROM and TO (which are now called key and value for self-attention). This fast weight attention mapping is applied to a query pattern.\n",
      "The modern Transformer was introduced by Ashish Vaswani et al. in their 2017 paper \"Attention Is All You Need.\" \n",
      "It combines this with a softmax operator and a projection matrix.\n",
      "Transformers have increasingly become the model of choice for natural language processing. Many modern large language models such as ChatGPT, GPT-4, and BERT use it. Transformers are also increasingly being used in computer vision.In 1991, Juergen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network's gain is the other network's loss. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity.\"\n",
      "In 2014, this principle was used in a generative adversarial network (GAN) by Ian Goodfellow et al. Here the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set. This can be used to create realistic deepfakes.\n",
      "Excellent image quality is achieved by Nvidia's StyleGAN (2018) based on the Progressive GAN by Tero Karras, Timo Aila, Samuli  Laine, and Jaakko Lehtinen. Here the GAN generator is grown from small to large scale in a pyramidal fashion.\n",
      "Sepp Hochreiter's diploma thesis (1991) was called \"one of the most important documents in the history of machine learning\" by his supervisor Juergen Schmidhuber. Hochreiter identified and analyzed the vanishing gradient problem and proposed recurrent residual connections to solve it. This led to the deep learning method called long short-term memory (LSTM), published in Neural Computation (1997). LSTM recurrent neural networks can learn \"very deep learning\" tasks with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. The \"vanilla LSTM\" with forget gate was introduced in 1999 by Felix Gers, Schmidhuber and Fred Cummins. LSTM has become the most cited neural network of the 20th century.\n",
      "In 2015, Rupesh Kumar Srivastava, Klaus Greff, and Schmidhuber used the LSTM principle to create the Highway network, a feedforward neural network with hundreds of layers, much deeper than previous networks. 7 months later, Kaiming He, Xiangyu Zhang;  Shaoqing Ren, and Jian Sun won the ImageNet 2015 competition with an open-gated or gateless Highway network variant called Residual neural network. This has become the most cited neural network of the 21st century.The development of metal–oxide–semiconductor (MOS) very-large-scale integration (VLSI), in the form of complementary MOS (CMOS) technology, enabled increasing MOS transistor counts in digital electronics. This provided more processing power for the development of practical artificial neural networks in the 1980s.Neural networks' early successes included predicting the stock market and in 1995 a (mostly) self-driving car.Geoffrey Hinton et al. (2006) proposed learning a high-level representation using successive layers of binary or real-valued latent variables with a restricted Boltzmann machine to model each layer. In 2012, Ng and Dean created a network that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images. Unsupervised pre-training and increased computing power from GPUs and distributed computing allowed the use of larger networks, particularly in image and visual recognition problems, which became known as \"deep learning\".Ciresan and colleagues (2010) showed that despite the vanishing gradient problem, GPUs make backpropagation feasible for many-layered feedforward neural networks. Between 2009 and 2012, ANNs began winning prizes in image recognition contests, approaching human level performance on various tasks, initially in pattern recognition and handwriting recognition. For example, the bi-directional and multi-dimensional long short-term memory (LSTM) of Graves et al. won three competitions in connected handwriting recognition in 2009 without any prior knowledge about the three languages to be learned.Ciresan and colleagues built the first pattern recognizers to achieve human-competitive/superhuman performance on benchmarks such as traffic sign recognition (IJCNN 2012).\n",
      "\n",
      "Models\n",
      "ANNs began as an attempt to exploit the architecture of the human brain to perform tasks that conventional algorithms had little success with. They soon reoriented towards improving empirical results, abandoning attempts to remain true to their biological precursors. ANNs have the ability to learn and model non-linearities and complex relationships. This is achieved by neurons being connected in various patterns, allowing the output of some neurons to become the input of others. The network forms a directed, weighted graph.An artificial neural network consists of simulated neurons. Each neuron is connected to other nodes via links like a biological axon-synapse-dendrite connection. All the nodes connected by links take in some data and use it to perform specific operations and tasks on the data. Each link has a weight, determining the strength of one node's influence on another, allowing weights to choose the signal between neurons.\n",
      "\n",
      "Artificial neurons\n",
      "ANNs are composed of artificial neurons which are conceptually derived from biological neurons. Each artificial neuron has inputs and produces a single output which can be sent to multiple other neurons. The inputs can be the feature values of a sample of external data, such as images or documents, or they can be the outputs of other neurons. The outputs of the final output neurons of the neural net accomplish the task, such as recognizing an object in an image.\n",
      "To find the output of the neuron we take the weighted sum of all the inputs, weighted by the weights of the connections from the inputs to the neuron. We add a bias term to this sum. This weighted sum is sometimes called the activation. This weighted sum is then passed through a (usually nonlinear) activation function to produce the output. The initial inputs are external data, such as images and documents. The ultimate outputs accomplish the task, such as recognizing an object in an image.\n",
      "\n",
      "Organization\n",
      "The neurons are typically organized into multiple layers, especially in deep learning. Neurons of one layer connect only to neurons of the immediately preceding and immediately following layers. The layer that receives external data is the input layer. The layer that produces the ultimate result is the output layer. In between them are zero or more hidden layers. Single layer and unlayered networks are also used. Between two layers, multiple connection patterns are possible. They can be 'fully connected', with every neuron in one layer connecting to every neuron in the next layer. They can be pooling, where a group of neurons in one layer connects to a single neuron in the next layer, thereby reducing the number of neurons in that layer. Neurons with only such connections form a directed acyclic graph and are known as feedforward networks. Alternatively, networks that allow connections between neurons in the same or previous layers are known as recurrent networks.\n",
      "\n",
      "Hyperparameter\n",
      "A hyperparameter is a constant parameter whose value is set before the learning process begins. The values of parameters are derived via learning. Examples of hyperparameters include learning rate, the number of hidden layers and batch size. The values of some hyperparameters can be dependent on those of other hyperparameters. For example, the size of some layers can depend on the overall number of layers.\n",
      "\n",
      "Learning\n",
      "Learning is the adaptation of the network to better handle a task by considering sample observations. Learning involves adjusting the weights (and optional thresholds) of the network to improve the accuracy of the result. This is done by minimizing the observed errors. Learning is complete when examining additional observations does not usefully reduce the error rate. Even after learning, the error rate typically does not reach 0. If after learning, the error rate is too high, the network typically must be redesigned. Practically this is done by defining a cost function that is evaluated periodically during learning. As long as its output continues to decline, learning continues. The cost is frequently defined as a statistic whose value can only be approximated. The outputs are actually numbers, so when the error is low, the difference between the output (almost certainly a cat) and the correct answer (cat) is small. Learning attempts to reduce the total of the differences across the observations. Most learning models can be viewed as a straightforward application of optimization theory and statistical estimation.\n",
      "\n",
      "Learning rate\n",
      "The learning rate defines the size of the corrective steps that the model takes to adjust for errors in each observation. A high learning rate shortens the training time, but with lower ultimate accuracy, while a lower learning rate takes longer, but with the potential for greater accuracy. Optimizations such as Quickprop are primarily aimed at speeding up error minimization, while other improvements mainly try to increase reliability. In order to avoid oscillation inside the network such as alternating connection weights, and to improve the rate of convergence, refinements use an adaptive learning rate that increases or decreases as appropriate. The concept of momentum allows the balance between the gradient and the previous change to be weighted such that the weight adjustment depends to some degree on the previous change. A momentum close to 0 emphasizes the gradient, while a value close to 1 emphasizes the last change.\n",
      "\n",
      "Cost function\n",
      "While it is possible to define a cost function ad hoc, frequently the choice is determined by the function's desirable properties (such as convexity) or because it arises from the model (e.g. in a probabilistic model the model's posterior probability can be used as an inverse cost).\n",
      "\n",
      "Backpropagation\n",
      "Backpropagation is a method used to adjust the connection weights to compensate for each error found during learning. The error amount is effectively divided among the connections. Technically, backprop calculates the gradient (the derivative) of the cost function associated with a given state with respect to the weights. The weight updates can be done via stochastic gradient descent or other methods, such as extreme learning machines, \"no-prop\" networks, training without backtracking, \"weightless\" networks, and non-connectionist neural networks.\n",
      "\n",
      "Learning paradigms\n",
      "Machine learning is commonly separated into three main learning paradigms, supervised learning, unsupervised learning and reinforcement learning. Each corresponds to a particular learning task.\n",
      "\n",
      "Supervised learning\n",
      "Supervised learning uses a set of paired inputs and desired outputs. The learning task is to produce the desired output for each input. In this case, the cost function is related to eliminating incorrect deductions. A commonly used cost is the mean-squared error, which tries to minimize the average squared error between the network's output and the desired output. Tasks suited for supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). Supervised learning is also applicable to sequential data (e.g., for handwriting, speech and gesture recognition). This can be thought of as learning with a \"teacher\", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far.\n",
      "\n",
      "Unsupervised learning\n",
      "In unsupervised learning, input data is given along with the cost function, some function of the data \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          x\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle x}\n",
      "   and the network's output. The cost function is dependent on the task (the model domain) and any a priori assumptions (the implicit properties of the model, its parameters and the observed variables). As a trivial example, consider the model \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          f\n",
      "          (\n",
      "          x\n",
      "          )\n",
      "          =\n",
      "          a\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle f(x)=a}\n",
      "   where \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          a\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle a}\n",
      "   is a constant and the cost \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          C\n",
      "          =\n",
      "          E\n",
      "          [\n",
      "          (\n",
      "          x\n",
      "          −\n",
      "          f\n",
      "          (\n",
      "          x\n",
      "          )\n",
      "          \n",
      "            )\n",
      "            \n",
      "              2\n",
      "            \n",
      "          \n",
      "          ]\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle C=E[(x-f(x))^{2}]}\n",
      "  . Minimizing this cost produces a value of \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          a\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle a}\n",
      "   that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          x\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle x}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          f\n",
      "          (\n",
      "          x\n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle f(x)}\n",
      "  , whereas in statistical modeling, it could be related to the posterior probability of the model given the data (note that in both of those examples, those quantities would be maximized rather than minimized). Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering.\n",
      "\n",
      "Reinforcement learning\n",
      "In applications such as playing video games, an actor takes a string of actions, receiving a generally unpredictable response from the environment after each one. The goal is to win the game, i.e., generate the most positive (lowest cost) responses. In reinforcement learning, the aim is to weight the network (devise a policy) to perform actions that minimize long-term (expected cumulative) cost. At each point in time the agent performs an action and the environment generates an observation and an instantaneous cost, according to some (usually unknown) rules. The rules and the long-term cost usually only can be estimated. At any juncture, the agent decides whether to explore new actions to uncover their costs or to exploit prior learning to proceed more quickly.\n",
      "Formally the environment is modeled as a Markov decision process (MDP) with states \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              s\n",
      "              \n",
      "                1\n",
      "              \n",
      "            \n",
      "            ,\n",
      "            .\n",
      "            .\n",
      "            .\n",
      "            ,\n",
      "            \n",
      "              s\n",
      "              \n",
      "                n\n",
      "              \n",
      "            \n",
      "          \n",
      "          ∈\n",
      "          S\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle {s_{1},...,s_{n}}\\in S}\n",
      "   and actions \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              a\n",
      "              \n",
      "                1\n",
      "              \n",
      "            \n",
      "            ,\n",
      "            .\n",
      "            .\n",
      "            .\n",
      "            ,\n",
      "            \n",
      "              a\n",
      "              \n",
      "                m\n",
      "              \n",
      "            \n",
      "          \n",
      "          ∈\n",
      "          A\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle {a_{1},...,a_{m}}\\in A}\n",
      "  . Because the state transitions are not known, probability distributions are used instead: the instantaneous cost distribution \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          P\n",
      "          (\n",
      "          \n",
      "            c\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            s\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle P(c_{t}|s_{t})}\n",
      "  , the observation distribution \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          P\n",
      "          (\n",
      "          \n",
      "            x\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            s\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle P(x_{t}|s_{t})}\n",
      "   and the transition distribution \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          P\n",
      "          (\n",
      "          \n",
      "            s\n",
      "            \n",
      "              t\n",
      "              +\n",
      "              1\n",
      "            \n",
      "          \n",
      "          \n",
      "            |\n",
      "          \n",
      "          \n",
      "            s\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          ,\n",
      "          \n",
      "            a\n",
      "            \n",
      "              t\n",
      "            \n",
      "          \n",
      "          )\n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\textstyle P(s_{t+1}|s_{t},a_{t})}\n",
      "  , while a policy is defined as the conditional distribution over actions given the observations. Taken together, the two define a Markov chain (MC). The aim is to discover the lowest-cost MC.\n",
      "ANNs serve as the learning component in such applications. Dynamic programming coupled with ANNs (giving neurodynamic programming) has been applied to problems such as those involved in vehicle routing, video games, natural resource management and medicine because of ANNs ability to mitigate losses of accuracy even when reducing the discretization grid density for numerically approximating the solution of control problems. Tasks that fall within the paradigm of reinforcement learning are control problems, games and other sequential decision making tasks.\n",
      "\n",
      "Self-learning\n",
      "Self-learning in neural networks was introduced in 1982 along with a neural network capable of self-learning named crossbar adaptive array (CAA). It is a system with only one input, situation s, and only one output, action (or behavior) a. It has neither external advice input nor external reinforcement input from the environment. The CAA computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about encountered situations. The system is driven by the interaction between cognition and emotion. Given the memory matrix, W =||w(a,s)||, the crossbar self-learning algorithm in each iteration performs the following computation:\n",
      "\n",
      "  In situation s perform action a;\n",
      "  Receive consequence situation s';\n",
      "  Compute emotion of being in consequence situation v(s');\n",
      "  Update crossbar memory w'(a,s) = w(a,s) + v(s').\n",
      "\n",
      "The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is behavioral environment where it behaves, and the other is genetic environment, where from it initially and only once receives initial emotions about to be encountered situations in the behavioral environment. Having received the genome vector (species vector) from the genetic environment, the CAA will learn a goal-seeking behavior, in the behavioral environment that contains both desirable and undesirable situations.\n",
      "\n",
      "Neuroevolution\n",
      "Neuroevolution can create neural network topologies and weights using evolutionary computation. It is competitive with sophisticated gradient descent approaches. One advantage of neuroevolution is that it may be less prone to get caught in \"dead ends\".\n",
      "\n",
      "Stochastic neural network\n",
      "Stochastic neural networks originating from  Sherrington–Kirkpatrick models  are a type of artificial neural network built by introducing random variations into the network, either by giving the network's artificial neurons stochastic transfer functions, or by giving them stochastic weights. This makes them useful tools for optimization problems, since the random fluctuations help the network escape from local minima. Stochastic neural networks trained using a Bayesian approach are known as Bayesian neural networks.\n",
      "\n",
      "Other\n",
      "In a Bayesian framework, a distribution over the set of allowed models is chosen to minimize the cost. Evolutionary methods, gene expression programming, simulated annealing, expectation-maximization, non-parametric methods and particle swarm optimization are other learning algorithms. Convergent recursion is a learning algorithm for cerebellar model articulation controller (CMAC) neural networks.\n",
      "\n",
      "Modes\n",
      "Two modes of learning are available: stochastic and batch. In stochastic learning, each input creates a weight adjustment. In batch learning weights are adjusted based on a batch of inputs, accumulating errors over the batch. Stochastic learning introduces \"noise\" into the process, using the local gradient calculated from one data point; this reduces the chance of the network getting stuck in local minima. However, batch learning typically yields a faster, more stable descent to a local minimum, since each update is performed in the direction of the batch's average error. A common compromise is to use \"mini-batches\", small batches with samples in each batch selected stochastically from the entire data set.\n",
      "\n",
      "Types\n",
      "ANNs have evolved into a broad family of techniques that have advanced the state of the art across multiple domains.  The simplest types have one or more static components, including number of units, number of layers, unit weights and topology. Dynamic types allow one or more of these to evolve via learning. The latter is much more complicated but can shorten learning periods and produce better results. Some types allow/require learning to be \"supervised\" by the operator, while others operate independently. Some types operate purely in hardware, while others are purely software and run on general purpose computers.\n",
      "Some of the main breakthroughs include: convolutional neural networks that have proven particularly successful in processing visual and other two-dimensional data; long short-term memory avoid the vanishing gradient problem and can handle signals that have a mix of low and high frequency components aiding large-vocabulary speech recognition, text-to-speech synthesis, and photo-real talking heads; competitive networks such as generative adversarial networks in which multiple networks (of varying structure) compete with each other, on tasks such as winning a game or on deceiving the opponent about the authenticity of an input.\n",
      "\n",
      "Network design\n",
      "Neural architecture search (NAS) uses machine learning to automate ANN design. Various approaches to NAS have designed networks that compare well with hand-designed systems. The basic search algorithm is to propose a candidate model, evaluate it against a dataset, and use the results as feedback to teach the NAS network. Available systems include AutoML and AutoKeras. scikit-learn library provides functions to help with building a deep network from scratch. We can then implement a deep network with TensorFlow or Keras.\n",
      "Design issues include deciding the number, type, and connectedness of network layers, as well as the size of each and the connection type (full, pooling, etc. ).\n",
      "\n",
      "Hyperparameters must also be defined as part of the design (they are not learned), governing matters such as how many neurons are in each layer, learning rate, step, stride, depth, receptive field and padding (for CNNs), etc. The Python code snippet provides an overview of the training function, which uses the training dataset, number of hidden layer units, learning rate, and number of iterations as parameters:\n",
      "\n",
      "Use\n",
      "Using artificial neural networks requires an understanding of their characteristics.\n",
      "\n",
      "Choice of model: This depends on the data representation and the application. Overly complex models are slow learning.\n",
      "Learning algorithm: Numerous trade-offs exist between learning algorithms. Almost any algorithm will work well with the correct hyperparameters for training on a particular data set. However, selecting and tuning an algorithm for training on unseen data requires significant experimentation.\n",
      "Robustness: If the model, cost function and learning algorithm are selected appropriately, the resulting ANN can become robust.ANN capabilities fall within the following broad categories:\n",
      "Function approximation, or regression analysis, including time series prediction, fitness approximation and modeling.\n",
      "Classification, including pattern and sequence recognition, novelty detection and sequential decision making.\n",
      "Data processing, including filtering, clustering, blind source separation and compression.\n",
      "Robotics, including directing manipulators and prostheses.\n",
      "\n",
      "Applications\n",
      "Because of their ability to reproduce and model nonlinear processes, artificial neural networks have found applications in many disciplines. Application areas include system identification and control (vehicle control, trajectory prediction, process control, natural resource management), quantum chemistry, general game playing, pattern recognition (radar systems, face identification, signal classification, 3D reconstruction, object recognition and more), sensor data analysis, sequence recognition (gesture, speech, handwritten and printed text recognition), medical diagnosis, finance (e.g. ex-ante models for specific financial long-run forecasts and artificial financial markets), data mining, visualization, machine translation, social network filtering and e-mail spam filtering. ANNs have been used to diagnose several types of cancers and to distinguish highly invasive cancer cell lines from less invasive lines using only cell shape information.ANNs have been used to accelerate reliability analysis of infrastructures subject to natural disasters and to predict foundation settlements. It can also be useful to mitigate flood by the use of ANNs for modelling rainfall-runoff. ANNs have also been used for building black-box models in geoscience: hydrology, ocean modelling and coastal engineering, and geomorphology. ANNs have been employed in cybersecurity, with the objective to discriminate between legitimate activities and malicious ones. For example, machine learning has been used for classifying Android malware, for identifying domains belonging to threat actors and for detecting URLs posing a security risk. Research is underway on ANN systems designed for penetration testing, for detecting botnets, credit cards frauds and network intrusions.\n",
      "ANNs have been proposed as a tool to solve partial differential equations in physics and simulate the properties of many-body open quantum systems. In brain research ANNs have studied short-term behavior of individual neurons, the dynamics of neural circuitry arise from interactions between individual neurons and how behavior can arise from abstract neural modules that represent complete subsystems. Studies considered long-and short-term plasticity of neural systems and their relation to learning and memory from the individual neuron to the system level.\n",
      "\n",
      "Theoretical properties\n",
      "Computational power\n",
      "The multilayer perceptron is a universal function approximator, as proven by the universal approximation theorem. However, the proof is not constructive regarding the number of neurons required, the network topology, the weights and the learning parameters.\n",
      "A specific recurrent architecture with rational-valued weights (as opposed to full precision real number-valued weights) has the power of a universal Turing machine, using a finite number of neurons and standard linear connections. Further, the use of irrational values for weights results in a machine with super-Turing power.\n",
      "\n",
      "Capacity\n",
      "A model's \"capacity\" property corresponds to its ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.\n",
      "Two notions of capacity are known by the community. The information capacity and the VC Dimension. The information capacity of a perceptron is intensively discussed in Sir David MacKay's book which summarizes work by Thomas Cover. The capacity of a network of standard neurons (not convolutional) can be derived by four rules that derive from understanding a neuron as an electrical element. The information capacity captures the functions modelable by the network given any data as input. The second notion, is the VC dimension. VC Dimension uses the principles of measure theory and finds the maximum capacity under the best possible circumstances. This is, given input data in a specific form.  As noted in, the VC Dimension for arbitrary inputs is half the information capacity of a Perceptron. The VC Dimension for arbitrary points is sometimes referred to as Memory Capacity.\n",
      "\n",
      "Convergence\n",
      "Models may not consistently converge on a single solution, firstly because local minima may exist, depending on the cost function and the model. Secondly, the optimization method used might not guarantee to converge when it begins far from any local minimum. Thirdly, for sufficiently large data or parameters, some methods become impractical.\n",
      "Another issue worthy to mention is that training may cross some Saddle point which may lead the convergence to the wrong direction.\n",
      "The convergence behavior of certain types of ANN architectures are more understood than others. When the width of network approaches to infinity, the ANN is well described by its first order Taylor expansion throughout training, and so inherits the convergence behavior of affine models. Another example is when parameters are small, it is observed that ANNs often fits target functions from low to high frequencies. This behavior is referred to as the spectral bias, or frequency principle, of neural networks. This phenomenon is the opposite to the behavior of some well studied iterative numerical schemes such as Jacobi method. Deeper neural networks have been observed to be more biased towards low frequency functions.\n",
      "\n",
      "Generalization and statistics\n",
      "Applications whose goal is to create a system that generalizes well to unseen examples, face the possibility of over-training. This arises in convoluted or over-specified systems when the network capacity significantly exceeds the needed free parameters. Two approaches address over-training. The first is to use cross-validation and similar techniques to check for the presence of over-training and to select hyperparameters to minimize the generalization error.\n",
      "The second is to use some form of regularization. This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the goal is to minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the training set and the predicted error in unseen data due to overfitting.\n",
      "\n",
      "Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model. The MSE on a validation set can be used as an estimate for variance. This value can then be used to calculate the confidence interval of network output, assuming a normal distribution. A confidence analysis made this way is statistically valid as long as the output probability distribution stays the same and the network is not modified.\n",
      "By assigning a softmax activation function, a generalization of the logistic function, on the output layer of the neural network (or a softmax component in a component-based network) for categorical target variables, the outputs can be interpreted as posterior probabilities. This is useful in classification as it gives a certainty measure on classifications.\n",
      "The softmax activation function is:\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          y\n",
      "          \n",
      "            i\n",
      "          \n",
      "        \n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              e\n",
      "              \n",
      "                \n",
      "                  x\n",
      "                  \n",
      "                    i\n",
      "                  \n",
      "                \n",
      "              \n",
      "            \n",
      "            \n",
      "              \n",
      "                ∑\n",
      "                \n",
      "                  j\n",
      "                  =\n",
      "                  1\n",
      "                \n",
      "                \n",
      "                  c\n",
      "                \n",
      "              \n",
      "              \n",
      "                e\n",
      "                \n",
      "                  \n",
      "                    x\n",
      "                    \n",
      "                      j\n",
      "                    \n",
      "                  \n",
      "                \n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle y_{i}={\\frac {e^{x_{i}}}{\\sum _{j=1}^{c}e^{x_{j}}}}}\n",
      "\n",
      "Criticism\n",
      "Training\n",
      "A common criticism of neural networks, particularly in robotics, is that they require too much training for real-world operation. Potential solutions include randomly shuffling training examples, by using a numerical optimization algorithm that does not take too large steps when changing the network connections following an example, grouping examples in so-called mini-batches and/or introducing a recursive least squares algorithm for CMAC.\n",
      "\n",
      "Theory\n",
      "A central claim of ANNs is that they embody new and powerful general principles for processing information. These principles are ill-defined. It is often claimed that they are emergent from the network itself. This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition. In 1997, Alexander Dewdney commented that, as a result, artificial neural networks have a \"something-for-nothing quality, one that imparts a peculiar aura of laziness and a distinct lack of curiosity about just how good these computing systems are. No human hand (or mind) intervenes; solutions are found as if by magic; and no one, it seems, has learned anything\". One response to Dewdney is that neural networks handle many complex and diverse tasks, ranging from autonomously flying aircraft to detecting credit card fraud to mastering the game of Go.\n",
      "Technology writer Roger Bridgman commented:\n",
      "\n",
      "Neural networks, for instance, are in the dock not only because they have been hyped to high heaven, (what hasn't?) but also because you could create a successful net without understanding how it worked: the bunch of numbers that captures its behaviour would in all probability be \"an opaque, unreadable table...valueless as a scientific resource\".\n",
      "In spite of his emphatic declaration that science is not technology, Dewdney seems here to pillory neural nets as bad science when most of those devising them are just trying to be good engineers. An unreadable table that a useful machine could read would still be well worth having.\n",
      "\n",
      "Biological brains use both shallow and deep circuits as reported by brain anatomy, displaying a wide variety of invariance. Weng argued that the brain self-wires largely according to signal statistics and therefore, a serial cascade cannot catch all major statistical dependencies.\n",
      "\n",
      "Hardware\n",
      "Large and effective neural networks require considerable computing resources. While the brain has hardware tailored to the task of processing signals through a graph of neurons, simulating even a simplified neuron on von Neumann architecture may consume vast amounts of memory and storage. Furthermore, the designer often needs to transmit signals through many of these connections and their associated neurons –  which require enormous CPU power and time.\n",
      "Schmidhuber noted that the resurgence of neural networks in the twenty-first century is largely attributable to advances in hardware: from 1991 to 2015, computing power, especially as delivered by GPGPUs (on GPUs), has increased around a million-fold, making the standard backpropagation algorithm feasible for training networks that are several layers deeper than before. The use of accelerators such as FPGAs and GPUs can reduce training times from months to days.Neuromorphic engineering or a physical neural network addresses the hardware difficulty directly, by constructing non-von-Neumann chips to directly implement neural networks in circuitry. Another type of chip optimized for neural network processing is called a Tensor Processing Unit, or TPU.\n",
      "\n",
      "Practical counterexamples\n",
      "Analyzing what has been learned by an ANN is much easier than analyzing what has been learned by a biological neural network. Furthermore, researchers involved in exploring learning algorithms for neural networks are gradually uncovering general principles that allow a learning machine to be successful. For example, local vs. non-local learning and shallow vs. deep architecture.\n",
      "\n",
      "Hybrid approaches\n",
      "Advocates of hybrid models (combining neural networks and symbolic approaches) say that such a mixture can better capture the mechanisms of the human mind.\n",
      "\n",
      "Dataset bias\n",
      "Neural networks are dependent on the quality of the data they are trained on, thus low quality data with imbalanced representativeness can lead to the model learning and perpetuating societal biases.  These inherited biases become especially critical when the ANNs are integrated into real-world scenarios where the training data may be imbalanced due to the scarcity of data for a specific race, gender or other attribute. This imbalance can result in the model having inadequate representation and understanding of underrepresented groups, leading to discriminatory outcomes that exasperate societal inequalities, especially in applications like facial recognition, hiring processes, and law enforcement. For example, in 2018, Amazon had to scrap a recruiting tool because the model favored men over women for jobs in software engineering due to the higher number of male workers in the field. The program would penalize any resume with the word \"woman\" or the name of any women's college. However, the use of synthetic data can help reduce dataset bias and increase representation in datasets.\n",
      "\n",
      "Gallery\n",
      "Recent Advancements and Future Directions\n",
      "Artificial Neural Networks (ANNs) are a pivotal element in the realm of machine learning, resembling the structure and function of the human brain. ANNs have undergone significant advancements, particularly in their ability to model complex systems, handle large data sets, and adapt to various types of applications. Their evolution over the past few decades has been marked by notable methodological developments and a broad range of applications in fields such as image processing, speech recognition, natural language processing, finance, and medicine.\n",
      "\n",
      "Image Processing\n",
      "In the realm of image processing, ANNs have made significant strides. They are employed in tasks such as image classification, object recognition, and image segmentation. For instance, deep convolutional neural networks (CNNs) have been instrumental in handwritten digit recognition, achieving state-of-the-art performance. This demonstrates the ability of ANNs to effectively process and interpret complex visual information, leading to advancements in fields ranging from automated surveillance to medical imaging.\n",
      "\n",
      "Speech Recognition\n",
      "ANNs have revolutionized speech recognition technology. By modeling speech signals, they are used for tasks like speaker identification and speech-to-text conversion. Deep neural network architectures have introduced significant improvements in large vocabulary continuous speech recognition, outperforming traditional techniques. These advancements have facilitated the development of more accurate and efficient voice-activated systems, enhancing user interfaces in technology products.\n",
      "\n",
      "Natural Language Processing\n",
      "In natural language processing, ANNs are vital for tasks such as text classification, sentiment analysis, and machine translation. They have enabled the development of models that can accurately translate between languages, understand the context and sentiment in textual data, and categorize text based on content. This has profound implications for automated customer service, content moderation, and language understanding technologies.\n",
      "\n",
      "Control Systems\n",
      "In the domain of control systems, ANNs are applied to model dynamic systems for tasks such as system identification, control design, and optimization. The backpropagation algorithm, for instance, has been employed for training multi-layer feedforward neural networks, which are instrumental in system identification and control applications. This highlights the versatility of ANNs in adapting to complex dynamic environments, which is crucial in automation and robotics.\n",
      "\n",
      "Finance\n",
      "Artificial Neural Networks (ANNs) have made a significant impact on the financial sector, particularly in stock market prediction and credit scoring. These powerful AI systems can process vast amounts of financial data, recognize complex patterns, and forecast stock market trends, aiding investors and risk managers in making informed decisions. In credit scoring, ANNs offer data-driven, personalized assessments of creditworthiness, improving the accuracy of default predictions and automating the lending process. While ANNs offer numerous benefits, they also require high-quality data and careful tuning, and their \"black-box\" nature can pose challenges in interpretation. Nevertheless, ongoing advancements suggest that ANNs will continue to play a pivotal role in shaping the future of finance, offering valuable insights and enhancing risk management strategies.\n",
      "\n",
      "Medicine\n",
      "Artificial Neural Networks (ANNs) are revolutionizing the field of medicine with their ability to process and analyze vast medical datasets. They have become instrumental in enhancing diagnostic accuracy, especially in interpreting complex medical imaging for early disease detection, and in predicting patient outcomes for personalized treatment planning. In drug discovery, ANNs expedite the identification of potential drug candidates and predict their efficacy and safety, significantly reducing development time and costs. Additionally, their application in personalized medicine and healthcare data analysis is leading to more tailored therapies and efficient patient care management. Despite these advancements, challenges such as data privacy and model interpretability remain, with ongoing research aimed at addressing these issues and expanding the scope of ANN applications in medicine.\n",
      "\n",
      "Content Creation\n",
      "ANNs such as Generative Adversarial Networks (GAN) and transformers are also being used for content creation across numerous industries. This is because Deep Learning models are able to learn the style of an artist or musician from huge datasets and generate completely new artworks and music compositions. For instance, DALL-E is a deep neural network trained on 650 million pairs of images and texts across the internet that can create artworks based on text entered by the user. In the field of music, transformers are being used to create original music for commercials and documentaries through companies such as AIVA and Jukedeck. In the marketing industry generative models are being used to create personalized advertisements for consumers. Additionally, major film companies are partnering with technology companies to analyze the financial success of a film, such as the partnership between Warner Bros and technology company Cinelytic established in 2020. Furthermore, neural networks have found uses in video game creation, where Non Player Characters (NPCs) can make decisions based on all the characters currently in the game.\n",
      "\n",
      "See also\n",
      "Notes\n",
      "References\n",
      "\n",
      "\n",
      "== Bibliography ==The Industrial Revolution, also known as the First Industrial Revolution,  was a period of global transition of human economy towards more widespread, efficient and stable manufacturing processes that succeeded the Agricultural Revolution, starting from Great Britain, continental Europe, and the United States, that occurred during the period from around 1760 to about 1820–1840. This transition included going from hand production methods to machines; new chemical manufacturing and iron production processes; the increasing use of water power and steam power; the development of machine tools; and the rise of the mechanized factory system. Output greatly increased, and the result was an unprecedented rise in population and the rate of population growth. The textile industry was the first to use modern production methods,: 40  and textiles became the dominant industry in terms of employment, value of output, and capital invested.\n",
      "The Industrial Revolution began in Great Britain, and many of the technological and architectural innovations were of British origin. By the mid-18th century, Britain was the world's leading commercial nation, controlling a global trading empire with colonies in North America and the Caribbean. Britain had major military and political hegemony on the Indian subcontinent; particularly with the proto-industrialised Mughal Bengal, through the activities of the East India Company. The development of trade and the rise of business were among the major causes of the Industrial Revolution.: 15 The Industrial Revolution marked a major turning point in history.  Comparable only to humanity's adoption of agriculture with respect to material advancement, the Industrial Revolution influenced in some way almost every aspect of daily life. In particular, average income and population began to exhibit unprecedented sustained growth. Some economists have said the most important effect of the Industrial Revolution was that the standard of living for the general population in the Western world began to increase consistently for the first time in history, although others have said that it did not begin to improve meaningfully until the late 19th and 20th centuries. GDP per capita was broadly stable before the Industrial Revolution and the emergence of the modern capitalist economy, while the Industrial Revolution began an era of per-capita economic growth in capitalist economies. Economic historians agree that the onset of the Industrial Revolution is the most important event in human history since the domestication of animals and plants.The precise start and end of the Industrial Revolution is still debated among historians, as is the pace of economic and social changes. Eric Hobsbawm held that the Industrial Revolution began in Britain in the 1780s and was not fully felt until the 1830s or 1840s, while T. S. Ashton held that it occurred roughly between 1760 and 1830. Rapid industrialisation first began in Britain, starting with mechanized textiles spinning in the 1780s, with high rates of growth in steam power and iron production occurring after 1800. Mechanized textile production spread from Great Britain to continental Europe and the United States in the early 19th century, with important centres of textiles, iron and coal emerging in Belgium and the United States and later textiles in France.An economic recession occurred from the late 1830s to the early 1840s when the adoption of the Industrial Revolution's early innovations, such as mechanized spinning and weaving, slowed as their markets matured. Innovations developed late in the period, such as the increasing adoption of locomotives, steamboats and steamships, and hot blast iron smelting. New technologies such as the electrical telegraph, widely introduced in the 1840s and 1850s, were not powerful enough to drive high rates of growth. Rapid economic growth began to occur after 1870, springing from a new group of innovations in what has been called the Second Industrial Revolution. These innovations included new steel-making processes, mass production, assembly lines, electrical grid systems, the large-scale manufacture of machine tools, and the use of increasingly advanced machinery in steam-powered factories.\n",
      "\n",
      "Etymology\n",
      "The earliest recorded use of the term \"Industrial Revolution\" was in July 1799 by French envoy Louis-Guillaume Otto, announcing that France had entered the race to industrialise. In his 1976 book Keywords: A Vocabulary of Culture and Society, Raymond Williams states in the entry for \"Industry\": \"The idea of a new social order based on major industrial change was clear in Southey and Owen, between 1811 and 1818, and was implicit as early as Blake in the early 1790s and Wordsworth at the turn of the [19th] century.\" The term Industrial Revolution applied to technological change was becoming more common by the late 1830s, as in Jérôme-Adolphe Blanqui's description in 1837 of la révolution industrielle.Friedrich Engels in The Condition of the Working Class in England in 1844 spoke of \"an industrial revolution, a revolution which at the same time changed the whole of civil society\". Although Engels wrote his book in the 1840s, it was not translated into English until the late 19th century, and his expression did not enter everyday language until then. Credit for popularising the term may be given to Arnold Toynbee, whose 1881 lectures gave a detailed account of the term.Economic historians and authors such as Mendels, Pomeranz, and Kridte argue that proto-industrialization in parts of Europe, the Muslim world, Mughal India, and China created the social and economic conditions that led to the Industrial Revolution, thus causing the Great Divergence. Some historians, such as John Clapham and Nicholas Crafts, have argued that the economic and social changes occurred gradually and that the term revolution is a misnomer. This is still a subject of debate among some historians.\n",
      "\n",
      "Requirements\n",
      "Six factors facilitated industrialization: high levels of agricultural productivity (see British Agricultural Revolution) to provide excess manpower and food; a pool of managerial and entrepreneurial skills;  available ports, rivers, canals, and roads to cheaply move raw materials and outputs; natural resources such as coal, iron, and waterfalls; political stability and a legal system that supported business; and financial capital available to invest. Once industrialization began in Great Britain, new factors can be added: the eagerness of British entrepreneurs to export industrial expertise and the willingness to import the process. Britain met the criteria and industrialized starting in the 18th century, and then it exported the process to western Europe (especially Belgium, France, and the German states) in the early 19th century. The United States copied the British model in the early 19th century, and Japan copied the Western European models in the late 19th century.\n",
      "\n",
      "Important technological developments\n",
      "The commencement of the Industrial Revolution is closely linked to a small number of innovations, beginning in the second half of the 18th century.  By the 1830s, the following gains had been made in important technologies:\n",
      "\n",
      "Textiles – mechanised cotton spinning powered by water, and later steam, increased the output of a worker by a factor of around 500. The power loom increased the output of a worker by a factor of over 40. The cotton gin increased productivity of removing seed from cotton by a factor of 50. Large gains in productivity also occurred in spinning and weaving of wool and linen, but they were not as great as in cotton.\n",
      "Steam power – the efficiency of steam engines increased so that they used between one-fifth and one-tenth as much fuel. The adaptation of stationary steam engines to rotary motion made them suitable for industrial uses.: 82  The high-pressure engine had a high power-to-weight ratio, making it suitable for transportation. Steam power underwent a rapid expansion after 1800.\n",
      "Iron making – the substitution of coke for charcoal greatly lowered the fuel cost of pig iron and wrought iron production.: 89–93  Using coke also allowed larger blast furnaces, resulting in economies of scale. The steam engine began being used to power blast air (indirectly by pumping water to a water wheel) in the 1750s, enabling a large increase in iron production by overcoming the limitation of water power. The cast iron blowing cylinder was first used in 1760. It was later improved by making it double acting, which allowed higher blast furnace temperatures. The puddling process produced a structural grade iron at a lower cost than the finery forge. The rolling mill was fifteen times faster than hammering wrought iron. Developed in 1828, hot blast greatly increased fuel efficiency in iron production in the following decades.\n",
      "Invention of machine tools – the first machine tools invented were the screw-cutting lathe, the cylinder boring machine, and the milling machine. Machine tools made the economical manufacture of precision metal parts possible, although it took several decades to develop effective techniques for making interchangeable parts.\n",
      "\n",
      "Textile manufacture\n",
      "British textile industry statistics\n",
      "In 1750, Britain imported 2.5 million pounds of raw cotton, most of which was spun and woven by the cottage industry in Lancashire. The work was done by hand in workers' homes or occasionally in master weavers' shops. Wages in Lancashire were about six times those in India in 1770 when overall productivity in Britain was about three times higher than in India. In 1787, raw cotton consumption was 22 million pounds, most of which was cleaned, carded, and spun on machines.: 41–42  The British textile industry used 52 million pounds of cotton in 1800, which increased to 588 million pounds in 1850.The share of value added by the cotton textile industry in Britain was 2.6% in 1760, 17% in 1801, and 22.4% in 1831. Value added by the British woollen industry was 14.1% in 1801. Cotton factories in Britain numbered approximately 900 in 1797.  In 1760, approximately one-third of cotton cloth manufactured in Britain was exported, rising to two-thirds by 1800. In 1781, cotton spun amounted to 5.1 million pounds, which increased to 56 million pounds by 1800. In 1800, less than 0.1% of world cotton cloth was produced on machinery invented in Britain. In 1788, there were 50,000 spindles in Britain, rising to 7 million over the next 30 years.\n",
      "\n",
      "Wool\n",
      "The earliest European attempts at mechanized spinning were with wool; however, wool spinning proved more difficult to mechanize than cotton.  Productivity improvement in wool spinning during the Industrial Revolution was significant but far less than that of cotton.\n",
      "\n",
      "Silk\n",
      "Arguably the first highly mechanised factory was John Lombe's water-powered silk mill at Derby, operational by 1721. Lombe learned silk thread manufacturing by taking a job in Italy and acting as an industrial spy; however, because the Italian silk industry guarded its secrets closely, the state of the industry at that time is unknown. Although Lombe's factory was technically successful, the supply of raw silk from Italy was cut off to eliminate competition. In order to promote manufacturing, the Crown paid for models of Lombe's machinery which were exhibited in the Tower of London.\n",
      "\n",
      "Cotton\n",
      "Parts of India, China, Central America, South America, and the Middle East have a long history of hand manufacturing cotton textiles, which became a major industry sometime after 1000 AD. In tropical and subtropical regions where it was grown, most was grown by small farmers alongside their food crops and was spun and woven in households, largely for domestic consumption.  In the 15th century, China began to require households to pay part of their taxes in cotton cloth. By the 17th century, almost all Chinese wore cotton clothing. Almost everywhere cotton cloth could be used as a medium of exchange. In India, a significant amount of cotton textiles were manufactured for distant markets, often produced by professional weavers. Some merchants also owned small weaving workshops. India produced a variety of cotton cloth, some of exceptionally fine quality.Cotton was a difficult raw material for Europe to obtain before it was grown on colonial plantations in the Americas. The early Spanish explorers found Native Americans growing unknown species of excellent quality cotton: sea island cotton (Gossypium barbadense) and upland green seeded cotton Gossypium hirsutum. Sea island cotton grew in tropical areas and on barrier islands of Georgia and South Carolina but did poorly inland. Sea island cotton began being exported from Barbados in the 1650s. Upland green seeded cotton grew well on inland areas of the southern U.S. but was not economical because of the difficulty of removing seed, a problem solved by the cotton gin.: 157  A strain of cotton seed brought from Mexico to Natchez, Mississippi, in 1806 became the parent genetic material for over 90% of world cotton production today; it produced bolls that were three to four times faster to pick.\n",
      "\n",
      "Trade and textiles\n",
      "The Age of Discovery was followed by a period of colonialism beginning around the 16th century. Following the discovery of a trade route to India around southern Africa by the Portuguese, the British founded the East India Company, along with smaller companies of different nationalities which established trading posts and employed agents to engage in trade throughout the Indian Ocean region.One of the largest segments of this trade was in cotton textiles, which were purchased in India and sold in Southeast Asia, including the Indonesian archipelago where spices were purchased for sale to Southeast Asia and Europe. By the mid-1760s cloth was over three-quarters of the East India Company's exports. Indian textiles were in demand in the North Atlantic region of Europe where previously only wool and linen were available; however, the number of cotton goods consumed in Western Europe was minor until the early 19th century.\n",
      "\n",
      "Pre-mechanized European textile production\n",
      "By 1600, Flemish refugees began weaving cotton cloth in English towns where cottage spinning and weaving of wool and linen was well established. They were left alone by the guilds who did not consider cotton a threat. Earlier European attempts at cotton spinning and weaving were in 12th-century Italy and 15th-century southern Germany, but these industries eventually ended when the supply of cotton was cut off.  The Moors in Spain grew, spun, and wove cotton beginning around the 10th century.British cloth could not compete with Indian cloth because India's labour cost was approximately one-fifth to one-sixth that of Britain's. In 1700 and 1721, the British government passed Calico Acts to protect the domestic woollen and linen industries from the increasing amounts of cotton fabric imported from India.The demand for heavier fabric was met by a domestic industry based around Lancashire that produced fustian, a cloth with flax warp and cotton weft.  Flax was used for the warp because wheel-spun cotton did not have sufficient strength, but the resulting blend was not as soft as 100% cotton and was more difficult to sew.On the eve of the Industrial Revolution, spinning and weaving were done in households, for domestic consumption, and as a cottage industry under the putting-out system.  Occasionally the work was done in the workshop of a master weaver. Under the putting-out system, home-based workers produced under contract to merchant sellers, who often supplied the raw materials. In the off-season the women, typically farmers' wives, did the spinning and the men did the weaving.  Using the spinning wheel, it took anywhere from four to eight spinners to supply one handloom weaver.: 823\n",
      "\n",
      "Invention of textile machinery\n",
      "The flying shuttle, patented in 1733 by John Kay—with a number of subsequent improvements including an important one in 1747—doubled the output of a weaver, worsening the imbalance between spinning and weaving. It became widely used around Lancashire after 1760 when John's son, Robert, invented the dropbox, which facilitated changing thread colors.: 821–822 Lewis Paul patented the roller spinning frame and the flyer-and-bobbin system for drawing wool to a more even thickness. The technology was developed with the help of John Wyatt of Birmingham. Paul and Wyatt opened a mill in Birmingham which used their rolling machine powered by a donkey. In 1743, a factory opened in Northampton with 50 spindles on each of five of Paul and Wyatt's machines. This operated until about 1764. A similar mill was built by Daniel Bourn in Leominster, but this burnt down. Both Lewis Paul and Daniel Bourn patented carding machines in 1748. Based on two sets of rollers that travelled at different speeds, it was later used in the first cotton spinning mill.\n",
      "In 1764, in the village of Stanhill, Lancashire, James Hargreaves invented the spinning jenny, which he patented in 1770. It was the first practical spinning frame with multiple spindles. The jenny worked in a similar manner to the spinning wheel, by first clamping down on the fibres, then by drawing them out, followed by twisting. It was a simple, wooden framed machine that only cost about £6 for a 40-spindle model in 1792 and was used mainly by home spinners. The jenny produced a lightly twisted yarn only suitable for weft, not warp.: 825–827 The spinning frame or water frame was developed by Richard Arkwright who, along with two partners, patented it in 1769. The design was partly based on a spinning machine built by Kay, who was hired by Arkwright.: 827–830  For each spindle the water frame used a series of four pairs of rollers, each operating at a successively higher rotating speed, to draw out the fibre which was then twisted by the spindle. The roller spacing was slightly longer than the fibre length. Too close a spacing caused the fibres to break while too distant a spacing caused uneven thread. The top rollers were leather-covered and loading on the rollers was applied by a weight. The weights kept the twist from backing up before the rollers. The bottom rollers were wood and metal, with fluting along the length. The water frame was able to produce a hard, medium-count thread suitable for warp, finally allowing 100% cotton cloth to be made in Britain. Arkwright and his partners used water power at a factory in Cromford, Derbyshire in 1771, giving the invention its name.\n",
      "Samuel Crompton's spinning mule was introduced in 1779. Mule implies a hybrid because it was a combination of the spinning jenny and the water frame, in which the spindles were placed on a carriage, which went through an operational sequence during which the rollers stopped while the carriage moved away from the drawing roller to finish drawing out the fibres as the spindles started rotating.: 832  Crompton's mule was able to produce finer thread than hand spinning and at a lower cost. Mule-spun thread was of suitable strength to be used as a warp and finally allowed Britain to produce highly competitive yarn in large quantities.: 832 Realising that the expiration of the Arkwright patent would greatly increase the supply of spun cotton and lead to a shortage of weavers, Edmund Cartwright developed a vertical power loom which he patented in 1785. In 1776, he patented a two-man operated loom.: 834  Cartwright's loom design had several flaws, the most serious being thread breakage. Samuel Horrocks patented a fairly successful loom in 1813. Horock's loom was improved by Richard Roberts in 1822, and these were produced in large numbers by Roberts, Hill & Co.The demand for cotton presented an opportunity to planters in the Southern United States, who thought upland cotton would be a profitable crop if a better way could be found to remove the seed. Eli Whitney responded to the challenge by inventing the inexpensive cotton gin. A man using a cotton gin could remove seed from as much upland cotton in one day as would previously have taken two months to process, working at the rate of one pound of cotton per day.These advances were capitalised on by entrepreneurs, of whom the best known is Arkwright. He is credited with a list of inventions, but these were actually developed by such people as Kay and Thomas Highs; Arkwright nurtured the inventors, patented the ideas, financed the initiatives, and protected the machines. He created the cotton mill which brought the production processes together in a factory, and he developed the use of power—first horsepower and then water power—which made cotton manufacture a mechanised industry. Other inventors increased the efficiency of the individual steps of spinning (carding, twisting and spinning, and rolling) so that the supply of yarn increased greatly. Steam power was then applied to drive textile machinery. Manchester acquired the nickname Cottonopolis during the early 19th century owing to its sprawl of textile factories.Although mechanization dramatically decreased the cost of cotton cloth, by the mid-19th century machine-woven cloth still could not equal the quality of hand-woven Indian cloth, in part because of the fineness of thread made possible by the type of cotton used in India, which allowed high thread counts. However, the high productivity of British textile manufacturing allowed coarser grades of British cloth to undersell hand-spun and woven fabric in low-wage India, eventually destroying the Indian industry.\n",
      "\n",
      "Iron industry\n",
      "British iron production statistics\n",
      "Bar iron was the commodity form of iron used as the raw material for making hardware goods such as nails, wire, hinges, horseshoes, wagon tires, chains, etc., as well as structural shapes. A small amount of bar iron was converted into steel. Cast iron was used for pots, stoves, and other items where its brittleness was tolerable. Most cast iron was refined and converted to bar iron, with substantial losses. Bar iron was made by the bloomery process, which was the predominant iron smelting process until the late 18th century.\n",
      "In the UK in 1720, there were 20,500 tons of cast iron produced with charcoal and 400 tons with coke. In 1750 charcoal iron production was 24,500 and coke iron was 2,500 tons. In 1788 the production of charcoal cast iron was 14,000 tons while coke iron production was 54,000 tons. In 1806 charcoal cast iron production was 7,800 tons and coke cast iron was 250,000 tons.: 125 In 1750 the UK imported 31,200 tons of bar iron and either refined from cast iron or directly produced 18,800 tons of bar iron using charcoal and 100 tons using coke. In 1796 the UK was making 125,000 tons of bar iron with coke and 6,400 tons with charcoal; imports were 38,000 tons and exports were 24,600 tons. In 1806 the UK did not import bar iron but exported 31,500 tons.: 125\n",
      "\n",
      "Iron process innovations\n",
      "A major change in the iron industries during the Industrial Revolution was the replacement of wood and other bio-fuels with coal; for a given amount of heat, mining coal required much less labour than cutting wood and converting it to charcoal, and coal was much more abundant than wood, supplies of which were becoming scarce before the enormous increase in iron production that took place in the late 18th century.: 122 In 1709, Abraham Darby made progress using coke to fuel his blast furnaces at Coalbrookdale. However, the coke pig iron he made was not suitable for making wrought iron and was used mostly for the production of cast iron goods, such as pots and kettles. He had the advantage over his rivals in that his pots, cast by his patented process, were thinner and cheaper than theirs.\n",
      "In 1750, coke had generally replaced charcoal in the smelting of copper and lead and was in widespread use in glass production. In the smelting and refining of iron, coal and coke produced inferior iron to that made with charcoal because of the coal's sulfur content. Low sulfur coals were known, but they still contained harmful amounts. Conversion of coal to coke only slightly reduces the sulfur content.: 122–125  A minority of coals are coking. Another factor limiting the iron industry before the Industrial Revolution was the scarcity of water power to power blast bellows. This limitation was overcome by the steam engine.Use of coal in iron smelting started somewhat before the Industrial Revolution, based on innovations by Clement Clerke and others from 1678, using coal reverberatory furnaces known as cupolas. These were operated by the flames playing on the ore and charcoal or coke mixture, reducing the oxide to metal. This has the advantage that impurities (such as sulphur ash) in the coal do not migrate into the metal. This technology was applied to lead from 1678 and to copper from 1687. It was also applied to iron foundry work in the 1690s, but in this case the reverberatory furnace was known as an air furnace. (The foundry cupola is a different, and later, innovation.)Coke pig iron was hardly used to produce wrought iron until 1755–56, when Darby's son Abraham Darby II built furnaces at Horsehay and Ketley where low sulfur coal was available (and not far from Coalbrookdale). These furnaces were equipped with water-powered bellows, the water being pumped by Newcomen steam engines. The Newcomen engines were not attached directly to the blowing cylinders because the engines alone could not produce a steady air blast. Abraham Darby III installed similar steam-pumped, water-powered blowing cylinders at the Dale Company when he took control in 1768. The Dale Company used several Newcomen engines to drain its mines and made parts for engines which it sold throughout the country.: 123–125 Steam engines made the use of higher-pressure and volume blast practical; however, the leather used in bellows was expensive to replace. In 1757, ironmaster John Wilkinson patented a hydraulic powered blowing engine for blast furnaces. The blowing cylinder for blast furnaces was introduced in 1760 and the first blowing cylinder made of cast iron is believed to be the one used at Carrington in 1768 that was designed by John Smeaton.: 124, 135 Cast iron cylinders for use with a piston were difficult to manufacture; the cylinders had to be free of holes and had to be machined smooth and straight to remove any warping.  James Watt had great difficulty trying to have a cylinder made for his first steam engine. In 1774 Wilkinson invented a precision boring machine for boring cylinders. After Wilkinson bored the first successful cylinder for a Boulton and Watt steam engine in 1776, he was given an exclusive contract for providing cylinders. After Watt developed a rotary steam engine in 1782, they were widely applied to blowing, hammering, rolling and slitting.: 124 The solutions to the sulfur problem were the addition of sufficient limestone to the furnace to force sulfur into the slag as well as the use of low sulfur coal. The use of lime or limestone required higher furnace temperatures to form a free-flowing slag. The increased furnace temperature made possible by improved blowing also increased the capacity of blast furnaces and allowed for increased furnace height.: 123–125 In addition to lower cost and greater availability, coke had other important advantages over charcoal in that it was harder and made the column of materials (iron ore, fuel, slag) flowing down the blast furnace more porous and did not crush in the much taller furnaces of the late 19th century.As cast iron became cheaper and widely available, it began being a structural material for bridges and buildings. A famous early example is the Iron Bridge built in 1778 with cast iron produced by Abraham Darby III. However, most cast iron was converted to wrought iron. Conversion of cast iron had long been done in a finery forge. An improved refining process known as potting and stamping was developed, but this was superseded by Henry Cort's puddling process. Cort developed two significant iron manufacturing processes: rolling in 1783 and puddling in 1784.: 91  Puddling produced a structural grade iron at a relatively low cost.\n",
      "Puddling was a means of decarburizing molten pig iron by slow oxidation in a reverberatory furnace by manually stirring it with a long rod.  The decarburized iron, having a higher melting point than cast iron, was raked into globs by the puddler. When the glob was large enough, the puddler would remove it. Puddling was backbreaking and extremely hot work. Few puddlers lived to be 40.: 218  Because puddling was done in a reverberatory furnace, coal or coke could be used as fuel. The puddling process continued to be used until the late 19th century when iron was being displaced by steel. Because puddling required human skill in sensing the iron globs, it was never successfully mechanised. Rolling was an important part of the puddling process because the grooved rollers expelled most of the molten slag and consolidated the mass of hot wrought iron. Rolling was 15 times faster at this than a trip hammer. A different use of rolling, which was done at lower temperatures than that for expelling slag, was in the production of iron sheets, and later structural shapes such as beams, angles, and rails.\n",
      "The puddling process was improved in 1818 by Baldwyn Rogers, who replaced some of the sand lining on the reverberatory furnace bottom with iron oxide. In 1838 John Hall patented the use of roasted tap cinder (iron silicate) for the furnace bottom, greatly reducing the loss of iron through increased slag caused by a sand lined bottom. The tap cinder also tied up some phosphorus, but this was not understood at the time.: 166  Hall's process also used iron scale or rust which reacted with carbon in the molten iron. Hall's process, called wet puddling, reduced losses of iron with the slag from almost 50% to around 8%.: 93 Puddling became widely used after 1800. Up to that time, British iron manufacturers had used considerable amounts of iron imported from Sweden and Russia to supplement domestic supplies. Because of the increased British production, imports began to decline in 1785, and by the 1790s Britain eliminated imports and became a net exporter of bar iron.\n",
      "Hot blast, patented by the Scottish inventor James Beaumont Neilson in 1828, was the most important development of the 19th century for saving energy in making pig iron. By using preheated combustion air, the amount of fuel to make a unit of pig iron was reduced at first by between one-third using coke or two-thirds using coal; the efficiency gains continued as the technology improved. Hot blast also raised the operating temperature of furnaces, increasing their capacity. Using less coal or coke meant introducing fewer impurities into the pig iron. This meant that lower quality coal could be used in areas where coking coal was unavailable or too expensive; however, by the end of the 19th century transportation costs fell considerably.\n",
      "Shortly before the Industrial Revolution, an improvement was made in the production of steel, which was an expensive commodity and used only where iron would not do, such as for cutting edge tools and for springs. Benjamin Huntsman developed his crucible steel technique in the 1740s. The raw material for this was blister steel, made by the cementation process. The supply of cheaper iron and steel aided a number of industries, such as those making nails, hinges, wire, and other hardware items. The development of machine tools allowed better working of iron, causing it to be increasingly used in the rapidly growing machinery and engine industries.\n",
      "\n",
      "Steam power\n",
      "The development of the stationary steam engine was an important element of the Industrial Revolution; however, during the early period of the Industrial Revolution, most industrial power was supplied by water and wind. In Britain, by 1800 an estimated 10,000 horsepower was being supplied by steam. By 1815 steam power had grown to 210,000 hp.The first commercially successful industrial use of steam power was patented by Thomas Savery in 1698. He constructed in London a low-lift combined vacuum and pressure water pump that generated about one horsepower (hp) and was used in numerous waterworks and in a few mines (hence its \"brand name\", The Miner's Friend). Savery's pump was economical in small horsepower ranges but was prone to boiler explosions in larger sizes. Savery pumps continued to be produced until the late 18th century.The first successful piston steam engine was introduced by Thomas Newcomen before 1712. Newcomen engines were installed for draining hitherto unworkable deep mines, with the engine on the surface; these were large machines, requiring a significant amount of capital to build, and produced upwards of 3.5 kW (5 hp). They were also used to power municipal water supply pumps. They were extremely inefficient by modern standards, but when located where coal was cheap at pit heads, they opened up a great expansion in coal mining by allowing mines to go deeper. Despite their disadvantages, Newcomen engines were reliable and easy to maintain and continued to be used in the coalfields until the early decades of the 19th century. \n",
      "By 1729, when Newcomen died, his engines had spread to Hungary in 1722, and then to Germany, Austria, and Sweden. A total of 110 are known to have been built by 1733 when the joint patent expired, of which 14 were abroad. In the 1770s the engineer John Smeaton built some very large examples and introduced a number of improvements. A total of 1,454 engines had been built by 1800.A fundamental change in working principles was brought about by Scotsman James Watt. With financial support from his business partner Englishman Matthew Boulton, he had succeeded by 1778 in perfecting his steam engine, which incorporated a series of radical improvements, notably the closing off of the upper part of the cylinder thereby making the low-pressure steam drive the top of the piston instead of the atmosphere; use of a steam jacket; and the celebrated separate steam condenser chamber. The separate condenser did away with the cooling water that had been injected directly into the cylinder which cooled the cylinder and wasted steam. Likewise, the steam jacket kept steam from condensing in the cylinder, also improving efficiency. These improvements increased engine efficiency so that Boulton and Watt's engines used only 20–25% as much coal per horsepower-hour as Newcomen's. Boulton and Watt opened the Soho Foundry for the manufacture of such engines in 1795.\n",
      "In 1783, the Watt steam engine had been fully developed into a double-acting rotative type, which meant that it could be used to directly drive the rotary machinery of a factory or mill. Both of Watt's basic engine types were commercially very successful, and by 1800 the firm Boulton & Watt had constructed 496 engines, with 164 driving reciprocating pumps, 24 serving blast furnaces, and 308 powering mill machinery; most of the engines generated from 3.5 to 7.5 kW (5 to 10 hp).\n",
      "Until about 1800, the most common pattern of steam engine was the beam engine, built as an integral part of a stone or brick engine-house, but soon various patterns of self-contained rotative engines (readily removable but not on wheels) were developed, such as the table engine. Around the start of the 19th century, at which time the Boulton and Watt patent expired, the Cornish engineer Richard Trevithick and the American Oliver Evans began to construct higher-pressure non-condensing steam engines, exhausting against the atmosphere. High pressure yielded an engine and boiler compact enough to be used on mobile road and rail locomotives and steamboats.Small industrial power requirements continued to be provided by animal and human muscle until widespread electrification in the early 20th century. These included crank-powered, treadle-powered and horse-powered workshop, and light industrial machinery.\n",
      "\n",
      "Machine tools\n",
      "Pre-industrial machinery was built by various craftsmen—millwrights built watermills and windmills; carpenters made wooden framing; and smiths and turners made metal parts. Wooden components had the disadvantage of changing dimensions with temperature and humidity, and the various joints tended to rack (work loose) over time. As the Industrial Revolution progressed, machines with metal parts and frames became more common. Other important uses of metal parts were in firearms and threaded fasteners, such as machine screws, bolts, and nuts. There was also the need for precision in making parts. Precision would allow better working machinery, interchangeability of parts, and standardization of threaded fasteners.\n",
      "The demand for metal parts led to the development of several machine tools. They have their origins in the tools developed in the 18th century by makers of clocks and watches and scientific instrument makers to enable them to batch-produce small mechanisms. Before the advent of machine tools, metal was worked manually using the basic hand tools of hammers, files, scrapers, saws, and chisels. Consequently, the use of metal machine parts was kept to a minimum. Hand methods of production were laborious and costly, and precision was difficult to achieve.The first large precision machine tool was the cylinder boring machine invented by John Wilkinson in 1774. It was used for boring the large-diameter cylinders on early steam engines. Wilkinson's boring machine differed from earlier cantilevered machines used for boring cannon in that the cutting tool was mounted on a beam that ran through the cylinder being bored and was supported outside on both ends.The planing machine, the milling machine and the shaping machine were developed in the early decades of the 19th century. Although the milling machine was invented at this time, it was not developed as a serious workshop tool until somewhat later in the 19th century.Henry Maudslay, who trained a school of machine tool makers early in the 19th century, was a mechanic with superior ability who had been employed at the Royal Arsenal, Woolwich. He worked as an apprentice at the Royal Arsenal under Jan Verbruggen. In 1774 Verbruggen had installed a horizontal boring machine which was the first industrial size lathe in the UK. Maudslay was hired away by Joseph Bramah for the production of high-security metal locks that required precision craftsmanship. Bramah patented a lathe that had similarities to the slide rest lathe.: 392–395  Maudslay perfected the slide rest lathe, which could cut machine screws of different thread pitches by using changeable gears between the spindle and the lead screw. Before its invention, screws could not be cut to any precision using various earlier lathe designs, some of which copied from a template.: 392–395  The slide rest lathe was called one of history's most important inventions. Although it was not entirely Maudslay's idea, he was the first person to build a functional lathe using a combination of known innovations of the lead screw, slide rest, and change gears.: 31, 36 Maudslay left Bramah's employment and set up his own shop. He was engaged to build the machinery for making ships' pulley blocks for the Royal Navy in the Portsmouth Block Mills. These machines were all-metal and were the first machines for mass production and making components with a degree of interchangeability. The lessons Maudslay learned about the need for stability and precision he adapted to the development of machine tools, and in his workshops, he trained a generation of men to build on his work, such as Richard Roberts, Joseph Clement and Joseph Whitworth.James Fox of Derby had a healthy export trade in machine tools for the first part of the 19th century, as did Matthew Murray of Leeds. Roberts was a maker of high-quality machine tools and a pioneer of the use of jigs and gauges for precision workshop measurement. The techniques to make mass-produced metal parts made with sufficient precision to be interchangeable is largely attributed to a program of the U.S. Department of War which perfected interchangeable parts for firearms in the early 19th century. In the half-century following the invention of the fundamental machine tools, the machine industry became the largest industrial sector of the U.S. economy, by value added.\n",
      "\n",
      "Chemicals\n",
      "The large-scale production of chemicals was an important development during the Industrial Revolution. The first of these was the production of sulphuric acid by the lead chamber process invented by the Englishman John Roebuck (James Watt's first partner) in 1746. He was able to greatly increase the scale of the manufacture by replacing the relatively expensive glass vessels formerly used with larger, less expensive chambers made of riveted sheets of lead. Instead of making a small amount each time, he was able to make around 50 kilograms (100 pounds) in each of the chambers, at least a tenfold increase.\n",
      "The production of an alkali on a large scale became an important goal as well, and Nicolas Leblanc succeeded in 1791 in introducing a method for the production of sodium carbonate (soda ash). The Leblanc process was a reaction of sulfuric acid with sodium chloride to give sodium sulfate and hydrochloric acid. The sodium sulfate was heated with calcium carbonate and coal to give a mixture of sodium carbonate and calcium sulfide. Adding water separated the soluble sodium carbonate from the calcium sulfide. The process produced a large amount of pollution (the hydrochloric acid was initially vented to the atmosphere, and calcium sulfide was a waste product). Nonetheless, this synthetic soda ash proved economical compared to that produced from burning specific plants (barilla or kelp), which were the previously dominant sources of soda ash, and also to potash (potassium carbonate) produced from hardwood ashes. These two chemicals were very important because they enabled the introduction of a host of other inventions, replacing many small-scale operations with more cost-effective and controllable processes. Sodium carbonate had many uses in the glass, textile, soap, and paper industries. Early uses for sulfuric acid included pickling (removing rust from) iron and steel, and for bleaching cloth.\n",
      "The development of bleaching powder (calcium hypochlorite) by Scottish chemist Charles Tennant in about 1800, based on the discoveries of French chemist Claude Louis Berthollet, revolutionised the bleaching processes in the textile industry by dramatically reducing the time required (from months to days) for the traditional process then in use, which required repeated exposure to the sun in bleach fields after soaking the textiles with alkali or sour milk. Tennant's factory at St Rollox, Glasgow, became the largest chemical plant in the world.\n",
      "After 1860 the focus on chemical innovation was in dyestuffs, and Germany took world leadership, building a strong chemical industry. Aspiring chemists flocked to German universities in the 1860–1914 era to learn the latest techniques. British scientists by contrast, lacked research universities and did not train advanced students; instead, the practice was to hire German-trained chemists.\n",
      "\n",
      "Concrete\n",
      "In 1824 Joseph Aspdin, a British bricklayer turned builder, patented a chemical process for making portland cement which was an important advance in the building trades. This process involves sintering a mixture of clay and limestone to about 1,400 °C (2,552 °F), then grinding it into a fine powder which is then mixed with water, sand and gravel to produce concrete. Portland cement concrete was used by the English engineer Marc Isambard Brunel several years later when constructing the Thames Tunnel. Concrete was used on a large scale in the construction of the London sewer system a generation later.\n",
      "\n",
      "Gas lighting\n",
      "Though others made a similar innovation elsewhere, the large-scale introduction of gas lighting was the work of William Murdoch, an employee of Boulton & Watt. The process consisted of the large-scale gasification of coal in furnaces, the purification of the gas (removal of sulphur, ammonia, and heavy hydrocarbons), and its storage and distribution. The first gas lighting utilities were established in London between 1812 and 1820. They soon became one of the major consumers of coal in the UK. Gas lighting affected social and industrial organisation because it allowed factories and stores to remain open longer than with tallow candles or oil lamps. Its introduction allowed nightlife to flourish in cities and towns as interiors and streets could be lighted on a larger scale than before.\n",
      "\n",
      "Glass making\n",
      "Glass was made in ancient Greece and Rome. A new method of glass production, known as the cylinder process, was developed in Europe during the early 19th century. In 1832 this process was used by the Chance Brothers to create sheet glass. They became the leading producers of window and plate glass. This advancement allowed for larger panes of glass to be created without interruption, thus freeing up the space planning in interiors as well as the fenestration of buildings. The Crystal Palace is the supreme example of the use of sheet glass in a new and innovative structure.\n",
      "\n",
      "Paper machine\n",
      "A machine for making a continuous sheet of paper on a loop of wire fabric was patented in 1798 by Louis-Nicolas Robert in France. The paper machine is known as a Fourdrinier after the financiers, brothers Sealy and Henry Fourdrinier, who were stationers in London. Although greatly improved and with many variations, the Fourdrinier machine is the predominant means of paper production today. The method of continuous production demonstrated by the paper machine influenced the development of continuous rolling of iron and later steel and other continuous production processes.\n",
      "\n",
      "Agriculture\n",
      "The British Agricultural Revolution is considered one of the causes of the Industrial Revolution because improved agricultural productivity freed up workers to work in other sectors of the economy. In contrast, per-capita food supply in Europe was stagnant or declining and did not improve in some parts of Europe until the late 18th century.The English lawyer Jethro Tull invented an improved seed drill in 1701. It was a mechanical seeder that distributed seeds evenly across a plot of land and planted them at the correct depth. This was important because the yield of seeds harvested to seeds planted at that time was around four or five. Tull's seed drill was very expensive and not very reliable and therefore did not have much of an effect. Good quality seed drills were not produced until the mid 18th century.: 26 Joseph Foljambe's Rotherham plough of 1730 was the first commercially successful iron plough.: 122 : 18, 21  The threshing machine, invented by the Scottish engineer Andrew Meikle in 1784, displaced hand threshing with a flail, a laborious job that took about one-quarter of agricultural labour.: 286  Lower labor requirements subsequently result in lowered wages and numbers of farm labourers, who faced near starvation, leading to the 1830 agricultural rebellion of the Swing Riots.\n",
      "Machine tools and metalworking techniques developed during the Industrial Revolution eventually resulted in precision manufacturing techniques in the late 19th century for mass-producing agricultural equipment, such as reapers, binders, and combine harvesters.\n",
      "\n",
      "Mining\n",
      "Coal mining in Britain, particularly in South Wales, started early. Before the steam engine, pits were often shallow bell pits following a seam of coal along the surface, which were abandoned as the coal was extracted. In other cases, if the geology was favourable the coal was mined by means of an adit or drift mine driven into the side of a hill. Shaft mining was done in some areas, but the limiting factor was the problem of removing water. It could be done by hauling buckets of water up the shaft or to a sough (a tunnel driven into a hill to drain a mine). In either case, the water had to be discharged into a stream or ditch at a level where it could flow away by gravity.The introduction of the steam pump by Thomas Savery in 1698 and the Newcomen steam engine in 1712 greatly facilitated the removal of water and enabled shafts to be made deeper, enabling more coal to be extracted. These were developments that had begun before the Industrial Revolution, but the adoption of John Smeaton's improvements to the Newcomen engine followed by James Watt's more efficient steam engines from the 1770s reduced the fuel costs of engines, making mines more profitable.  The Cornish engine, developed in the 1810s, was much more efficient than the Watt steam engine.Coal mining was very dangerous owing to the presence of firedamp in many coal seams. Some degree of safety was provided by the safety lamp which was invented in 1816 by Sir Humphry Davy and independently by George Stephenson. However, the lamps proved a false dawn because they became unsafe very quickly and provided a weak light. Firedamp explosions continued, often setting off coal dust explosions, so casualties grew during the entire 19th century. Conditions of work were very poor, with a high casualty rate from rock falls.\n",
      "\n",
      "Transportation\n",
      "At the beginning of the Industrial Revolution, inland transport was by navigable rivers and roads, with coastal vessels employed to move heavy goods by sea. Wagonways were used for conveying coal to rivers for further shipment, but canals had not yet been widely constructed. Animals supplied all of the motive power on land, with sails providing the motive power on the sea. The first horse railways were introduced toward the end of the 18th century, with steam locomotives being introduced in the early decades of the 19th century. Improving sailing technologies boosted average sailing speed by 50% between 1750 and 1830.The Industrial Revolution improved Britain's transport infrastructure with a turnpike road network, a canal and waterway network, and a railway network. Raw materials and finished products could be moved more quickly and cheaply than before. Improved transportation also allowed new ideas to spread quickly.\n",
      "\n",
      "Canals and improved waterways\n",
      "Before and during the Industrial Revolution navigation on several British rivers was improved by removing obstructions, straightening curves, widening and deepening, and building navigation locks. Britain had over 1,600 kilometres (1,000 mi) of navigable rivers and streams by 1750.: 46  Canals and waterways allowed bulk materials to be economically transported long distances inland. This was because a horse could pull a barge with a load dozens of times larger than the load that could be drawn in a cart.Canals began to be built in the UK in the late 18th century to link the major manufacturing centres across the country. Known for its huge commercial success, the Bridgewater Canal in North West England, which opened in 1761 and was mostly funded by The 3rd Duke of Bridgewater.  From Worsley to the rapidly growing town of Manchester its construction cost £168,000 (£22,589,130 as of 2013), but its advantages over land and river transport meant that within a year of its opening in 1761, the price of coal in Manchester fell by about half. This success helped inspire a period of intense canal building, known as Canal Mania. Canals were hastily built with the aim of replicating the commercial success of the Bridgewater Canal, the most notable being the Leeds and Liverpool Canal and the Thames and Severn Canal which opened in 1774 and 1789 respectively.\n",
      "By the 1820s a national network was in existence. Canal construction served as a model for the organisation and methods later used to construct the railways. They were eventually largely superseded as profitable commercial enterprises by the spread of the railways from the 1840s on. The last major canal to be built in the United Kingdom was the Manchester Ship Canal, which upon opening in 1894 was the largest ship canal in the world, and opened Manchester as a port. However, it never achieved the commercial success its sponsors had hoped for and signalled canals as a dying mode of transport in an age dominated by railways, which were quicker and often cheaper.\n",
      "Britain's canal network, together with its surviving mill buildings, is one of the most enduring features of the early Industrial Revolution to be seen in Britain.\n",
      "\n",
      "Roads\n",
      "France was known for having an excellent system of roads at the time of the Industrial Revolution; however, most of the roads on the European continent and in the UK were in bad condition and dangerously rutted. Much of the original British road system was poorly maintained by thousands of local parishes, but from the 1720s (and occasionally earlier) turnpike trusts were set up to charge tolls and maintain some roads. Increasing numbers of main roads were turnpiked from the 1750s to the extent that almost every main road in England and Wales was the responsibility of a turnpike trust. New engineered roads were built by John Metcalf, Thomas Telford and most notably John McAdam, with the first 'macadam' stretch of road being Marsh Road at Ashton Gate, Bristol in 1816. The first macadam road in the U.S. was the \"Boonsborough Turnpike Road\" between Hagerstown and Boonsboro, Maryland in 1823.The major turnpikes radiated from London and were the means by which the Royal Mail was able to reach the rest of the country. Heavy goods transport on these roads was by means of slow, broad-wheeled carts hauled by teams of horses. Lighter goods were conveyed by smaller carts or by teams of packhorse. Stagecoaches carried the rich, and the less wealthy could pay to ride on carriers carts. Productivity of road transport increased greatly during the Industrial Revolution, and the cost of travel fell dramatically. Between 1690 and 1840 productivity almost tripled for long-distance carrying and increased four-fold in stage coaching.\n",
      "\n",
      "Railways\n",
      "Railways were made practical by the widespread introduction of inexpensive puddled iron after 1800, the rolling mill for making rails, and the development of the high-pressure steam engine also around 1800. Reducing friction was one of the major reasons for the success of railroads compared to wagons. This was demonstrated on an iron plate-covered wooden tramway in 1805 at Croydon, England.\n",
      "\n",
      "A good horse on an ordinary turnpike road can draw two thousand pounds, or one ton. A party of gentlemen were invited to witness the experiment, that the superiority of the new road might be established by ocular demonstration. Twelve wagons were loaded with stones, till each wagon weighed three tons, and the wagons were fastened together. A horse was then attached, which drew the wagons with ease, six miles [10 km] in two hours, having stopped four times, in order to show he had the power of starting, as well as drawing his great load.\n",
      "Wagonways for moving coal in the mining areas had started in the 17th century and were often associated with canal or river systems for the further movement of coal. These were all horse-drawn or relied on gravity, with a stationary steam engine to haul the wagons back to the top of the incline. The first applications of the steam locomotive were on wagon or plate ways (as they were then often called from the cast-iron plates used). Horse-drawn public railways begin in the early 19th century when improvements to pig and wrought iron production were lowering costs.\n",
      "Steam locomotives began being built after the introduction of high-pressure steam engines after the expiration of the Boulton and Watt patent in 1800. High-pressure engines exhausted used steam to the atmosphere, doing away with the condenser and cooling water. They were also much lighter weight and smaller in size for a given horsepower than the stationary condensing engines. A few of these early locomotives were used in mines. Steam-hauled public railways began with the Stockton and Darlington Railway in 1825.The rapid introduction of railways followed the 1829 Rainhill trials, which demonstrated Robert Stephenson's successful locomotive design and the 1828 development of hot blast, which dramatically reduced the fuel consumption of making iron and increased the capacity of the blast furnace. On 15 September 1830, the Liverpool and Manchester Railway, the first inter-city railway in the world, was opened and was attended by Prime Minister Arthur Wellesley. The railway was engineered by Joseph Locke and George Stephenson, linked the rapidly expanding industrial town of Manchester with the port town of Liverpool. The opening was marred by problems caused by the primitive nature of the technology being employed; however, problems were gradually solved, and the railway became highly successful, transporting passengers and freight.\n",
      "The success of the inter-city railway, particularly in the transport of freight and commodities, led to Railway Mania. Construction of major railways connecting the larger cities and towns began in the 1830s but only gained momentum at the very end of the first Industrial Revolution. After many of the workers had completed the railways, they did not return to their rural lifestyles but instead remained in the cities, providing additional workers for the factories.\n",
      "\n",
      "Social effects\n",
      "On a structural level the Industrial Revolution asked society the so-called social question, demanding new ideas for managing large groups of individuals. Visible poverty on one hand and growing population and materialistic wealth on the other caused tensions between the very rich and the poorest people within society. These tensions were sometimes violently released and led to philosophical ideas such as socialism, communism and anarchism.\n",
      "\n",
      "Factory system\n",
      "Prior to the Industrial Revolution, most of the workforce was employed in agriculture, either as self-employed farmers as landowners or tenants or as landless agricultural labourers. It was common for families in various parts of the world to spin yarn, weave cloth and make their own clothing. Households also spun and wove for market production.  At the beginning of the Industrial Revolution, India, China, and regions of Iraq and elsewhere in Asia and the Middle East produced most of the world's cotton cloth while Europeans produced wool and linen goods.\n",
      "In Great Britain in the 16th century, the putting-out system was practised, by which farmers and townspeople produced goods for a market in their homes, often described as cottage industry. Typical putting-out system goods included spinning and weaving. Merchant capitalists typically provided the raw materials, paid workers by the piece, and were responsible for the sale of the goods. Embezzlement of supplies by workers and poor quality were common problems. The logistical effort in procuring and distributing raw materials and picking up finished goods were also limitations of the putting-out system.: 57–59 Some early spinning and weaving machinery, such as a 40 spindle jenny for about six pounds in 1792, was affordable for cottagers.: 59  Later machinery such as spinning frames, spinning mules and power looms were expensive (especially if water-powered), giving rise to capitalist ownership of factories.\n",
      "The majority of textile factory workers during the Industrial Revolution were unmarried women and children, including many orphans. They typically worked for 12 to 14 hours per day with only Sundays off. It was common for women to take factory jobs seasonally during slack periods of farm work. Lack of adequate transportation, long hours, and poor pay made it difficult to recruit and maintain workers.The change in the social relationship of the factory worker compared to farmers and cottagers was viewed unfavourably by Karl Marx; however, he recognized the increase in productivity made possible by technology.\n",
      "\n",
      "Standards of living\n",
      "Some economists, such as Robert Lucas Jr., say that the real effect of the Industrial Revolution was that \"for the first time in history, the living standards of the masses of ordinary people have begun to undergo sustained growth ... Nothing remotely like this economic behaviour is mentioned by the classical economists, even as a theoretical possibility.\" Others argue that while the growth of the economy's overall productive powers was unprecedented during the Industrial Revolution, living standards for the majority of the population did not grow meaningfully until the late 19th and 20th centuries and that in many ways workers' living standards declined under early capitalism: some studies have estimated that real wages in Britain only increased 15% between the 1780s and 1850s and that life expectancy in Britain did not begin to dramatically increase until the 1870s.The average height of the population declined during the Industrial Revolution, implying that their nutritional status was also decreasing.During the Industrial Revolution, the life expectancy of children increased dramatically. The percentage of the children born in London who died before the age of five decreased from 74.5% in 1730–1749 to 31.8% in 1810–1829. The effects on living conditions have been controversial and were hotly debated by economic and social historians from the 1950s to the 1980s. Over the course of the period from 1813 to 1913, there was a significant increase in worker wages.\n",
      "\n",
      "Food and nutrition\n",
      "Chronic hunger and malnutrition were the norms for the majority of the population of the world including Britain and France until the late 19th century. Until about 1750, malnutrition limited life expectancy in France to about 35 years and about 40 years in Britain. The United States population of the time was adequately fed, much taller on average, and had a life expectancy of 45–50 years, although U.S. life expectancy declined by a few years by the mid 19th century. Food consumption per capita also declined during an episode known as the Antebellum Puzzle.Food supply in Great Britain was adversely affected by the Corn Laws (1815–1846) which imposed tariffs on imported grain. The laws were enacted to keep prices high in order to benefit domestic producers. The Corn Laws were repealed in the early years of the Great Irish Famine.\n",
      "The initial technologies of the Industrial Revolution, such as mechanized textiles, iron and coal, did little, if anything, to lower food prices. In Britain and the Netherlands, food supply increased before the Industrial Revolution with better agricultural practices; however, population grew as well.\n",
      "\n",
      "Housing\n",
      "The rapid population growth in the 19th century included the new industrial and manufacturing cities, as well as service centers such as Edinburgh and London. The critical factor was financing, which was handled by building societies that dealt directly with large contracting firms. Private renting from housing landlords was the dominant tenure. P. Kemp says this was usually of advantage to tenants. People moved in so rapidly there was not enough capital to build adequate housing for everyone, so low-income newcomers squeezed into increasingly overcrowded slums. Clean water, sanitation, and public health facilities were inadequate; the death rate was high, especially infant mortality, and tuberculosis among young adults. Cholera from polluted water and typhoid were endemic. Unlike rural areas, there were no famines such as the one that devastated Ireland in the 1840s.A large exposé literature grew up condemning the unhealthy conditions. By far the most famous publication was by one of the founders of the socialist movement, The Condition of the Working Class in England in 1844 Friedrich Engels describes backstreet sections of Manchester and other mill towns, where people lived in crude shanties and shacks, some not completely enclosed, some with dirt floors. These shanty towns had narrow walkways between irregularly shaped lots and dwellings.  There were no sanitary facilities. The population density was extremely high. However, not everyone lived in such poor conditions. The Industrial Revolution also created a middle class of businessmen, clerks, foremen, and engineers who lived in much better conditions.\n",
      "Conditions improved over the course of the 19th century with new public health acts regulating things such as sewage, hygiene, and home construction. In the introduction of his 1892 edition, Engels notes that most of the conditions he wrote about in 1844 had been greatly improved. For example, the Public Health Act 1875 led to the more sanitary byelaw terraced house.\n",
      "\n",
      "Water and sanitation\n",
      "Pre-industrial water supply relied on gravity systems, and pumping of water was done by water wheels. Pipes were typically made of wood. Steam-powered pumps and iron pipes allowed the widespread piping of water to horse watering troughs and households.Engels' book describes how untreated sewage created awful odours and turned the rivers green in industrial cities. In 1854 John Snow traced a cholera outbreak in Soho in London to fecal contamination of a public water well by a home cesspit. Snow's findings that cholera could be spread by contaminated water took some years to be accepted, but his work led to fundamental changes in the design of public water and waste systems.\n",
      "\n",
      "Literacy\n",
      "In the 18th century, there were relatively high levels of literacy among farmers in England and Scotland. This permitted the recruitment of literate craftsmen, skilled workers, foremen, and managers who supervised the emerging textile factories and coal mines. Much of the labour was unskilled, and especially in textile mills children as young as eight proved useful in handling chores and adding to the family income. Indeed, children were taken out of school to work alongside their parents in the factories. However, by the mid-19th century, unskilled labor forces were common in Western Europe, and British industry moved upscale, needing many more engineers and skilled workers who could handle technical instructions and handle complex situations. Literacy was essential to be hired. A senior government official told Parliament in 1870:\n",
      "\n",
      "Upon the speedy provision of elementary education depends are industrial prosperity. It is of no use trying to give technical teaching to our citizens without elementary education; uneducated labourers—and many of our labourers are utterly uneducated—are, for the most part, unskilled labourers, and if we leave our work–folk any longer unskilled, notwithstanding their strong sinews and determined energy, they will become overmatched in the competition of the world.The invention of the paper machine and the application of steam power to the industrial processes of printing supported a massive expansion of newspaper and pamphlet publishing, which contributed to rising literacy and demands for mass political participation.\n",
      "\n",
      "Clothing and consumer goods\n",
      "Consumers benefited from falling prices for clothing and household articles such as cast iron cooking utensils, and in the following decades, stoves for cooking and space heating. Coffee, tea, sugar, tobacco, and chocolate became affordable to many in Europe. The consumer revolution in England from the early 17th century to the mid-18th century had seen a marked increase in the consumption and variety of luxury goods and products by individuals from different economic and social backgrounds. With improvements in transport and manufacturing technology, opportunities for buying and selling became faster and more efficient than previous. The expanding textile trade in the north of England meant the three-piece suit became affordable to the masses. Founded by Josiah Wedgwood in 1759, Wedgwood fine china and porcelain tableware was starting to become a common feature on dining tables. Rising prosperity and social mobility in the 18th century increased the number of people with disposable income for consumption, and the marketing of goods (of which Wedgwood was a pioneer) for individuals, as opposed to items for the household, started to appear, and the new status of goods as status symbols related to changes in fashion and desired for aesthetic appeal.\n",
      "With the rapid growth of towns and cities, shopping became an important part of everyday life. Window shopping and the purchase of goods became a cultural activity in its own right, and many exclusive shops were opened in elegant urban districts: in the Strand and Piccadilly in London, for example, and in spa towns such as Bath and Harrogate. Prosperity and expansion in manufacturing industries such as pottery and metalware increased consumer choice dramatically. Where once labourers ate from metal platters with wooden implements, ordinary workers now dined on Wedgwood porcelain. Consumers came to demand an array of new household goods and furnishings: metal knives and forks, for example, as well as rugs, carpets, mirrors, cooking ranges, pots, pans, watches, clocks, and a dizzying array of furniture. The age of mass consumption had arrived.\n",
      "New businesses in various industries appeared in towns and cities throughout Britain. Confectionery was one such industry that saw rapid expansion. According to food historian Polly Russell: \"chocolate and biscuits became products for the masses, thanks to the Industrial Revolution and the consumers it created. By the mid-19th century, sweet biscuits were an affordable indulgence and business was booming. Manufacturers such as Huntley & Palmers in Reading, Carr's of Carlisle and McVitie's in Edinburgh transformed from small family-run businesses into state-of-the-art operations\". In 1847 Fry's of Bristol produced the first chocolate bar. Their competitor Cadbury of Birmingham was the first to commercialize the association between confectionery and romance when they produced a heart-shaped box of chocolates for Valentine's Day in 1868. The department store became a common feature in major High Streets across Britain; one of the first was opened in 1796 by Harding, Howell & Co. on Pall Mall in London.In addition to goods being sold in the growing number of stores, street sellers were common in an increasingly urbanized country. Matthew White: \"Crowds swarmed in every thoroughfare. Scores of street sellers 'cried' merchandise from place to place, advertising the wealth of goods and services on offer. Milkmaids, orange sellers, fishwives and piemen, for example, all walked the streets offering their various wares for sale, while knife grinders and the menders of broken chairs and furniture could be found on street corners\". An early soft drinks company, R. White's Lemonade, began in 1845 by selling drinks in London in a wheelbarrow.Increased literacy rates, industrialisation, and the invention of the railway created a new market for cheap popular literature for the masses and the ability for it to be circulated on a large scale. Penny dreadfuls were created in the 1830s to meet this demand. The Guardian described penny dreadfuls as \"Britain's first taste of mass-produced popular culture for the young\", and \"the Victorian equivalent of video games\". By the 1860s and 1870s more than one million boys' periodicals were sold per week. Labelled an \"authorpreneur\" by The Paris Review, Charles Dickens used innovations from the revolution to sell his books, such as the new printing presses, enhanced advertising revenues, and the expansion of railroads. His first novel, The Pickwick Papers (1836), became a publishing phenomenon with its unprecedented success sparking numerous spin-offs and merchandise ranging from Pickwick cigars, playing cards, china figurines, Sam Weller puzzles, Weller boot polish and joke books. Nicholas Dames in The Atlantic writes, \"Literature\" is not a big enough category for Pickwick. It defined its own, a new one that we have learned to call \"entertainment\".In 1861, Welsh entrepreneur Pryce Pryce-Jones formed the first mail order business, an idea which would change the nature of retail. Selling Welsh flannel, he created mail order catalogues, with customers able to order by mail for the first time—this following the Uniform Penny Post in 1840 and the invention of the postage stamp (Penny Black) where there was a charge of one penny for carriage and delivery between any two places in the United Kingdom irrespective of distance—and the goods were delivered throughout the UK via the newly created railway system. As the railway network expanded overseas, so did his business.\n",
      "\n",
      "Population increase\n",
      "The Industrial Revolution was the first period in history during which there was a simultaneous increase in both population and per capita income. According to Robert Hughes in The Fatal Shore, the population of England and Wales, which had remained steady at six million from 1700 to 1740, rose dramatically after 1740. The population of England had more than doubled from 8.3 million in 1801 to 16.8 million in 1850 and, by 1901, had nearly doubled again to 30.5 million. Improved conditions led to the population of Britain increasing from 10 million to 30 million in the 19th century. Europe's population increased from about 100 million in 1700 to 400 million by 1900.\n",
      "\n",
      "Urbanization\n",
      "The growth of the modern industry since the late 18th century led to massive urbanisation and the rise of new great cities, first in Europe and then in other regions, as new opportunities brought huge numbers of migrants from rural communities into urban areas.  In 1800, only 3% of the world's population lived in cities, compared to nearly 50% by the beginning of the 21st century. Manchester had a population of 10,000 in 1717, but by 1911 it had burgeoned to 2.3 million.\n",
      "\n",
      "Effect on women and family life\n",
      "Women's historians have debated the effect of the Industrial Revolution and capitalism generally on the status of women. Taking a pessimistic side, Alice Clark argues that when capitalism arrived in 17th-century England, it lowered the status of women as they lost much of their economic importance. Clark argues that in 16th-century England, women were engaged in many aspects of industry and agriculture. The home was a central unit of production, and women played a vital role in running farms and in some trades and landed estates. Their useful economic roles gave them a sort of equality with their husbands. However, Clark argues, as capitalism expanded in the 17th century, there was more division of labour with the husband taking paid labour jobs outside the home, and the wife was reduced to unpaid household work. Middle- and upper-class women were confined to an idle domestic existence, supervising servants; lower-class women were forced to take poorly paid jobs. Capitalism, therefore, had a negative effect on powerful women.In a more positive interpretation, Ivy Pinchbeck argues that capitalism created the conditions for women's emancipation. Tilly and Scott have emphasised the continuity in the status of women, finding three stages in English history. In the pre-industrial era, production was mostly for home use, and women produced much of the needs of the households. The second stage was the \"family wage economy\" of early industrialisation; the entire family depended on the collective wages of its members, including husband, wife, and older children. The third or modern stage is the \"family consumer economy\", in which the family is the site of consumption, and women are employed in large numbers in retail and clerical jobs to support rising standards of consumption.Ideas of thrift and hard work characterized middle-class families as the Industrial Revolution swept Europe. These values were displayed in Samuel Smiles' book Self-Help, in which he states that the misery of the poorer classes was \"voluntary and self-imposed—the results of idleness, thriftlessness, intemperance, and misconduct.\"\n",
      "\n",
      "Labour conditions\n",
      "Social structure and working conditions\n",
      "In terms of social structure, the Industrial Revolution witnessed the triumph of a middle class of industrialists and businessmen over a landed class of nobility and gentry. Ordinary working people found increased opportunities for employment in mills and factories, but these were often under strict working conditions with long hours of labour dominated by a pace set by machines. As late as 1900, most industrial workers in the United States worked a 10-hour day (12 hours in the steel industry), yet earned 20–40% less than the minimum deemed necessary for a decent life; however, most workers in textiles, which was by far the leading industry in terms of employment, were women and children. For workers of the labouring classes, industrial life \"was a stony desert, which they had to make habitable by their own efforts.\"Harsh working conditions were prevalent long before the Industrial Revolution took place. Pre-industrial society was very static and often cruel—child labour, dirty living conditions, and long working hours were just as prevalent before the Industrial Revolution.\n",
      "\n",
      "Factories and urbanisation\n",
      "Industrialisation led to the creation of the factory. The factory system contributed to the growth of urban areas as large numbers of workers migrated into the cities in search of work in the factories. Nowhere was this better illustrated than the mills and associated industries of Manchester, nicknamed \"Cottonopolis\", and the world's first industrial city. Manchester experienced a six-times increase in its population between 1771 and 1831. Bradford grew by 50% every ten years between 1811 and 1851, and by 1851 only 50% of the population of Bradford were actually born there.In addition, between 1815 and 1939, 20% of Europe's population left home, pushed by poverty, a rapidly growing population, and the displacement of peasant farming and artisan manufacturing. They were pulled abroad by the enormous demand for labour overseas, the ready availability of land, and cheap transportation. Still, many did not find a satisfactory life in their new homes, leading 7 million of them to return to Europe. This mass migration had large demographic effects: in 1800, less than 1% of the world population consisted of overseas Europeans and their descendants; by 1930, they represented 11%. The Americas felt the brunt of this huge emigration, largely concentrated in the United States.\n",
      "For much of the 19th century, production was done in small mills which were typically water-powered and built to serve local needs. Later, each factory would have its own steam engine and a chimney to give an efficient draft through its boiler.\n",
      "In other industries, the transition to factory production was not so divisive. Some industrialists tried to improve factory and living conditions for their workers. One of the earliest such reformers was Robert Owen, known for his pioneering efforts in improving conditions for workers at the New Lanark mills and often regarded as one of the key thinkers of the early socialist movement.\n",
      "By 1746 an integrated brass mill was working at Warmley near Bristol. Raw material went in at one end, was smelted into brass and was turned into pans, pins, wire, and other goods. Housing was provided for workers on site. Josiah Wedgwood and Matthew Boulton (whose Soho Manufactory was completed in 1766) were other prominent early industrialists who employed the factory system.\n",
      "\n",
      "Child labour\n",
      "The Industrial Revolution led to a population increase, but the chances of surviving childhood did not improve throughout the Industrial Revolution, although infant mortality rates were reduced markedly. There was still limited opportunity for education, and children were expected to work. Employers could pay a child less than an adult even though their productivity was comparable; there was no need for strength to operate an industrial machine, and since the industrial system was new, there were no experienced adult labourers. This made child labour the labour of choice for manufacturing in the early phases of the Industrial Revolution between the 18th and 19th centuries. In England and Scotland in 1788, two-thirds of the workers in 143 water-powered cotton mills were described as children.Child labour existed before the Industrial Revolution, but with the increase in population and education it became more visible. Many children were forced to work in relatively bad conditions for much lower pay than their elders, 10–20% of an adult male's wage.Reports were written detailing some of the abuses, particularly in the coal mines and textile factories, and these helped to popularise the children's plight. The public outcry, especially among the upper and middle classes, helped stir change in the young workers' welfare.\n",
      "Politicians and the government tried to limit child labour by law, but factory owners resisted; some felt that they were aiding the poor by giving their children money to buy food to avoid starvation, and others simply welcomed the cheap labour. In 1833 and 1844, the first general laws against child labour, the Factory Acts, were passed in Britain: children younger than nine were not allowed to work, children were not permitted to work at night, and the workday of youth under age 18 was limited to twelve hours. Factory inspectors supervised the execution of the law; however, their scarcity made enforcement difficult. About ten years later, the employment of children and women in mining was forbidden. Although laws such as these decreased the number of child labourers, child labour remained significantly present in Europe and the United States until the 20th century.\n",
      "\n",
      "Organisation of labour\n",
      "The Industrial Revolution concentrated labour into mills, factories, and mines, thus facilitating the organisation of combinations or trade unions to help advance the interests of working people. The power of a union could demand better terms by withdrawing all labour and causing a consequent cessation of production. Employers had to decide between giving in to the union demands at a cost to themselves or suffering the cost of the lost production. Skilled workers were difficult to replace, and these were the first groups to successfully advance their conditions through this kind of bargaining.\n",
      "The main method the unions used to effect change was strike action. Many strikes were painful events for both sides, the unions and the management. In Britain, the Combination Act 1799 forbade workers to form any kind of trade union until its repeal in 1824. Even after this, unions were still severely restricted. One British newspaper in 1834 described unions as \"the most dangerous institutions that were ever permitted to take root, under shelter of law, in any country...\"In 1832, the Reform Act extended the vote in Britain but did not grant universal suffrage. That year six men from Tolpuddle in Dorset founded the Friendly Society of Agricultural Labourers to protest against the gradual lowering of wages in the 1830s. They refused to work for less than ten shillings per week, although by this time wages had been reduced to seven shillings per week and were due to be further reduced to six. In 1834 James Frampton, a local landowner, wrote to Prime Minister Lord Melbourne to complain about the union, invoking an obscure law from 1797 prohibiting people from swearing oaths to each other, which the members of the Friendly Society had done. Six men were arrested, found guilty, and transported to Australia. They became known as the Tolpuddle Martyrs. In the 1830s and 1840s, the chartist movement was the first large-scale organised working-class political movement that campaigned for political equality and social justice. Its Charter of reforms received over three million signatures but was rejected by Parliament without consideration.\n",
      "Working people also formed friendly societies and cooperative societies as mutual support groups against times of economic hardship. Enlightened industrialists, such as Robert Owen supported these organisations to improve the conditions of the working class. Unions slowly overcame the legal restrictions on the right to strike. In 1842, a general strike involving cotton workers and colliers was organised through the chartist movement which stopped production across Great Britain. Eventually, effective political organisation for working people was achieved through the trades unions who, after the extensions of the franchise in 1867 and 1885, began to support socialist political parties that later merged to become the British Labour Party.\n",
      "\n",
      "Luddites\n",
      "The rapid industrialisation of the English economy cost many craft workers their jobs. The movement started first with lace and hosiery workers near Nottingham and spread to other areas of the textile industry. Many weavers also found themselves suddenly unemployed since they could no longer compete with machines which only required relatively limited (and unskilled) labour to produce more cloth than a single weaver. Many such unemployed workers, weavers, and others turned their animosity towards the machines that had taken their jobs and began destroying factories and machinery. These attackers became known as Luddites, supposedly followers of Ned Ludd, a folklore figure. The first attacks of the Luddite movement began in 1811. The Luddites rapidly gained popularity, and the British government took drastic measures using the militia or army to protect industry. Those rioters who were caught were tried and hanged, or transported for life.Unrest continued in other sectors as they industrialised, such as with agricultural labourers in the 1830s when large parts of southern Britain were affected by the Captain Swing disturbances. Threshing machines were a particular target, and hayrick burning was a popular activity. However, the riots led to the first formation of trade unions and further pressure for reform.\n",
      "\n",
      "Shift in production's center of gravity\n",
      "The traditional centers of hand textile production such as India, parts of the Middle East, and later China could not withstand the competition from machine-made textiles, which over a period of decades destroyed the hand made textile industries and left millions of people without work, many of whom starved.The Industrial Revolution generated an enormous and unprecedented economic division in the world, as measured by the share of manufacturing output.\n",
      "\n",
      "Cotton and the expansion of slavery\n",
      "Cheap cotton textiles increased the demand for raw cotton; previously, it had primarily been consumed in subtropical regions where it was grown, with little raw cotton available for export. Consequently, prices of raw cotton rose. British production grew from 2 million pounds in 1700 to 5 million pounds in 1781 to 56 million in 1800. The invention of the cotton gin by American Eli Whitney in 1792 was the decisive event. It allowed green-seeded cotton to become profitable, leading to the widespread growth of the large slave plantation in the United States, Brazil, and the West Indies. In 1791 American cotton production was about 2 million pounds, soaring to 35 million by 1800, half of which was exported. America's cotton plantations were highly efficient and profitable and were able to keep up with demand. The U.S. Civil War created a \"cotton famine\" that led to increased production in other areas of the world, including European colonies in Africa.\n",
      "\n",
      "Effect on environment\n",
      "The origins of the environmental movement lay in the response to increasing levels of smoke pollution in the atmosphere during the Industrial Revolution. The emergence of great factories and the concomitant immense growth in coal consumption gave rise to an unprecedented level of air pollution in industrial centers; after 1900 the large volume of industrial chemical discharges added to the growing load of untreated human waste. The first large-scale, modern environmental laws came in the form of Britain's Alkali Acts, passed in 1863, to regulate the deleterious air pollution (gaseous hydrochloric acid) given off by the Leblanc process used to produce soda ash. An alkali inspector and four sub-inspectors were appointed to curb this pollution. The responsibilities of the inspectorate were gradually expanded, culminating in the Alkali Order 1958 which placed all major heavy industries that emitted smoke, grit, dust, and fumes under supervision.\n",
      "The manufactured gas industry began in British cities in 1812–1820. The technique used produced highly toxic effluent that was dumped into sewers and rivers. The gas companies were repeatedly sued in nuisance lawsuits. They usually lost and modified the worst practices. The City of London repeatedly indicted gas companies in the 1820s for polluting the Thames and poisoning its fish. Finally, Parliament wrote company charters to regulate toxicity. The industry reached the U.S. around 1850 causing pollution and lawsuits.In industrial cities local experts and reformers, especially after 1890, took the lead in identifying environmental degradation and pollution, and initiating grass-roots movements to demand and achieve reforms. Typically the highest priority went to water and air pollution. The Coal Smoke Abatement Society was formed in Britain in 1898 making it one of the oldest environmental non-governmental organizations. It was founded by artist William Blake Richmond, frustrated with the pall cast by coal smoke. Although there were earlier pieces of legislation, the Public Health Act 1875 required all furnaces and fireplaces to consume their own smoke. It also provided for sanctions against factories that emitted large amounts of black smoke. The provisions of this law were extended in 1926 with the Smoke Abatement Act to include other emissions, such as soot, ash, and gritty particles, and to empower local authorities to impose their own regulations.\n",
      "\n",
      "Industrialisation beyond Great Britain\n",
      "Europe\n",
      "The Industrial Revolution in continental Europe came later than in Great Britain. It started in Belgium and France, then spread to the German states by the middle of the 19th century. In many industries, this involved the application of technology developed in Britain in new places. Typically, the technology was purchased from Britain or British engineers and entrepreneurs moved abroad in search of new opportunities. By 1809, part of the Ruhr Valley in Westphalia was called 'Miniature England' because of its similarities to the industrial areas of Britain. Most European governments provided state funding to the new industries. In some cases (such as iron), the different availability of resources locally meant that only some aspects of the British technology were adopted.\n",
      "\n",
      "Austria-Hungary\n",
      "The Habsburg realms which became Austria-Hungary in 1867 included 23 million inhabitants in 1800, growing to 36 million by 1870. Nationally, the per capita rate of industrial growth averaged about 3% between 1818 and 1870. However, there were strong regional differences. The railway system was built in the 1850–1873 period. Before they arrived transportation was very slow and expensive. In the Alpine and Bohemian (modern-day Czech Republic) regions, proto-industrialization began by 1750 and became the center of the first phases of the Industrial Revolution after 1800. The textile industry was the main factor, utilizing mechanization, steam engines, and the factory system. In the Czech lands, the \"first mechanical loom followed in Varnsdorf in 1801\", with the first steam engines appearing in Bohemia and Moravia just a few years later. The textile production flourished particularly in Prague and Brno (German: Brünn), which was considered the 'Moravian Manchester'. The Czech lands, especially Bohemia, became the center of industrialization due to its natural and human resources. The iron industry had developed in the Alpine regions after 1750, with smaller centers in Bohemia and Moravia. Hungary—the eastern half of the Dual Monarchy, was heavily rural with little industry before 1870.In 1791, Prague organized the first World's Fair/List of world's fairs, Bohemia (modern-day Czech Republic). The first industrial exhibition was on the occasion of the coronation of Leopold II as a king of Bohemia, which took place in Clementinum, and therefore celebrated the considerable sophistication of manufacturing methods in the Czech lands during that time period.Technological change accelerated industrialization and urbanization. The GNP per capita grew roughly 1.76% per year from 1870 to 1913. That level of growth compared very favorably to that of other European nations such as Britain (1%), France (1.06%), and Germany (1.51%). However, in a comparison with Germany and Britain: the Austro-Hungarian economy as a whole still lagged considerably, as sustained modernization had begun much later.\n",
      "\n",
      "Belgium\n",
      "Belgium was the second country in which the Industrial Revolution took place and the first in continental Europe: Wallonia (French-speaking southern Belgium) took the lead. Starting in the middle of the 1820s, and especially after Belgium became an independent nation in 1830, numerous works comprising coke blast furnaces as well as puddling and rolling mills were built in the coal mining areas around Liège and Charleroi. The leader was a transplanted Englishman John Cockerill. His factories at Seraing integrated all stages of production, from engineering to the supply of raw materials, as early as 1825.Wallonia exemplified the radical evolution of industrial expansion. Thanks to coal (the French word \"houille\" was coined in Wallonia), the region geared up to become the 2nd industrial power in the world after Britain. But it is also pointed out by many researchers, with its Sillon industriel, \"Especially in the Haine, Sambre and Meuse valleys, between the Borinage and Liège...there was a huge industrial development based on coal-mining and iron-making...\". Philippe Raxhon wrote about the period after 1830: \"It was not propaganda but a reality the Walloon regions were becoming the second industrial power all over the world after Britain.\" \"The sole industrial centre outside the collieries and blast furnaces of Walloon was the old cloth-making town of Ghent.\" Professor Michel De Coster stated: \"The historians and the economists say that Belgium was the second industrial power of the world, in proportion to its population and its territory [...] But this rank is the one of Wallonia where the coal-mines, the blast furnaces, the iron and zinc factories, the wool industry, the glass industry, the weapons industry... were concentrated.\" Many of the 19th-century coal mines in Wallonia are now protected as World Heritage Sites.Wallonia was also the birthplace of a strong socialist party and strong trade unions in a particular sociological landscape. At the left, the Sillon industriel, which runs from Mons in the west, to Verviers in the east (except part of North Flanders, in another period of the industrial revolution, after 1920). Even if Belgium is the second industrial country after Britain, the effect of the industrial revolution there was very different. In 'Breaking stereotypes', Muriel Neven and Isabelle Devious say:\n",
      "\n",
      "The Industrial Revolution changed a mainly rural society into an urban one, but with a strong contrast between northern and southern Belgium. During the Middle Ages and the early modern period, Flanders was characterised by the presence of large urban centres [...] at the beginning of the nineteenth century this region (Flanders), with an urbanisation degree of more than 30 percent, remained one of the most urbanised in the world. By comparison, this proportion reached only 17 percent in Wallonia, barely 10 percent in most West European countries, 16 percent in France, and 25 percent in Britain. Nineteenth-century industrialisation did not affect the traditional urban infrastructure, except in Ghent... Also, in Wallonia, the traditional urban network was largely unaffected by the industrialisation process, even though the proportion of city-dwellers rose from 17 to 45 percent between 1831 and 1910. Especially in the Haine, Sambre and Meuse valleys, between the Borinage and Liège, where there was a huge industrial development based on coal-mining and iron-making, urbanisation was fast. During these eighty years, the number of municipalities with more than 5,000 inhabitants increased from only 21 to more than one hundred, concentrating nearly half of the Walloon population in this region. Nevertheless, industrialisation remained quite traditional in the sense that it did not lead to the growth of modern and large urban centres, but to a conurbation of industrial villages and towns developed around a coal mine or a factory. Communication routes between these small centres only became populated later and created a much less dense urban morphology than, for instance, the area around Liège where the old town was there to direct migratory flows.\n",
      "\n",
      "France\n",
      "The Industrial Revolution in France followed a particular course as it did not correspond to the main model followed by other countries. Notably, most French historians argue France did not go through a clear take-off. Instead, France's economic growth and industrialisation process was slow and steady through the 18th and 19th centuries. However, some stages were identified by Maurice Lévy-Leboyer:\n",
      "\n",
      "French Revolution and Napoleonic Wars (1789–1815),\n",
      "industrialisation, along with Britain (1815–1860),\n",
      "economic slowdown (1860–1905),\n",
      "renewal of the growth after 1905.\n",
      "\n",
      "Germany\n",
      "Based on its leadership in chemical research in the universities and industrial laboratories, Germany, which was unified in 1871, became dominant in the world's chemical industry in the late 19th century. At first the production of dyes based on aniline was critical.Germany's political disunity—with three dozen states—and a pervasive conservatism made it difficult to build railways in the 1830s. However, by the 1840s, trunk lines linked the major cities; each German state was responsible for the lines within its own borders. Lacking a technological base at first, the Germans imported their engineering and hardware from Britain, but quickly learned the skills needed to operate and expand the railways. In many cities, the new railway shops were the centres of technological awareness and training, so that by 1850, Germany was self-sufficient in meeting the demands of railroad construction, and the railways were a major impetus for the growth of the new steel industry. Observers found that even as late as 1890, their engineering was inferior to Britain's. However, German unification in 1871 stimulated consolidation, nationalisation into state-owned companies, and further rapid growth. Unlike the situation in France, the goal was the support of industrialisation, and so heavy lines crisscrossed the Ruhr and other industrial districts and provided good connections to the major ports of Hamburg and Bremen. By 1880, Germany had 9,400 locomotives pulling 43,000 passengers and 30,000 tons of freight, and pulled ahead of France.\n",
      "\n",
      "Sweden\n",
      "During the period 1790–1815, Sweden experienced two parallel economic movements: an agricultural revolution with larger agricultural estates, new crops, and farming tools and commercialisation of farming, and a proto industrialisation, with small industries being established in the countryside and with workers switching between agricultural work in summer and industrial production in winter. This led to economic growth benefiting large sections of the population and leading up to a consumption revolution starting in the 1820s. Between 1815 and 1850, the protoindustries developed into more specialised and larger industries. This period witnessed increasing regional specialisation with mining in Bergslagen, textile mills in Sjuhäradsbygden, and forestry in Norrland. Several important institutional changes took place in this period, such as free and mandatory schooling introduced in 1842 (as the first country in the world), the abolition of the national monopoly on trade in handicrafts in 1846, and a stock company law in 1848.From 1850 to 1890, Sweden experienced its \"first\" Industrial Revolution with a veritable explosion in export, dominated by crops, wood, and steel. Sweden abolished most tariffs and other barriers to free trade in the 1850s and joined the gold standard in 1873. Large infrastructural investments were made during this period, mainly in the expanding railroad network, which was financed in part by the government and in part by private enterprises. From 1890 to 1930, new industries developed with their focus on the domestic market: mechanical engineering, power utilities, papermaking and textile.\n",
      "\n",
      "Japan\n",
      "The Industrial Revolution began about 1870 as Meiji period leaders decided to catch up with the West. The government built railroads, improved roads, and inaugurated a land reform program to prepare the country for further development. It inaugurated a new Western-based education system for all young people, sent thousands of students to the United States and Europe, and hired more than 3,000 Westerners to teach modern science, mathematics, technology, and foreign languages in Japan (Foreign government advisors in Meiji Japan).\n",
      "In 1871, a group of Japanese politicians known as the Iwakura Mission toured Europe and the United States to learn Western ways. The result was a deliberate state-led industrialisation policy to enable Japan to quickly catch up. The Bank of Japan, founded in 1882, used taxes to fund model steel and textile factories. Education was expanded and Japanese students were sent to study in the West.\n",
      "Modern industry first appeared in textiles, including cotton and especially silk, which was based in home workshops in rural areas.\n",
      "\n",
      "United States\n",
      "During the late 18th and early 19th centuries when the UK and parts of Western Europe began to industrialise, the US was primarily an agricultural and natural resource producing and processing economy. The building of roads and canals, the introduction of steamboats and the building of railroads were important for handling agricultural and natural resource products in the large and sparsely populated country of the period.Important American technological contributions during the period of the Industrial Revolution were the cotton gin and the development of a system for making interchangeable parts, the latter aided by the development of the milling machine in the US.  The development of machine tools and the system of interchangeable parts was the basis for the rise of the US as the world's leading industrial nation in the late 19th century.\n",
      "Oliver Evans invented an automated flour mill in the mid-1780s that used control mechanisms and conveyors so that no labour was needed from the time grain was loaded into the elevator buckets until the flour was discharged into a wagon.  This is considered to be the first modern materials handling system an important advance in the progress toward mass production.The United States originally used horse-powered machinery for small-scale applications such as grain milling, but eventually switched to water power after textile factories began being built in the 1790s. As a result, industrialisation was concentrated in New England and the Northeastern United States, which has fast-moving rivers. The newer water-powered production lines proved more economical than horse-drawn production. In the late 19th century steam-powered manufacturing overtook water-powered manufacturing, allowing the industry to spread to the Midwest.\n",
      "Thomas Somers and the Cabot Brothers founded the Beverly Cotton Manufactory in 1787, the first cotton mill in America, the largest cotton mill of its era, and a significant milestone in the research and development of cotton mills in the future. This mill was designed to use horsepower, but the operators quickly learned that the horse-drawn platform was economically unstable, and had economic losses for years. Despite the losses, the Manufactory served as a playground of innovation, both in turning a large amount of cotton, but also developing the water-powered milling structure used in Slater's Mill.In 1793, Samuel Slater (1768–1835) founded the Slater Mill at Pawtucket, Rhode Island. He had learned of the new textile technologies as a boy apprentice in Derbyshire, England, and defied laws against the emigration of skilled workers by leaving for New York in 1789, hoping to make money with his knowledge. After founding Slater's Mill, he went on to own 13 textile mills. Daniel Day established a wool carding mill in the Blackstone Valley at Uxbridge, Massachusetts in 1809, the third woollen mill established in the US (The first was in Hartford, Connecticut, and the second at Watertown, Massachusetts.). The John H. Chafee Blackstone River Valley National Heritage Corridor retraces the history of \"America's Hardest-Working River', the Blackstone. The Blackstone River and its tributaries, which cover more than 70 kilometres (45 mi) from Worcester, Massachusetts to Providence, Rhode Island, was the birthplace of America's Industrial Revolution. At its peak over 1,100 mills operated in this valley, including Slater's Mill, and with it the earliest beginnings of America's industrial and technological development.\n",
      "Merchant Francis Cabot Lowell from Newburyport, Massachusetts, memorised the design of textile machines on his tour of British factories in 1810. Realising that the War of 1812 had ruined his import business but that demand for domestic finished cloth was emerging in America, on his return to the United States, he set up the Boston Manufacturing Company. Lowell and his partners built America's second cotton-to-cloth textile mill at Waltham, Massachusetts, second to the Beverly Cotton Manufactory. After his death in 1817, his associates built America's first planned factory town, which they named after him. This enterprise was capitalised in a public stock offering, one of the first uses of it in the United States. Lowell, Massachusetts, using nine kilometres (5+1⁄2 miles) of canals and 7,500 kilowatts (10,000 horsepower) delivered by the Merrimack River, is considered by some as a major contributor to the success of the American Industrial Revolution. The short-lived utopia-like Waltham-Lowell system was formed, as a direct response to the poor working conditions in Britain. However, by 1850, especially following the Great Famine of Ireland, the system had been replaced by poor immigrant labour.\n",
      "A major U.S. contribution to industrialisation was the development of techniques to make interchangeable parts from metal.  Precision metal machining techniques were developed by the U.S. Department of War to make interchangeable parts for small firearms.  The development work took place at the Federal Arsenals at Springfield Armory and Harpers Ferry Armory.  Techniques for precision machining using machine tools included using fixtures to hold the parts in the proper position, jigs to guide the cutting tools and precision blocks and gauges to measure the accuracy.  The milling machine, a fundamental machine tool, is believed to have been invented by Eli Whitney, who was a government contractor who built firearms as part of this program.  Another important invention was the Blanchard lathe, invented by Thomas Blanchard.  The Blanchard lathe, or pattern tracing lathe, was actually a shaper that could produce copies of wooden gun stocks.  The use of machinery and the techniques for producing standardised and interchangeable parts became known as the American system of manufacturing.Precision manufacturing techniques made it possible to build machines that mechanised the shoe industry and the watch industry. The industrialisation of the watch industry started in 1854 also in Waltham, Massachusetts, at the Waltham Watch Company, with the development of machine tools, gauges and assembling methods adapted to the micro precision required for watches.\n",
      "\n",
      "Second Industrial Revolution\n",
      "Steel is often cited as the first of several new areas for industrial mass-production, which are said to characterise a \"Second Industrial Revolution\", beginning around 1850, although a method for mass manufacture of steel was not invented until the 1860s, when Sir Henry Bessemer invented a new furnace which could convert molten pig iron into steel in large quantities. However, it only became widely available in the 1870s after the process was modified to produce more uniform quality. Bessemer steel was being displaced by the open hearth furnace near the end of the 19th century.\n",
      "\n",
      "This Second Industrial Revolution gradually grew to include chemicals, mainly the chemical industries, petroleum (refining and distribution), and, in the 20th century, the automotive industry, and was marked by a transition of technological leadership from Britain to the United States and Germany.\n",
      "The increasing availability of economical petroleum products also reduced the importance of coal and further widened the potential for industrialisation.\n",
      "A new revolution began with electricity and electrification in the electrical industries. The introduction of hydroelectric power generation in the Alps enabled the rapid industrialisation of coal-deprived northern Italy, beginning in the 1890s.\n",
      "By the 1890s, industrialisation in these areas had created the first giant industrial corporations with burgeoning global interests, as companies like U.S. Steel, General Electric, Standard Oil and Bayer AG joined the railroad and ship companies on the world's stock markets.\n",
      "\n",
      "New Industrialism\n",
      "The New Industrialist movement advocates for increasing domestic manufacturing while reducing emphasis on a financial-based economy that relies on real estate and trading speculative assets. New Industrialism has been described as \"supply-side progressivism\" or embracing the idea of \"Building More Stuff\". New Industrialism developed after the China Shock that resulted in lost manufacturing jobs in the U.S. after China joined the World Trade Organization in 2001. The movement strengthened after the reduction of manufacturing jobs during the Great Recession and when the U.S. was not able to manufacture enough tests or facemasks during the COVID-19 pandemic. New Industrialism calls for building enough housing to satisfy demand in order to reduce the profit in land speculation, to invest in infrastructure, and to develop advanced technology to manufacture green energy for the world. New Industrialists believe that the United States is not building enough productive capital and should invest more into economic growth.\n",
      "\n",
      "Causes\n",
      "The causes of the Industrial Revolution were complicated and remain a topic for debate.  Geographic factors include Britain's vast mineral resources.  In addition to metal ores, Britain had the highest quality coal reserves known at the time, as well as abundant water power, highly productive agriculture, and numerous seaports and navigable waterways.Some historians believe the Industrial Revolution was an outgrowth of social and institutional changes brought by the end of feudalism in Britain after the English Civil War in the 17th century, although feudalism began to break down after the Black Death of the mid 14th century, followed by other epidemics, until the population reached a low in the 14th century. This created labour shortages and led to falling food prices and a peak in real wages around 1500, after which population growth began reducing wages. Inflation caused by coinage debasement after 1540 followed by precious metals supply increasing from the Americas caused land rents (often long-term leases that transferred to heirs on death) to fall in real terms.The Enclosure movement and the British Agricultural Revolution made food production more efficient and less labour-intensive, forcing the farmers who could no longer be self-sufficient in agriculture into cottage industry, for example weaving, and in the longer term into the cities and the newly developed factories. The colonial expansion of the 17th century with the accompanying development of international trade, creation of financial markets and accumulation of capital are also cited as factors, as is the scientific revolution of the 17th century. A change in marrying patterns to getting married later made people able to accumulate more human capital during their youth, thereby encouraging economic development.Until the 1980s, it was universally believed by academic historians that technological innovation was the heart of the Industrial Revolution and the key enabling technology was the invention and improvement of the steam engine. Marketing professor Ronald Fullerton suggested that innovative marketing techniques, business practices, and competition also influenced changes in the manufacturing industry.Lewis Mumford has proposed that the Industrial Revolution had its origins in the Early Middle Ages, much earlier than most estimates. He explains that the model for standardised mass production was the printing press and that \"the archetypal model for the industrial era was the clock\". He also cites the monastic emphasis on order and time-keeping, as well as the fact that medieval cities had at their centre a church with bell ringing at regular intervals as being necessary precursors to a greater synchronisation necessary for later, more physical, manifestations such as the steam engine.\n",
      "The presence of a large domestic market should also be considered an important driver of the Industrial Revolution, particularly explaining why it occurred in Britain. In other nations, such as France, markets were split up by local regions, which often imposed tolls and tariffs on goods traded among them. Internal tariffs were abolished by Henry VIII of England, they survived in Russia until 1753, 1789 in France and 1839 in Spain.\n",
      "Governments' grant of limited monopolies to inventors under a developing patent system (the Statute of Monopolies in 1623) is considered an influential factor. The effects of patents, both good and ill, on the development of industrialisation are clearly illustrated in the history of the steam engine, the key enabling technology. In return for publicly revealing the workings of an invention the patent system rewarded inventors such as James Watt by allowing them to monopolise the production of the first steam engines, thereby rewarding inventors and increasing the pace of technological development. However, monopolies bring with them their own inefficiencies which may counterbalance, or even overbalance, the beneficial effects of publicising ingenuity and rewarding inventors. Watt's monopoly prevented other inventors, such as Richard Trevithick, William Murdoch, or Jonathan Hornblower, whom Boulton and Watt sued, from introducing improved steam engines, thereby retarding the spread of steam power.\n",
      "\n",
      "Causes in Europe\n",
      "One question of active interest to historians is why the Industrial Revolution occurred in Europe and not in other parts of the world in the 18th century, particularly China, India, and the Middle East (which pioneered in shipbuilding, textile production, water mills, and much more in the period between 750 and 1100), or at other times like in Classical Antiquity or the Middle Ages. A recent account argued that Europeans have been characterized for thousands of years by a freedom-loving culture originating from the aristocratic societies of early Indo-European invaders. Many historians, however, have challenged this explanation as being not only Eurocentric, but also ignoring historical context. In fact, before the Industrial Revolution, \"there existed something of a global economic parity between the most advanced regions in the world economy.\" These historians have suggested a number of other factors, including education, technological changes (see Scientific Revolution in Europe), \"modern\" government, \"modern\" work attitudes, ecology, and culture.China was the world's most technologically advanced country for many centuries; however, China stagnated economically and technologically and was surpassed by Western Europe before the Age of Discovery, by which time China banned imports and denied entry to foreigners. China was also a totalitarian society. It also taxed transported goods heavily. Modern estimates of per capita income in Western Europe in the late 18th century are of roughly 1,500 dollars in purchasing power parity (and Britain had a per capita income of nearly 2,000 dollars) whereas China, by comparison, had only 450 dollars. India was essentially feudal, politically fragmented and not as economically advanced as Western Europe.Historians such as David Landes and sociologists Max Weber and Rodney Stark credit the different belief systems in Asia and Europe with dictating where the revolution occurred. The religion and beliefs of Europe were largely products of Judaeo-Christianity and Greek thought. Conversely, Chinese society was founded on men like Confucius, Mencius, Han Feizi (Legalism), Lao Tzu (Taoism), and Buddha (Buddhism), resulting in very different worldviews. Other factors include the considerable distance of China's coal deposits, though large, from its cities as well as the then unnavigable Yellow River that connects these deposits to the sea.Regarding India, the Marxist historian Rajani Palme Dutt said, \"The capital to finance the Industrial Revolution in India instead went into financing the Industrial Revolution in Britain.\" In contrast to China, India was split up into many competing kingdoms after the decline of the Mughal Empire, with the major ones in its aftermath including the Marathas, Sikhs, Bengal Subah, and Kingdom of Mysore. In addition, the economy was highly dependent on two sectors—agriculture of subsistence and cotton, and there appears to have been little technical innovation. It is believed that the vast amounts of wealth were largely stored away in palace treasuries by monarchs prior to the British take over.Economic historian Joel Mokyr argued that political fragmentation, the presence of a large number of European states, made it possible for heterodox ideas to thrive, as entrepreneurs, innovators, ideologues and heretics could easily flee to a neighboring state in the event that the one state would try to suppress their ideas and activities. This is what set Europe apart from the technologically advanced, large unitary empires such as China and India by providing \"an insurance against economic and technological stagnation\". China had both a printing press and movable type, and India had similar levels of scientific and technological achievement as Europe in 1700, yet the Industrial Revolution would occur in Europe, not China or India. In Europe, political fragmentation was coupled with an \"integrated market for ideas\" where Europe's intellectuals used the lingua franca of Latin, had a shared intellectual basis in Europe's classical heritage and the pan-European institution of the Republic of Letters.In addition, Europe's monarchs desperately needed revenue, pushing them into alliances with their merchant classes. Small groups of merchants were granted monopolies and tax-collecting responsibilities in exchange for payments to the state. Located in a region \"at the hub of the largest and most varied network of exchange in history\", Europe advanced as the leader of the Industrial Revolution. In the Americas, Europeans found a windfall of silver, timber, fish, and maize, leading historian Peter Stearns to conclude that \"Europe's Industrial Revolution stemmed in great part from Europe's ability to draw disproportionately on world resources.\"Modern capitalism originated in the Italian city-states around the end of the first millennium. The city-states were prosperous cities that were independent from feudal lords. They were largely republics whose governments were typically composed of merchants, manufacturers, members of guilds, bankers and financiers. The Italian city-states built a network of branch banks in leading western European cities and introduced double entry bookkeeping. Italian commerce was supported by schools that taught numeracy in financial calculations through abacus schools.\n",
      "\n",
      "Causes in Britain\n",
      "Great Britain provided the legal and cultural foundations that enabled entrepreneurs to pioneer the Industrial Revolution. Key factors fostering this environment were:\n",
      "\n",
      "The period of peace and stability which followed the unification of England and Scotland\n",
      "There were no internal trade barriers, including between England and Scotland, or feudal tolls and tariffs, making Britain the \"largest coherent market in Europe\": 46 \n",
      "The rule of law (enforcing property rights and respecting the sanctity of contracts)\n",
      "A straightforward legal system that allowed the formation of joint-stock companies (corporations)\n",
      "Free market (capitalism)\n",
      "Geographical and natural resource advantages of Great Britain were the fact that it had extensive coastlines and many navigable rivers in an age where water was the easiest means of transportation and Britain had the highest quality coal in Europe. Britain also had a large number of sites for water power.\n",
      "There were two main values that drove the Industrial Revolution in Britain. These values were self-interest and an entrepreneurial spirit. Because of these interests, many industrial advances were made that resulted in a huge increase in personal wealth and a consumer revolution. These advancements also greatly benefitted British society as a whole. Countries around the world started to recognise the changes and advancements in Britain and use them as an example to begin their own Industrial Revolutions.A debate sparked by Trinidadian politician and historian Eric Williams in his work Capitalism and Slavery (1944) concerned the role of slavery in financing the Industrial Revolution. Williams argued that European capital amassed from slavery was vital in the early years of the revolution, contending that the rise of industrial capitalism was the driving force behind abolitionism instead of humanitarian motivations. These arguments led to significant historiographical debates among historians, with American historian Seymour Drescher critiquing Williams' arguments in Econocide (1977).Instead, the greater liberalisation of trade from a large merchant base may have allowed Britain to produce and use emerging scientific and technological developments more effectively than countries with stronger monarchies, particularly China and Russia. Britain emerged from the Napoleonic Wars as the only European nation not ravaged by financial plunder and economic collapse, and having the only merchant fleet of any useful size (European merchant fleets were destroyed during the war by the Royal Navy). Britain's extensive exporting cottage industries also ensured markets were already available for many early forms of manufactured goods. The conflict resulted in most British warfare being conducted overseas, reducing the devastating effects of territorial conquest that affected much of Europe. This was further aided by Britain's geographical position—an island separated from the rest of mainland Europe.\n",
      "\n",
      "Another theory is that Britain was able to succeed in the Industrial Revolution due to the availability of key resources it possessed. It had a dense population for its small geographical size. Enclosure of common land and the related agricultural revolution made a supply of this labour readily available. There was also a local coincidence of natural resources in the North of England, the English Midlands, South Wales and the Scottish Lowlands. Local supplies of coal, iron, lead, copper, tin, limestone and water power resulted in excellent conditions for the development and expansion of industry. Also, the damp, mild weather conditions of the North West of England provided ideal conditions for the spinning of cotton, providing a natural starting point for the birth of the textiles industry.\n",
      "The stable political situation in Britain from around 1689 following the Glorious Revolution, and British society's greater receptiveness to change (compared with other European countries) can also be said to be factors favouring the Industrial Revolution. Peasant resistance to industrialisation was largely eliminated by the Enclosure movement, and the landed upper classes developed commercial interests that made them pioneers in removing obstacles to the growth of capitalism. (This point is also made in Hilaire Belloc's The Servile State.)\n",
      "The French philosopher Voltaire wrote about capitalism and religious tolerance in his book on English society, Letters on the English (1733), noting why England at that time was more prosperous in comparison to the country's less religiously tolerant European neighbours. \"Take a view of the Royal Exchange in London, a place more venerable than many courts of justice, where the representatives of all nations meet for the benefit of mankind. There the Jew, the Mahometan [Muslim], and the Christian transact together, as though they all professed the same religion, and give the name of infidel to none but bankrupts. There the Presbyterian confides in the Anabaptist, and the Churchman depends on the Quaker's word. If one religion only were allowed in England, the Government would very possibly become arbitrary; if there were but two, the people would cut one another's throats; but as there are such a multitude, they all live happy and in peace.\"Britain's population grew 280% from 1550 to 1820, while the rest of Western Europe grew 50–80%. Seventy percent of European urbanisation happened in Britain from 1750 to 1800. By 1800, only the Netherlands was more urbanised than Britain. This was only possible because coal, coke, imported cotton, brick and slate had replaced wood, charcoal, flax, peat and thatch. The latter compete with land grown to feed people while mined materials do not. Yet more land would be freed when chemical fertilisers replaced manure and horse's work was mechanised. A workhorse needs 1.2 to 2.0 ha (3 to 5 acres) for fodder while even early steam engines produced four times more mechanical energy.\n",
      "In 1700, five-sixths of the coal mined worldwide was in Britain, while the Netherlands had none; so despite having Europe's best transport, lowest taxes, and most urbanised, well-paid, and literate population, it failed to industrialise. In the 18th century, it was the only European country whose cities and population shrank. Without coal, Britain would have run out of suitable river sites for mills by the 1830s. Based on science and experimentation from the continent, the steam engine was developed specifically for pumping water out of mines, many of which in Britain had been mined to below the water table. Although extremely inefficient they were economical because they used unsaleable coal. Iron rails were developed to transport coal, which was a major economic sector in Britain.\n",
      "Economic historian Robert Allen has argued that high wages, cheap capital and very cheap energy in Britain made it the ideal place for the industrial revolution to occur. These factors made it vastly more profitable to invest in research and development, and to put technology to use in Britain than other societies. However, two 2018 studies in The Economic History Review showed that wages were not particularly high in the British spinning sector or the construction sector, casting doubt on Allen's explanation. A 2022 study in the Journal of Political Economy by Morgan Kelly, Joel Mokyr, and Cormac O Grada found that industrialization happened in areas with low wages and high mechanical skills, whereas literacy, banks and proximity to coal had little explanatory power.\n",
      "\n",
      "Transfer of knowledge\n",
      "Knowledge of innovation was spread by several means. Workers who were trained in the technique might move to another employer or might be poached. A common method was for someone to make a study tour, gathering information where he could. During the whole of the Industrial Revolution and for the century before, all European countries and America engaged in study-touring; some nations, like Sweden and France, even trained civil servants or technicians to undertake it as a matter of state policy. In other countries, notably Britain and America, this practice was carried out by individual manufacturers eager to improve their own methods. Study tours were common then, as now, as was the keeping of travel diaries. Records made by industrialists and technicians of the period are an incomparable source of information about their methods.\n",
      "Another means for the spread of innovation was by the network of informal philosophical societies, like the Lunar Society of Birmingham, in which members met to discuss natural philosophy and often its application to manufacturing. The Lunar Society flourished from 1765 to 1809, and it has been said of them, \"They were, if you like, the revolutionary committee of that most far reaching of all the eighteenth-century revolutions, the Industrial Revolution\". Other such societies published volumes of proceedings and transactions. For example, the London-based Royal Society of Arts published an illustrated volume of new inventions, as well as papers about them in its annual Transactions.\n",
      "There were publications describing technology. Encyclopaedias such as Harris's Lexicon Technicum (1704) and Abraham Rees's Cyclopaedia (1802–1819) contain much of value. Cyclopaedia contains an enormous amount of information about the science and technology of the first half of the Industrial Revolution, very well illustrated by fine engravings. Foreign printed sources such as the Descriptions des Arts et Métiers and Diderot's Encyclopédie explained foreign methods with fine engraved plates.\n",
      "Periodical publications about manufacturing and technology began to appear in the last decade of the 18th century, and many regularly included notice of the latest patents. Foreign periodicals, such as the Annales des Mines, published accounts of travels made by French engineers who observed British methods on study tours.\n",
      "\n",
      "Protestant work ethic\n",
      "Another theory is that the British advance was due to the presence of an entrepreneurial class which believed in progress, technology and hard work. The existence of this class is often linked to the Protestant work ethic (see Max Weber) and the particular status of the Baptists and the dissenting Protestant sects, such as the Quakers and Presbyterians that had flourished with the English Civil War. Reinforcement of confidence in the rule of law, which followed establishment of the prototype of constitutional monarchy in Britain in the Glorious Revolution of 1688, and the emergence of a stable financial market there based on the management of the national debt by the Bank of England, contributed to the capacity for, and interest in, private financial investment in industrial ventures.Dissenters found themselves barred or discouraged from almost all public offices, as well as education at England's only two universities at the time (although dissenters were still free to study at Scotland's four universities). When the restoration of the monarchy took place and membership in the official Anglican Church became mandatory due to the Test Act, they thereupon became active in banking, manufacturing and education. The Unitarians, in particular, were very involved in education, by running Dissenting Academies, where, in contrast to the universities of Oxford and Cambridge and schools such as Eton and Harrow, much attention was given to mathematics and the sciences – areas of scholarship vital to the development of manufacturing technologies.\n",
      "Historians sometimes consider this social factor to be extremely important, along with the nature of the national economies involved. While members of these sects were excluded from certain circles of the government, they were considered fellow Protestants, to a limited extent, by many in the middle class, such as traditional financiers or other businessmen. Given this relative tolerance and the supply of capital, the natural outlet for the more enterprising members of these sects would be to seek new opportunities in the technologies created in the wake of the scientific revolution of the 17th century.\n",
      "\n",
      "Criticisms\n",
      "The industrial revolution has been criticised for causing ecological collapse, mental illness, pollution and detrimental social systems. It has also been criticised for valuing profits and corporate growth over life and wellbeing. Multiple movements have arisen which reject aspects of the industrial revolution, such as the Amish or primitivists.\n",
      "\n",
      "Individualism humanism and harsh conditions\n",
      "Humanists and individualists criticise the Industrial revolution for mistreating women and children and turning men into work machines that lacked autonomy. Critics of the Industrial revolution promoted a more interventionist state and formed new organizations to promote human rights.\n",
      "\n",
      "Primitivism\n",
      "Primitivism argues that the Industrial Revolution have created an un-natural frame of society and the world in which humans need to adapt to an un-natural urban landscape in which humans are perpetual cogs without personal autonomy.Certain primitivists argue for a return to pre-industrial society, while others argue that technology such as modern medicine, and agriculture are all positive for humanity assuming they are controlled by and serve humanity and have no effect on the natural environment.\n",
      "\n",
      "Pollution and ecological collapse\n",
      "The Industrial Revolution has been criticised for leading to immense ecological and habitat destruction, certain studies state that over 95% of species have gone extinct since humanity became the dominant species on Earth. It has also led to immense decrease in the biodiversity of life on Earth. The Industrial revolution has been said to be inherently unsustainable and will lead to eventual collapse of society, mass hunger, starvation, and resource scarcity.\n",
      "\n",
      "The Anthropocene\n",
      "The Anthropocene is a proposed epoch or mass extinction coming from humanity (Anthro is the Greek root for humanity). Since the start of the Industrial revolution humanity has permanently changed the Earth, such as immense decrease in biodiversity, and mass extinction caused by the Industrial revolution. The effects include permanent changes to the Earth's atmosphere and soil, forests, the mass destruction of the Industrial revolution has led to catastrophic impacts on the Earth. Most organisms are unable to adapt leading to mass extinction with the remaining undergoing evolutionary rescue, as a result of the Industrial revolution.\n",
      "Permanent changes in the distribution of organisms from human influence will become identifiable in the geologic record. Researchers have documented the movement of many species into regions formerly too cold for them, often at rates faster than initially expected. This has occurred in part as a result of changing climate, but also in response to farming and fishing, and to the accidental introduction of non-native species to new areas through global travel. The ecosystem of the entire Black Sea may have changed during the last 2000 years as a result of nutrient and silica input from eroding deforested lands along the Danube River.\n",
      "\n",
      "Opposition from Romanticism\n",
      "During the Industrial Revolution, an intellectual and artistic hostility towards the new industrialisation developed, associated with the Romantic movement.  Romanticism revered the traditionalism of rural life and recoiled against the upheavals caused by industrialization, urbanization and the wretchedness of the working classes. Its major exponents in English included the artist and poet William Blake and poets William Wordsworth, Samuel Taylor Coleridge, John Keats, Lord Byron and Percy Bysshe Shelley. \n",
      "The movement stressed the importance of \"nature\" in art and language, in contrast to \"monstrous\" machines and factories; the \"Dark satanic mills\" of Blake's poem \"And did those feet in ancient time\". Mary Shelley's Frankenstein reflected concerns that scientific progress might be two-edged. French Romanticism likewise was highly critical of industry.\n",
      "\n",
      "See also\n",
      "Footnotes\n",
      "References\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "Internet Modern History Sourcebook: Industrial Revolution\n",
      "BBC History Home Page: Industrial Revolution\n",
      "National Museum of Science and Industry website: machines and personalities\n",
      "Factory Workers in the Industrial Revolution\n",
      "History.com: The Industrial Revolution – articles, videos, pictures, and facts\n",
      "\"The Day the World Took Off\" Six-part video series from the University of Cambridge tracing the question \"Why did the Industrial Revolution begin when and where it did.\"Genome editing, or genome engineering, or gene editing, is a type of genetic engineering in which DNA is inserted, deleted, modified or replaced in the genome of a living organism. Unlike early genetic engineering techniques that randomly inserts genetic material into a host genome, genome editing targets the insertions to site-specific locations. The basic mechanism involved in genetic manipulations through programmable nucleases is the recognition of target genomic loci and binding of effector DNA-binding domain (DBD), double-strand breaks (DSBs) in target DNA by the restriction endonucleases (FokI and Cas), and the repair of DSBs through homology-directed recombination (HDR) or non-homologous end joining (NHEJ).\n",
      "\n",
      "History\n",
      "Genome editing was pioneered in the 1990s, before the advent of the common current nuclease-based gene editing platforms but its use was limited by low efficiencies of editing. Genome editing with engineered nucleases, i.e. all three major classes of these enzymes—zinc finger nucleases (ZFNs), transcription activator-like effector nucleases (TALENs) and engineered meganucleases—were selected by Nature Methods as the 2011 Method of the Year. The CRISPR-Cas system was selected by Science as 2015 Breakthrough of the Year.As of 2015 four families of engineered nucleases were used: meganucleases, zinc finger nucleases (ZFNs), transcription activator-like effector-based nucleases (TALEN), and the clustered regularly interspaced short palindromic repeats (CRISPR/Cas9) system. Nine genome editors were available as of 2017.In 2018, the common methods for such editing used engineered nucleases, or \"molecular scissors\". These nucleases create site-specific double-strand breaks (DSBs) at desired locations in the genome. The induced double-strand breaks are repaired through nonhomologous end-joining (NHEJ) or homologous recombination (HR), resulting in targeted mutations ('edits').\n",
      "In May 2019, lawyers in China reported, in light of the purported creation by Chinese scientist He Jiankui of the first gene-edited humans (see Lulu and Nana controversy), the drafting of regulations that anyone manipulating the human genome by gene-editing techniques, like CRISPR, would be held responsible for any related adverse consequences. A cautionary perspective on the possible blind spots and risks of CRISPR and related biotechnologies has been recently discussed, focusing on the stochastic nature of cellular control processes.\n",
      "The University of Edinburgh Roslin Institute engineered pigs resistant to a virus that causes porcine reproductive and respiratory syndrome, which costs US and European pig farmers $2.6 billion annually.In February 2020, a US trial safely showed CRISPR gene editing on 3 cancer patients. In 2020 Sicilian Rouge High GABA, a tomato that makes more of an amino acid said to promote relaxation, was approved for sale in Japan.In 2021, England (not the rest of the UK) planned to remove restrictions on gene-edited plants and animals, moving from European Union-compliant regulation to rules closer to those of the US and some other countries. An April 2021 European Commission report found \"strong indications\" that the current regulatory regime was not appropriate for gene editing Later in 2021, researchers announced a CRISPR alternative, labeled obligate mobile element–guided activity (OMEGA) proteins including IscB, IsrB and TnpB as endonucleases found in transposons, and guided by small ωRNAs.\n",
      "\n",
      "Background\n",
      "Genetic engineering as method of introducing new genetic elements into organisms has been around since the 1970s. One drawback of this technology has been the random nature with which the DNA is inserted into the hosts genome, which can impair or alter other genes within the organism. Although, several methods have been discovered which target the inserted genes to specific sites within an organism genome. It has also enabled the editing of specific sequences within a genome as well as reduced off target effects. This could be used for research purposes, by targeting mutations to specific genes, and in gene therapy. By inserting a functional gene into an organism and targeting it to replace the defective one it could be possible to cure certain genetic diseases.\n",
      "\n",
      "Gene targeting\n",
      "Homologous recombination\n",
      "Early methods to target genes to certain sites within a genome of an organism (called gene targeting) relied on homologous recombination (HR). By creating DNA constructs that contain a template that matches the targeted genome sequence it is possible that the HR processes within the cell will insert the construct at the desired location. Using this method on embryonic stem cells led to the development of transgenic mice with targeted genes knocked out. It has also been possible to knock in genes or alter gene expression patterns. In recognition of their discovery of how homologous recombination can be used to introduce genetic modifications in mice through embryonic stem cells, Mario Capecchi, Martin Evans and Oliver Smithies were awarded the 2007 Nobel Prize for Physiology or Medicine.\n",
      "\n",
      "Conditional targeting\n",
      "If a vital gene is knocked out it can prove lethal to the organism. In order to study the function of these genes site specific recombinases (SSR) were used. The two most common types are the Cre-LoxP and Flp-FRT systems. Cre recombinase is an enzyme that removes DNA by homologous recombination between binding sequences known as Lox-P sites. The Flip-FRT system operates in a similar way, with the Flip recombinase recognising FRT sequences. By crossing an organism containing the recombinase sites flanking the gene of interest with an organism that express the SSR under control of tissue specific promoters, it is possible to knock out or switch on genes only in certain cells. These techniques were also used to remove marker genes from transgenic animals. Further modifications of these systems allowed researchers to induce recombination only under certain conditions, allowing genes to be knocked out or expressed at desired times or stages of development.\n",
      "\n",
      "Process\n",
      "Double strand break repair\n",
      "A common form of Genome editing relies on the concept of DNA double stranded break (DSB) repair mechanics. There are two major pathways that repair DSB; non-homologous end joining (NHEJ) and homology directed repair (HDR). NHEJ uses a variety of enzymes to directly join the DNA ends while the more accurate HDR uses a homologous sequence as a template for regeneration of missing DNA sequences at the break point. This can be exploited by creating a vector with the desired genetic elements within a sequence that is homologous to the flanking sequences of a DSB. This will result in the desired change being inserted at the site of the DSB. While HDR based gene editing is similar to the homologous recombination based gene targeting, the rate of recombination is increased by at least three orders of magnitude.\n",
      "\n",
      "Engineered nucleases\n",
      "The key to genome editing is creating a DSB at a specific point within the genome. Commonly used restriction enzymes are effective at cutting DNA, but generally recognize and cut at multiple sites. To overcome this challenge and create site-specific DSB, three distinct classes of nucleases have been discovered and bioengineered to date. These are the Zinc finger nucleases (ZFNs), transcription-activator like effector nucleases (TALEN), meganucleases and the clustered regularly interspaced short palindromic repeats (CRISPR/Cas9) system.\n",
      "\n",
      "Meganucleases\n",
      "Meganucleases, discovered in the late 1980s, are enzymes in the endonuclease family which are characterized by their capacity to recognize and cut large DNA sequences (from 14 to 40 base pairs). The most widespread and best known meganucleases are the proteins in the LAGLIDADG family, which owe their name to a conserved amino acid sequence.\n",
      "Meganucleases, found commonly in microbial species, have the unique property of having very long recognition sequences (>14bp) thus making them naturally very specific. However, there is virtually no chance of finding the exact meganuclease required to act on a chosen specific DNA sequence. To overcome this challenge, mutagenesis and high throughput screening methods have been used to create meganuclease variants that recognize unique sequences. Others have been able to fuse various meganucleases and create hybrid enzymes that recognize a new sequence. Yet others have attempted to alter the DNA interacting aminoacids of the meganuclease to design sequence specific meganucelases in a method named rationally designed meganuclease. Another approach involves using computer models to try to predict as accurately as possible the activity of the modified meganucleases and the specificity of the recognized nucleic sequence.A large bank containing several tens of thousands of protein units has been created. These units can be combined to obtain chimeric meganucleases that recognize the target site, thereby providing research and development tools that meet a wide range of needs (fundamental research, health, agriculture, industry, energy, etc.) These include the industrial-scale production of two meganucleases able to cleave the human XPC gene; mutations in this gene result in Xeroderma pigmentosum, a severe monogenic disorder that predisposes the patients to skin cancer and burns whenever their skin is exposed to UV rays.Meganucleases have the benefit of causing less toxicity in cells than methods such as Zinc finger nuclease (ZFN), likely because of more stringent DNA sequence recognition; however, the construction of sequence-specific enzymes for all possible sequences is costly and time-consuming, as one is not benefiting from combinatorial possibilities that methods such as ZFNs and TALEN-based fusions utilize.\n",
      "\n",
      "Zinc finger nucleases\n",
      "As opposed to meganucleases, the concept behind ZFNs and TALEN technology is based on a non-specific DNA cutting catalytic domain, which can then be linked to specific DNA sequence recognizing peptides such as zinc fingers and transcription activator-like effectors (TALEs). The first step to this was to find an endonuclease whose DNA recognition site and cleaving site were separate from each other, a situation that is not the most common among restriction enzymes. Once this enzyme was found, its cleaving portion could be separated which would be very non-specific as it would have no recognition ability. This portion could then be linked to sequence recognizing peptides that could lead to very high specificity.\n",
      "Zinc finger motifs occur in several transcription factors. The zinc ion, found in 8% of all human proteins, plays an important role in the organization of their three-dimensional structure. In transcription factors, it is most often located at the protein-DNA interaction sites, where it stabilizes the motif. The C-terminal part of each finger is responsible for the specific recognition of the DNA sequence.\n",
      "The recognized sequences are short, made up of around 3 base pairs, but by combining 6 to 8 zinc fingers whose recognition sites have been characterized, it is possible to obtain specific proteins for sequences of around 20 base pairs. It is therefore possible to control the expression of a specific gene. It has been demonstrated that this strategy can be used to promote a process of angiogenesis in animals. It is also possible to fuse a protein constructed in this way with the catalytic domain of an endonuclease in order to induce a targeted DNA break, and therefore to use these proteins as genome engineering tools.The method generally adopted for this involves associating two DNA binding proteins – each containing 3 to 6 specifically chosen zinc fingers – with the catalytic domain of the FokI endonuclease which need to dimerize to cleave the double-strand DNA. The two proteins recognize two DNA sequences that are a few nucleotides apart. Linking the two zinc finger proteins to their respective sequences brings the two FokI domains closer together. FokI requires dimerization to have nuclease activity and this means the specificity increases dramatically as each nuclease partner would recognize a unique DNA sequence. To enhance this effect, FokI nucleases have been engineered that can only function as heterodimers.Several approaches are used to design specific zinc finger nucleases for the chosen sequences. The most widespread involves combining zinc-finger units with known specificities (modular assembly). Various selection techniques, using bacteria, yeast or mammal cells have been developed to identify the combinations that offer the best specificity and the best cell tolerance. Although the direct genome-wide characterization of zinc finger nuclease activity has not been reported, an assay that measures the total number of double-strand DNA breaks in cells found that only one to two such breaks occur above background in cells treated with zinc finger nucleases with a 24 bp composite recognition site and obligate heterodimer FokI nuclease domains.The heterodimer functioning nucleases would avoid the possibility of unwanted homodimer activity and thus increase specificity of the DSB. Although the nuclease portions of both ZFNs and TALEN constructs have similar properties, the difference between these engineered nucleases is in their DNA recognition peptide. ZFNs rely on Cys2-His2 zinc fingers and TALEN constructs on TALEs. Both of these DNA recognizing peptide domains have the characteristic that they are naturally found in combinations in their proteins. Cys2-His2 Zinc fingers typically happen in repeats that are 3 bp apart and are found in diverse combinations in a variety of nucleic acid interacting proteins such as transcription factors. Each finger of the Zinc finger domain is completely independent and the binding capacity of one finger is impacted by its neighbor. TALEs on the other hand are found in repeats with a one-to-one recognition ratio between the amino acids and the recognized nucleotide pairs. Because both zinc fingers and TALEs happen in repeated patterns, different combinations can be tried to create a wide variety of sequence specificities. Zinc fingers have been more established in these terms and approaches such as modular assembly (where Zinc fingers correlated with a triplet sequence are attached in a row to cover the required sequence), OPEN (low-stringency selection of peptide domains vs. triplet nucleotides followed by high-stringency selections of peptide combination vs. the final target in bacterial systems), and bacterial one-hybrid screening of zinc finger libraries among other methods have been used to make site specific nucleases.\n",
      "Zinc finger nucleases are research and development tools that have already been used to modify a range of genomes, in particular by the laboratories in the Zinc Finger Consortium. The US company Sangamo BioSciences uses zinc finger nucleases to carry out research into the genetic engineering of stem cells and the modification of immune cells for therapeutic purposes. Modified T lymphocytes are currently undergoing phase I clinical trials to treat a type of brain tumor (glioblastoma) and in the fight against AIDS.\n",
      "\n",
      "TALEN\n",
      "Transcription activator-like effector nucleases (TALENs) are specific DNA-binding proteins that feature an array of 33 or 34-amino acid repeats. TALENs are artificial restriction enzymes designed by fusing the DNA cutting domain of a nuclease to TALE domains, which can be tailored to specifically recognize a unique DNA sequence. These fusion proteins serve as readily targetable \"DNA scissors\" for gene editing applications that enable to perform targeted genome modifications such as sequence insertion, deletion, repair and replacement in living cells. The DNA binding domains, which can be designed to bind any desired DNA sequence, comes from TAL effectors, DNA-binding proteins excreted by plant pathogenic Xanthomanos app. TAL effectors consists of repeated domains, each of which contains a highly conserved sequence of 34 amino acids, and recognize a single DNA nucleotide within the target site. The nuclease can create double strand breaks at the target site that can be repaired by error-prone non-homologous end-joining (NHEJ), resulting in gene disruptions through the introduction of small insertions or deletions. Each repeat is conserved, with the exception of the so-called repeat variable di-residues (RVDs) at amino acid positions 12 and 13. The RVDs determine the DNA sequence to which the TALE will bind. This simple one-to-one correspondence between the TALE repeats and the corresponding DNA sequence makes the process of assembling repeat arrays to recognize novel DNA sequences straightforward. These TALEs can be fused to the catalytic domain from a DNA nuclease, FokI, to generate a transcription activator-like effector nuclease (TALEN). The resultant TALEN constructs combine specificity and activity, effectively generating engineered sequence-specific nucleases that bind and cleave DNA sequences only at pre-selected sites. The TALEN target recognition system is based on an easy-to-predict code. TAL nucleases are specific to their target due in part to the length of their 30+ base pairs binding site. TALEN can be performed within a 6 base pairs range of any single nucleotide in the entire genome.TALEN constructs are used in a similar way to designed zinc finger nucleases, and have three advantages in targeted mutagenesis: (1) DNA binding specificity is higher, (2) off-target effects are lower, and (3) construction of DNA-binding domains is easier.\n",
      "\n",
      "CRISPR\n",
      "CRISPRs (Clustered Regularly Interspaced Short Palindromic Repeats) are genetic elements that bacteria use as a kind of acquired immunity to protect against viruses. They consist of short sequences that originate from viral genomes and have been incorporated into the bacterial genome. Cas (CRISPR associated proteins) process these sequences and cut matching viral DNA sequences. By introducing plasmids containing Cas genes and specifically constructed CRISPRs into eukaryotic cells, the eukaryotic genome can be cut at any desired position.\n",
      "\n",
      "Editing by nucleobase modification (Base editing)\n",
      "One of the earliest methods of efficiently editing nucleic acids employs nucleobase modifying enzymes directed by nucleic acid guide sequences was first described in the 1990s and has seen resurgence more recently. This method has the advantage that it does not require breaking the genomic DNA strands, and thus avoids the random insertion and deletions associated with DNA strand breakage. It is only appropriate for precise editing requiring single nucleotide changes and has found to be highly efficient for this type of editing.\n",
      "\n",
      "ARCUT\n",
      "ARCUT stands for artificial restriction DNA cutter, it is a technique developed by Komiyama. This method uses pseudo-complementary peptide nucleic acid (pcPNA), for identifying cleavage site within the chromosome. Once pcPNA specifies the site, excision is carried out by cerium (CE) and EDTA (chemical mixture), which performs the splicing function.\n",
      "\n",
      "Precision and efficiency of engineered nucleases\n",
      "Meganucleases method of gene editing is the least efficient of the methods mentioned above. Due to the nature of its DNA-binding element and the cleaving element, it is limited to recognizing one potential target every 1,000 nucleotides. ZFN was developed to overcome the limitations of meganuclease. The number of possible targets ZFN can recognized was increased to one in every 140 nucleotides. However, both methods are unpredictable because of their DNA-binding elements affecting each other. As a result, high degrees of expertise and lengthy and costly validations processes are required.\n",
      "TALE nucleases being the most precise and specific method yields a higher efficiency than the previous two methods. It achieves such efficiency because the DNA-binding element consists of an array of TALE subunits, each of them having the capability of recognizing a specific DNA nucleotide chain independent from others, resulting in a higher number of target sites with high precision. New TALE nucleases take about one week and a few hundred dollars to create, with specific expertise in molecular biology and protein engineering.CRISPR nucleases have a slightly lower precision when compared to the TALE nucleases. This is caused by the need of having a specific nucleotide at one end in order to produce the guide RNA that CRISPR uses to repair the double-strand break it induces. It has been shown to be the quickest and cheapest method, only costing less than two hundred dollars and a few days of time. CRISPR also requires the least amount of expertise in molecular biology as the design lays in the guide RNA instead of the proteins. One major advantage that CRISPR has over the ZFN and TALEN methods is that it can be directed to target different DNA sequences using its ~80nt CRISPR sgRNAs, while both ZFN and TALEN methods required construction and testing of the proteins created for targeting each DNA sequence.Because off-target activity of an active nuclease would have potentially dangerous consequences at the genetic and organismal levels, the precision of meganucleases, ZFNs, CRISPR, and TALEN-based fusions has been an active area of research. While variable figures have been reported, ZFNs tend to have more cytotoxicity than TALEN methods or RNA-guided nucleases, while TALEN and RNA-guided approaches tend to have the greatest efficiency and fewer off-target effects. Based on the maximum theoretical distance between DNA binding and nuclease activity, TALEN approaches result in the greatest precision.\n",
      "\n",
      "Multiplex Automated Genomic Engineering (MAGE)\n",
      "The methods for scientists and researchers wanting to study genomic diversity and all possible associated phenotypes were very slow, expensive, and inefficient. Prior to this new revolution, researchers would have to do single-gene manipulations and tweak the genome one little section at a time, observe the phenotype, and start the process over with a different single-gene manipulation. Therefore, researchers at the Wyss Institute at Harvard University designed the MAGE, a powerful technology that improves the process of in vivo genome editing. It allows for quick and efficient manipulations of a genome, all happening in a machine small enough to put on top of a small kitchen table. Those mutations combine with the variation that naturally occurs during cell mitosis creating billions of cellular mutations.\n",
      "Chemically combined, synthetic single-stranded DNA (ssDNA) and a pool of oligionucleotides are introduced at targeted areas of the cell thereby creating genetic modifications. The cyclical process involves transformation of ssDNA (by electroporation) followed by outgrowth, during which bacteriophage homologous recombination proteins mediate annealing of ssDNAs to their genomic targets. Experiments targeting selective phenotypic markers are screened and identified by plating the cells on differential medias. Each cycle ultimately takes 2.5 hours to process, with additional time required to grow isogenic cultures and characterize mutations. By iteratively introducing libraries of mutagenic ssDNAs targeting multiple sites, MAGE can generate combinatorial genetic diversity in a cell population. There can be up to 50 genome edits, from single nucleotide base pairs to whole genome or gene networks simultaneously with results in a matter of days.MAGE experiments can be divided into three classes, characterized by varying degrees of scale and complexity: (i) many target sites, single genetic mutations; (ii) single target site, many genetic mutations; and (iii) many target sites, many genetic mutations. An example of class three was reflected in 2009, where Church and colleagues were able to program Escherichia coli to produce five times the normal amount of lycopene, an antioxidant normally found in tomato seeds and linked to anti-cancer properties. They applied MAGE to optimize the 1-deoxy-d-xylulose-5-phosphate (DXP) metabolic pathway in Escherichia coli to overproduce isoprenoid lycopene. It took them about 3 days and just over $1,000 in materials. The ease, speed, and cost efficiency in which MAGE can alter genomes can transform how industries approach the manufacturing and production of important compounds in the bioengineering, bioenergy, biomedical engineering, synthetic biology, pharmaceutical, agricultural, and chemical industries.\n",
      "\n",
      "Applications\n",
      "As of 2012 efficient genome editing had been developed for a wide range of experimental systems ranging from plants to animals, often beyond clinical interest, and was becoming a standard experimental strategy in research labs. The recent generation of rat, zebrafish, maize and tobacco ZFN-mediated mutants and the improvements in TALEN-based approaches testify to the significance of the methods, and the list is expanding rapidly. Genome editing with engineered nucleases will likely contribute to many fields of life sciences from studying gene functions in plants and animals to gene therapy in humans. For instance, the field of synthetic biology which aims to engineer cells and organisms to perform novel functions, is likely to benefit from the ability of engineered nuclease to add or remove genomic elements and therefore create complex systems. In addition, gene functions can be studied using stem cells with engineered nucleases.\n",
      "Listed below are some specific tasks this method can carry out:\n",
      "\n",
      "Targeted gene mutation\n",
      "Gene therapy\n",
      "Creating chromosome rearrangement\n",
      "Study gene function with stem cells\n",
      "Transgenic animals\n",
      "Endogenous gene labeling\n",
      "Targeted transgene addition\n",
      "\n",
      "Targeted gene modification in animals\n",
      "The combination of recent discoveries in genetic engineering, particularly gene editing and the latest improvement in bovine reproduction technologies (e.g. in vitro embryo culture) allows for genome editing directly in fertilised oocytes using synthetic highly specific endonucleases. RNA-guided endonucleases:clustered regularly interspaced short palindromic repeats associated Cas9 (CRISPR/Cas9) are a new tool, further increasing the range of methods available. In particular CRISPR/Cas9 engineered endonucleases allows the use of multiple guide RNAs for simultaneous Knockouts (KO) in one step by cytoplasmic direct injection (CDI) on mammalian zygotes.Furthermore, gene editing can be applied to certain types of fish in aquaculture such as Atlantic salmon. Gene editing in fish is currently experimental, but the possibilities include growth, disease resistance, sterility, controlled reproduction, and colour. Selecting for these traits can allow for a more sustainable environment and better welfare for the fish.AquAdvantage salmon is a genetically modified Atlantic salmon developed by AquaBounty Technologies. The growth hormone-regulating gene in the Atlantic salmon is replaced with the growth hormone-regulating gene from the Pacific Chinook salmon and a promoter sequence from the ocean poutThanks to the parallel development of single-cell transcriptomics, genome editing and new stem cell models we are now entering a scientifically exciting period where functional genetics is no longer restricted to animal models but can be performed directly in human samples. Single-cell gene expression analysis has resolved a transcriptional road-map of human development from which key candidate genes are being identified for functional studies. Using global transcriptomics data to guide experimentation, the CRISPR based genome editing tool has made it feasible to disrupt or remove key genes in order to elucidate function in a human setting.\n",
      "\n",
      "Targeted gene modification in plants\n",
      "Genome editing using Meganuclease, ZFNs, and TALEN provides a new strategy for genetic manipulation in plants and are likely to assist in the engineering of desired plant traits by modifying endogenous genes. For instance, site-specific gene addition in major crop species can be used for 'trait stacking' whereby several desired traits are physically linked to ensure their co-segregation during the breeding processes. Progress in such cases have been recently reported in Arabidopsis thaliana and Zea mays. In Arabidopsis thaliana, using ZFN-assisted gene targeting, two herbicide-resistant genes (tobacco acetolactate synthase SuRA and SuRB) were introduced to SuR loci with as high as 2% transformed cells with mutations. In Zea mays, disruption of the target locus was achieved by ZFN-induced DSBs and the resulting NHEJ. ZFN was also used to drive herbicide-tolerance gene expression cassette (PAT) into the targeted endogenous locus IPK1 in this case. Such genome modification observed in the regenerated plants has been shown to be inheritable and was transmitted to the next generation. A potentially successful example of the application of genome editing techniques in crop improvement can be found in banana, where scientists used CRISPR/Cas9 editing to inactivate the endogenous banana streak virus in the B genome of banana (Musa spp.) to overcome a major challenge in banana breeding.In addition, TALEN-based genome engineering has been extensively tested and optimized for use in plants. TALEN fusions have also been used by a U.S. food ingredient company, Calyxt, to improve the quality of soybean oil products and to increase the storage potential of potatoesSeveral optimizations need to be made in order to improve editing plant genomes using ZFN-mediated targeting. There is a need for reliable design and subsequent test of the nucleases, the absence of toxicity of the nucleases, the appropriate choice of the plant tissue for targeting, the routes of induction of enzyme activity, the lack of off-target mutagenesis, and a reliable detection of mutated cases.A common delivery method for CRISPR/Cas9 in plants is Agrobacterium-based transformation. T-DNA is introduced directly into the plant genome by a T4SS mechanism. Cas9 and gRNA-based expression cassettes are turned into Ti plasmids, which are transformed in Agrobacterium for plant application. To improve Cas9 delivery in live plants, viruses are being used more effective transgene delivery.\n",
      "\n",
      "Research\n",
      "Gene therapy\n",
      "The ideal gene therapy practice is that which replaces the defective gene with a normal allele at its natural location. This is advantageous over a virally delivered gene as there is no need to include the full coding sequences and regulatory sequences when only a small proportions of the gene needs to be altered as is often the case. The expression of the partially replaced genes is also more consistent with normal cell biology than full genes that are carried by viral vectors.\n",
      "The first clinical use of TALEN-based genome editing was in the treatment of CD19+ acute lymphoblastic leukemia in an 11-month old child in 2015. Modified donor T cells were engineered to attack the leukemia cells, to be resistant to Alemtuzumab, and to evade detection by the host immune system after introduction.Extensive research has been done in cells and animals using CRISPR-Cas9 to attempt to correct genetic mutations which cause genetic diseases such as Down syndrome, spina bifida, anencephaly, and Turner and Klinefelter syndromes.In February 2019, medical scientists working with Sangamo Therapeutics, headquartered in Richmond, California, announced the first ever \"in body\" human gene editing therapy to permanently alter DNA - in a patient with Hunter syndrome. Clinical trials by Sangamo involving gene editing using Zinc Finger Nuclease (ZFN) are ongoing.\n",
      "\n",
      "Eradicating diseases\n",
      "Researchers have used CRISPR-Cas9 gene drives to modify genes associated with sterility in A. gambiae, the vector for malaria. This technique has further implications in eradicating other vector borne diseases such as yellow fever, dengue, and Zika.The CRISPR-Cas9 system can be programmed to modulate the population of any bacterial species by targeting clinical genotypes or epidemiological isolates. It can selectively enable the beneficial bacterial species over the harmful ones by eliminating pathogen, which gives it an advantage over broad-spectrum antibiotics.Antiviral applications for therapies targeting human viruses such as HIV, herpes, and hepatitis B virus are under research. CRISPR can be used to target the virus or the host to disrupt genes encoding the virus cell-surface receptor proteins. In November 2018, He Jiankui announced that he had edited two human embryos, to attempt to disable the gene for CCR5, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier. He said that the girls still carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature.In January 2019, scientists in China reported the creation of five identical cloned gene-edited monkeys, using the same cloning technique that was used with Zhong Zhong and Hua Hua – the first ever cloned monkeys - and Dolly the sheep, and the same gene-editing Crispr-Cas9 technique allegedly used by He Jiankui in creating the first ever gene-modified human babies Lulu and Nana. The monkey clones were made in order to study several medical diseases.\n",
      "\n",
      "Prospects and limitations\n",
      "In the future, an important goal of research into genome editing with engineered nucleases must be the improvement of the safety and specificity of the nucleases action. For example, improving the ability to detect off-target events can improve our ability to learn about ways of preventing them. In addition, zinc-fingers used in ZFNs are seldom completely specific, and some may cause a toxic reaction. However, the toxicity has been reported to be reduced by modifications done on the cleavage domain of the ZFN.In addition, research by Dana Carroll into modifying the genome with engineered nucleases has shown the need for better understanding of the basic recombination and repair machinery of DNA. In the future, a possible method to identify secondary targets would be to capture broken ends from cells expressing the ZFNs and to sequence the flanking DNA using high-throughput sequencing.Because of the ease of use and cost-efficiency of CRISPR, extensive research is currently being done on it. There are now more publications on CRISPR than ZFN and TALEN despite how recent the discovery of CRISPR is. Both CRISPR and TALEN are favored to be the choices to be implemented in large-scale productions due to their precision and efficiency.\n",
      "Genome editing occurs also as a natural process without artificial genetic engineering. The agents that are competent to edit genetic codes are viruses or subviral RNA-agents.\n",
      "Although GEEN has higher efficiency than many other methods in reverse genetics, it is still not highly efficient; in many cases less than half of the treated populations obtain the desired changes. For example, when one is planning to use the cell's NHEJ to create a mutation, the cell's HDR systems will also be at work correcting the DSB with lower mutational rates.\n",
      "Traditionally, mice have been the most common choice for researchers as a host of a disease model. CRISPR can help bridge the gap between this model and human clinical trials by creating transgenic disease models in larger animals such as pigs, dogs, and non-human primates. Using the CRISPR-Cas9 system, the programmed Cas9 protein and the sgRNA can be directly introduced into fertilized zygotes to achieve the desired gene modifications when creating transgenic models in rodents. This allows bypassing of the usual cell targeting stage in generating transgenic lines, and as a result, it reduces generation time by 90%.One potential that CRISPR brings with its effectiveness is the application of xenotransplantation. In previous research trials, CRISPR demonstrated the ability to target and eliminate endogenous retroviruses, which reduces the risk of transmitting diseases and reduces immune barriers. Eliminating these problems improves donor organ function, which brings this application closer to a reality.\n",
      "In plants, genome editing is seen as a viable solution to the conservation of biodiversity. Gene drive are a potential tool to alter the reproductive rate of invasive species, although there are significant associated risks.\n",
      "\n",
      "Human enhancement\n",
      "Many transhumanists see genome editing as a potential tool for human enhancement. Australian biologist and Professor of Genetics David Andrew Sinclair notes that \"the new technologies with genome editing will allow it to be used on individuals (...) to have (...) healthier children\" – designer babies. According to a September 2016 report by the Nuffield Council on Bioethics in the future it may be possible to enhance people with genes from other organisms or wholly synthetic genes to for example improve night vision and sense of smell. George Church has compiled a list of potential genetic modifications for possibly advantageous traits such as less need for sleep, cognition-related changes that protect against Alzheimer's disease, disease resistances and enhanced learning abilities along with some of the associated studies and potential negative effects.The American National Academy of Sciences and National Academy of Medicine issued a report in February 2017 giving qualified support to human genome editing. They recommended that clinical trials for genome editing might one day be permitted once answers have been found to safety and efficiency problems \"but only for serious conditions under stringent oversight.\"\n",
      "\n",
      "Risks\n",
      "In the 2016 Worldwide Threat Assessment of the US Intelligence Community statement United States Director of National Intelligence, James R. Clapper, named genome editing as a potential weapon of mass destruction, stating that genome editing conducted by countries with regulatory or ethical standards \"different from Western countries\" probably increases the risk of the creation of harmful biological agents or products. According to the statement the broad distribution, low cost, and accelerated pace of development of this technology, its deliberate or unintentional misuse might lead to far-reaching economic and national security implications. For instance technologies such as CRISPR could be used to make \"killer mosquitoes\" that cause plagues that wipe out staple crops.According to a September 2016 report by the Nuffield Council on Bioethics, the simplicity and low cost of tools to edit the genetic code will allow amateurs – or \"biohackers\" – to perform their own experiments, posing a potential risk from the release of genetically modified bugs. The review also found that the risks and benefits of modifying a person's genome – and having those changes pass on to future generations – are so complex that they demand urgent ethical scrutiny. Such modifications might have unintended consequences which could harm not only the child, but also their future children, as the altered gene would be in their sperm or eggs. In 2001 Australian researchers Ronald Jackson and Ian Ramshaw were criticized for publishing a paper in the Journal of Virology that explored the potential control of mice, a major pest in Australia, by infecting them with an altered mousepox virus that would cause infertility as the provided sensitive information could lead to the manufacture of biological weapons by potential bioterrorists who might use the knowledge to create vaccine resistant strains of other pox viruses, such as smallpox, that could affect humans. Furthermore, there are additional concerns about the ecological risks of releasing gene drives into wild populations.\n",
      "\n",
      "Nobel prize\n",
      "In 2007, the Nobel Prize for Physiology or Medicine was awarded to Mario Capecchi, Martin Evans and Oliver Smithies \"for their discoveries of principles for introducing specific gene modifications in mice by the use of embryonic stem cells.\"In 2020, the Nobel Prize in Chemistry was awarded to Emmanuelle Charpentier and Jennifer Doudna for \"the development of a method for genome editing\".\n",
      "\n",
      "See also\n",
      "CRISPR/Cpf1\n",
      "RNA editing\n",
      "Epigenome editing\n",
      "Prime editing\n",
      "Transposons as a genetic tool\n",
      "Germinal choice technology\n",
      "NgAgo, a ssDNA-guided Argonaute endonuclease\n",
      "\n",
      "References\n",
      "\"WHO launches global registry on human genome editing.\" PharmaBiz, 31 Aug. 2019. Gale General OneFile, Accessed 27 Apr. 2020.\n",
      "\n",
      "Further reading\n",
      "Saurabh S (March 2021). \"Genome Editing: Revolutionizing the Crop Improvement\". Plant Molecular Biology Reporte. 39 (4): 752–772. doi:10.1007/s11105-021-01286-7. S2CID 233713026.\n",
      "\"Special Issue on Human Germline Editing\". Bioethics. 34. 2020.\n",
      "\"Customized Human Genes: New Promises and Perils\". Scientific American. Retrieved 2019-02-21.\n",
      "Connor S (25 April 2014). \"Scientific split - the human genome breakthrough dividing former colleagues\". The Independent. Retrieved 2016-02-11.\n",
      "\"What is genome editing?\". yourgenome.org. Retrieved 2018-04-13.Michelangelo di Lodovico Buonarroti Simoni (Italian: [mikeˈlandʒelo di lodoˈviːko ˌbwɔnarˈrɔːti siˈmoːni]; 6 March 1475 – 18 February 1564), known mononymously as Michelangelo (English: ), was an Italian sculptor, painter, architect, and poet of the High Renaissance. Born in the Republic of Florence, his work was inspired by models from classical antiquity and had a lasting influence on Western art. Michelangelo's creative abilities and mastery in a range of artistic arenas define him as an archetypal Renaissance man, along with his rival and elder contemporary, Leonardo da Vinci. Given the sheer volume of surviving correspondence, sketches, and reminiscences, Michelangelo is one of the best-documented artists of the 16th century. He was lauded by contemporary biographers as the most accomplished artist of his era.Michelangelo achieved fame early; two of his best-known works, the Pietà and David, were sculpted before the age of thirty. Although he did not consider himself a painter, Michelangelo created two of the most influential frescoes in the history of Western art: the scenes from Genesis on the ceiling of the Sistine Chapel in Rome, and The Last Judgment on its altar wall. His design of the Laurentian Library pioneered Mannerist architecture. At the age of 71, he succeeded Antonio da Sangallo the Younger as the architect of St. Peter's Basilica. Michelangelo transformed the plan so that the western end was finished to his design, as was the dome, with some modification, after his death.\n",
      "Michelangelo was the first Western artist whose biography was published while he was alive. In fact, three biographies were published during his lifetime. One of them, by Giorgio Vasari, proposed that Michelangelo's work transcended that of any artist living or dead, and was \"supreme in not one art alone but in all three.\"In his lifetime, Michelangelo was often called Il Divino (\"the divine one\"). His contemporaries often admired his terribilità—his ability to instill a sense of awe in viewers of his art. Attempts by subsequent artists to imitate the expressive physicality of Michelangelo's style contributed to the rise of Mannerism, a short-lived movement in Western art between the High Renaissance and the Baroque.\n",
      "\n",
      "Life\n",
      "Early life, 1475–1488\n",
      "Michelangelo was born on 6 March 1475 in Caprese, known today as Caprese Michelangelo, a small town situated in Valtiberina, near Arezzo, Tuscany. For several generations, his family had been small-scale bankers in Florence; but the bank failed, and his father, Ludovico di Leonardo Buonarroti Simoni, briefly took a government post in Caprese, where Michelangelo was born. At the time of Michelangelo's birth, his father was the town's judicial administrator and podestà or local administrator of Chiusi della Verna. Michelangelo's mother was Francesca di Neri del Miniato di Siena. The Buonarrotis claimed to descend from the Countess Matilde di Canossa—a claim that remains unproven, but which Michelangelo believed.Several months after Michelangelo's birth, the family returned to Florence, where he was raised. During his mother's later prolonged illness, and after her death in 1481 (when he was six years old), Michelangelo lived with a nanny and her husband, a stonecutter, in the town of Settignano, where his father owned a marble quarry and a small farm. There he gained his love for marble. As Giorgio Vasari quotes him:\n",
      "\n",
      "If there is some good in me, it is because I was born in the subtle atmosphere of your country of Arezzo. Along with the milk of my nurse I received the knack of handling chisel and hammer, with which I make my figures.\n",
      "\n",
      "Apprenticeships, 1488–1492\n",
      "As a young boy, Michelangelo was sent to Florence to study grammar under the Humanist Francesco da Urbino. He showed no interest in his schooling, preferring to copy paintings from churches and seek the company of other painters.The city of Florence was at that time Italy's greatest centre of the arts and learning. Art was sponsored by the Signoria (the town council), the merchant guilds, and wealthy patrons such as the Medici and their banking associates. The Renaissance, a renewal of Classical scholarship and the arts, had its first flowering in Florence. In the early 15th century, the architect Filippo Brunelleschi, having studied the remains of Classical buildings in Rome, had created two churches, San Lorenzo's and Santo Spirito, which embodied the Classical precepts. The sculptor Lorenzo Ghiberti had laboured for fifty years to create the north and east bronze doors of the Baptistry, which Michelangelo was to describe as \"The Gates of Paradise\". The exterior niches of the Church of Orsanmichele contained a gallery of works by the most acclaimed sculptors of Florence: Donatello, Ghiberti, Andrea del Verrocchio, and Nanni di Banco. The interiors of the older churches were covered with frescos (mostly in Late Medieval, but also in the Early Renaissance style), begun by Giotto and continued by Masaccio in the Brancacci Chapel, both of whose works Michelangelo studied and copied in drawings.During Michelangelo's childhood, a team of painters had been called from Florence to the Vatican to decorate the walls of the Sistine Chapel. Among them was Domenico Ghirlandaio, a master in fresco painting, perspective, figure drawing and portraiture who had the largest workshop in Florence. In 1488, at age 13, Michelangelo was apprenticed to Ghirlandaio. The next year, his father persuaded Ghirlandaio to pay Michelangelo as an artist, which was rare for someone of fourteen. When in 1489, Lorenzo de' Medici, de facto ruler of Florence, asked Ghirlandaio for his two best pupils, Ghirlandaio sent Michelangelo and Francesco Granacci.From 1490 to 1492, Michelangelo attended the Platonic Academy, a Humanist academy founded by the Medici. There, his work and outlook were influenced by many of the most prominent philosophers and writers of the day, including Marsilio Ficino, Pico della Mirandola and Poliziano. At this time, Michelangelo sculpted the reliefs Madonna of the Stairs (1490–1492) and Battle of the Centaurs (1491–1492), the latter based on a theme suggested by Poliziano and commissioned by Lorenzo de' Medici. Michelangelo worked for a time with the sculptor Bertoldo di Giovanni. When he was seventeen, another pupil, Pietro Torrigiano, struck him on the nose, causing the disfigurement that is conspicuous in the portraits of Michelangelo.\n",
      "\n",
      "Bologna, Florence, and Rome, 1492–1499\n",
      "Lorenzo de' Medici's death on 8 April 1492 brought a reversal of Michelangelo's circumstances. Michelangelo left the security of the Medici court and returned to his father's house. In the following months he carved a polychrome wooden Crucifix (1493), as a gift to the prior of the Florentine church of Santo Spirito, which had allowed him to do some anatomical studies of the corpses from the church's hospital. This was the first of several instances during his career that Michelangelo studied anatomy by dissecting cadavers.Between 1493 and 1494, he bought a block of marble, and carved a larger-than-life statue of Hercules, which was sent to France and subsequently disappeared sometime in the 18th century. On 20 January 1494, after heavy snowfalls, Lorenzo's heir, Piero de Medici, commissioned a statue made of snow, and Michelangelo again entered the court of the Medici.In the same year, the Medici were expelled from Florence as the result of the rise of Savonarola. Michelangelo left the city before the end of the political upheaval, moving to Venice and then to Bologna. In Bologna, he was commissioned to carve several of the last small figures for the completion of the Shrine of St. Dominic, in the church dedicated to that saint. At this time Michelangelo studied the robust reliefs carved by Jacopo della Quercia around the main portal of the Basilica of St Petronius, including the panel of The Creation of Eve, the composition of which was to reappear on the Sistine Chapel ceiling. Towards the end of 1495, the political situation in Florence was calmer; the city, previously under threat from the French, was no longer in danger as Charles VIII had suffered defeats. Michelangelo returned to Florence but received no commissions from the new city government under Savonarola. He returned to the employment of the Medici. During the half-year he spent in Florence, he worked on two small statues, a child St. John the Baptist and a sleeping Cupid. According to Condivi, Lorenzo di Pierfrancesco de' Medici, for whom Michelangelo had sculpted St. John the Baptist, asked that Michelangelo \"fix it so that it looked as if it had been buried\" so he could \"send it to Rome ... pass [it off as] an ancient work and ... sell it much better.\" Both Lorenzo and Michelangelo were unwittingly cheated out of the real value of the piece by a middleman. Cardinal Raffaele Riario, to whom Lorenzo had sold it, discovered that it was a fraud, but was so impressed by the quality of the sculpture that he invited the artist to Rome.  This apparent success in selling his sculpture abroad as well as the conservative Florentine situation may have encouraged Michelangelo to accept the prelate's invitation.Michelangelo arrived in Rome on 25 June 1496 at the age of 21. On 4 July of the same year, he began work on a commission for Cardinal Riario, an over-life-size statue of the Roman wine god Bacchus. Upon completion, the work was rejected by the cardinal, and subsequently entered the collection of the banker Jacopo Galli, for his garden.In November 1497, the French ambassador to the Holy See, Cardinal Jean de Bilhères-Lagraulas, commissioned him to carve a Pietà, a sculpture showing the Virgin Mary grieving over the body of Jesus. The subject, which is not part of the Biblical narrative of the Crucifixion, was common in religious sculpture of Medieval Northern Europe and would have been very familiar to the Cardinal. The contract was agreed upon in August of the following year. Michelangelo was 24 at the time of its completion. It was soon to be regarded as one of the world's great masterpieces of sculpture, \"a revelation of all the potentialities and force of the art of sculpture\". Contemporary opinion was summarised by Vasari: \"It is certainly a miracle that a formless block of stone could ever have been reduced to a perfection that nature is scarcely able to create in the flesh.\" It is now located in St Peter's Basilica.\n",
      "\n",
      "Florence, 1499–1505\n",
      "Michelangelo returned to Florence in 1499. The Republic was changing after the fall of its leader, anti-Renaissance priest Girolamo Savonarola, who was executed in 1498, and the rise of the gonfaloniere Piero Soderini. Michelangelo was asked by the consuls of the Guild of Wool to complete an unfinished project begun 40 years earlier by Agostino di Duccio: a colossal statue of Carrara marble portraying David as a symbol of Florentine freedom to be placed on the gable of Florence Cathedral. Michelangelo responded by completing his most famous work, the statue of David, in 1504. The masterwork definitively established his prominence as a sculptor of extraordinary technical skill and strength of symbolic imagination. A team of consultants, including Botticelli, Leonardo da Vinci, Filippino Lippi, Pietro Perugino, Lorenzo di Credi, Antonio and Giuliano da Sangallo, Andrea della Robbia, Cosimo Rosselli, Davide Ghirlandaio, Piero di Cosimo, Andrea Sansovino and Michelangelo's dear friend Francesco Granacci, was called together to decide upon its placement, ultimately the Piazza della Signoria, in front of the Palazzo Vecchio. It now stands in the Academia while a replica occupies its place in the square. In the same period of placing the David, Michelangelo may have been involved in creating the sculptural profile on Palazzo Vecchio's façade known as the Importuno di Michelangelo. The hypothesis on Michelangelo's possible involvement in the creation of the profile is based on the strong resemblance of the latter to a profile drawn by the artist, datable to the beginning of the 16th century, now preserved in the Louvre.With the completion of the David came another commission. In early 1504 Leonardo da Vinci had been commissioned to paint The Battle of Anghiari in the council chamber of the Palazzo Vecchio, depicting the battle between Florence and Milan in 1440. Michelangelo was then commissioned to paint the Battle of Cascina. The two paintings are very different: Leonardo depicts soldiers fighting on horseback, while Michelangelo has soldiers being ambushed as they bathe in the river. Neither work was completed and both were lost forever when the chamber was refurbished. Both works were much admired, and copies remain of them, Leonardo's work having been copied by Rubens and Michelangelo's by Bastiano da Sangallo.Also during this period, Michelangelo was commissioned by Angelo Doni to paint a \"Holy Family\" as a present for his wife, Maddalena Strozzi. It is known as the Doni Tondo and hangs in the Uffizi Gallery in its original magnificent frame, which Michelangelo may have designed. He also may have painted the Madonna and Child with John the Baptist, known as the Manchester Madonna and now in the National Gallery, London.\n",
      "\n",
      "Tomb of Julius II, 1505–1545\n",
      "In 1505 Michelangelo was invited back to Rome by the newly elected Pope Julius II and commissioned to build the Pope's tomb, which was to include forty statues and be finished in five years. Under the patronage of the pope, Michelangelo experienced constant interruptions to his work on the tomb in order to accomplish numerous other tasks.\n",
      "The commission for the tomb forced the artist to leave Florence with his planned Battle of Cascina painting unfinished. By this time, Michelangelo was established as an artist; both he and Julius II had hot tempers and soon argued. On 17 April 1506, Michelangelo left Rome in secret for Florence, remaining there until the Florentine government pressed him to return to the pope.Although Michelangelo worked on the tomb for 40 years, it was never finished to his satisfaction. It is located in the Church of San Pietro in Vincoli in Rome and is most famous for the central figure of Moses, completed in 1516. Of the other statues intended for the tomb, two, known as the Rebellious Slave and the Dying Slave, are now in the Louvre.\n",
      "\n",
      "Sistine Chapel ceiling, 1508 –1512\n",
      "During the same period, Michelangelo painted the ceiling of the Sistine Chapel, which took approximately four years to complete (1508–1512). According to Condivi's account, Bramante, who was working on the building of St. Peter's Basilica, resented Michelangelo's commission for the pope's tomb and convinced the pope to commission him in a medium with which he was unfamiliar, in order that he might fail at the task. Michelangelo was originally commissioned to paint the Twelve Apostles on the triangular pendentives that supported the ceiling, and to cover the central part of the ceiling with ornament. Michelangelo persuaded Pope Julius II to give him a free hand and proposed a different and more complex scheme, representing the Creation, the Fall of Man, the Promise of Salvation through the prophets, and the genealogy of Christ. The work is part of a larger scheme of decoration within the chapel that represents much of the doctrine of the Catholic Church.The composition stretches over 500 square metres of ceiling and contains over 300 figures. At its centre are nine episodes from the Book of Genesis, divided into three groups: God's creation of the earth; God's creation of humankind and their fall from God's grace; and lastly, the state of humanity as represented by Noah and his family. On the pendentives supporting the ceiling are painted twelve men and women who prophesied the coming of Jesus, seven prophets of Israel, and five Sibyls, prophetic women of the Classical world. Among the most famous paintings on the ceiling are The Creation of Adam, Adam and Eve in the Garden of Eden, the Deluge, the Prophet Jeremiah, and the Cumaean Sibyl.\n",
      "\n",
      "Florence under Medici popes, 1513 – early 1534\n",
      "In 1513, Pope Julius II died and was succeeded by Pope Leo X, the second son of Lorenzo de' Medici. From 1513 to 1516, Pope Leo was on good terms with Pope Julius's surviving relatives, so encouraged Michelangelo to continue work on Julius's tomb, but the families became enemies again in 1516 when Pope Leo tried to seize the Duchy of Urbino from Julius's nephew Francesco Maria I della Rovere. Pope Leo then had Michelangelo stop working on the tomb, and commissioned him to reconstruct the façade of the Basilica of San Lorenzo in Florence and to adorn it with sculptures. He spent three years creating drawings and models for the façade, as well as attempting to open a new marble quarry at Pietrasanta specifically for the project. In 1520, the work was abruptly cancelled by his financially strapped patrons before any real progress had been made. The basilica lacks a façade to this day.In 1520, the Medici came back to Michelangelo with another grand proposal, this time for a family funerary chapel in the Basilica of San Lorenzo. For posterity, this project, occupying the artist for much of the 1520s and 1530s, was more fully realised. Michelangelo used his own discretion to create the composition of the Medici Chapel, which houses the large tombs of two of the younger members of the Medici family, Giuliano, Duke of Nemours, and Lorenzo, his nephew. It also serves to commemorate their more famous predecessors, Lorenzo the Magnificent and his brother Giuliano, who are buried nearby. The tombs display statues of the two Medici and allegorical figures representing Night and Day, and Dusk and Dawn. The chapel also contains Michelangelo's Medici Madonna. In 1976, a concealed corridor was discovered with drawings on the walls that related to the chapel itself.Pope Leo X died in 1521 and was succeeded briefly by the austere Adrian VI, and then by his cousin Giulio Medici as Pope Clement VII. In 1524, Michelangelo received an architectural commission from the Medici pope for the Laurentian Library at San Lorenzo's Church. He designed both the interior of the library itself and its vestibule, a building utilising architectural forms with such dynamic effect that it is seen as the forerunner of Baroque architecture. It was left to assistants to interpret his plans and carry out construction. The library was not opened until 1571, and the vestibule remained incomplete until 1904.In 1527, Florentine citizens, encouraged by the sack of Rome, threw out the Medici and restored the republic. A siege of the city ensued, and Michelangelo went to the aid of his beloved Florence by working on the city's fortifications from 1528 to 1529. The city fell in 1530, and the Medici were restored to power, with the young Alessandro Medici as the first Duke of Florence. Pope Clement, a Medici, sentenced Michelangelo to death. It is thought that Michelangelo hid for two months in a small chamber under the Medici chapels in the Basilica of San Lorenzo with light from just a tiny window, making many charcoal and chalk drawings which remained hidden until the room was rediscovered in 1975, and opened to small numbers of visitors in 2023. Michelangelo was eventually pardoned by the Medicis and the death sentence lifted, so that he could complete work on the Sistine Chapel and the Medici family tomb. He left Florence for Rome in 1534. Despite Michelangelo's support of the republic and resistance to the Medici rule, Pope Clement reinstated an allowance that he had previously granted the artist and made a new contract with him over the tomb of Pope Julius.\n",
      "\n",
      "Rome, 1534–1546\n",
      "In Rome, Michelangelo lived near the church of Santa Maria di Loreto. It was at this time that he met the poet Vittoria Colonna, marchioness of Pescara, who was to become one of his closest friends until her death in 1547.Shortly before his death in 1534, Pope Clement VII commissioned Michelangelo to paint a fresco of The Last Judgment on the altar wall of the Sistine Chapel. His successor, Pope Paul III, was instrumental in seeing that Michelangelo began and completed the project, which he laboured on from 1534 to October 1541. The fresco depicts the Second Coming of Christ and his Judgement of the souls. Michelangelo ignored the usual artistic conventions in portraying Jesus, showing him as a massive, muscular figure, youthful, beardless and naked. He is surrounded by saints, among whom Saint Bartholomew holds a drooping flayed skin, bearing the likeness of Michelangelo. The dead rise from their graves, to be consigned either to Heaven or to Hell.Once completed, the depiction of Christ and the Virgin Mary naked was considered sacrilegious, and Cardinal Carafa and Monsignor Sernini (Mantua's ambassador) campaigned to have the fresco removed or censored, but the Pope resisted. At the Council of Trent, shortly before Michelangelo's death in 1564, it was decided to obscure the genitals and Daniele da Volterra, an apprentice of Michelangelo, was commissioned to make the alterations. An uncensored copy of the original, by Marcello Venusti, is in the Capodimonte Museum of Naples.Michelangelo worked on a number of architectural projects at this time. They included a design for the Capitoline Hill with its trapezoid piazza displaying the ancient bronze statue of Marcus Aurelius. He designed the upper floor of the Palazzo Farnese and the interior of the Church of Santa Maria degli Angeli, in which he transformed the vaulted interior of an Ancient Roman bathhouse. Other architectural works include San Giovanni dei Fiorentini, the Sforza Chapel (Capella Sforza) in the Basilica di Santa Maria Maggiore and the Porta Pia.\n",
      "\n",
      "St Peter's Basilica, 1546–1564\n",
      "While still working on the Last Judgment, Michelangelo received yet another commission for the Vatican. This was for the painting of two large frescos in the Cappella Paolina depicting significant events in the lives of the two most important saints of Rome, the Conversion of Saint Paul and the Crucifixion of Saint Peter. Like the Last Judgment, these two works are complex compositions containing a great number of figures. They were completed in 1550. In the same year, Giorgio Vasari published his Vita, including a biography of Michelangelo.In 1546, Michelangelo was appointed architect of St. Peter's Basilica, Rome. The process of replacing the Constantinian basilica of the 4th century had been underway for fifty years and in 1506 foundations had been laid to the plans of Bramante. Successive architects had worked on it, but little progress had been made. Michelangelo was persuaded to take over the project. He returned to the concepts of Bramante, and developed his ideas for a centrally planned church, strengthening the structure both physically and visually. The dome, not completed until after his death, has been called by Banister Fletcher, \"the greatest creation of the Renaissance\".As construction was progressing on St Peter's, there was concern that Michelangelo would pass away before the dome was finished. However, once building commenced on the lower part of the dome, the supporting ring, the completion of the design was inevitable.\n",
      "On 7 December 2007, a red chalk sketch for the dome of St Peter's Basilica, possibly the last made by Michelangelo before his death, was discovered in the Vatican archives. It is extremely rare, since he destroyed his designs later in life. The sketch is a partial plan for one of the radial columns of the cupola drum of St Peter's.\n",
      "\n",
      "Personal life\n",
      "Faith\n",
      "Michelangelo was a devout Catholic whose faith deepened at the end of his life. His poetry includes the following closing lines from what is known as poem 285 (written in 1554): \"Neither painting nor sculpture will be able any longer to calm my soul, now turned toward that divine love that opened his arms on the cross to take us in.\"\n",
      "\n",
      "Personal habits\n",
      "Michelangelo was abstemious in his personal life, and once told his apprentice, Ascanio Condivi: \"However rich I may have been, I have always lived like a poor man.\" Michelangelo's bank accounts and numerous deeds of purchase show that his net worth was about 50,000 gold ducats, more than many princes and dukes of his time. Condivi said he was indifferent to food and drink, eating \"more out of necessity than of pleasure\" and that he \"often slept in his clothes and ... boots.\" His biographer Paolo Giovio says, \"His nature was so rough and uncouth that his domestic habits were incredibly squalid, and deprived posterity of any pupils who might have followed him.\" This, however, may not have affected him, as he was by nature a solitary and melancholy person, bizzarro e fantastico, a man who \"withdrew himself from the company of men.\"\n",
      "\n",
      "Relationships and poetry\n",
      "It is impossible to know whether Michelangelo had any physical relationships (Condivi ascribed to him a \"monk-like chastity\"). Speculation about his sexuality is rooted in his poetry. He wrote more than three hundred sonnets and madrigals. The longest sequence, displaying deep loving feeling, was written to the young Roman patrician Tommaso dei Cavalieri (c. 1509–1587), who was 23 years old when Michelangelo first met him in 1532, at the age of 57. The Florentine Benedetto Varchi fifteen years later described Cavalieri as of \"incomparable beauty\", with \"graceful manners, so excellent an endowment and so charming a demeanour that he indeed deserved, and still deserves, the more to be loved the better he is known\". In his \"Lives of the Artists\", Giorgio Vasari observed: \"But infinitely more than any of the others he loved M. Tommaso de' Cavalieri, a Roman gentleman, for whom, being a young man and much inclined to these arts, [Michelangelo] made, to the end that he might learn to draw, many most superb drawings of divinely beautiful heads, designed in black and red chalk; and then he drew for him a Ganymede rapt to Heaven by Jove's Eagle, a Tityus with the Vulture devouring his heart, the Chariot of the Sun falling with Phaëthon into the Po, and a Bacchanal of children, which are all in themselves most rare things, and drawings the like of which have never been seen.\" Scholars agree that Michelangelo became infatuated with Cavalieri. \n",
      "The poems to Cavalieri make up the first large sequence of poems in any modern tongue addressed by one man to another; they predate by 50 years Shakespeare's sonnets to the fair youth:\n",
      "\n",
      "Cavalieri replied: \"I swear to return your love. Never have I loved a man more than I love you, never have I wished for a friendship more than I wish for yours.\" Cavalieri remained devoted to Michelangelo until his death.In 1542, Michelangelo met Cecchino dei Bracci who died only a year later, inspiring Michelangelo to write 48 funeral epigrams. Some of the objects of Michelangelo's affections, and subjects of his poetry, took advantage of him: the model Febo di Poggio asked for money in response to a love-poem, and a second model, Gherardo Perini, shamelessly stole from him.The homoerotic nature of the poetry has been a source of discomfort to later generations. Michelangelo's grandnephew, Michelangelo Buonarroti the Younger, published the poems in 1623 with the gender of pronouns changed, and it was not until John Addington Symonds translated them into English in 1893 that the original genders were restored. In modern times some scholars insist that, despite the restoration of the pronouns, they represent \"an emotionless and elegant re-imagining of Platonic dialogue, whereby erotic poetry was seen as an expression of refined sensibilities\", but others read his poems at face value, suggesting a preference by him for young men over women.Late in life, Michelangelo nurtured a great platonic love for the poet and noble widow Vittoria Colonna, whom he met in Rome in 1536 or 1538 and who was in her late forties at the time. They wrote sonnets for each other and were in regular contact until she died. These sonnets mostly deal with the spiritual issues that occupied them. Condivi recalls Michelangelo's saying that his sole regret in life was that he did not kiss the widow's face in the same manner that he had her hand.\n",
      "\n",
      "Feuds with other artists\n",
      "In a letter from late 1542, Michelangelo blamed the tensions between Julius II and him on the envy of Bramante and Raphael, saying of the latter, \"all he had in art, he got from me\". According to Gian Paolo Lomazzo, Michelangelo and Raphael met once: the former was alone, while the latter was accompanied by several others. Michelangelo commented that he thought he had encountered the chief of police with such an assemblage, and Raphael replied that he thought he had met an executioner, as they are wont to walk alone.\n",
      "\n",
      "Works\n",
      "Madonna and Child\n",
      "The Madonna of the Stairs is Michelangelo's earliest known work in marble. It is carved in shallow relief, a technique often employed by the master-sculptor of the early 15th century, Donatello, and others such as Desiderio da Settignano. While the Madonna is in profile, the easiest aspect for a shallow relief, the child displays a twisting motion that was to become characteristic of Michelangelo's work. The Taddei Tondo of 1502 shows the Christ Child frightened by a Bullfinch, a symbol of the Crucifixion. The lively form of the child was later adapted by Raphael in the Bridgewater Madonna. The Madonna of Bruges was, at the time of its creation, unlike other such statues depicting the Virgin proudly presenting her son. Here, the Christ Child, restrained by his mother's clasping hand, is about to step off into the world. The Doni Tondo, depicting the Holy Family, has elements of all three previous works: the frieze of figures in the background has the appearance of a low-relief, while the circular shape and dynamic forms echo the Taddeo Tondo. The twisting motion present in the Madonna of Bruges is accentuated in the painting. The painting heralds the forms, movement and colour that Michelangelo was to employ on the ceiling of the Sistine Chapel.\n",
      "\n",
      "Male figure\n",
      "The kneeling Angel is an early work, one of several that Michelangelo created as part of a large decorative scheme for the Arca di San Domenico in the church dedicated to that saint in Bologna. Several other artists had worked on the scheme, beginning with Nicola Pisano in the 13th century. In the late 15th century, the project was managed by Niccolò dell'Arca. An angel holding a candlestick, by Niccolò, was already in place. Although the two angels form a pair, there is a great contrast between the two works, the one depicting a delicate child with flowing hair clothed in Gothic robes with deep folds, and Michelangelo's depicting a robust and muscular youth with eagle's wings, clad in a garment of Classical style. Everything about Michelangelo's Angel is dynamic. Michelangelo's Bacchus was a commission with a specified subject, the youthful God of Wine. The sculpture has all the traditional attributes, a vine wreath, a cup of wine and a fawn, but Michelangelo ingested an air of reality into the subject, depicting him with bleary eyes, a swollen bladder and a stance that suggests he is unsteady on his feet. While the work is plainly inspired by Classical sculpture, it is innovative for its rotating movement and strongly three-dimensional quality, which encourages the viewer to look at it from every angle.In the so-called Dying Slave, Michelangelo again utilised the figure with marked contrapposto to suggest a particular human state, in this case waking from sleep. With the Rebellious Slave, it is one of two such earlier figures for the Tomb of Pope Julius II, now in the Louvre, that the sculptor brought to an almost finished state. These two works were to have a profound influence on later sculpture, through Rodin who studied them at the Louvre.\n",
      "The Atlas Slave is one of the later figures for Pope Julius' tomb. The works, known collectively as The Captives, each show the figure struggling to free itself, as if from the bonds of the rock in which it is lodged. The works give a unique insight into the sculptural methods that Michelangelo employed and his way of revealing what he perceived within the rock.\n",
      "\n",
      "Sistine Chapel ceiling\n",
      "The Sistine Chapel ceiling was painted between 1508 and 1512. The ceiling is a flattened barrel vault supported on twelve triangular pendentives that rise from between the windows of the chapel. The commission, as envisaged by Pope Julius II, was to adorn the pendentives with figures of the twelve apostles. Michelangelo, who was reluctant to take the job, persuaded the Pope to give him a free hand in the composition. The resultant scheme of decoration awed his contemporaries and has inspired other artists ever since. The scheme is of nine panels illustrating episodes from the Book of Genesis, set in an architectonic frame. On the pendentives, Michelangelo replaced the proposed Apostles with Prophets and Sibyls who heralded the coming of the Messiah.\n",
      "\n",
      "Michelangelo began painting with the later episodes in the narrative, the pictures including locational details and groups of figures, the Drunkenness of Noah being the first of this group. In the later compositions, painted after the initial scaffolding had been removed, Michelangelo made the figures larger. One of the central images, The Creation of Adam is one of the best known and most reproduced works in the history of art. The final panel, showing the Separation of Light from Darkness is the broadest in style and was painted in a single day. As the model for the Creator, Michelangelo has depicted himself in the action of painting the ceiling.\n",
      "\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "As supporters to the smaller scenes, Michelangelo painted twenty youths who have variously been interpreted as angels, as muses, or simply as decoration. Michelangelo referred to them as \"ignudi\". The figure reproduced may be seen in context in the above image of the Separation of Light from Darkness.\n",
      "In the process of painting the ceiling, Michelangelo made studies for different figures, of which some, such as that for The Libyan Sibyl have survived, demonstrating the care taken by Michelangelo in details such as the hands and feet. The Prophet Jeremiah, contemplating the downfall of Jerusalem, is a self-portrait.\n",
      "\n",
      "Figure compositions\n",
      "Michelangelo's relief of the Battle of the Centaurs, created while he was still a youth associated with the Medici Academy, is an unusually complex relief in that it shows a great number of figures involved in a vigorous struggle. Such a complex disarray of figures was rare in Florentine art, where it would usually only be found in images showing either the Massacre of the Innocents or the Torments of Hell. The relief treatment, in which some of the figures are boldly projecting, may indicate Michelangelo's familiarity with Roman sarcophagus reliefs from the collection of Lorenzo Medici, and similar marble panels created by Nicola and Giovanni Pisano, and with the figurative compositions on Ghiberti's Baptistry Doors.The composition of the Battle of Cascina is known in its entirety only from copies, as the original cartoon, according to Vasari, was so admired that it deteriorated and was eventually in pieces. It reflects the earlier relief in the energy and diversity of the figures, with many different postures, and many being viewed from the back, as they turn towards the approaching enemy and prepare for battle.In The Last Judgment it is said that Michelangelo drew inspiration from a fresco by Melozzo da Forlì in Rome's Santi Apostoli. Melozzo had depicted figures from different angles, as if they were floating in the Heaven and seen from below. Melozzo's majestic figure of Christ, with windblown cloak, demonstrates a degree of foreshortening of the figure that had also been employed by Andrea Mantegna, but was not usual in the frescos of Florentine painters. In The Last Judgment Michelangelo had the opportunity to depict, on an unprecedented scale, figures in the action of either rising heavenward or falling and being dragged down.In the two frescos of the Pauline Chapel, The Crucifixion of St. Peter and The Conversion of Saul, Michelangelo has used the various groups of figures to convey a complex narrative. In the Crucifixion of Peter soldiers busy themselves about their assigned duty of digging a post hole and raising the cross while various people look on and discuss the events. A group of horrified women cluster in the foreground, while another group of Christians is led by a tall man to witness the events. In the right foreground, Michelangelo walks out of the painting with an expression of disillusionment.\n",
      "\n",
      "Architecture\n",
      "Michelangelo's architectural commissions included a number that were not realised, notably the façade for Brunelleschi's Church of San Lorenzo in Florence, for which Michelangelo had a wooden model constructed, but which remains to this day unfinished rough brick. At the same church, Giulio de' Medici (later Pope Clement VII) commissioned him to design the Medici Chapel and the tombs of Giuliano and Lorenzo Medici. Pope Clement also commissioned the Laurentian Library, for which Michelangelo also designed the extraordinary vestibule with columns recessed into niches, and a staircase that appears to spill out of the library like a flow of lava, according to Nikolaus Pevsner, \"... revealing Mannerism in its most sublime architectural form.\"In 1546 Michelangelo produced the highly complex ovoid design for the pavement of the Campidoglio and began designing an upper storey for the Farnese Palace. In 1547 he took on the job of completing St Peter's Basilica, begun to a design by Bramante, and with several intermediate designs by several architects. Michelangelo returned to Bramante's design, retaining the basic form and concepts by simplifying and strengthening the design to create a more dynamic and unified whole. Although the late 16th-century engraving depicts the dome as having a hemispherical profile, the dome of Michelangelo's model is somewhat ovoid and the final product, as completed by Giacomo della Porta, is more so.\n",
      "\n",
      "Final years\n",
      "In his old age, Michelangelo created a number of Pietàs in which he apparently reflects upon mortality. They are heralded by the Victory, perhaps created for the tomb of Pope Julius II but left unfinished. In this group, the youthful victor overcomes an older hooded figure, with the features of Michelangelo.\n",
      "The Pietà of Vittoria Colonna is a chalk drawing of a type described as \"presentation drawings\", as they might be given as a gift by an artist, and were not necessarily studies towards a painted work. In this image, Mary's upraised arms and hands are indicative of her prophetic role. The frontal aspect is reminiscent of Masaccio's fresco of the Holy Trinity in the Basilica of Santa Maria Novella, Florence.\n",
      "In the Florentine Pietà, Michelangelo again depicts himself, this time as the aged Nicodemus lowering the body of Jesus from the cross into the arms of Mary his mother and Mary Magdalene. Michelangelo smashed the left arm and leg of the figure of Jesus. His pupil Tiberio Calcagni repaired the arm and drilled a hole in which to fix a replacement leg which was not subsequently attached. He also worked on the figure of Mary Magdalene.The last sculpture that Michelangelo worked on (six days before his death), the Rondanini Pietà, could never be completed because Michelangelo carved it away until there was insufficient stone. The legs and a detached arm remain from a previous stage of the work. As it remains, the sculpture has an abstract quality, in keeping with 20th-century concepts of sculpture.Michelangelo died in Rome on 18 February 1564, at the age of 88 (three weeks before his 89th birthday). His body was taken from Rome for interment at the Basilica of Santa Croce, fulfilling the maestro's last request to be buried in his beloved Florence.Michelangelo's heir Lionardo Buonarroti commissioned Giorgio Vasari to design and build the Tomb of Michelangelo, a monumental project that cost 770 scudi, and took over 14 years to complete. Marble for the tomb was supplied by Cosimo I de' Medici, Duke of Tuscany, who had also organized a state funeral to honour Michelangelo in Florence.\n",
      "\n",
      "Legacy\n",
      "Michelangelo, with Leonardo da Vinci and Raphael, is one of the three giants of the Florentine High Renaissance. Although their names are often cited together, Michelangelo was younger than Leonardo by 23 years, and older than Raphael by eight. Because of his reclusive nature, he had little to do with either artist and outlived both of them by more than forty years. Michelangelo took few sculpture students. He employed Francesco Granacci, who was his fellow pupil at the Medici Academy, and became one of several assistants on the Sistine Chapel ceiling. Michelangelo appears to have used assistants mainly for the more manual tasks of preparing surfaces and grinding colours. Despite this, his works were to have a great influence on painters, sculptors and architects for many generations to come.\n",
      "While Michelangelo's David is the most famous male nude of all time and now graces cities around the world, some of his other works have had perhaps even greater impact on the course of art. The twisting forms and tensions of the Victory, the Bruges Madonna and the Medici Madonna make them the heralds of the Mannerist art. The unfinished giants for the tomb of Pope Julius II had profound effect on late-19th- and 20th-century sculptors such as Rodin and Henry Moore.\n",
      "Michelangelo's foyer of the Laurentian Library was one of the earliest buildings to utilise Classical forms in a plastic and expressive manner. This dynamic quality was later to find its major expression in his centrally planned St Peter's, with its giant order, its rippling cornice and its upward-launching pointed dome. The dome of St Peter's was to influence the building of churches for many centuries, including Sant'Andrea della Valle in Rome and St Paul's Cathedral, London, as well as the civic domes of many public buildings and the state capitals across America.\n",
      "Artists who were directly influenced by Michelangelo include Raphael, whose monumental treatment of the figure in the School of Athens and The Expulsion of Heliodorus from the Temple owes much to Michelangelo, and whose fresco of Isaiah in Sant'Agostino closely imitates the older master's prophets. Other artists, such as Pontormo, drew on the writhing forms of the Last Judgment and the frescoes of the Capella Paolina.The Sistine Chapel ceiling was a work of unprecedented grandeur, both for its architectonic forms, to be imitated by many Baroque ceiling painters, and also for the wealth of its inventiveness in the study of figures. Vasari wrote:\n",
      "\n",
      "The work has proved a veritable beacon to our art, of inestimable benefit to all painters, restoring light to a world that for centuries had been plunged into darkness. Indeed, painters no longer need to seek for new inventions, novel attitudes, clothed figures, fresh ways of expression, different arrangements, or sublime subjects, for this work contains every perfection possible under those headings.\n",
      "\n",
      "In popular culture\n",
      "MoviesVita di Michelangelo (1964)\n",
      "The Agony and the Ecstasy (1965), directed by Carol Reed and starring Charlton Heston as Michelangelo\n",
      "A Season of Giants (1990)\n",
      "Michelangelo - Endless (2018), starring Enrico Lo Verso as Michelangelo\n",
      "Sin  (2019), directed by Andrei Konchalovsky\n",
      "\n",
      "See also\n",
      "Michelangelo and the Medici\n",
      "Italian Renaissance sculpture\n",
      "Italian Renaissance painting\n",
      "Michelangelo phenomenon\n",
      "Nicodemite\n",
      "Restoration of the Sistine Chapel frescoes\n",
      "\n",
      "Footnotes\n",
      "References\n",
      "Sources\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "The Digital Michelangelo Project\n",
      "Works by Michelangelo at Project Gutenberg\n",
      "Works by or about Michelangelo at Internet Archive\n",
      "Works by Michelangelo at LibriVox (public domain audiobooks) \n",
      "The BP Special Exhibition Michelangelo Drawings – closer to the master\n",
      "Michelangelo's Drawings: Real or Fake? How to decide if a drawing is by Michelangelo.\n",
      "\"Michelangelo: The Man and the Myth\"In astronomy, dark matter is a hypothetical form of matter that appears not to interact with light or the electromagnetic field. Dark matter is implied by gravitational effects which cannot be explained by general relativity unless more matter is present than can be seen. Such effects occur in the context of formation and evolution of galaxies, gravitational lensing, the observable universe's current structure, mass position in galactic collisions, the motion of galaxies within galaxy clusters, and cosmic microwave background anisotropies.\n",
      "In the standard lambda-CDM model of cosmology, the mass–energy content of the universe is 5% ordinary matter, 26.8% dark matter, and 68.2% a form of energy known as dark energy. Thus, dark matter constitutes 85% of the total mass, while dark energy and dark matter constitute 95% of the total mass–energy content.Dark matter is not known to interact with ordinary baryonic matter and radiation except through gravity, making it difficult to detect in the laboratory. The most prevalent explanation is that dark matter is some as-yet-undiscovered subatomic particle, such as weakly interacting massive particles (WIMPs) or axions. The other main possibility is that dark matter is composed of primordial black holes.Dark matter is classified as \"cold\", \"warm\", or \"hot\" according to its velocity (more precisely, its free streaming length). Recent models have favored a cold dark matter scenario, in which structures emerge by the gradual accumulation of particles, but after a half century of fruitless dark matter particle searches, more recent gravitational wave and James Webb Space Telescope observations have considerably strengthened the case for primordial and direct collapse black holes.Although the astrophysics community generally accepts dark matter's existence, a minority of astrophysicists, intrigued by specific observations that are not well-explained by ordinary dark matter, argue for various modifications of the standard laws of general relativity. These include modified Newtonian dynamics, tensor–vector–scalar gravity, or entropic gravity. So far none of the proposed modified gravity theories can successfully describe every piece of observational evidence at the same time, suggesting that even if gravity has to be modified, some form of dark matter will still be required.\n",
      "\n",
      "History\n",
      "Early history\n",
      "The hypothesis of dark matter has an elaborate history. In the appendices of the book Baltimore lectures on molecular dynamics and the wave theory of light where the main text was based on a series of lectures given in 1884, Lord Kelvin discussed the potential number of stars around the Sun from the observed velocity dispersion of the stars near the Sun, assuming that the Sun was 20 to 100 million years old. He posed what would happen if there were a thousand million stars within 1 kilo-parsec of the Sun (at which distance their parallax would be 1 milli-arcsec). Lord Kelvin concluded \"Many of our supposed thousand million stars, perhaps a great majority of them, may be dark bodies\". In 1906, Henri Poincaré in \"The Milky Way and Theory of Gases\" used the French term matière obscure (\"dark matter\") in discussing Kelvin's work. He found that the amount of dark matter would need to be less than that of visible matter.The second to suggest the existence of dark matter using stellar velocities was Dutch astronomer Jacobus Kapteyn in 1922. A publication from 1930 points to Swedish Knut Lundmark being the first to realise that the universe must contain much more mass than can be observed. Dutchman and radio astronomy pioneer Jan Oort also hypothesized the existence of dark matter in 1932. Oort was studying stellar motions in the local galactic neighborhood and found the mass in the galactic plane must be greater than what was observed, but this measurement was later determined to be erroneous.In 1933, Swiss astrophysicist Fritz Zwicky, who studied galaxy clusters while working at the California Institute of Technology, made a similar inference. Zwicky applied the virial theorem to the Coma Cluster and obtained evidence of unseen mass he called dunkle Materie ('dark matter'). Zwicky estimated its mass based on the motions of galaxies near its edge and compared that to an estimate based on its brightness and number of galaxies. He estimated the cluster had about 400 times more mass than was visually observable. The gravity effect of the visible galaxies was far too small for such fast orbits, thus mass must be hidden from view. Based on these conclusions, Zwicky inferred some unseen matter provided the mass and associated gravitation attraction to hold the cluster together. Zwicky's estimates were off by more than an order of magnitude, mainly due to an obsolete value of the Hubble constant; the same calculation today shows a smaller fraction, using greater values for luminous mass. Nonetheless, Zwicky did correctly conclude from his calculation that the bulk of the matter was dark.Further indications of mass-to-light ratio anomalies came from measurements of galaxy rotation curves. In 1939, Horace W. Babcock reported the rotation curve for the Andromeda nebula (known now as the Andromeda Galaxy), which suggested the mass-to-luminosity ratio increases radially. He attributed it to either light absorption within the galaxy or modified dynamics in the outer portions of the spiral and not to the missing matter he had uncovered. Following Babcock's 1939 report of unexpectedly rapid rotation in the outskirts of the Andromeda galaxy and a mass-to-light ratio of 50; in 1940 Jan Oort discovered and wrote about the large non-visible halo of NGC 3115.\n",
      "\n",
      "1960s\n",
      "Early radio astronomy observations, performed by Seth Shostak, later SETI Institute Senior Astronomer, showed a half-dozen galaxies spun too fast in their outer regions, pointing to the existence of dark matter as a means of creating the gravitational pull needed to keep the stars in their orbits.\n",
      "\n",
      "1970s\n",
      "Vera Rubin, Kent Ford, and Ken Freeman's work in the 1960s and 1970s provided further strong evidence, also using galaxy rotation curves. Rubin and Ford worked with a new spectrograph to measure the velocity curve of edge-on spiral galaxies with greater accuracy. This result was confirmed in 1978. An influential paper presented Rubin and Ford's results in 1980. They showed most galaxies must contain about six times as much dark as visible mass; thus, by around 1980 the apparent need for dark matter was widely recognized as a major unsolved problem in astronomy.At the same time Rubin and Ford were exploring optical rotation curves, radio astronomers were making use of new radio telescopes to map the 21 cm line of atomic hydrogen in nearby galaxies. The radial distribution of interstellar atomic hydrogen (HⅠ) often extends to much greater galactic distances than can be observed as collective starlight, expanding the sampled distances for rotation curves – and thus of the total mass distribution – to a new dynamical regime. Early mapping of Andromeda with the 300 foot telescope at Green Bank and the 250 foot dish at Jodrell Bank already showed the HⅠ rotation curve did not trace the expected Keplerian decline. As more sensitive receivers became available, Roberts & Whitehurst (1975) were able to trace the rotational velocity of Andromeda to 30 kpc, much beyond the optical measurements. Illustrating the advantage of tracing the gas disk at large radii; that paper's Figure 16 combines the optical data (the cluster of points at radii of less than 15 kpc with a single point further out) with the HⅠ data between 20 and 30 kpc, exhibiting the flatness of the outer galaxy rotation curve; the solid curve peaking at the center is the optical surface density, while the other curve shows the cumulative mass, still rising linearly at the outermost measurement. In parallel, the use of interferometric arrays for extragalactic HⅠ spectroscopy was being developed. Rogstad & Shostak (1972) published HⅠ rotation curves of five spirals mapped with the Owens Valley interferometer; the rotation curves of all five were very flat, suggesting very large values of mass-to-light ratio in the outer parts of their extended HⅠ disks.\n",
      "\n",
      "1980s\n",
      "A stream of observations in the 1980s supported the presence of dark matter, including gravitational lensing of background objects by galaxy clusters, the temperature distribution of hot gas in galaxies and clusters, and the pattern of anisotropies in the cosmic microwave background. According to consensus among cosmologists, dark matter is composed primarily of a not-yet-characterized type of subatomic particle. The search for this particle, by a variety of means, is one of the major efforts in particle physics.\n",
      "\n",
      "Twenty-first century\n",
      "While primordial black holes were long considered possibly important if not nearly exclusive components of dark matter, the latter perspective was strengthened by both LIGO/Virgo interferometer gravitational wave and James Webb Space Telescope (JWST) observations. Early constraints on PBHs as dark matter usually assumed most black holes would have similar or identical (\"monochromatic\") mass, which was disproven by LIGO/Virgo results, and further suggestions that the actual black hole mass distribution is broadly platykurtic were evident from JWST observations of early large galaxies.\n",
      "\n",
      "Technical definition\n",
      "In standard cosmologic calculations, \"matter\" means any constituent of the universe whose energy density scales with the inverse cube of the scale factor, i.e., ρ ∝ a−3 . This is in contrast to \"radiation\", which scales as the inverse fourth power of the scale factor ρ ∝ a−4 , and a cosmological constant, which does not change with respect to a  (ρ ∝ a0). The different scaling factors for matter and radiation are a consequence of radiation redshift: For example, after gradually doubling the diameter of the observable Universe via cosmic expansion of General Relativity, the scale, a, has doubled. The energy of the cosmic background radiation has been halved (because the wavelength of each photon has doubled); the energy of ultra-relativistic particles, such as early-era standard-model neutrinos, is similarly halved.\n",
      "The cosmological constant, as an intrinsic property of space, has a constant energy density regardless of the volume under consideration.In principle, \"dark matter\" means all components of the universe which are not visible but still obey ρ ∝ a−3 . In practice, the term \"dark matter\" is often used to mean only the non-baryonic component of dark matter, i.e., excluding \"missing baryons\". Context will usually indicate which meaning is intended.\n",
      "\n",
      "Observational evidence\n",
      "Galaxy rotation curves\n",
      "The arms of spiral galaxies rotate around the galactic center. The luminous mass density of a spiral galaxy decreases as one goes from the center to the outskirts. If luminous mass were all the matter, then we can model the galaxy as a point mass in the centre and test masses orbiting around it, similar to the Solar System. From Kepler's Third Law, it is expected that the rotation velocities will decrease with distance from the center, similar to the Solar System. This is not observed. Instead, the galaxy rotation curve remains flat as distance from the center increases.\n",
      "If Kepler's laws are correct, then the obvious way to resolve this discrepancy is to conclude the mass distribution in spiral galaxies is not similar to that of the Solar System. In particular, there is a lot of non-luminous matter (dark matter) in the outskirts of the galaxy.\n",
      "\n",
      "Velocity dispersions\n",
      "Stars in bound systems must obey the virial theorem. The theorem, together with the measured velocity distribution, can be used to measure the mass distribution in a bound system, such as elliptical galaxies or globular clusters. With some exceptions, velocity dispersion estimates of elliptical galaxies do not match the predicted velocity dispersion from the observed mass distribution, even assuming complicated distributions of stellar orbits.As with galaxy rotation curves, the obvious way to resolve the discrepancy is to postulate the existence of non-luminous matter.\n",
      "\n",
      "Galaxy clusters\n",
      "Galaxy clusters are particularly important for dark matter studies since their masses can be estimated in three independent ways:\n",
      "\n",
      "From the scatter in radial velocities of the galaxies within clusters\n",
      "From X-rays emitted by hot gas in the clusters. From the X-ray energy spectrum and flux, the gas temperature and density can be estimated, hence giving the pressure; assuming pressure and gravity balance determines the cluster's mass profile.\n",
      "Gravitational lensing (usually of more distant galaxies) can measure cluster masses without relying on observations of dynamics (e.g., velocity).Generally, these three methods are in reasonable agreement that dark matter outweighs visible matter by approximately 5 to 1.\n",
      "\n",
      "Gravitational lensing\n",
      "One of the consequences of general relativity is massive objects (such as a cluster of galaxies) lying between a more distant source (such as a quasar) and an observer should act as a lens to bend light from this source. The more massive an object, the more lensing is observed.\n",
      "Strong lensing is the observed distortion of background galaxies into arcs when their light passes through such a gravitational lens. It has been observed around many distant clusters including Abell 1689. By measuring the distortion geometry, the mass of the intervening cluster can be obtained. In the dozens of cases where this has been done, the mass-to-light ratios obtained correspond to the dynamical dark matter measurements of clusters. Lensing can lead to multiple copies of an image. By analyzing the distribution of multiple image copies, scientists have been able to deduce and map the distribution of dark matter around the MACS J0416.1-2403 galaxy cluster.Weak gravitational lensing investigates minute distortions of galaxies, using statistical analyses from vast galaxy surveys. By examining the apparent shear deformation of the adjacent background galaxies, the mean distribution of dark matter can be characterized. The mass-to-light ratios correspond to dark matter densities predicted by other large-scale structure measurements. Dark matter does not bend light itself; mass (in this case the mass of the dark matter) bends spacetime. Light follows the curvature of spacetime, resulting in the lensing effect.In May 2021, a new detailed dark matter map was revealed by the Dark Energy Survey Collaboration. In addition, the map revealed previously undiscovered filamentary structures connecting galaxies, by using a machine learning method.An April 2023 study in Nature Astronomy examined the inferred distribution of the dark matter responsible for the lensing of the elliptical galaxy HS 0810+2554, and found tentative evidence of interference patterns within the dark matter. The observation of interference patterns is incompatible with WIMPs, but would be compatible with simulations involving 10−22 eV axions. While acknowledging the need to corroborate the findings by examining other astrophysical lenses, the authors argued that \"The ability of (axion-based dark matter) to resolve lensing anomalies even in demanding cases such as HS 0810+2554, together with its success in reproducing other astrophysical observations, tilt the balance toward new physics invoking axions.\"\n",
      "\n",
      "Cosmic microwave background\n",
      "Although both dark matter and ordinary matter are matter, they do not behave in the same way. In particular, in the early universe, ordinary matter was ionized and interacted strongly with radiation via Thomson scattering. Dark matter does not interact directly with radiation, but it does affect the cosmic microwave background (CMB) by its gravitational potential (mainly on large scales) and by its effects on the density and velocity of ordinary matter. Ordinary and dark matter perturbations, therefore, evolve differently with time and leave different imprints on the CMB.\n",
      "The cosmic microwave background is very close to a perfect blackbody but contains very small temperature anisotropies of a few parts in 100,000. A sky map of anisotropies can be decomposed into an angular power spectrum, which is observed to contain a series of acoustic peaks at near-equal spacing but different heights.\n",
      "The series of peaks can be predicted for any assumed set of cosmological parameters by modern computer codes such as CMBFAST and CAMB, and matching theory to data, therefore, constrains cosmological parameters. The first peak mostly shows the density of baryonic matter, while the third peak relates mostly to the density of dark matter, measuring the density of matter and the density of atoms.The CMB anisotropy was first discovered by COBE in 1992, though this had too coarse resolution to detect the acoustic peaks.\n",
      "After the discovery of the first acoustic peak by the balloon-borne BOOMERanG experiment in 2000, the power spectrum was precisely observed by WMAP in 2003–2012, and even more precisely by the Planck spacecraft in 2013–2015. The results support the Lambda-CDM model.The observed CMB angular power spectrum provides powerful evidence in support of dark matter, as its precise structure is well fitted by the lambda-CDM model, but difficult to reproduce with any competing model such as modified Newtonian dynamics (MOND).\n",
      "\n",
      "Structure formation\n",
      "Structure formation refers to the period after the Big Bang when density perturbations collapsed to form stars, galaxies, and clusters. Prior to structure formation, the Friedmann solutions to general relativity describe a homogeneous universe. Later, small anisotropies gradually grew and condensed the homogeneous universe into stars, galaxies and larger structures. Ordinary matter is affected by radiation, which is the dominant element of the universe at very early times. As a result, its density perturbations are washed out and unable to condense into structure. If there were only ordinary matter in the universe, there would not have been enough time for density perturbations to grow into the galaxies and clusters currently seen.\n",
      "Dark matter provides a solution to this problem because it is unaffected by radiation. Therefore, its density perturbations can grow first. The resulting gravitational potential acts as an attractive potential well for ordinary matter collapsing later, speeding up the structure formation process.\n",
      "\n",
      "Bullet Cluster\n",
      "If dark matter does not exist, then the next most likely explanation must be that general relativity – the prevailing theory of gravity – is incorrect and should be modified. The Bullet Cluster, the result of a recent collision of two galaxy clusters, provides a challenge for modified gravity theories because its apparent center of mass is far displaced from the baryonic center of mass. Standard dark matter models can easily explain this observation, but modified gravity has a much harder time, especially since the observational evidence is model-independent.\n",
      "\n",
      "Type Ia supernova distance measurements\n",
      "Type Ia supernovae can be used as standard candles to measure extragalactic distances, which can in turn be used to measure how fast the universe has expanded in the past. Data indicates the universe is expanding at an accelerating rate, the cause of which is usually ascribed to dark energy. Since observations indicate the universe is almost flat, it is expected the total energy density of everything in the universe should sum to 1 (Ωtot ≈ 1). The measured dark energy density is ΩΛ ≈ 0.690; the observed ordinary (baryonic) matter energy density is Ωb ≈ 0.0482 and the energy density of radiation is negligible. This leaves a missing Ωdm ≈ 0.258 which nonetheless behaves like matter (see technical definition section above) – dark matter.\n",
      "\n",
      "Sky surveys and baryon acoustic oscillations\n",
      "Baryon acoustic oscillations (BAO) are fluctuations in the density of the visible baryonic matter (normal matter) of the universe on large scales. These are predicted to arise in the Lambda-CDM model due to acoustic oscillations in the photon–baryon fluid of the early universe, and can be observed in the cosmic microwave background angular power spectrum. BAOs set up a preferred length scale for baryons. As the dark matter and baryons clumped together after recombination, the effect is much weaker in the galaxy distribution in the nearby universe, but is detectable as a subtle (≈1 percent) preference for pairs of galaxies to be separated by 147 Mpc, compared to those separated by 130–160 Mpc. This feature was predicted theoretically in the 1990s and then discovered in 2005, in two large galaxy redshift surveys, the Sloan Digital Sky Survey and the 2dF Galaxy Redshift Survey. Combining the CMB observations with BAO measurements from galaxy redshift surveys provides a precise estimate of the Hubble constant and the average matter density in the Universe. The results support the Lambda-CDM model.\n",
      "\n",
      "Redshift-space distortions\n",
      "Large galaxy redshift surveys may be used to make a three-dimensional map of the galaxy distribution. These maps are slightly distorted because distances are estimated from observed redshifts; the redshift contains a contribution from the galaxy's so-called peculiar velocity in addition to the dominant Hubble expansion term. On average, superclusters are expanding more slowly than the cosmic mean due to their gravity, while voids are expanding faster than average. In a redshift map, galaxies in front of a supercluster have excess radial velocities towards it and have redshifts slightly higher than their distance would imply, while galaxies behind the supercluster have redshifts slightly low for their distance. This effect causes superclusters to appear squashed in the radial direction, and likewise voids are stretched. Their angular positions are unaffected. This effect is not detectable for any one structure since the true shape is not known, but can be measured by averaging over many structures. It was predicted quantitatively by Nick Kaiser in 1987, and first decisively measured in 2001 by the 2dF Galaxy Redshift Survey. Results are in agreement with the lambda-CDM model.\n",
      "\n",
      "Lyman-alpha forest\n",
      "In astronomical spectroscopy, the Lyman-alpha forest is the sum of the absorption lines arising from the Lyman-alpha transition of neutral hydrogen in the spectra of distant galaxies and quasars. Lyman-alpha forest observations can also constrain cosmological models. These constraints agree with those obtained from WMAP data.\n",
      "\n",
      "Theoretical classifications\n",
      "Composition\n",
      "The exact identity of dark matter is unknown, but there are many hypotheses about what dark matter could consist of, as set out in the table below.\n",
      "\n",
      "Baryonic matter\n",
      "Dark matter can refer to any substance which interacts predominantly via gravity with visible matter (e.g., stars and planets). Hence in principle it need not be composed of a new type of fundamental particle but could, at least in part, be made up of standard baryonic matter, such as protons or neutrons. Most of the ordinary matter familiar to astronomers, including planets, brown dwarfs, red dwarfs, visible stars, white dwarfs, neutron stars, and black holes, fall into this category. Solitary black holes, neutron stars, burnt-out dwarfs, and other massive objects that that are hard to detect are collectively known as MACHOs; some scientists initially hoped that baryonic MACHOs could account for and explain all the dark matter.However, multiple lines of evidence suggest the majority of dark matter is not baryonic:\n",
      "\n",
      "Sufficient diffuse, baryonic gas or dust would be visible when backlit by stars.\n",
      "The theory of Big Bang nucleosynthesis predicts the observed abundance of the chemical elements. If there are more baryons, then there should also be more helium, lithium and heavier elements synthesized during the Big Bang. Agreement with observed abundances requires that baryonic matter makes up between 4–5% of the universe's critical density. In contrast, large-scale structure and other observations indicate that the total matter density is about 30% of the critical density.\n",
      "Astronomical searches for gravitational microlensing in the Milky Way found at most only a small fraction of the dark matter may be in dark, compact, conventional objects (MACHOs, etc.); the excluded range of object masses is from half the Earth's mass up to 30 solar masses, which covers nearly all the plausible candidates.\n",
      "Detailed analysis of the small irregularities (anisotropies) in the cosmic microwave background. Observations by WMAP and Planck indicate that around five-sixths of the total matter is in a form that interacts significantly with ordinary matter or photons only through gravitational effects.\n",
      "\n",
      "Non-baryonic matter\n",
      "There are two main candidates for non-baryonic dark matter: hypothetical particles such as axions, sterile neutrinos, weakly interacting massive particle (WIMPs), supersymmetric particles, atomic dark matter, or geons; and primordial black holes. Once a black hole ingests either kind of matter, baryonic or not, the distinction is lost.Unlike baryonic matter, nonbaryonic particles do not contribute to the formation of the elements in the early universe (Big Bang nucleosynthesis) and so its presence is revealed only via its gravitational effects, or weak lensing. In addition, if the particles of which it is composed are supersymmetric, they can undergo annihilation interactions with themselves, possibly resulting in observable by-products such as gamma rays and neutrinos (indirect detection).In 2015, the idea that dense dark matter was composed of primordial black holes made a comeback\n",
      "following results of gravitational wave measurements which detected the merger of intermediate-mass black holes. Black holes with about 30 solar masses are not predicted to form by either stellar collapse (typically less than 15 solar masses) or by the merger of black holes in galactic centers (millions or billions of solar masses). It was proposed that the intermediate-mass black holes causing the detected merger formed in the hot dense early phase of the universe due to denser regions collapsing. A later survey of about a thousand supernovae detected no gravitational lensing events, when about eight would be expected if intermediate-mass primordial black holes above a certain mass range accounted for over 60% of dark matter.\n",
      "However, that study assumed a monochromatic distribution to represent the LIGO/Virgo mass range, which is inapplicable to the broadly platykurtic mass distribution suggested by subsequent James Webb Space Telescope observations.The possibility that atom-sized primordial black holes account for a significant fraction of dark matter was ruled out by measurements of positron and electron fluxes outside the Sun's heliosphere by the Voyager 1 spacecraft. Tiny black holes are theorized to emit Hawking radiation. However the detected fluxes were too low and did not have the expected energy spectrum, suggesting that tiny primordial black holes are not widespread enough to account for dark matter. Nonetheless, research and theories proposing dense dark matter accounts for dark matter continue as of 2018, including approaches to dark matter cooling,\n",
      "and the question remains unsettled. In 2019, the lack of microlensing effects in the observation of Andromeda suggests that tiny black holes do not exist.However, there still exists a largely unconstrained mass range smaller than that which can be limited by optical microlensing observations, where primordial black holes may account for all dark matter.\n",
      "\n",
      "Free streaming length\n",
      "Dark matter can be divided into cold, warm, and hot categories. These categories refer to velocity rather than an actual temperature, indicating how far corresponding objects moved due to random motions in the early universe, before they slowed due to cosmic expansion – this is an important distance called the free streaming length (FSL). Primordial density fluctuations smaller than this length get washed out as particles spread from overdense to underdense regions, while larger fluctuations are unaffected; therefore this length sets a minimum scale for later structure formation.\n",
      "The categories are set with respect to the size of a protogalaxy (an object that later evolves into a dwarf galaxy): Dark matter particles are classified as cold, warm, or hot according to their FSL; much smaller (cold), similar to (warm), or much larger (hot) than a protogalaxy. Mixtures of the above are also possible: a theory of mixed dark matter was popular in the mid-1990s, but was rejected following the discovery of dark energy.Cold dark matter leads to a bottom-up formation of structure with galaxies forming first and galaxy clusters at a latter stage, while hot dark matter would result in a top-down formation scenario with large matter aggregations forming early, later fragmenting into separate galaxies; the latter is excluded by high-redshift galaxy observations.\n",
      "\n",
      "Fluctuation spectrum effects\n",
      "These categories also correspond to fluctuation spectrum effects and the interval following the Big Bang at which each type became non-relativistic. Davis et al. wrote in 1985:\n",
      "\n",
      "Candidate particles can be grouped into three categories on the basis of their effect on the fluctuation spectrum (Bond et al. 1983). If the dark matter is composed of abundant light particles which remain relativistic until shortly before recombination, then it may be termed \"hot\". The best candidate for hot dark matter is a neutrino ... A second possibility is for the dark matter particles to interact more weakly than neutrinos, to be less abundant, and to have a mass of order 1 keV. Such particles are termed \"warm dark matter\", because they have lower thermal velocities than massive neutrinos ... there are at present few candidate particles which fit this description. Gravitinos and photinos have been suggested (Pagels and Primack 1982; Bond, Szalay and Turner 1982) ... Any particles which became nonrelativistic very early, and so were able to diffuse a negligible distance, are termed \"cold\" dark matter (CDM). There are many candidates for CDM including supersymmetric particles.\n",
      "\n",
      "Alternative definitions\n",
      "Another approximate dividing line is warm dark matter became non-relativistic when the universe was approximately 1 year old and 1 millionth of its present size and in the radiation-dominated era (photons and neutrinos), with a photon temperature 2.7 million Kelvins. Standard physical cosmology gives the particle horizon size as 2 c t (speed of light multiplied by time) in the radiation-dominated era, thus 2 light-years. A region of this size would expand to 2 million light-years today (absent structure formation). The actual FSL is approximately 5 times the above length, since it continues to grow slowly as particle velocities decrease inversely with the scale factor after they become non-relativistic. In this example the FSL would correspond to 10 million light-years, or 3 megaparsecs, today, around the size containing an average large galaxy.\n",
      "The 2.7 million K photon temperature gives a typical photon energy of 250 electronvolts, thereby setting a typical mass scale for warm dark matter: particles much more massive than this, such as GeV–TeV mass WIMPs, would become non-relativistic much earlier than one year after the Big Bang and thus have FSLs much smaller than a protogalaxy, making them cold. Conversely, much lighter particles, such as neutrinos with masses of only a few eV, have FSLs much larger than a protogalaxy, thus qualifying them as hot.\n",
      "\n",
      "Cold dark matter\n",
      "Cold dark matter offers the simplest explanation for most cosmological observations. It is dark matter composed of constituents with an FSL much smaller than a protogalaxy. This is the focus for dark matter research, as hot dark matter does not seem capable of supporting galaxy or galaxy cluster formation, and most particle candidates slowed early.\n",
      "The constituents of cold dark matter are unknown. Possibilities range from large objects like MACHOs (such as black holes and Preon stars) or RAMBOs (such as clusters of brown dwarfs), to new particles such as WIMPs and axions.\n",
      "The 1997 DAMA/NaI experiment and its successor DAMA/LIBRA in 2013, claimed to directly detect dark matter particles passing through the Earth, but many researchers remain skeptical, as negative results from similar experiments seem incompatible with the DAMA results.\n",
      "Many supersymmetric models offer dark matter candidates in the form of the WIMPy Lightest Supersymmetric Particle (LSP). Separately, heavy sterile neutrinos exist in non-supersymmetric extensions to the standard model which explain the small neutrino mass through the seesaw mechanism.\n",
      "\n",
      "Warm dark matter\n",
      "Warm dark matter comprises particles with an FSL comparable to the size of a protogalaxy. Predictions based on warm dark matter are similar to those for cold dark matter on large scales, but with less small-scale density perturbations. This reduces the predicted abundance of dwarf galaxies and may lead to lower density of dark matter in the central parts of large galaxies. Some researchers consider this a better fit to observations. A challenge for this model is the lack of particle candidates with the required mass ≈ 300 eV to 3000 eV.No known particles can be categorized as warm dark matter. A postulated candidate is the sterile neutrino: A heavier, slower form of neutrino that does not interact through the weak force, unlike other neutrinos. Some modified gravity theories, such as scalar–tensor–vector gravity, require \"warm\" dark matter to make their equations work.\n",
      "\n",
      "Hot dark matter\n",
      "Hot dark matter consists of particles whose FSL is much larger than the size of a protogalaxy. The neutrino qualifies as such a particle. They were discovered independently, long before the hunt for dark matter: they were postulated in 1930, and detected in 1956. Neutrinos' mass is less than 10−6 that of an electron. Neutrinos interact with normal matter only via gravity and the weak force, making them difficult to detect (the weak force only works over a small distance, thus a neutrino triggers a weak force event only if it hits a nucleus head-on). This makes them \"weakly interacting slender particles\" (WISPs), as opposed to WIMPs.\n",
      "The three known flavours of neutrinos are the electron, muon, and tau. Their masses are slightly different. Neutrinos oscillate among the flavours as they move. It is hard to determine an exact upper bound on the collective average mass of the three neutrinos (or for any of the three individually). For example, if the average neutrino mass were over 50 eV/c2 (less than 10−5 of the mass of an electron), the universe would collapse. CMB data and other methods indicate that their average mass probably does not exceed 0.3 eV/c2. Thus, observed neutrinos cannot explain dark matter.Because galaxy-size density fluctuations get washed out by free-streaming, hot dark matter implies the first objects that can form are huge supercluster-size pancakes, which then fragment into galaxies. Deep-field observations show instead that galaxies formed first, followed by clusters and superclusters as galaxies clump together.\n",
      "\n",
      "Dark matter aggregation and dense dark matter objects\n",
      "If dark matter is composed of weakly-interacting particles, then an obvious question is whether it can form objects equivalent to planets, stars, or black holes. Historically, the answer has been it cannot,\n",
      "because of two factors:\n",
      "\n",
      "It lacks an efficient means to lose energy\n",
      "Ordinary matter forms dense objects because it has numerous ways to lose energy. Losing energy would be essential for object formation, because a particle that gains energy during compaction or falling \"inward\" under gravity, and cannot lose it any other way, will heat up and increase velocity and momentum. Dark matter appears to lack a means to lose energy, simply because it is not capable of interacting strongly in other ways except through gravity. The virial theorem suggests that such a particle would not stay bound to the gradually forming object – as the object began to form and compact, the dark matter particles within it would speed up and tend to escape.\n",
      "It lacks a diversity of interactions needed to form structures\n",
      "Ordinary matter interacts in many different ways, which allows the matter to form more complex structures. For example, stars form through gravity, but the particles within them interact and can emit energy in the form of neutrinos and electromagnetic radiation through fusion when they become energetic enough. Protons and neutrons can bind via the strong interaction and then form atoms with electrons largely through electromagnetic interaction. There is no evidence that dark matter is capable of such a wide variety of interactions, since it seems to only interact through gravity (and possibly through some means no stronger than the weak interaction, although until dark matter is better understood, this is only speculation).However, there are theories of atomic dark matter similar to normal matter that overcome these problems.\n",
      "\n",
      "Detection of dark matter particles\n",
      "If dark matter is made up of subatomic particles, then millions, possibly billions, of such particles must pass through every square centimeter of the Earth each second. Many experiments aim to test this hypothesis. Although WIMPs have been the main search candidates, axions have drawn renewed attention, with the Axion Dark Matter Experiment (ADMX) searches for axions and many more planned in the future. Another candidate is heavy hidden sector particles which only interact with ordinary matter via gravity.\n",
      "These experiments can be divided into two classes: direct detection experiments, which search for the scattering of dark matter particles off atomic nuclei within a detector; and indirect detection, which look for the products of dark matter particle annihilations or decays.\n",
      "\n",
      "Direct detection\n",
      "Direct detection experiments aim to observe low-energy recoils (typically a few keVs) of nuclei induced by interactions with particles of dark matter, which (in theory) are passing through the Earth. After such a recoil the nucleus will emit energy in the form of scintillation light or phonons, as they pass through sensitive detection apparatus. To do so effectively, it is crucial to maintain an extremely low background, which is the reason why such experiments typically operate deep underground, where interference from cosmic rays is minimized. Examples of underground laboratories with direct detection experiments include the Stawell mine, the Soudan mine, the SNOLAB underground laboratory at Sudbury, the Gran Sasso National Laboratory, the Canfranc Underground Laboratory, the Boulby Underground Laboratory, the Deep Underground Science and Engineering Laboratory and the China Jinping Underground Laboratory.\n",
      "These experiments mostly use either cryogenic or noble liquid detector technologies. Cryogenic detectors operating at temperatures below 100 mK, detect the heat produced when a particle hits an atom in a crystal absorber such as germanium. Noble liquid detectors detect scintillation produced by a particle collision in liquid xenon or argon. Cryogenic detector experiments include: CDMS, CRESST, EDELWEISS, EURECA. Noble liquid experiments include LZ, XENON, DEAP, ArDM, WARP, DarkSide, PandaX, and LUX, the Large Underground Xenon experiment. Both of these techniques focus strongly on their ability to distinguish background particles (which predominantly scatter off electrons) from dark matter particles (that scatter off nuclei). Other experiments include SIMPLE and PICASSO.\n",
      "Currently there has been no well-established claim of dark matter detection from a direct detection experiment, leading instead to strong upper limits on the mass and interaction cross section with nucleons of such dark matter particles. The DAMA/NaI and more recent DAMA/LIBRA experimental collaborations have detected an annual modulation in the rate of events in their detectors, which they claim is due to dark matter. This results from the expectation that as the Earth orbits the Sun, the velocity of the detector relative to the dark matter halo will vary by a small amount. This claim is so far unconfirmed and in contradiction with negative results from other experiments such as LUX, SuperCDMS and XENON100.A special case of direct detection experiments covers those with directional sensitivity. This is a search strategy based on the motion of the Solar System around the Galactic Center. A low-pressure time projection chamber makes it possible to access information on recoiling tracks and constrain WIMP-nucleus kinematics. WIMPs coming from the direction in which the Sun travels (approximately towards Cygnus) may then be separated from background, which should be isotropic. Directional dark matter experiments include DMTPC, DRIFT, Newage and MIMAC.\n",
      "\n",
      "Indirect detection\n",
      "Indirect detection experiments search for the products of the self-annihilation or decay of dark matter particles in outer space. For example, in regions of high dark matter density (e.g., the centre of our galaxy) two dark matter particles could annihilate to produce gamma rays or Standard Model particle–antiparticle pairs. Alternatively, if a dark matter particle is unstable, it could decay into Standard Model (or other) particles. These processes could be detected indirectly through an excess of gamma rays, antiprotons or positrons emanating from high density regions in our galaxy or others. A major difficulty inherent in such searches is that various astrophysical sources can mimic the signal expected from dark matter, and so multiple signals are likely required for a conclusive discovery.A few of the dark matter particles passing through the Sun or Earth may scatter off atoms and lose energy. Thus dark matter may accumulate at the center of these bodies, increasing the chance of collision/annihilation. This could produce a distinctive signal in the form of high-energy neutrinos. Such a signal would be strong indirect proof of WIMP dark matter. High-energy neutrino telescopes such as AMANDA, IceCube and ANTARES are searching for this signal.\n",
      "The detection by LIGO in September 2015 of gravitational waves opens the possibility of observing dark matter in a new way, particularly if it is in the form of primordial black holes.Many experimental searches have been undertaken to look for such emission from dark matter annihilation or decay, examples of which follow.\n",
      "The Energetic Gamma Ray Experiment Telescope observed more gamma rays in 2008 than expected from the Milky Way, but scientists concluded this was most likely due to incorrect estimation of the telescope's sensitivity.The Fermi Gamma-ray Space Telescope is searching for similar gamma rays. In 2009, an as yet unexplained surplus of gamma rays from the Milky Way's galactic center was found in Fermi data. This Galactic Center GeV excess might be due to dark matter annihilation or to a population of pulsars. In April 2012, an analysis of previously available data from Fermi's Large Area Telescope instrument produced statistical evidence of a 130 GeV signal in the gamma radiation coming from the center of the Milky Way. WIMP annihilation was seen as the most probable explanation.At higher energies, ground-based gamma-ray telescopes have set limits on the annihilation of dark matter in dwarf spheroidal galaxies and in clusters of galaxies.The PAMELA experiment (launched in 2006) detected excess positrons. They could be from dark matter annihilation or from pulsars. No excess antiprotons were observed.In 2013, results from the Alpha Magnetic Spectrometer on the International Space Station indicated excess high-energy cosmic rays which could be due to dark matter annihilation.\n",
      "\n",
      "Collider searches for dark matter\n",
      "An alternative approach to the detection of dark matter particles in nature is to produce them in a laboratory. Experiments with the Large Hadron Collider (LHC) may be able to detect dark matter particles produced in collisions of the LHC proton beams. Because a dark matter particle should have negligible interactions with normal visible matter, it may be detected indirectly as (large amounts of) missing energy and momentum that escape the detectors, provided other (non-negligible) collision products are detected. Constraints on dark matter also exist from the LEP experiment using a similar principle, but probing the interaction of dark matter particles with electrons rather than quarks. Any discovery from collider searches must be corroborated by discoveries in the indirect or direct detection sectors to prove that the particle discovered is, in fact, dark matter.\n",
      "\n",
      "Alternative hypotheses\n",
      "Because dark matter has not yet been identified, many other hypotheses have emerged aiming to explain the same observational phenomena without introducing a new unknown type of matter. The most common method is to modify general relativity. General relativity is well-tested on solar system scales, but its validity on galactic or cosmological scales has not been well proven. A suitable modification to general relativity can in principle conceivably eliminate the need for dark matter. The best-known theories of this class are MOND and its relativistic generalization tensor–vector–scalar gravity (TeVeS), f(R) gravity, negative mass, dark fluid, and entropic gravity. Alternative theories abound.A problem with alternative hypotheses is that observational evidence for dark matter comes from so many independent approaches (see the \"observational evidence\" section above). Explaining any individual observation is possible but explaining all of them in the absence of dark matter is very difficult. Nonetheless, there have been some scattered successes for alternative hypotheses, such as a 2016 test of gravitational lensing in entropic gravity and a 2020 measurement of a unique MOND effect.The prevailing opinion among most astrophysicists is that while modifications to general relativity can conceivably explain part of the observational evidence, there is probably enough data to conclude there must be some form of dark matter present in the Universe.\n",
      "\n",
      "In popular culture\n",
      "Dark matter regularly appears as a topic in hybrid periodicals that cover both factual scientific topics and science fiction,\n",
      "and dark matter itself has been referred to as \"the stuff of science fiction\".Mention of dark matter is made in works of fiction. In such cases, it is usually attributed extraordinary physical or magical properties, thus becoming inconsistent with the hypothesized properties of dark matter in physics and cosmology. For example:\n",
      "\n",
      "Dark matter serves as a plot device in the X-Files episode \"Soft Light\", in a manner that one reviewer found reliant upon the audience's ignorance\n",
      "A dark-matter-inspired substance known as \"Dust\" features prominently in Philip Pullman's His Dark Materials trilogy\n",
      "Beings made of dark matter are antagonists in Stephen Baxter's Xeelee SequenceMore broadly, the phrase \"dark matter\" is used metaphorically in fiction to evoke the unseen or invisible.\n",
      "\n",
      "Gallery\n",
      "See also\n",
      "Notes\n",
      "References\n",
      "Works cited\n",
      "Further reading\n",
      "Hossenfelder, Sabine; McGaugh, Stacy S. (August 2018). \"Is dark matter real?\". Scientific American. Vol. 319, no. 2. pp. 36–43.\n",
      "Weiss, Rainer, \"The Dark Universe Comes into Focus: The LIGO experiment opened a whole new window to the universe. We asked [2017 Nobel laureate] Rainer Weiss, one of LIGO's lead architects, what gravitational-wave astronomy could reveal next\" (sponsor feature), Scientific American, vol. 329, no. 1 (July/August 2023), between p. 7 and p. 8. \"I... think that dark matter is made of black holes – really small black holes, a tiny fraction of a solar mass, that don't interact much with light so you can't see them.... According to [cosmic inflation theory], the universe was created by a fluctuation in the vacuum. That kind of fluctuation will have instabilities and explode asymmetrically – which will generate gravitational waves.\"\n",
      "\n",
      "External links\n",
      "\n",
      "Dark matter at Curlie\n",
      "Tremaine, Scott. Lecture on dark matter (Video). IAS.\n",
      "Gray, Meghan; Merrifield, Mike; Copeland, Ed (2010). Haran, Brady (ed.). \"Dark Matter\". Sixty Symbols. University of Nottingham.The Three Musketeers (French: Les Trois Mousquetaires, [le tʁwɑ muskətɛːʁ]) is a French historical adventure novel written in 1844 by French author Alexandre Dumas. As with some of his other works, he wrote it in collaboration with ghostwriter Auguste Maquet. It is in the swashbuckler genre, which has heroic, chivalrous swordsmen who fight for justice.\n",
      "Set between 1625 and 1628, it recounts the adventures of a young man named d'Artagnan (a character based on Charles de Batz-Castelmore d'Artagnan) after he leaves home to travel to Paris, hoping to join the Musketeers of the Guard. Although d'Artagnan is not able to join this elite corps immediately, he is befriended by three of the most formidable musketeers of the age – Athos, Porthos and Aramis, \"the three musketeers\" or \"the three inseparables\" – and becomes involved in affairs of state and at court.\n",
      "The Three Musketeers is primarily a historical and adventure novel. However, Dumas frequently portrays various injustices, abuses and absurdities of the Ancien Régime, giving the novel an additional political significance at the time of its publication, a time when the debate in France between republicans and monarchists was still fierce. The story was first serialised from March to July 1844, during the July Monarchy, four years before the French Revolution of 1848 established the Second Republic.\n",
      "The story of d'Artagnan is continued in Twenty Years After and The Vicomte of Bragelonne: Ten Years Later.\n",
      "\n",
      "Origin\n",
      "Dumas presents his novel as one of a series of recovered manuscripts, turning the origins of his romance into a little drama of its own. In the preface, he tells of being inspired by a scene in Mémoires de Monsieur d'Artagnan (1700), a historical novel by Gatien de Courtilz de Sandras, printed by Pierre Rouge in Amsterdam, which Dumas discovered during his research for his history of Louis XIV. According to Dumas, the incident where d'Artagnan tells of his first visit to M. de Tréville, captain of the Musketeers, and how, in the antechamber, he encountered three young Béarnese with the names Athos, Porthos and Aramis, made such an impression on him that he continued to investigate. That much is true – the rest is fiction: He finally found the names of the three musketeers in a manuscript titled Mémoire de M. le comte de la Fère, etc. Dumas \"requested permission\" to reprint the manuscript; permission was granted:\n",
      "\n",
      "Now, this is the first part of this precious manuscript which we offer to our readers, restoring it to the title which belongs to it, and entering into an engagement that if (of which we have no doubt) this first part should obtain the success it merits, we will publish the second immediately.\n",
      "In the meanwhile, since godfathers are second fathers, as it were, we beg the reader to lay to our account and not to that of the Comte de la Fère, the pleasure or the ennui he may experience.\n",
      "This being understood, let us proceed with our story.\n",
      "\n",
      "The Three Musketeers was written in collaboration with Auguste Maquet, who also worked with Dumas on its sequels (Twenty Years After and The Vicomte of Bragelonne: Ten Years Later), as well as The Count of Monte Cristo. Maquet would suggest plot outlines after doing historical research; Dumas then expanded the plot, removing some characters, including new ones and imbuing the story with his unmistakable style.\n",
      "The Three Musketeers was first published in serial form in the newspaper Le Siècle between March and July 1844.\n",
      "\n",
      "Plot\n",
      "In 1625 France, D'Artagnan leaves his family in Gascony and travels to Paris to join the Musketeers of the Guard. At a house in Meung-sur-Loire, an older man derides D'Artagnan's horse. Insulted, D'Artagnan demands a duel. But the older man's companions instead beat D'Artagnan unconscious with a cooking pot and a metal tong that breaks his sword. His letter of introduction to Monsieur de Tréville, the commander of the Musketeers, a King's elite regiment, is also stolen. D'Artagnan resolves to avenge himself upon the older man, who is actually the Comte de Rochefort, an agent of Cardinal Richelieu, who is passing the latter's orders to his spy, Milady de Winter or simply \"Milady\". In Paris, D'Artagnan visits Tréville at the headquarters of the Musketeers. Without the letter, he faces a lukewarm reception from Tréville. Before their conversation concludes, D'Artagnan sees Rochefort passing in the street by a Tréville's window and rushes out of the building to confront him. Pursuing Rochefort, he offends three musketeers, Athos, Porthos and Aramis, who each demand satisfaction; D'Artagnan must fight a duel with all of them that afternoon.\n",
      "As D'Artagnan prepares himself for the first duel, he realizes that Athos's seconds are Porthos and Aramis, who are astonished that the Gascon intends to duel them all. As D'Artagnan and Athos begin, Richelieu's guards appear and attempt to arrest the musketeers for illegal dueling. Offered to leave by the Cardinal's guards, D'Artagnan decides to help the musketeers. Despite being outnumbered four to five, the four men win the battle. D'Artagnan seriously wounds Jussac, one of Richelieu's officers and a renowned fighter. King Louis XIII appoints D'Artagnan to Des Essart's company of the King's Guards, a less prestigious regiment, and gives him forty pistoles. D'Artagnan hires a servant named Planchet and finds lodgings with some Bonacieux, a merchant. His landlord later speaks to him about the kidnapping of his wife, Constance Bonacieux, who works for Queen Anne of France. When she is released, D'Artagnan falls in love at first sight with her.  Queen Anne secretly meets the Duke of Buckingham, the England's first minister. At the meeting, Anne gives Buckingham a diamond necklace, a King's gift to her, as a keepsake.\n",
      "Richelieu, who wants to diminish the destructive influence of  Queen Anne and her Spanish entourage on French internal affairs, plots to persuade the King that his wife is having an affair with Buckingham. On his advice, the King demands that the Queen wear the diamonds to an upcoming soirée. Constance tries to send her husband to London to fetch the diamonds, but he is instead manipulated by Richelieu and thus does not go, so D'Artagnan and his friends intercede. En route to England, Richelieu's henchmen repeatedly attack them and only D'Artagnan and Planchet reach London. Before arriving, D'Artagnan is compelled to assault and nearly to kill Comte de Wardes, a friend of Richelieu, cousin of Rochefort and Milady's love interest. Although Milady stole two of the diamond studs, Buckingham provides replacements while delaying the thief's return to Paris. D'Artagnan thus manages to return a complete set of jewels to Queen Anne just in time to save her honor. \n",
      "D'Artagnan hopes to begin an affair with grateful Constance. Invited to a date, he sees signs of a struggle and discovers that Rochefort and Bonacieux, acting under the orders of Richelieu, have kidnapped Constance. D'Artagnan traces his steps back to find his friends whom he abandoned wounded on his way to London. At their meeting, Athos, heavily drunk, tells D'Artagnan a story about a count who felt in love with and married a young woman. After several months of happiness, the count discovered that his wife was branded with fleur-de-lis on her shoulder, a common punishment for felony at the time. The count left her in a forest with her hands tied to an apparent death, abandoned his family castle, and joined the King's guard under an assumed name. Though Athos does not say so, D'Artagnan understands that Athos is telling his own story.\n",
      "In Paris, D'Artagnan meets Milady de Winter and recognizes her as one of Richelieu's agents. He becomes infatuated with her, though her maid reveals that Milady is indifferent towards him. Entering her quarters in the dark, he pretends to be Comte de Wardes, whom she invited in a letter that D'Artagnan intercepted, and makes love to her. However, D'Artagnan is not content with Milady's having sex with him thinking that he is de Wardes. He fakes a rude letter from de Wardes, offending Milady. She asks D'Artagnan to duel and kill the Comte. As a prepayment, he has sex with her again, now under his own name.  In the heat of passion, D'Artagnan reveals that it is not the first time they are together. Milday is enraged and in the subsequent scuffle, D'Artagnan discoveres a fleur-de-lis branded on her shoulder. Milady attempts to kill him, but D'Artagnan eludes her. He tells Athos that his former wife is alive.\n",
      "Cardinal Richelieu offers D'Artagnan a career in his guards' ranks. Dreading the prospect of losing his friends, D'Artagnan refuses, though he understanding that his career prospects diminish as a result. With their regiments, D'Artagnan and the three musketeers are ordered to the Siege of La Rochelle. There he and his friends barely survive two assassination attempts by Milady's agents. The would-be assassins die in the process.\n",
      "At a local inn, Athos overhears Richelieu asking Milady to murder Buckingham, whose support is critical to the Protestant rebels at La Rochelle. Richelieu gives her his order absolving the bearer from any responsibility, but Athos takes the order from her. To get time to consult with his friends in secret, Athos bets that he, D'Artagnan, Porthos, and Aramis will hold the recaptured St. Gervais bastion against the rebels for an hour next morning. They resist for an hour and a half before retreating, killing a dozen of Rochellese in the process, which adds to their legend. They warn the Queen and Lord de Winter about the Milady's plan to assassinate Buckingham. Milady is imprisoned on arrival in England, but seduces her guard, Felton, and persuades him to allow her to escape and to kill Buckingham himself. \n",
      "D'Artagnan is informed that the Queen has rescued Constance from prison. He gets a permission to take her from a convent where the Queen sent her.\n",
      "Upon her return to France, Milady hides, by sheer chance, in the same convent where Constance hides on Queen's orders. The naïve Constance clings to Milady who pretends to be another victim of Cardinal's intrigues. Seeing a chance for revenge on D'Artagnan, Milady poisons Constance minutes before D'Artagnan arrives to rescue her. The musketeers pursue and catch Milady before she reaches Richelieu. Summoning a local executioner, they put Milady on trial, sentence her to death, and have her executed. The executioner reveals that it was him who branded Milady as a felon many years ago after she, a young nun at the time, seduced and then abandoned his brother, a local priest. Upon the four friends' return to the Siege of La Rochelle, Richelieu's Guards arrest D’Artagnan. D'Artagnan gives the Cardinal the secret order absolving the bearer of any responsibility that Athos has taken from Milady. Impressed with D'Artagnan's candor and secretly glad to be rid of his dreaded agent, Richelieu destroys the order and writes a new one, giving the bearer a promotion to lieutenant in Tréville's company of Musketeers, leaving the name blank. D'Artagnan offers the letter to his three friends in turn but each refuses it; Athos because it is beneath him, Porthos because he is retiring to marry his wealthy mistress, and Aramis because he is joining the priesthood. D'Artagnan, though heartbroken and full of regrets, receives the promotion he had coveted.\n",
      "\n",
      "Characters\n",
      "MusketeersAthos – Comte de la Fère: he has never recovered from his marriage to Milady and seeks solace in wine. He becomes a father figure to d'Artagnan.\n",
      "Porthos – M. du Vallon: a dandy, fond of fashionable clothes and keen to make a fortune for himself. The least cerebral of the quartet, he compensates with his homeric strength of body and character.\n",
      "Aramis – René d'Herblay, a handsome young man who wavers between his religious calling and his fondness for women and intrigue.\n",
      "D'Artagnan – Charles de Batz de Castelmore D'Artagnan: an impetuous, brave and clever young man seeking to become a musketeer in France.Musketeers' servantsPlanchet – a young man from Picardy, he is seen by Porthos on the Pont de la Tournelle spitting into the river below. Porthos takes this as a sign of good character and hires him on the spot to serve d'Artagnan. He turns out to be a brave, intelligent and loyal servant.\n",
      "Grimaud – a Breton, whom Athos, a strict master, only permits to speak in emergencies; he mostly communicates through sign language.\n",
      "Mousqueton – originally a Norman named Boniface; Porthos, however, changes his name to one that sounds better. He is a would-be dandy, just as vain as his master. In lieu of pay, he is clothed and lodged in a manner superior to that usual for servants, dressing grandly in his master's renovated old clothing.\n",
      "Bazin – from the province of Berry, Bazin is a pious man who waits for the day his master (Aramis) will join the church, as he has always dreamed of serving a churchman.OthersMilady de Winter – a beautiful and evil spy of the Cardinal, she is also Athos's ex-wife. D'Artagnan impersonates a rival to spend a night with her, attracting her deadly hatred when the deceit is revealed.\n",
      "Rochefort – a more conventional agent of the Cardinal. Following their meeting at Meung on the road to Paris, d'Artagnan swears to have his revenge. He misses several opportunities, but their paths finally cross again towards the end of the novel.\n",
      "Constance Bonacieux – the queen's seamstress and confidante. After d'Artagnan rescues her from the Cardinal's Guard, he immediately falls in love with her. She appreciates his protection, but the relationship is never consummated.\n",
      "Monsieur Bonacieux – Constance's husband. He initially enlists d'Artagnan's help to rescue his wife from the Cardinal's Guards, but when he himself is arrested Richelieu turns Monsieur Bonacieux against his wife, and he goes on to play a role in her abduction.\n",
      "Kitty – a servant of Milady de Winter. She dislikes her mistress and adores d'Artagnan.\n",
      "Lord de Winter – brother of Milady's second husband who died of a mysterious disease (apparently poisoned by Milady). Acting on a warning from d'Artagnan, he imprisons Milady upon her arrival in England and plans to send her overseas in exile. Later, he takes part in Milady's trial.Historical charactersKing Louis XIII of France – presented by Dumas as a fairly weak and self-indulgent monarch, often manipulated by his chief minister.\n",
      "Queen Anne of Austria – the queen of France, described as often neglected by her husband and persecuted by the Cardinal.\n",
      "Cardinal Richelieu – Armand Jean du Plessis, the king's chief minister, who plots against the queen in resentment at having his advances rebuffed. Dumas describes him as being \"36 or 37\" though in 1625 Richelieu was 40.\n",
      "M. de Tréville – captain of the musketeers and something of a mentor to d'Artagnan, though he has only a minor role.\n",
      "George Villiers, 1st Duke of Buckingham – a handsome and charismatic man used to getting his way; he thinks nothing of starting a war between England and France for his personal convenience. His courtship of Anne of Austria places her in great peril.\n",
      "John Felton – a Puritan officer assigned by Lord de Winter to guard Milady and warned about her ways, he is nonetheless seduced by her in a matter of days and assassinates Buckingham at her request.\n",
      "\n",
      "Editions\n",
      "Les Trois Mousquetaires was translated into three English versions by 1846. One of these, by William Barrow (1817–1877), is still in print and fairly faithful to the original, available in the Oxford World's Classics 1999 edition. To conform to 19th-century English standards, all of the explicit and many of the implicit references to sexuality were removed, adversely affecting the readability of several scenes, such as the scenes between d'Artagnan and Milady.\n",
      "There are 3 modern translations as well. One recent English translation is by Will Hobson in 2002.\n",
      "Another is by Richard Pevear (2006), who, though applauding Barrow's work, states that most of the modern translations available today are \"textbook examples of bad translation practices\" which \"give their readers an extremely distorted notion of Dumas' writing.\"The most recent translation is by the American translator Lawrence Ellsworth (Lawrence Schick) published by Pegasus Books in February 2018 from the 1956 French edition.\n",
      "Ellsworth decided to translate the full trilogy of The d'Artagnan Romances as well as the two novels of The Count of Moret for 21st century readers in 9 volumes, making it the first complete translation in over a century and a half. 7 out of 9 volumes have been published and the 8th volume is in progress in a serialized translation on Substack.\n",
      "\n",
      "Adaptations\n",
      "Film\n",
      "The Three Musketeers (1921), a silent film adaptation starring Douglas Fairbanks.\n",
      "The Three Musketeers (1939), a musical comedy adaptation starring Don Ameche and The Ritz Brothers.\n",
      "The Three Musketeers (1948), a 1948 adaptation starring Van Heflin, Lana Turner, June Allyson, Angela Lansbury, Vincent Price, and Gene Kelly.\n",
      "The Three Musketeers (1973), an adaptation by Richard Lester starring Oliver Reed, Frank Finlay, Richard Chamberlain and Michael York. This was only the first half of the Dumas novel, with the rest appearing in the following year's The Four Musketeers.\n",
      "D'Artagnan and Three Musketeers (1978), a popular Soviet musical featuring Mikhail Boyarsky\n",
      "The Three Musketeers (1993), a 1993 Disney adaptation starring Charlie Sheen, Kiefer Sutherland, Oliver Platt and Chris O'Donnell.\n",
      "The Musketeer, a 2001 film.\n",
      "The Three Musketeers (2011), directed by Paul W. S. Anderson and starring Luke Evans, Ray Stevenson and Milla Jovovich.\n",
      "The Three Musketeers: D'Artagnan and The Three Musketeers: Milady, a 2023 two-part French adventure film saga starring François Civil, Vincent Cassel, Pio Marmaï, Romain Duris and Eva Green\n",
      "\n",
      "Television\n",
      "The novel has been adapted also for television in live action and animation.\n",
      "\n",
      "Live action\n",
      "The BBC has adapted the novel on three occasions:\n",
      "\n",
      "The Three Musketeers, a 1954 BBC adaptation in six 30-minute episodes, starring Laurence Payne, Roger Delgado, Paul Whitsun-Jones and Paul Hansard\n",
      "The Three Musketeers, a 1966 BBC adaptation in ten 25-minute episodes, directed by Peter Hammond and starring Jeremy Brett, Jeremy Young and Brian Blessed\n",
      "The Musketeers, a 2014 series by Adrian Hodges, is the newest BBC adaptation starring Tom Burke, Santiago Cabrera, Howard Charles and Luke Pasqualino as the titular musketeers.Young Blades is an American/Canadian television series that aired on PAX in 2005. The series serves as a sequel to the novels, centered on the son of d'Artagnan, played by Tobias Mehler.\n",
      "A series adapted for Korean history aired in 2014.\n",
      "\n",
      "Animation\n",
      "Walt Disney Productions produced a Silly Symphony cartoon called, Three Blind Mouseketeers, which is loosely based on the novel in 1936, in which the characters are depicted as anthropomorphic animals.\n",
      "A two-part adaptation aired on The Famous Adventures of Mr. Magoo, with Magoo portraying D'Artagnan.\n",
      "The Three Musketeers was a series of animated shorts produced by Hanna-Barbera as part of The Banana Splits Comedy-Adventure Hour and The Banana Splits & Friends show.\n",
      "The Three Musketeers was a Hanna-Barbera animated special from 1973. It was part of the 1970s-80s CBS anthology series Famous Classic Tales that was produced by Hanna-Barbera's Australian division and often aired around the holidays between Thanksgiving and New Year's Day.\n",
      "Dogtanian and the Three Muskehounds is a 1981 Spanish–Japanese anime adaptation, where the characters are anthropomorphic dogs. A sequel, The Return of Dogtanian, was released in 1989 by BRB Internacional, Thames Television and Wang Film Productions. Set 10 years after the original, it is loosely based on the novel The Vicomte de Bragelonne. A key difference between the two Dogtanian adaptions and Dumas' novel is that the character traits of Athos and Porthos were interchanged, making Athos the extrovert and Porthos the secretive noble of the group.\n",
      "In 1989, Gakken produced a new anime adaptation called The Three Musketeers Anime, this time with human characters, which features several departures from the original.\n",
      "Albert the Fifth Musketeer is a 1994 French-British animated series featuring a new musketeer, the titular Albert.\n",
      "Mickey, Donald, Goofy: The Three Musketeers, a direct-to-video animated movie produced by Walt Disney Pictures and the Australian office of DisneyToon Studios, directed by Donovan Cook and released on 17 August 2004.\n",
      "The Backyardigans had a 2009 episode in its third season by the name of The Two Musketeers; a third musketeer joins by the end of the episode.\n",
      "A Barbie adaptation of the tale by the name of Barbie and the Three Musketeers was released in 2009.\n",
      "\n",
      "Stage\n",
      "The first stage production was in Dumas' own lifetime as the opera Les Trois Mousquetaires with a libretto by Dumas himself and music by Albert Visetti.\n",
      "An 1898 play, by Henry Hamilton, opened as The Three Musketeers at the Theatre Metropole, Camberwell, England, on 12 September 1898. Renamed The King's Musketeer, it was mounted at the Knickerbocker Theatre in New York on 22 February 1899.The Three Musketeers is a musical with a book by William Anthony McGuire, lyrics by Clifford Grey and P. G. Wodehouse, and music by Rudolf Friml. The original 1928 production ran on Broadway for 318 performances. A 1984 revival ran for 15 previews and 9 performances.\n",
      "The Stratford Festival has staged different theatrical productions of playwright Peter Raby's adaptation of the novel:\n",
      "\n",
      "In 1968, Raby collaborated with composer Raymond Pannell on a production at the Festival Theatre in 1968 directed by John Hirsch, with Powys Thomas as Athos, James Blendick as Porthos, Christopher Newton as Aramis and Douglas Rain as d'Artagnan.\n",
      "In 1988, a production was staged at the Festival Theatre with music by Alan Laing and directed by Richard Ouzounian, with Colm Feore as Athos, Stephen Russell as Porthos, Lorne Kennedy as Aramis and Geraint Wyn Davies as d'Artagnan.\n",
      "In 2000, a production was staged at the Festival Theatre with music by Berthold Carriere and directed by Richard Monette and Paul Leishman, with Benedict Campbell as Athos, Thom Marriott as Porthos, Andy Velasquez as Aramis and Timothy Askew as d'Artagnan.\n",
      "In 2013, a production was staged at the Festival Theatre with music by Lesley Arden and directed by Miles Potter, with Graham Abbey as Athos, Jonathan Goad as Porthos, Mike Shara as Aramis and Luke Humphrey as d'Artagnan.In 2003, a Dutch musical 3 Musketiers with a book by André Breedland and music & lyrics by Rob & Ferdi Bolland premiered, which went on to open in Germany (both the Dutch and German production starring Pia Douwes as Milady De Winter) and Hungary.\n",
      "Playwright Peter Raby, composer George Stiles and lyricist Paul Leigh have written another adaptation titled The 3 Musketeers, One Musical For All, originally produced by the now defunct American Musical Theatre of San Jose.\n",
      "In 2006, an adaptation by Ken Ludwig premiered at the Bristol Old Vic. In this version, d'Artagnan's sister Sabine, \"the quintessential tomboy,\" poses as a young man and participates in her brother's adventures.\n",
      "In 2018, The Dukes performed an outdoor promenade production in Williamson Park, Lancaster, adapted by Hattie Naylor: in this version d'Artagnan was a young woman aspiring to be a musketeer.\n",
      "\n",
      "Video games and board games\n",
      "In 1995, publisher U.S. Gold released Touché: The Adventures of the Fifth Musketeer by video game developers Clipper Software, a classic point-and-click adventure game. In 2005, Swedish developer Legendo Entertainment published the side-scrolling platform game The Three Musketeers for Windows XP and Windows Vista. In July 2009, a version of the game was released for WiiWare in North America and Europe under the title The Three Musketeers: One for All!. In 2009, Canadian developer Dingo Games self-published The Three Musketeers: The Game for Windows and Mac OS X. It is the first game to be truly based on the novel (in that it closely follows the novel's story). 2009 also saw the publication of the asymmetric team board game The Three Musketeers \"The Queen's Pendants\" (Настольная игра \"Три мушкетера\") from French designer Pascal Bernard by the Russian publisher Zvezda. In 2010, a co-operative game called \"Mousquetaires du Roy\" was released by Ystari and Rio Grande. The alternative spelling of \"Roy\" was taken from the old French and is rumoured to be preferred over the regular spelling because the publishers desire to have a letter \"Y\" in the name of the games they publish. Designed by François Combe and Gilles Lehmann for 1-5 players, the medium heavy game depicts the quest to retrieve the Queen's diamonds, while at the same time fending off disasters back in Paris. A sixth player expansion, called \"Treville\" was also made available in 2010.In 2010, Anuman Interactive launched The Three Musketeers, a hidden object game on PC and MAC. Players follow d'Artagnan in his quest to become a king's musketeer.\n",
      "\n",
      "Web series\n",
      "In 2016, KindaTV launched a web series based on the story of The Three Musketeers, called \"All For One\". It follows a group of college students, mainly Dorothy Castlemore and is centred around a sorority- Mu Sigma Theta (MST). The majority of characters have been gender-swapped from the original story and most character names are based on the original characters.\n",
      "It covers several themes including the LGBT community, mental health, long-distance relationships and college life.\n",
      "\n",
      "Audio\n",
      "A musical version with music by Rudolf Friml, book by William Anthony McGuire, lyrics by Clifford Grey and directed by Alastair Scott Johnson was broadcast on BBC Radio 2 on 21 March 1970.An adaptation in twelve parts by Patrick Riddell was broadcast on the BBC Light Programme 4 April-20 June 1946. The cast included Marius Goring as d'Artgagnan, Philip Cunningham as Athos, Howard Marion-Crawford as Porthos, Allan McClelland as Aramis, Lucille Lisle as Milady de Winter, Leon Quartermaine as Cardinal Richelieu and Valentine Dyall as the Narrator.\n",
      "In the early 1960s, United Artists Records released an audio dramatization of the first half of The Three Musketeers (UAC 11007) (dealing with the affair of the Queen's Diamonds) as part of their Tale Spinners for Children series, starring Robert Hardy as d'Artagnan and John Wood as Cardinal Richelieu.Michael York was the narrator for a 1982 Caedmon Records LP recording (TC 1692) consisting of the first five chapters of the novel. Since then, the novel has been released in audiobook format many times.\n",
      "An adaptation in six parts by James Saunders directed by Martin Jenkins was broadcast on BBC Radio 4 28 April-2 June 1994. The cast included Jamie Glover as d'Artgagnan, Robert Glenister as Athos, Timothy Spall as Porthos, Anton Lesser as Aramis, Imelda Staunton as Milady de Winter, Michael Cochrane as the Duke of Buckingham and Julian Glover as Cardinal Richelieu. This adaptation was rebroadcast on BBC Radio 4 in 1995, on BBC Radio 7 in 2010 and on BBC Radio 4 Extra in 2014.\n",
      "In September 2019, Amazon released The Three Musketeers: an Audible Original Audio Drama, which follows the story of the book told from Milady's perspective.\n",
      "In April 2021, Durham University Audio Society began releasing the first season of DUADS' The Three Musketeers.  The show originally aired on Durham University's student radio station, Purple Radio, and went on to be nominated for and receive several local awards.  The show remains faithful to the events of the novel, but adds in several adventures and touches on additional themes, including LGBT themes.  The first season covers the first arc of the book, the quest for the Queen's diamond studs. A second and third season are in the works.\n",
      "In May 2022, Radio Mirchi Kolkata station aired The Three Musketeers in Bangla version, translated by Rajarshee Gupta for Mirchi's Sunday Suspense Programme. It was narrated by Deepanjan Ghosh. D'Artagnan was voiced by actor Rwitobroto Mukherjee. Athos was voiced by Gaurav Chakrabarty, Porthos by Agni, Aramis by Somak, King Louis XIII by Sayak Aman and Cardinal Richelieu by Mir Afsar Ali.\n",
      "\n",
      "Other\n",
      "Publisher Albert Lewis Kanter (1897–1973), created Classic Comics for Elliot Publishing Company in 1941 with its debut issues being The Three Musketeers. The Three Mouseketeers was the title of two series produced by DC Comics; the first series was a loose parody of The Three Musketeers. It was also made into motion comics in the Video Comic Book series\n",
      "In 1939, American author Tiffany Thayer published a book titled Three Musketeers (Thayer, 1939). This is a re-telling of the story in Thayer's words, true to the original plot but told in a different order and with different points of view and emphasis from the original.\n",
      "Fantasy novelist Steven Brust's Khaavren Romances series have all used Dumas novels (particularly the D'Artagnan Romances) as their chief inspiration, recasting the plots of those novels to fit within Brust's established world of Dragaera. His 2020 novel The Baron of Magister Valley follows suit, using The Count of Monte Cristo as a starting point.Sarah Hoyt's (nom de plume Sarah D'Almeida) Musketeers series begins with Death of a Musketeer, a Mystery Book Club selection, and includes four other titles from Berkley Prime Crime and Goldport Press.\n",
      "Tansy Rayner Roberts wrote Musketeer Space, a space opera retelling of the original book in which almost all characters have a different gender, as a weekly serialized novel from 2014 to 2016.\n",
      "\n",
      "In popular culture\n",
      "Literature\n",
      "The American translator Lawrence Ellsworth is currently translating The d'Artagnan Romances in its entirety, and he has also written a 2-volume novel called The Rose Knight's Crucifixion that is a parallel novel to The Three Musketeers, in which most of the characters from The Three Musketeers and Sir Percy Blakeney from The Laughing Cavalier and The First Sir Percy by Baroness Orczy appear. The protagonist's physical appearance, however, is based on Quasimodo from Victor Hugo's The Hunchback of Notre-Dame.\n",
      "In the book The Assault, The Three Musketeers is quoted in the Prologue as the protagonist had the story read to him by Mr. Beumer, a lawyer who later becomes senile and in morbidity.\n",
      "\n",
      "Film and television\n",
      "In Slumdog Millionaire, Jamal Malik's final question was to correctly identify the name of the third musketeer- which was Aramis. Jamal did so and won twenty million rupees.\n",
      "In the film Django Unchained, one of the slaves, owned by Calvin Candie, is named D'Artagnan.\n",
      "\n",
      "Video games\n",
      "In Pokémon Black and White, the Pokémon Cobalion, Terrakion and Virizion, known as the Swords of Justice, are based on the Three Musketeers. Cobalion represents Athos, Terrakion represents Porthos and Virizion represents Aramis. The fourth Sword of Justice, Keldeo, represents d'Artagnan.\n",
      "\n",
      "Music\n",
      "The Smiths song You've Got Everything Now features the line: \"I've seen you smile, but I've never really heard you laugh\" and is borrowed from a narrative description of Athos:\n",
      "\n",
      "He was very taciturn, this worthy signor. Be it understood we are speaking of Athos. During the five or six years that he had lived in the strictest intimacy with his companions, Porthos and Aramis, they could remember having often seen him smile, but had never heard him laugh.\n",
      "Ppcocaine's song \"Three Musketeers\" shares little with the novel but its title.\n",
      "\n",
      "Notes\n",
      "References\n",
      "External links\n",
      "\n",
      "The Three Musketeers at Standard Ebooks\n",
      "\n",
      " The Three Musketeers at Project Gutenberg. Plain text format.\n",
      "Listen to Take Spinners for Children: The Three Musketeers on Internet Archive.\n",
      " The Three Musketeers public domain audiobook at LibriVox\n",
      "History of Dumas' Musketeers, shows links between the characters and actual history.\n",
      "Comprehensive collection of Dumas links\n",
      "The Three Musketeers. Scanned public domain editions in PDF format from Archive.org, some w/ illustrations, introductions and other helpful material.\n",
      "\"The Paris of The Three Musketeers\", by E. H. Blashfield and E. W. Blashfield. Scribner's Magazine, August 1890. Cornell University Library.\n",
      "Cooper, Barbara T., \"Alexandre Dumas, père\", in Dictionary of Literary Biography, Vol. 119: Nineteenth-Century French Fiction Writers: Romanticism and Realism, 1800–1860, edited by Catharine Savage Brosman, Gale Research, 1992, pp. 98–119.\n",
      "Hemmings, F. W. J., \"Alexandre Dumas Père\", in European Writers: The Romantic Century, Vol. 6, edited by Jacques Barzun and George Stade, Charles Scribner's Sons, 1985, pp. 719–43.\n",
      "Foote-Greenwell, Victoria, \"The Life and Resurrection of Alexandre Dumas\", in Smithsonian, July 1996, p. 110.\n",
      "Thayer, Tiffany, Three Musketeers, New York: Citadel Press, 1939. (On the hard cover, the title is printed as Tiffany Thayer's Three Musketeers.)\n",
      "Discussion of the work, bibliography and links\n",
      "Bibliography and references for The Three MusketeersNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain. A neuromorphic computer/chip is any device that uses physical artificial neurons to do computations. In recent times, the term neuromorphic has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). The implementation of neuromorphic computing on the hardware level can be realized by oxide-based memristors, spintronic memories, threshold switches, transistors, among others. Training software-based neuromorphic systems of spiking neural networks can be achieved using error backpropagation, e.g., using Python based frameworks such as snnTorch, or using canonical learning rules from the biological learning literature, e.g., using BindsNet.A key aspect of neuromorphic engineering is understanding how the morphology of individual neurons, circuits, applications, and overall architectures creates desirable computations, affects how information is represented, influences robustness to damage, incorporates learning and development, adapts to local change (plasticity), and facilitates evolutionary change.\n",
      "Neuromorphic engineering is an interdisciplinary subject that takes inspiration from biology, physics, mathematics, computer science, and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems. One of the first applications for neuromorphic engineering was proposed by Carver Mead in the late 1980s.\n",
      "\n",
      "Neurological inspiration\n",
      "Neuromorphic engineering is for now set apart by the inspiration it takes from what we know about the structure and operations of the brain. Neuromorphic engineering translates what we know about the brain's function into computer systems. Work has mostly focused on replicating the analog nature of biological computation and the role of neurons in cognition.\n",
      "The biological processes of neurons and their synapses are dauntingly complex, and thus very difficult to artificially simulate. A key feature of biological brains is that all of the processing in neurons uses analog chemical signals. This makes it hard to replicate brains in computers because the current generation of computers is completely digital. However, the characteristics of these parts can be abstracted into mathematical functions that closely capture the essence of the neuron's operations.\n",
      "The goal of neuromorphic computing is not to perfectly mimic the brain and all of its functions, but instead to extract what is known of its structure and operations to be used in a practical computing system. No neuromorphic system will claim nor attempt to reproduce every element of neurons and synapses, but all adhere to the idea that computation is highly distributed throughout a series of small computing elements analogous to a neuron. While this sentiment is standard, researchers chase this goal with different methods.\n",
      "\n",
      "Examples\n",
      "As early as 2006, researchers at Georgia Tech published a field programmable neural array. This chip was the first in a line of increasingly complex arrays of floating gate transistors that allowed programmability of charge on the gates of MOSFETs to model the channel-ion characteristics of neurons in the brain and was one of the first cases of a silicon programmable array of neurons.\n",
      "In November 2011, a group of MIT researchers created a computer chip that mimics the analog, ion-based communication in a synapse between two neurons using 400 transistors and standard CMOS manufacturing techniques.In June 2012, spintronic researchers at Purdue University presented a paper on the design of a neuromorphic chip using lateral spin valves and memristors. They argue that the architecture works similarly to neurons and can therefore be used to test methods of reproducing the brain's processing. In addition, these chips are significantly more energy-efficient than conventional ones.Research at HP Labs on Mott memristors has shown that while they can be non-volatile, the volatile behavior exhibited at temperatures significantly below the phase transition temperature can be exploited to fabricate a neuristor, a biologically-inspired device that mimics behavior found in neurons. In September 2013, they presented models and simulations that show how the spiking behavior of these neuristors can be used to form the components required for a Turing machine.Neurogrid, built by Brains in Silicon at Stanford University, is an example of hardware designed using neuromorphic engineering principles. The circuit board is composed of 16 custom-designed chips, referred to as NeuroCores. Each NeuroCore's analog circuitry is designed to emulate neural elements for 65536 neurons, maximizing energy efficiency. The emulated neurons are connected using digital circuitry designed to maximize spiking throughput.A research project with implications for neuromorphic engineering is the Human Brain Project that is attempting to simulate a complete human brain in a supercomputer using biological data. It is made up of a group of researchers in neuroscience, medicine, and computing. Henry Markram, the project's co-director, has stated that the project proposes to establish a foundation to explore and understand the brain and its diseases, and to use that knowledge to build new computing technologies. The three primary goals of the project are to better understand how the pieces of the brain fit and work together, to understand how to objectively diagnose and treat brain diseases, and to use the understanding of the human brain to develop neuromorphic computers. That the simulation of a complete human brain will require a powerful supercomputer encourages the current focus on neuromorphic computers. $1.3 billion has been allocated to the project by The European Commission.Other research with implications for neuromorphic engineering involve the BRAIN Initiative and the TrueNorth chip from IBM. Neuromorphic devices have also been demonstrated using nanocrystals, nanowires, and conducting polymers. There also is development of a memristive device for quantum neuromorphic architectures. In 2022, researchers at MIT have reported the development of brain-inspired artificial synapses, using the ion proton (H+), for 'analog deep learning'.Intel unveiled its neuromorphic research chip, called “Loihi”, in October 2017. The chip uses an asynchronous spiking neural network (SNN) to implement adaptive self-modifying event-driven fine-grained parallel computations used to implement learning and inference with high efficiency.IMEC, a Belgium-based nanoelectronics research center, demonstrated the world's first self-learning neuromorphic chip. The brain-inspired chip, based on OxRAM technology, has the capability of self-learning and has been demonstrated to have the ability to compose music. IMEC released the 30-second tune composed by the prototype. The chip was sequentially loaded with songs in the same time signature and style. The songs were old Belgian and French flute minuets, from which the chip learned the rules at play and then applied them.The Blue Brain Project, led by Henry Markram, aims to build biologically detailed digital reconstructions and simulations of the mouse brain. The Blue Brain Project has created in silico models of rodent brains, while attempting to replicate as many details about its biology as possible. The supercomputer-based simulations offer new perspectives on understanding the structure and functions of the brain.\n",
      "The European Union funded a series of projects at the University of Heidelberg, which led to the development of \n",
      "BrainScaleS (brain-inspired multiscale computation in neuromorphic hybrid systems), a hybrid analog neuromorphic supercomputer located at Heidelberg University, Germany. It was developed as part of the Human Brain Project neuromorphic computing platform and is the complement to the SpiNNaker supercomputer (which is based on digital technology). The architecture used in BrainScaleS mimics biological neurons and their connections on a physical level; additionally, since the components are made of silicon, these model neurons operate on average 864 times (24 hours of real time is 100 seconds in the machine simulation) that of their biological counterparts.Brainchip announced in October 2021 that it was taking orders for its Akida AI Processor Development Kits and in January 2022 that it was taking orders for its Akida AI Processor PCIe boards, making it the world's first commercially available neuromorphic processor.\n",
      "\n",
      "Neuromemristive systems\n",
      "Neuromemristive systems is a subclass of neuromorphic computing systems that focuses on the use of memristors to implement neuroplasticity. While neuromorphic engineering focuses on mimicking biological behavior, neuromemristive systems focus on abstraction. For example, a neuromemristive system may replace the details of a cortical microcircuit's behavior with an abstract neural network model.There exist several neuron inspired threshold logic functions implemented with memristors that have applications in high level pattern recognition applications. Some of the applications reported recently include speech recognition, face recognition and object recognition. They also find applications in replacing conventional digital logic gates.For (quasi)ideal passive memristive circuits, the evolution of the memristive memories can be written in a closed form (Caravelli-Traversa-Di Ventra equation):\n",
      "\n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            d\n",
      "            \n",
      "              d\n",
      "              t\n",
      "            \n",
      "          \n",
      "        \n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "        =\n",
      "        −\n",
      "        α\n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "        +\n",
      "        \n",
      "          \n",
      "            1\n",
      "            β\n",
      "          \n",
      "        \n",
      "        (\n",
      "        I\n",
      "        −\n",
      "        χ\n",
      "        Ω\n",
      "        X\n",
      "        \n",
      "          )\n",
      "          \n",
      "            −\n",
      "            1\n",
      "          \n",
      "        \n",
      "        Ω\n",
      "        \n",
      "          \n",
      "            \n",
      "              S\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\frac {d}{dt}}{\\vec {X}}=-\\alpha {\\vec {X}}+{\\frac {1}{\\beta }}(I-\\chi \\Omega X)^{-1}\\Omega {\\vec {S}}}\n",
      "  as a function of the properties of the physical memristive network and the external sources. The equation is valid for the case of the Williams-Strukov original toy model, as  in the case of ideal memristors, \n",
      "  \n",
      "    \n",
      "      \n",
      "        α\n",
      "        =\n",
      "        0\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\alpha =0}\n",
      "  . However, the hypothesis of the existence of an ideal memristor is debatable. In the equation above, \n",
      "  \n",
      "    \n",
      "      \n",
      "        α\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\alpha }\n",
      "   is the \"forgetting\" time scale constant, typically associated to memory volatility, while \n",
      "  \n",
      "    \n",
      "      \n",
      "        χ\n",
      "        =\n",
      "        \n",
      "          \n",
      "            \n",
      "              \n",
      "                R\n",
      "                \n",
      "                  off\n",
      "                \n",
      "              \n",
      "              −\n",
      "              \n",
      "                R\n",
      "                \n",
      "                  on\n",
      "                \n",
      "              \n",
      "            \n",
      "            \n",
      "              R\n",
      "              \n",
      "                off\n",
      "              \n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\chi ={\\frac {R_{\\text{off}}-R_{\\text{on}}}{R_{\\text{off}}}}}\n",
      "   is the ratio of off and on values of the limit resistances of the memristors, \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              S\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\vec {S}}}\n",
      "   is the vector of the sources of the circuit and \n",
      "  \n",
      "    \n",
      "      \n",
      "        Ω\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\Omega }\n",
      "   is a projector on the fundamental loops of the circuit. The constant \n",
      "  \n",
      "    \n",
      "      \n",
      "        β\n",
      "      \n",
      "    \n",
      "    {\\displaystyle \\beta }\n",
      "   has the dimension of a voltage and is associated to the properties of the memristor; its physical origin is the charge mobility in the conductor. The diagonal matrix and vector \n",
      "  \n",
      "    \n",
      "      \n",
      "        X\n",
      "        =\n",
      "        diag\n",
      "        ⁡\n",
      "        (\n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "        )\n",
      "      \n",
      "    \n",
      "    {\\displaystyle X=\\operatorname {diag} ({\\vec {X}})}\n",
      "   and \n",
      "  \n",
      "    \n",
      "      \n",
      "        \n",
      "          \n",
      "            \n",
      "              X\n",
      "              →\n",
      "            \n",
      "          \n",
      "        \n",
      "      \n",
      "    \n",
      "    {\\displaystyle {\\vec {X}}}\n",
      "   respectively, are instead the internal value of the memristors, with values between 0 and 1. This equation thus requires adding extra constraints on the memory values in order to be reliable.\n",
      "It has been recently shown that the equation above exhibits tunneling phenomena and used to study Lyapunov functions.\n",
      "\n",
      "Neuromorphic sensors\n",
      "The concept of neuromorphic systems can be extended to sensors (not just to computation). An example of this applied to detecting light is the retinomorphic sensor or, when employed in an array, the event camera. In 2022, researchers from the Max Planck Institute for Polymer Research reported an organic artificial spiking neuron that exhibits the signal diversity of biological neurons while operating in the biological wetware, thus enabling in-situ neuromorphic sensing and biointerfacing applications.\n",
      "\n",
      "Military applications\n",
      "The Joint Artificial Intelligence Center, a branch of the U.S. military, is a center dedicated to the procurement and implementation of AI software and neuromorphic hardware for combat use. Specific applications include smart headsets/goggles and robots. JAIC intends to rely heavily on neuromorphic technology to connect \"every sensor (to) every shooter\" within a network of neuromorphic-enabled units.\n",
      "\n",
      "Ethical and legal considerations\n",
      "While the interdisciplinary concept of neuromorphic engineering is relatively new, many of the same ethical considerations apply to neuromorphic systems as apply to human-like machines and artificial intelligence in general. However, the fact that neuromorphic systems are designed to mimic a human brain gives rise to unique ethical questions surrounding their usage.\n",
      "However, the practical debate is that neuromorphic hardware as well as artificial \"neural networks\" are immensely simplified models of how the brain operates or processes information at a much lower complexity in terms of size and functional technology and a much more regular structure in terms of connectivity. Comparing neuromorphic chips to the brain is a very crude comparison similar to comparing a plane to a bird just because they both have wings and a tail. The fact is that biological neural cognitive systems are many orders of magnitude more energy- and compute-efficient than current state-of-the-art AI and neuromorphic engineering is an attempt to narrow this gap by inspiring from the brain's mechanism just like many engineering designs have bio-inspired features.\n",
      "\n",
      "Social concerns\n",
      "Significant ethical limitations may be placed on neuromorphic engineering due to public perception. Special Eurobarometer 382: Public Attitudes Towards Robots, a survey conducted by the European Commission, found that 60% of European Union citizens wanted a ban of robots in the care of children, the elderly, or the disabled. Furthermore, 34% were in favor of a ban on robots in education, 27% in healthcare, and 20% in leisure. The European Commission classifies these areas as notably “human.” The report cites increased public concern with robots that are able to mimic or replicate human functions. Neuromorphic engineering, by definition, is designed to replicate the function of the human brain.The social concerns surrounding neuromorphic engineering are likely to become even more profound in the future. The European Commission found that EU citizens between the ages of 15 and 24 are more likely to think of robots as human-like (as opposed to instrument-like) than EU citizens over the age of 55. When presented an image of a robot that had been defined as human-like, 75% of EU citizens aged 15–24 said it corresponded with the idea they had of robots while only 57% of EU citizens over the age of 55 responded the same way. The human-like nature of neuromorphic systems, therefore, could place them in the categories of robots many EU citizens would like to see banned in the future.\n",
      "\n",
      "Personhood\n",
      "As neuromorphic systems have become increasingly advanced, some scholars have advocated for granting personhood rights to these systems.  Daniel Lim, a critic of technology development in the Human Brain Project, which aims to advance brain-inspired computing, has argued that advancement in neuromorphic computing could lead to machine consciousness or personhood.  If these systems are to be treated as people, then many tasks humans perform using neuromorphic systems, including their termination, may be morally impermissible as these acts would violate their autonomy.\n",
      "\n",
      "Ownership and property rights\n",
      "There is significant legal debate around property rights and artificial intelligence. In Acohs Pty Ltd v. Ucorp Pty Ltd, Justice Christopher Jessup of the Federal Court of Australia found that the source code for Material Safety Data Sheets could not be copyrighted as it was generated by a software interface rather than a human author. The same question may apply to neuromorphic systems: if a neuromorphic system successfully mimics a human brain and produces a piece of original work, who, if anyone, should be able to claim ownership of the work?\n",
      "\n",
      "See also\n",
      "References\n",
      "External links\n",
      "\n",
      "Telluride Neuromorphic Engineering Workshop\n",
      "CapoCaccia Cognitive Neuromorphic Engineering Workshop\n",
      "Institute of Neuromorphic Engineering\n",
      "INE news site.\n",
      "Frontiers in Neuromorphic Engineering Journal\n",
      "Computation and Neural Systems department at the California Institute of Technology.\n",
      "Human Brain Project official site\n",
      "Building a Silicon Brain: Computer chips based on biological neurons may help simulate larger and more-complex brain models. May 1, 2019. SANDEEP RAVINDRANGalileo di Vincenzo Bonaiuti de' Galilei (15 February 1564 – 8 January 1642), commonly referred to as Galileo Galilei ( GAL-il-AY-oh GAL-il-AY, US also  GAL-il-EE-oh -⁠, Italian: [ɡaliˈlɛːo ɡaliˈlɛi]) or simply Galileo, was an Italian astronomer, physicist and engineer, sometimes described as a polymath. He was born in the city of Pisa, then part of the Duchy of Florence. Galileo has been called the father of observational astronomy, modern-era classical physics, the scientific method, and modern science.Galileo studied speed and velocity, gravity and free fall, the principle of relativity, inertia, projectile motion and also worked in applied science and technology, describing the properties of the pendulum and \"hydrostatic balances\". He was one of the earliest Renaissance developers of the thermoscope and the inventor of various military compasses, and used the telescope for scientific observations of celestial objects. With an improved telescope he built, he observed the stars of the Milky Way, the phases of Venus, the four largest satellites of Jupiter, Saturn's rings, lunar craters and sunspots. He also built an early microscope.\n",
      "Galileo's championing of Copernican heliocentrism (Earth rotating daily and revolving around the Sun) was met with opposition from within the Catholic Church and from some astronomers. The matter was investigated by the Roman Inquisition in 1615, which concluded that heliocentrism was foolish, absurd, and heretical since it contradicted biblical creationism.Galileo later defended his views in Dialogue Concerning the Two Chief World Systems (1632), which appeared to attack Pope Urban VIII and thus alienated both the Pope and the Jesuits, who had both supported Galileo up until this point. He was tried by the Inquisition, found \"vehemently suspect of heresy\", and forced to recant. He spent the rest of his life under house arrest. During this time, he wrote Two New Sciences (1638), primarily concerning kinematics and the strength of materials, summarizing work he had done around forty years earlier.\n",
      "\n",
      "Early life and family\n",
      "Galileo was born in Pisa (then part of the Duchy of Florence), Italy, on 15 February 1564, the first of six children of Vincenzo Galilei, a lutenist, composer, and music theorist, and Giulia Ammannati, who had married in 1562. Galileo became an accomplished lutenist himself and would have learned early from his father a scepticism for established authority.Three of Galileo's five siblings survived infancy. The youngest, Michelangelo (or Michelagnolo), also became a lutenist and composer who added to Galileo's financial burdens for the rest of his life. Michelangelo was unable to contribute his fair share of their father's promised dowries to their brothers-in-law, who would later attempt to seek legal remedies for payments due. Michelangelo would also occasionally have to borrow funds from Galileo to support his musical endeavours and excursions. These financial burdens may have contributed to Galileo's early desire to develop inventions that would bring him additional income.When Galileo Galilei was eight, his family moved to Florence, but he was left under the care of Muzio Tedaldi for two years. When Galileo was ten, he left Pisa to join his family in Florence and there he was under the tutelage of Jacopo Borghini. He was educated, particularly in logic, from 1575 to 1578 in the Vallombrosa Abbey, about 30 km southeast of Florence.\n",
      "\n",
      "Name\n",
      "Galileo tended to refer to himself only by his given name. At the time, surnames were optional in Italy, and his given name had the same origin as his sometimes-family name, Galilei. Both his given and family name ultimately derive from an ancestor, Galileo Bonaiuti, an important physician, professor, and politician in Florence in the 15th century. Galileo Bonaiuti was buried in the same church, the Basilica of Santa Croce in Florence, where about 200 years later, Galileo Galilei was also buried.When he did refer to himself with more than one name, it was sometimes as Galileo Galilei Linceo, a reference to his being a member of the Accademia dei Lincei, an elite pro-science organization in Italy. It was common for mid-sixteenth-century Tuscan families to name the eldest son after the parents' surname. Hence, Galileo Galilei was not necessarily named after his ancestor Galileo Bonaiuti. The Italian male given name \"Galileo\" (and thence the surname \"Galilei\") derives from the Latin \"Galilaeus\", meaning \"of Galilee\", a biblically significant region in Northern Israel. Because of that region, the adjective galilaios (Greek Γαλιλαῖος, Latin Galilaeus, Italian Galileo), which means \"Galilean\", was used in antiquity (particularly by emperor Julian) to refer to Christ and his followers.The biblical roots of Galileo's name and surname were to become the subject of a famous pun. In 1614, during the Galileo affair, one of Galileo's opponents, the Dominican priest Tommaso Caccini, delivered against Galileo a controversial and influential sermon. In it he made a point of quoting Acts 1:11, \"Ye men of Galilee, why stand ye gazing up into heaven?\" (in the Latin version found in the Vulgate: Viri Galilaei, quid statis aspicientes in caelum?).\n",
      "\n",
      "Children\n",
      "Despite being a genuinely pious Roman Catholic, Galileo fathered three children out of wedlock with Marina Gamba. They had two daughters, Virginia (born 1600) and Livia (born 1601), and a son, Vincenzo (born 1606).Due to their illegitimate birth, Galileo considered the girls unmarriageable, if not posing problems of prohibitively expensive support or dowries, which would have been similar to Galileo's previous extensive financial problems with two of his sisters. Their only worthy alternative was the religious life. Both girls were accepted by the convent of San Matteo in Arcetri and remained there for the rest of their lives.Virginia took the name Maria Celeste upon entering the convent. She died on 2 April 1634, and is buried with Galileo at the Basilica of Santa Croce, Florence. Livia took the name Sister Arcangela and was ill for most of her life. Vincenzo was later legitimised as the legal heir of Galileo and married Sestilia Bocchineri.\n",
      "\n",
      "Career and first scientific contributions\n",
      "Although Galileo seriously considered the priesthood as a young man, at his father's urging he instead enrolled in 1580 at the University of Pisa for a medical degree. He was influenced by the lectures of Girolamo Borro and Francesco Buonamici of Florence. In 1581, when he was studying medicine, he noticed a swinging chandelier, which air currents shifted about to swing in larger and smaller arcs. To him, it seemed, by comparison with his heartbeat, that the chandelier took the same amount of time to swing back and forth, no matter how far it was swinging. When he returned home, he set up two pendulums of equal length and swung one with a large sweep and the other with a small sweep and found that they kept time together. It was not until the work of Christiaan Huygens, almost one hundred years later, that the tautochrone nature of a swinging pendulum was used to create an accurate timepiece. Up to this point, Galileo had deliberately been kept away from mathematics, since a physician earned a higher income than a mathematician. However, after accidentally attending a lecture on geometry, he talked his reluctant father into letting him study mathematics and natural philosophy instead of medicine. He created a thermoscope, a forerunner of the thermometer, and, in 1586, published a small book on the design of a hydrostatic balance he had invented (which first brought him to the attention of the scholarly world). Galileo also studied disegno, a term encompassing fine art, and, in 1588, obtained the position of instructor in the Accademia delle Arti del Disegno in Florence, teaching perspective and chiaroscuro. In the same year, upon invitation by the Florentine Academy, he presented two lectures, On the Shape, Location, and Size of Dante's Inferno, in an attempt to propose a rigorous cosmological model of Dante's hell. Being inspired by the artistic tradition of the city and the works of the Renaissance artists, Galileo acquired an aesthetic mentality. While a young teacher at the Accademia, he began a lifelong friendship with the Florentine painter Cigoli.In 1589, he was appointed to the chair of mathematics in Pisa. In 1591, his father died, and he was entrusted with the care of his younger brother Michelagnolo. In 1592, he moved to the University of Padua where he taught geometry, mechanics, and astronomy until 1610. During this period, Galileo made significant discoveries in both pure fundamental science (for example, kinematics of motion and astronomy) as well as practical applied science (for example, strength of materials and pioneering the telescope). His multiple interests included the study of astrology, which at the time was a discipline tied to the studies of mathematics and astronomy.\n",
      "\n",
      "Astronomy\n",
      "Kepler's supernova\n",
      "Tycho Brahe and others had observed the supernova of 1572. Ottavio Brenzoni's letter of 15 January 1605 to Galileo brought the 1572 supernova and the less bright nova of 1601 to Galileo's notice. Galileo observed and discussed Kepler's Supernova in 1604. Since these new stars displayed no detectable diurnal parallax, Galileo concluded that they were distant stars, and, therefore, disproved the Aristotelian belief in the immutability of the heavens.\n",
      "\n",
      "Refracting telescope\n",
      "Based only on uncertain descriptions of the first practical telescope which Hans Lippershey tried to patent in the Netherlands in 1608, Galileo, in the following year, made a telescope with about 3x magnification. He later made improved versions with up to about 30x magnification. With a Galilean telescope, the observer could see magnified, upright images on the Earth—it was what is commonly known as a terrestrial telescope or a spyglass. He could also use it to observe the sky; for a time he was one of those who could construct telescopes good enough for that purpose. On 25 August 1609, he demonstrated one of his early telescopes, with a magnification of about 8 or 9, to Venetian lawmakers. His telescopes were also a profitable sideline for Galileo, who sold them to merchants who found them useful both at sea and as items of trade. He published his initial telescopic astronomical observations in March 1610 in a brief treatise entitled Sidereus Nuncius (Starry Messenger).\n",
      "\n",
      "Moon\n",
      "On 30 November 1609, Galileo aimed his telescope at the Moon. While not being the first person to observe the Moon through a telescope (English mathematician Thomas Harriot had done it four months before but only saw a \"strange spottednesse\"), Galileo was the first to deduce the cause of the uneven waning as light occlusion from lunar mountains and craters. In his study, he also made topographical charts, estimating the heights of the mountains. The Moon was not what was long thought to have been a translucent and perfect sphere, as Aristotle claimed, and hardly the first \"planet\", an \"eternal pearl to magnificently ascend into the heavenly empyrian\", as put forth by Dante. Galileo is sometimes credited with the discovery of the lunar libration in latitude in 1632, although Thomas Harriot or William Gilbert might have done it before.A friend of Galileo's, the painter Cigoli, included a realistic depiction of the Moon in one of his paintings, though probably used his own telescope to make the observation.\n",
      "\n",
      "Jupiter's moons\n",
      "On 7 January 1610, Galileo observed with his telescope what he described at the time as \"three fixed stars, totally invisible by their smallness\", all close to Jupiter, and lying on a straight line through it. Observations on subsequent nights showed that the positions of these \"stars\" relative to Jupiter were changing in a way that would have been inexplicable if they had really been fixed stars. On 10 January, Galileo noted that one of them had disappeared, an observation which he attributed to its being hidden behind Jupiter. Within a few days, he concluded that they were orbiting Jupiter: he had discovered three of Jupiter's four largest moons. He discovered the fourth on 13 January. Galileo named the group of four the Medicean stars, in honour of his future patron, Cosimo II de' Medici, Grand Duke of Tuscany, and Cosimo's three brothers. Later astronomers, however, renamed them Galilean satellites in honour of their discoverer. These satellites were independently discovered by Simon Marius on 8 January 1610 and are now called Io, Europa, Ganymede, and Callisto, the names given by Marius in his Mundus Iovialis published in 1614.\n",
      "Galileo's observations of the satellites of Jupiter caused controversy in astronomy: a planet with smaller planets orbiting it did not conform to the principles of Aristotelian cosmology, which held that all heavenly bodies should circle the Earth, and many astronomers and philosophers initially refused to believe that Galileo could have discovered such a thing. Compounding this problem, other astronomers had difficulty confirming Galileo's observations. When he demonstrated the telescope in Balogna, the attendees struggled to see the moons. One of them, Martin Horky, observed several stars and found them also surrounded by smaller stars. He took this as evidence that the moons were merely an internal defect of the instrument and that Galileo's imagination had run away with him. Horky's sharp attack drew a rebuke from Kepler but set the tone for later disputes. Christopher Clavius's observatory in Rome confirmed the observations and, although unsure how to interpret them, gave Galileo a hero's welcome when he visited the next year. Galileo continued to observe the satellites over the next eighteen months, and by mid-1611, he had obtained remarkably accurate estimates for their periods—a feat which Johannes Kepler had believed impossible.Galileo saw a practical use for his discovery. Determining the east–west position of ships at sea required their clocks be synchronized with clocks at the prime meridian. Solving this longitude problem had great importance to safe navigation and large prizes were established by Spain and later Holland for its solution. Since eclipses of the moons he discovered were relatively frequent and their times could be predicted with great accuracy, they could be used to set shipboard clocks and Galileo applied for the prizes. Observing the moons from a ship proved too difficult, but the method was used for land surveys, including the remapping of France.: 15–16\n",
      "\n",
      "Phases of Venus\n",
      "From September 1610, Galileo observed that Venus exhibits a full set of phases similar to that of the Moon. The heliocentric model of the Solar System developed by Nicolaus Copernicus predicted that all phases would be visible since the orbit of Venus around the Sun would cause its illuminated hemisphere to face the Earth when it was on the opposite side of the Sun and to face away from the Earth when it was on the Earth-side of the Sun. In Ptolemy's geocentric model, it was impossible for any of the planets' orbits to intersect the spherical shell carrying the Sun. Traditionally, the orbit of Venus was placed entirely on the near side of the Sun, where it could exhibit only crescent and new phases. It was also possible to place it entirely on the far side of the Sun, where it could exhibit only gibbous and full phases. After Galileo's telescopic observations of the crescent, gibbous and full phases of Venus, the Ptolemaic model became untenable. In the early 17th century, as a result of his discovery, the great majority of astronomers converted to one of the various geo-heliocentric planetary models, such as the Tychonic, Capellan and Extended Capellan models, each either with or without a daily rotating Earth. These all explained the phases of Venus without the 'refutation' of full heliocentrism's prediction of stellar parallax. Galileo's discovery of the phases of Venus was thus his most empirically practically influential contribution to the two-stage transition from full geocentrism to full heliocentrism via geo-heliocentrism.\n",
      "\n",
      "Saturn and Neptune\n",
      "In 1610, Galileo also observed the planet Saturn, and at first mistook its rings for planets, thinking it was a three-bodied system. When he observed the planet later, Saturn's rings were directly oriented to Earth, causing him to think that two of the bodies had disappeared. The rings reappeared when he observed the planet in 1616, further confusing him.Galileo observed the planet Neptune in 1612. It appears in his notebooks as one of many unremarkable dim stars. He did not realise that it was a planet, but he did note its motion relative to the stars before losing track of it.\n",
      "\n",
      "Sunspots\n",
      "Galileo made naked-eye and telescopic studies of sunspots. Their existence raised another difficulty with the unchanging perfection of the heavens as posited in orthodox Aristotelian celestial physics. An apparent annual variation in their trajectories, observed by Francesco Sizzi and others in 1612–1613, also provided a powerful argument against both the Ptolemaic system and the geoheliocentric system of Tycho Brahe. A dispute over claimed priority in the discovery of sunspots, and in their interpretation, led Galileo to a long and bitter feud with the Jesuit Christoph Scheiner. In the middle was Mark Welser, to whom Scheiner had announced his discovery, and who asked Galileo for his opinion. Both of them were unaware of Johannes Fabricius' earlier observation and publication of sunspots.\n",
      "\n",
      "Milky Way and stars\n",
      "Galileo observed the Milky Way, previously believed to be nebulous, and found it to be a multitude of stars packed so densely that they appeared from Earth to be clouds. He located many other stars too distant to be visible to the naked eye. He observed the double star Mizar in Ursa Major in 1617.In the Starry Messenger, Galileo reported that stars appeared as mere blazes of light, essentially unaltered in appearance by the telescope, and contrasted them to planets, which the telescope revealed to be discs. But shortly thereafter, in his Letters on Sunspots, he reported that the telescope revealed the shapes of both stars and planets to be \"quite round\". From that point forward, he continued to report that telescopes showed the roundness of stars, and that stars seen through the telescope measured a few seconds of arc in diameter. He also devised a method for measuring the apparent size of a star without a telescope. As described in his Dialogue Concerning the Two Chief World Systems, his method was to hang a thin rope in his line of sight to the star and measure the maximum distance from which it would wholly obscure the star. From his measurements of this distance and of the width of the rope, he could calculate the angle subtended by the star at his viewing point.In his Dialogue, he reported that he had found the apparent diameter of a star of first magnitude to be no more than 5 arcseconds, and that of one of sixth magnitude to be about 5/6 arcseconds. Like most astronomers of his day, Galileo did not recognise that the apparent sizes of stars that he measured were spurious, caused by diffraction and atmospheric distortion, and did not represent the true sizes of stars. However, Galileo's values were much smaller than previous estimates of the apparent sizes of the brightest stars, such as those made by Brahe, and enabled Galileo to counter anti-Copernican arguments such as those made by Tycho that these stars would have to be absurdly large for their annual parallaxes to be undetectable. Other astronomers such as Simon Marius, Giovanni Battista Riccioli, and Martinus Hortensius made similar measurements of stars, and Marius and Riccioli concluded the smaller sizes were not small enough to answer Tycho's argument.\n",
      "\n",
      "Theory of tides\n",
      "Cardinal Bellarmine had written in 1615 that the Copernican system could not be defended without \"a true physical demonstration that the sun does not circle the earth but the earth circles the sun\". Galileo considered his theory of the tides to provide such evidence. This theory was so important to him that he originally intended to call his Dialogue Concerning the Two Chief World Systems the Dialogue on the Ebb and Flow of the Sea. The reference to tides was removed from the title by order of the Inquisition.For Galileo, the tides were caused by the sloshing back and forth of water in the seas as a point on the Earth's surface sped up and slowed down because of the Earth's rotation on its axis and revolution around the Sun. He circulated his first account of the tides in 1616, addressed to Cardinal Orsini. His theory gave the first insight into the importance of the shapes of ocean basins in the size and timing of tides; he correctly accounted, for instance, for the negligible tides halfway along the Adriatic Sea compared to those at the ends. As a general account of the cause of tides, however, his theory was a failure.If this theory were correct, there would be only one high tide per day. Galileo and his contemporaries were aware of this inadequacy because there are two daily high tides at Venice instead of one, about 12 hours apart. Galileo dismissed this anomaly as the result of several secondary causes including the shape of the sea, its depth, and other factors. Albert Einstein later expressed the opinion that Galileo developed his \"fascinating arguments\" and accepted them uncritically out of a desire for physical proof of the motion of the Earth. Galileo also dismissed the idea, known from antiquity and by his contemporary Johannes Kepler, that the Moon caused the tides—Galileo also took no interest in Kepler's elliptical orbits of the planets. Galileo continued to argue in favour of his theory of tides, considering it the ultimate proof of Earth's motion.\n",
      "\n",
      "Controversy over comets and The Assayer\n",
      "In 1619, Galileo became embroiled in a controversy with Father Orazio Grassi, professor of mathematics at the Jesuit Collegio Romano. It began as a dispute over the nature of comets, but by the time Galileo had published The Assayer (Il Saggiatore) in 1623, his last salvo in the dispute, it had become a much wider controversy over the very nature of science itself. The title page of the book describes Galileo as a philosopher and \"Matematico Primario\" of the Grand Duke of Tuscany.Because The Assayer contains such a wealth of Galileo's ideas on how science should be practised, it has been referred to as his scientific manifesto. Early in 1619, Father Grassi had anonymously published a pamphlet, An Astronomical Disputation on the Three Comets of the Year 1618, which discussed the nature of a comet that had appeared late in November of the previous year. Grassi concluded that the comet was a fiery body that had moved along a segment of a great circle at a constant distance from the earth, and since it moved in the sky more slowly than the Moon, it must be farther away than the Moon.Grassi's arguments and conclusions were criticised in a subsequent article, Discourse on Comets, published under the name of one of Galileo's disciples, a Florentine lawyer named Mario Guiducci, although it had been largely written by Galileo himself. Galileo and Guiducci offered no definitive theory of their own on the nature of comets, although they did present some tentative conjectures that are now known to be mistaken. (The correct approach to the study of comets had been proposed at the time by Tycho Brahe.) In its opening passage, Galileo and Guiducci's Discourse gratuitously insulted the Jesuit Christoph Scheiner, and various uncomplimentary remarks about the professors of the Collegio Romano were scattered throughout the work. The Jesuits were offended, and Grassi soon replied with a polemical tract of his own, The Astronomical and Philosophical Balance, under the pseudonym Lothario Sarsio Sigensano, purporting to be one of his own pupils.The Assayer was Galileo's devastating reply to the Astronomical Balance. It has been widely recognized as a masterpiece of polemical literature, in which \"Sarsi's\" arguments are subjected to withering scorn. It was greeted with wide acclaim, and particularly pleased the new pope, Urban VIII, to whom it had been dedicated. In Rome, in the previous decade, Barberini, the future Urban VIII, had come down on the side of Galileo and the Lincean Academy.Galileo's dispute with Grassi permanently alienated many Jesuits, and Galileo and his friends were convinced that they were responsible for bringing about his later condemnation, although supporting evidence for this is not conclusive.\n",
      "\n",
      "Controversy over heliocentrism\n",
      "At the time of Galileo's conflict with the Church, the majority of educated people subscribed to the Aristotelian geocentric view that the Earth is the centre of the Universe and the orbit of all heavenly bodies, or Tycho Brahe's new system blending geocentrism with heliocentrism. Opposition to heliocentrism and Galileo's writings on it combined religious and scientific objections. Religious opposition to heliocentrism arose from biblical passages implying the fixed nature of the Earth. Scientific opposition came from Brahe, who argued that if heliocentrism were true, an annual stellar parallax should be observed, though none was at the time. Aristarchus and Copernicus had correctly postulated that parallax was negligible because the stars were so distant. However, Tycho countered that since stars appear to have measurable angular size, if the stars were that distant and their apparent size is due to their physical size, they would be far larger than the Sun. In fact, it is not possible to observe the physical size of distant stars without modern telescopes.Galileo defended heliocentrism based on his astronomical observations of 1609. In December 1613, the Grand Duchess Christina of Florence confronted one of Galileo's friends and followers, Benedetto Castelli, with biblical objections to the motion of the Earth. Prompted by this incident, Galileo wrote a letter to Castelli in which he argued that heliocentrism was actually not contrary to biblical texts, and that the Bible was an authority on faith and morals, not science. This letter was not published, but circulated widely. Two years later, Galileo wrote a letter to Christina that expanded his arguments previously made in eight pages to forty pages.By 1615, Galileo's writings on heliocentrism had been submitted to the Roman Inquisition by Father Niccolò Lorini, who claimed that Galileo and his followers were attempting to reinterpret the Bible, which was seen as a violation of the Council of Trent and looked dangerously like Protestantism. Lorini specifically cited Galileo's letter to Castelli. Galileo went to Rome to defend himself and his ideas. At the start of 1616, Francesco Ingoli initiated a debate with Galileo, sending him an essay disputing the Copernican system. Galileo later stated that he believed this essay to have been instrumental in the action against Copernicanism that followed. Ingoli may have been commissioned by the Inquisition to write an expert opinion on the controversy, with the essay providing the basis for the Inquisition's actions. The essay focused on eighteen physical and mathematical arguments against heliocentrism. It borrowed primarily from Tycho Brahe's arguments, notably that heliocentrism would require the stars as they appeared to be much larger than the Sun. The essay also included four theological arguments, but Ingoli suggested Galileo focus on the physical and mathematical arguments, and he did not mention Galileo's biblical ideas.In February 1616, an Inquisitorial commission declared heliocentrism to be \"foolish and absurd in philosophy, and formally heretical since it explicitly contradicts in many places the sense of Holy Scripture\". The Inquisition found that the idea of the Earth's movement \"receives the same judgement in philosophy and ... in regard to theological truth, it is at least erroneous in faith\". Pope Paul V instructed Cardinal Bellarmine to deliver this finding to Galileo, and to order him to abandon heliocentrism. On 26 February, Galileo was called to Bellarmine's residence and ordered \"to abandon completely ... the opinion that the sun stands still at the centre of the world and the Earth moves, and henceforth not to hold, teach, or defend it in any way whatever, either orally or in writing.\" The decree of the Congregation of the Index banned Copernicus's De Revolutionibus and other heliocentric works until correction.For the next decade, Galileo stayed well away from the controversy. He revived his project of writing a book on the subject, encouraged by the election of Cardinal Maffeo Barberini as Pope Urban VIII in 1623. Barberini was a friend and admirer of Galileo, and had opposed the admonition of Galileo in 1616. Galileo's resulting book, Dialogue Concerning the Two Chief World Systems, was published in 1632, with formal authorization from the Inquisition and papal permission.\n",
      "Earlier, Pope Urban VIII had personally asked Galileo to give arguments for and against heliocentrism in the book, and to be careful not to advocate heliocentrism. Whether unknowingly or deliberately, Simplicio, the defender of the Aristotelian geocentric view in Dialogue Concerning the Two Chief World Systems, was often caught in his own errors and sometimes came across as a fool. Indeed, although Galileo states in the preface of his book that the character is named after a famous Aristotelian philosopher (Simplicius in Latin, \"Simplicio\" in Italian), the name \"Simplicio\" in Italian also has the connotation of \"simpleton\". This portrayal of Simplicio made Dialogue Concerning the Two Chief World Systems appear as an advocacy book: an attack on Aristotelian geocentrism and defence of the Copernican theory.Most historians agree Galileo did not act out of malice and felt blindsided by the reaction to his book. However, the Pope did not take the suspected public ridicule lightly, nor the Copernican advocacy.Galileo had alienated one of his biggest and most powerful supporters, the Pope, and was called to Rome to defend his writings in September 1632. He finally arrived in February 1633 and was brought before inquisitor Vincenzo Maculani to be charged. Throughout his trial, Galileo steadfastly maintained that since 1616 he had faithfully kept his promise not to hold any of the condemned opinions, and initially he denied even defending them. However, he was eventually persuaded to admit that, contrary to his true intention, a reader of his Dialogue could well have obtained the impression that it was intended to be a defence of Copernicanism. In view of Galileo's rather implausible denial that he had ever held Copernican ideas after 1616 or ever intended to defend them in the Dialogue, his final interrogation, in July 1633, concluded with his being threatened with torture if he did not tell the truth, but he maintained his denial despite the threat.The sentence of the Inquisition was delivered on 22 June. It was in three essential parts:\n",
      "\n",
      "Galileo was found \"vehemently suspect of heresy\" (though he was never formally charged with heresy, relieving him of facing corporal punishment), namely of having held the opinions that the Sun lies motionless at the centre of the universe, that the Earth is not at its centre and moves, and that one may hold and defend an opinion as probable after it has been declared contrary to Holy Scripture. He was required to \"abjure, curse and detest\" those opinions.\n",
      "He was sentenced to formal imprisonment at the pleasure of the Inquisition. On the following day, this was commuted to house arrest, under which he remained for the rest of his life.\n",
      "His offending Dialogue was banned; and in an action not announced at the trial, publication of any of his works was forbidden, including any he might write in the future.According to popular legend, after recanting his theory that the Earth moved around the Sun, Galileo allegedly muttered the rebellious phrase \"And yet it moves\". There was a claim that a 1640s painting by the Spanish painter Bartolomé Esteban Murillo or an artist of his school, in which the words were hidden until restoration work in 1911, depicts an imprisoned Galileo apparently gazing at the words \"E pur si muove\" written on the wall of his dungeon. The earliest known written account of the legend dates to a century after his death. Based on the painting, Stillman Drake wrote  \"there is no doubt now that the famous words were already attributed to Galileo before his death\". However, an intensive investigation by astrophysicist Mario Livio has revealed that said painting is most probably a copy of an 1837 painting by the Flemish painter Roman-Eugene Van Maldeghem.After a period with the friendly Ascanio Piccolomini (the Archbishop of Siena), Galileo was allowed to return to his villa at Arcetri near Florence in 1634, where he spent part of his life under house arrest. Galileo was ordered to read the Seven Penitential Psalms once a week for the next three years. However, his daughter Maria Celeste relieved him of the burden after securing ecclesiastical permission to take it upon herself.It was while Galileo was under house arrest that he dedicated his time to one of his finest works, Two New Sciences. Here he summarised work he had done some forty years earlier, on the two sciences now called kinematics and strength of materials, published in Holland to avoid the censor. This book was highly praised by Albert Einstein. As a result of this work, Galileo is often called the \"father of modern physics\". He went completely blind in 1638 and developed a painful hernia and insomnia, so he was permitted to travel to Florence for medical advice.Dava Sobel argues that prior to Galileo's 1633 trial and judgement for heresy, Pope Urban VIII had become preoccupied with court intrigue and problems of state and began to fear persecution or threats to his own life. In this context, Sobel argues that the problem of Galileo was presented to the pope by court insiders and enemies of Galileo. Having been accused of weakness in defending the church, Urban reacted against Galileo out of anger and fear. Mario Livio places Galileo and his discoveries in modern scientific and social contexts. In particular, he argues that the Galileo affair has its counterpart in science denial.\n",
      "\n",
      "Death\n",
      "Galileo continued to receive visitors until his death on 8 January 1642, aged 77, following a fever and heart palpitations. The Grand Duke of Tuscany, Ferdinando II, wished to bury him in the main body of the Basilica of Santa Croce, next to the tombs of his father and other ancestors, and to erect a marble mausoleum in his honour.\n",
      "These plans were dropped, however, after Pope Urban VIII and his nephew, Cardinal Francesco Barberini, protested, because Galileo had been condemned by the Catholic Church for \"vehement suspicion of heresy\". He was instead buried in a small room next to the novices' chapel at the end of a corridor from the southern transept of the basilica to the sacristy. He was reburied in the main body of the basilica in 1737 after a monument had been erected there in his honour; during this move, three fingers and a tooth were removed from his remains. One of these fingers is currently on exhibition at the Museo Galileo in Florence, Italy.\n",
      "\n",
      "Scientific contributions\n",
      "This and other facts, not few in number or less worth knowing, I have succeeded in proving; and what I consider more important, there have been opened up to this vast and most excellent science, of which my work is merely the beginning, ways and means by which other minds more acute than mine will explore its remote corners.\n",
      "\n",
      "Scientific methods\n",
      "Galileo made original contributions to the science of motion through an innovative combination of experiments and mathematics. More typical of science at the time were the qualitative studies of William Gilbert, on magnetism and electricity. Galileo's father, Vincenzo Galilei, a lutenist and music theorist, had performed experiments establishing perhaps the oldest known non-linear relation in physics: for a stretched string, the pitch varies as the square root of the tension. These observations lay within the framework of the Pythagorean tradition of music, well known to instrument makers, which included the fact that subdividing a string by a whole number produces a harmonious scale. Thus, a limited amount of mathematics had long related to music and physical science, and young Galileo could see his own father's observations expand on that tradition.Galileo was one of the first modern thinkers to clearly state that the laws of nature are mathematical. In The Assayer, he wrote \"Philosophy is written in this grand book, the universe ... It is written in the language of mathematics, and its characters are triangles, circles, and other geometric figures;....\" His mathematical analyses are a further development of a tradition employed by late scholastic natural philosophers, which Galileo learned when he studied philosophy. His work marked another step towards the eventual separation of science from both philosophy and religion; a major development in human thought. He was often willing to change his views in accordance with observation.\n",
      "In order to perform his experiments, Galileo had to set up standards of length and time, so that measurements made on different days and in different laboratories could be compared in a reproducible fashion. This provided a reliable foundation on which to confirm mathematical laws using inductive reasoning. Galileo showed a modern appreciation for the proper relationship between mathematics, theoretical physics, and experimental physics. He understood the parabola, both in terms of conic sections and in terms of the ordinate (y) varying as the square of the abscissa (x). Galileo further asserted that the parabola was the theoretically ideal trajectory of a uniformly accelerated projectile in the absence of air resistance or other disturbances. He conceded that there are limits to the validity of this theory, noting on theoretical grounds that a projectile trajectory of a size comparable to that of the Earth could not possibly be a parabola, but he nevertheless maintained that for distances up to the range of the artillery of his day, the deviation of a projectile's trajectory from a parabola would be only very slight.\n",
      "\n",
      "Astronomy\n",
      "Using his refracting telescope, Galileo observed in late 1609 that the surface of the Moon is not smooth. Early the next year, he observed the four largest moons of Jupiter. Later in 1610, he observed the phases of Venus—a proof of heliocentrism—as well as Saturn, though he thought the planet's rings were two other planets. In 1612, he observed Neptune and noted its motion, but did not identify it as a planet.Galileo made studies of sunspots, the Milky Way, and made various observations about stars, including how to measure their apparent size without a telescope.He coined the term Aurora Borealis in 1619 from the Roman goddess of the dawn and the Greek name for the north wind, to describe lights in the northern and southern sky when particles from the solar wind energise the magnetosphere.\n",
      "\n",
      "Engineering\n",
      "Galileo made a number of contributions to what is now known as engineering, as distinct from pure physics. Between 1595 and 1598, Galileo devised and improved a geometric and military compass suitable for use by gunners and surveyors. This expanded on earlier instruments designed by Niccolò Tartaglia and Guidobaldo del Monte. For gunners, it offered, in addition to a new and safer way of elevating cannons accurately, a way of quickly computing the charge of gunpowder for cannonballs of different sizes and materials. As a geometric instrument, it enabled the construction of any regular polygon, computation of the area of any polygon or circular sector, and a variety of other calculations. Under Galileo's direction, instrument maker Marc'Antonio Mazzoleni produced more than 100 of these compasses, which Galileo sold (along with an instruction manual he wrote) for 50 lire and offered a course of instruction in the use of the compasses for 120 lire.In 1593, Galileo constructed a thermometer, using the expansion and contraction of air in a bulb to move water in an attached tube.In 1609, Galileo was, along with Englishman Thomas Harriot and others, among the first to use a refracting telescope as an instrument to observe stars, planets or moons. The name \"telescope\" was coined for Galileo's instrument by a Greek mathematician, Giovanni Demisiani, at a banquet held in 1611 by Prince Federico Cesi to make Galileo a member of his Accademia dei Lincei. In 1610, he used a telescope at close range to magnify the parts of insects. By 1624, Galileo had used a compound microscope. He gave one of these instruments to Cardinal Zollern in May of that year for presentation to the Duke of Bavaria, and in September, he sent another to Prince Cesi. The Linceans played a role again in naming the \"microscope\" a year later when fellow academy member Giovanni Faber coined the word for Galileo's invention from the Greek words μικρόν (micron) meaning \"small\", and σκοπεῖν (skopein) meaning \"to look at\". The word was meant to be analogous with \"telescope\". Illustrations of insects made using one of Galileo's microscopes and published in 1625, appear to have been the first clear documentation of the use of a compound microscope.\n",
      "In 1612, having determined the orbital periods of Jupiter's satellites, Galileo proposed that with sufficiently accurate knowledge of their orbits, one could use their positions as a universal clock, and this would make possible the determination of longitude. He worked on this problem from time to time during the remainder of his life, but the practical problems were severe. The method was first successfully applied by Giovanni Domenico Cassini in 1681 and was later used extensively for large land surveys; this method, for example, was used to survey France, and later by Zebulon Pike of the midwestern United States in 1806. For sea navigation, where delicate telescopic observations were more difficult, the longitude problem eventually required the development of a practical portable marine chronometer, such as that of John Harrison. Late in his life, when totally blind, Galileo designed an escapement mechanism for a pendulum clock (called Galileo's escapement), although no clock using this was built until after the first fully operational pendulum clock was made by Christiaan Huygens in the 1650s.Galileo was invited on several occasions to advise on engineering schemes to alleviate river flooding. In 1630 Mario Guiducci was probably instrumental in ensuring that he was consulted on a scheme by Bartolotti to cut a new channel for the Bisenzio River near Florence.\n",
      "\n",
      "Physics\n",
      "Galileo's theoretical and experimental work on the motions of bodies, along with the largely independent work of Kepler and René Descartes, was a precursor of the classical mechanics developed by Sir Isaac Newton.\n",
      "\n",
      "Pendulum\n",
      "Galileo conducted several experiments with pendulums. It is popularly believed (thanks to the biography by Vincenzo Viviani) that these began by watching the swings of the bronze chandelier in the cathedral of Pisa, using his pulse as a timer.  The first recorded interest in pendulums made by Galileo were in his posthumously published notes titled On Motion, but later experiments are described in his Two New Sciences. Galileo claimed that a simple pendulum is isochronous, i.e. that its swings always take the same amount of time, independently of the amplitude. In fact, this is only approximately true, as was discovered by Christiaan Huygens. Galileo also found that the square of the period varies directly with the length of the pendulum.\n",
      "\n",
      "Pendulum clock\n",
      "Galileo's son, Vincenzo, sketched a clock based on his father's theories in 1642. The clock was never built and, because of the large swings required by its verge escapement, would have been a poor timekeeper.\n",
      "\n",
      "Sound frequency\n",
      "Galileo is lesser known for, yet still credited with, being one of the first to understand sound frequency. By scraping a chisel at different speeds, he linked the pitch of the sound produced to the spacing of the chisel's skips, a measure of frequency.\n",
      "\n",
      "Water pump\n",
      "By the 17th century, water pump designs had improved to the point that they produced measurable vacuums, but this was not immediately understood. What was known was that suction pumps could not pull water beyond a certain height: 18 Florentine yards according to a measurement taken around 1635, or about 34 feet (10 m). This limit was a concern in irrigation projects, mine drainage, and decorative water fountains planned by the Duke of Tuscany, so the duke commissioned Galileo to investigate the problem. In his Two New Sciences (1638) Galileo suggested, incorrectly, that the column of water pulled up by a water pump would break of its own weight once reaching beyond 34 feet.\n",
      "\n",
      "Speed of light\n",
      "In 1638, Galileo described an experimental method to measure the speed of light by arranging that two observers, each having lanterns equipped with shutters, observe each other's lanterns at some distance. The first observer opens the shutter of his lamp, and, the second, upon seeing the light, immediately opens the shutter of his own lantern. The time between the first observer's opening his shutter and seeing the light from the second observer's lamp indicates the time it takes light to travel back and forth between the two observers. Galileo reported that when he tried this at a distance of less than a mile, he was unable to determine whether or not the light appeared instantaneously. Sometime between Galileo's death and 1667, the members of the Florentine Accademia del Cimento repeated the experiment over a distance of about a mile and obtained a similarly inconclusive result. The speed of light has since been determined to be far too fast to be measured by such methods.\n",
      "\n",
      "Galilean invariance\n",
      "Galileo put forward the basic principle of relativity, that the laws of physics are the same in any system that is moving at a constant speed in a straight line, regardless of its particular speed or direction. Hence, there is no absolute motion or absolute rest. This principle provided the basic framework for Newton's laws of motion and is central to Einstein's special theory of relativity.\n",
      "\n",
      "Falling bodies\n",
      "John Philoponus, Nicole Oresme, and Domingo de Soto\n",
      "That unequal weights would fall with the same speed may have been proposed as early as by the Roman philosopher Lucretius. Observations that similarly sized objects of different weights fall at the same speed is documented in sixth century works by John Philoponus, which Galileo was aware of. In the 14th century, Nicole Oresme had derived the time-squared law for uniformly accelerated change, and in the 16th century, Domingo de Soto had suggested that bodies falling through a homogeneous medium would be uniformly accelerated. De Soto, however, did not anticipate many of the qualifications and refinements contained in Galileo's theory of falling bodies. He did not, for instance, recognise, as Galileo did, that a body would fall with a strictly uniform acceleration only in a vacuum, and that it would otherwise eventually reach a uniform terminal velocity.\n",
      "\n",
      "Delft tower experiment\n",
      "In 1586, Simon Stevin (commonly known as Stevinus) and Jan Cornets de Groot dropped lead balls from the Nieuwe Kerk in the Dutch city of Delft. The experiment established that objects of identical size, but different masses, fall at the same speed.  While the Delft tower experiment had been a success, it was not conducted with the same scientific rigor that later experiments were. Stevin was forced to rely on audio feedback (caused by the spheres impacting a wooden platform below) to deduce that the balls had fallen at the same speed. The experiment was given less credence than the more substantive work of Galileo Galilei and his famous Leaning Tower of Pisa thought experiment of 1589.\n",
      "\n",
      "Leaning Tower of Pisa experiment\n",
      "A biography by Galileo's pupil Vincenzo Viviani stated that Galileo had dropped balls of the same material, but different masses, from the Leaning Tower of Pisa to demonstrate that their time of descent was independent of their mass. This was contrary to what Aristotle had taught: that heavy objects fall faster than lighter ones, in direct proportion to weight. While this story has been retold in popular accounts, there is no account by Galileo himself of such an experiment, and it is generally accepted by historians that it was at most a thought experiment which did not actually take place. An exception is Stillman Drake, who argues that the experiment did take place, more or less as Viviani described it. However, most of Galileo's experiments with falling bodies were carried out using inclined planes where both the issues of timing and air resistance were much reduced.\n",
      "\n",
      "Two New Sciences\n",
      "In his 1638 Two New Sciences, Galileo's character Salviati, widely regarded as Galileo's spokesman, held that all unequal weights would fall with the same finite speed in a vacuum. Salviati also held that this could be experimentally demonstrated by the comparison of pendulum motions in air with bobs of lead and of cork which had different weights but which were otherwise similar.\n",
      "\n",
      "Time-squared law\n",
      "Galileo proposed that a falling body would fall with a uniform acceleration, as long as the resistance of the medium through which it was falling remained negligible, or in the limiting case of its falling through a vacuum. He also derived the correct kinematical law for the distance travelled during a uniform acceleration starting from rest—namely, that it is proportional to the square of the elapsed time (d∝t2). Galileo expressed the time-squared law using geometrical constructions and mathematically precise words, adhering to the standards of the day. (It remained for others to re-express the law in algebraic terms.)\n",
      "\n",
      "Inertia\n",
      "Galileo also concluded that objects retain their velocity in the absence of any impediments to their motion, thereby contradicting the generally accepted Aristotelian hypothesis that a body could only remain in so-called \"violent\", \"unnatural\", or \"forced\" motion so long as an agent of change (the \"mover\") continued to act on it. Philosophical ideas relating to inertia had been proposed by John Philoponus and Jean Buridan. Galileo stated:\n",
      "Imagine any particle projected along a horizontal plane without friction; then we know, from what has been more fully explained in the preceding pages, that this particle will move along this same plane with a motion which is uniform and perpetual, provided the plane has no limits.\n",
      "But the surface of the earth would be an instance of such a plane if all its unevenness could be removed. This was incorporated into Newton's laws of motion (first law), except for the direction of the motion: Newton's is straight, Galileo's is circular (for example, the planets' motion around the Sun, which according to him, and unlike Newton, takes place in absence of gravity). According to Dijksterhuis Galileo's conception of inertia as a tendency to persevere in circular motion is closely related to his Copernican conviction.\n",
      "\n",
      "Mathematics\n",
      "While Galileo's application of mathematics to experimental physics was innovative, his mathematical methods were the standard ones of the day, including dozens of examples of an inverse proportion square root method passed down from Fibonacci and Archimedes. The analysis and proofs relied heavily on the Eudoxian theory of proportion, as set forth in the fifth book of Euclid's Elements. This theory had become available only a century before, thanks to accurate translations by Tartaglia and others; but by the end of Galileo's life, it was being superseded by the algebraic methods of Descartes. The concept now named Galileo's paradox was not original with him. His proposed solution, that infinite numbers cannot be compared, is no longer considered useful.\n",
      "\n",
      "Legacy\n",
      "Later Church reassessments\n",
      "The Galileo affair was largely forgotten after Galileo's death, and the controversy subsided. The Inquisition's ban on reprinting Galileo's works was lifted in 1718 when permission was granted to publish an edition of his works (excluding the condemned Dialogue) in Florence. In 1741, Pope Benedict XIV authorised the publication of an edition of Galileo's complete scientific works which included a mildly censored version of the Dialogue. In 1758, the general prohibition against works advocating heliocentrism was removed from the Index of prohibited books, although the specific ban on uncensored versions of the Dialogue and Copernicus's De Revolutionibus remained. All traces of official opposition to heliocentrism by the church disappeared in 1835 when these works were finally dropped from the Index.Interest in the Galileo affair was revived in the early 19th century when Protestant polemicists used it (and other events such as the Spanish Inquisition and the myth of the flat Earth) to attack Roman Catholicism. Interest in it has waxed and waned ever since. In 1939, Pope Pius XII, in his first speech to the Pontifical Academy of Sciences, within a few months of his election to the papacy, described Galileo as being among the \"most audacious heroes of research... not afraid of the stumbling blocks and the risks on the way, nor fearful of the funereal monuments\". His close advisor of 40 years, Professor Robert Leiber, wrote: \"Pius XII was very careful not to close any doors (to science) prematurely. He was energetic on this point and regretted that in the case of Galileo.\"On 15 February 1990, in a speech delivered at the Sapienza University of Rome, Cardinal Ratzinger (later Pope Benedict XVI) cited some current views on the Galileo affair as forming what he called \"a symptomatic case that permits us to see how deep the self-doubt of the modern age, of science and technology goes today\". Some of the views he cited were those of the philosopher Paul Feyerabend, whom he quoted as saying: \"The Church at the time of Galileo kept much more closely to reason than did Galileo himself, and she took into consideration the ethical and social consequences of Galileo's teaching too. Her verdict against Galileo was rational and just and the revision of this verdict can be justified only on the grounds of what is politically opportune.\" The Cardinal did not clearly indicate whether he agreed or disagreed with Feyerabend's assertions. He did, however, say: \"It would be foolish to construct an impulsive apologetic on the basis of such views.\"On 31 October 1992, Pope John Paul II acknowledged that the Inquisition had erred in condemning Galileo for asserting that the Earth revolves around the Sun. \"John Paul said the theologians who condemned Galileo did not recognize the formal distinction between the Bible and its interpretation.\"In March 2008, the head of the Pontifical Academy of Sciences, Nicola Cabibbo, announced a plan to honour Galileo by erecting a statue of him inside the Vatican walls. In December of the same year, during events to mark the 400th anniversary of Galileo's earliest telescopic observations, Pope Benedict XVI praised his contributions to astronomy. A month later, however, the head of the Pontifical Council for Culture, Gianfranco Ravasi, revealed that the plan to erect a statue of Galileo on the grounds of the Vatican had been suspended.\n",
      "\n",
      "Impact on modern science\n",
      "According to Stephen Hawking, Galileo probably bears more of the responsibility for the birth of modern science than anybody else, and Albert Einstein called him the father of modern science.Galileo's astronomical discoveries and investigations into the Copernican theory have led to a lasting legacy which includes the categorisation of the four large moons of Jupiter discovered by Galileo (Io, Europa, Ganymede and Callisto) as the Galilean moons. Other scientific endeavours and principles are named after Galileo including the Galileo spacecraft, the first spacecraft to enter orbit around Jupiter, the Galileo global satellite navigation system, the transformation between inertial systems in classical mechanics denoted Galilean transformation and the Gal (unit), sometimes known as the Galileo, which is a non-SI unit of acceleration.Partly because the year 2009 was the fourth centenary of Galileo's first recorded astronomical observations with the telescope, the United Nations scheduled it to be the International Year of Astronomy. A global scheme was laid out by the International Astronomical Union (IAU), also endorsed by UNESCO—the UN body responsible for educational, scientific and cultural matters. The International Year of Astronomy 2009 was intended to be a global celebration of astronomy and its contributions to society and culture, stimulating worldwide interest not only in astronomy but science in general, with a particular slant towards young people.Planet Galileo and asteroid 697 Galilea are named in his honour.\n",
      "\n",
      "In artistic and popular media\n",
      "Galileo is mentioned several times in the \"opera\" section of the Queen song, \"Bohemian Rhapsody\". He features prominently in the song \"Galileo\" performed by the Indigo Girls and Amy Grant's \"Galileo\" on her Heart in Motion album.Twentieth-century plays have been written on Galileo's life, including Life of Galileo (1943) by the German playwright Bertolt Brecht, with a film adaptation (1975) of it, and Lamp at Midnight (1947) by Barrie Stavis, as well as the 2008 play \"Galileo Galilei\".Kim Stanley Robinson wrote a science fiction novel entitled Galileo's Dream (2009), in which Galileo is brought into the future to help resolve a crisis of scientific philosophy; the story moves back and forth between Galileo's own time and a hypothetical distant future and contains a great deal of biographical information.Galileo Galilei was recently selected as a main motif for a high-value collectors' coin: the €25 International Year of Astronomy commemorative coin, minted in 2009. This coin also commemorates the 400th anniversary of the invention of Galileo's telescope. The obverse shows a portion of his portrait and his telescope. The background shows one of his first drawings of the surface of the moon. In the silver ring, other telescopes are depicted: the Isaac Newton Telescope, the observatory in Kremsmünster Abbey, a modern telescope, a radio telescope and a space telescope. In 2009, the Galileoscope was also released. This is a mass-produced, low-cost educational 2-inch (51 mm) telescope with relatively high quality.\n",
      "\n",
      "Writings\n",
      "Galileo's early works describing scientific instruments include the 1586 tract entitled The Little Balance (La Billancetta) describing an accurate balance to weigh objects in air or water and the 1606 printed manual Le Operazioni del Compasso Geometrico et Militare on the operation of a geometrical and military compass.His early works on dynamics, the science of motion and mechanics were his circa 1590 Pisan De Motu (On Motion) and his circa 1600 Paduan Le Meccaniche (Mechanics). The former was based on Aristotelian–Archimedean fluid dynamics and held that the speed of gravitational fall in a fluid medium was proportional to the excess of a body's specific weight over that of the medium, whereby in a vacuum, bodies would fall with speeds in proportion to their specific weights. It also subscribed to the Philoponan impetus dynamics in which impetus is self-dissipating and free-fall in a vacuum would have an essential terminal speed according to specific weight after an initial period of acceleration.Galileo's 1610 The Starry Messenger (Sidereus Nuncius) was the first scientific treatise to be published based on observations made through a telescope. It reported his discoveries of:\n",
      "\n",
      "the Galilean moons\n",
      "the roughness of the Moon's surface\n",
      "the existence of a large number of stars invisible to the naked eye, particularly those responsible for the appearance of the Milky Way\n",
      "differences between the appearances of the planets and those of the fixed stars—the former appearing as small discs, while the latter appeared as unmagnified points of lightGalileo published a description of sunspots in 1613 entitled Letters on Sunspots suggesting the Sun and heavens are corruptible. The Letters on Sunspots also reported his 1610 telescopic observations of the full set of phases of Venus, and his discovery of the puzzling \"appendages\" of Saturn and their even more puzzling subsequent disappearance. In 1615, Galileo prepared a manuscript known as the \"Letter to the Grand Duchess Christina\" which was not published in printed form until 1636. This letter was a revised version of the Letter to Castelli, which was denounced by the Inquisition as an incursion upon theology by advocating Copernicanism both as physically true and as consistent with Scripture. In 1616, after the order by the Inquisition for Galileo not to hold or defend the Copernican position, Galileo wrote the \"Discourse on the Tides\" (Discorso sul flusso e il reflusso del mare) based on the Copernican earth, in the form of a private letter to Cardinal Orsini. In 1619, Mario Guiducci, a pupil of Galileo's, published a lecture written largely by Galileo under the title Discourse on the Comets (Discorso Delle Comete), arguing against the Jesuit interpretation of comets.In 1623, Galileo published The Assayer—Il Saggiatore, which attacked theories based on Aristotle's authority and promoted experimentation and the mathematical formulation of scientific ideas. The book was highly successful and even found support among the higher echelons of the Christian church. Following the success of The Assayer, Galileo published the Dialogue Concerning the Two Chief World Systems (Dialogo sopra i due massimi sistemi del mondo) in 1632. Despite taking care to adhere to the Inquisition's 1616 instructions, the claims in the book favouring Copernican theory and a non-geocentric model of the solar system led to Galileo being tried and banned from publication. Despite the publication ban, Galileo published his Discourses and Mathematical Demonstrations Relating to Two New Sciences (Discorsi e Dimostrazioni Matematiche, intorno a due nuove scienze) in 1638 in Holland, outside the jurisdiction of the Inquisition.\n",
      "\n",
      "Published written works\n",
      "Galileo's main written works are as follows:\n",
      "The Little Balance (1586; in Italian: La Bilancetta)\n",
      "On Motion (c. 1590; in Latin: De Motu Antiquiora)\n",
      "Mechanics (c. 1600; in Italian: Le Meccaniche)\n",
      "The Operations of Geometrical and Military Compass (1606; in Italian: Le operazioni del compasso geometrico et militare)\n",
      "The Starry Messenger (1610; in Latin: Sidereus Nuncius)\n",
      "Discourse on Floating Bodies (1612; in Italian: Discorso intorno alle cose che stanno in su l'acqua, o che in quella si muovono, \"Discourse on Bodies that Stay Atop Water, or Move in It\")\n",
      "History and Demonstration Concerning Sunspots (1613; in Italian: Istoria e dimostrazioni intorno alle macchie solari; work based on the Three Letters on Sunspots, Tre lettere sulle macchie solari, 1612)\n",
      "\"Letter to the Grand Duchess Christina\" (1615; published in 1636)\n",
      "\"Discourse on the Tides\" (1616; in Italian: Discorso del flusso e reflusso del mare)\n",
      "Discourse on the Comets (1619; in Italian: Discorso delle Comete)\n",
      "The Assayer (1623; in Italian: Il Saggiatore)\n",
      "Dialogue Concerning the Two Chief World Systems (1632; in Italian: Dialogo sopra i due massimi sistemi del mondo)\n",
      "Discourses and Mathematical Demonstrations Relating to Two New Sciences (1638; in Italian: Discorsi e Dimostrazioni Matematiche, intorno a due nuove scienze)\n",
      "\n",
      "Personal library\n",
      "In the last years of his life, Galileo Galilei kept a library of at least 598 volumes (560 of which have been identified) at Villa Il Gioiello, on the outskirts of Florence. Under the restrictions of house arrest, he was forbidden to write or publish his ideas. However, he continued to receive visitors right up to his death and it was through them that he remained supplied with the latest scientific texts from Northern Europe.With his past experience, Galileo may have feared that his collection of books and manuscripts would be seized by the authorities and burned, as no reference to such items was made in his last will and testament. An itemized inventory was only later produced after Galileo's death, when the majority of his possessions including his library passed to his son, Vincenzo Galilei Jr. On his death in 1649, the collection was inherited by his wife Sestilia Bocchineri.Galileo's books, personal papers and unedited manuscripts were then collected by Vincenzo Viviani, his former assistant and student, with the intent of preserving his old teacher's works in published form. It was a project that never materialised and in his final will, Viviani bequeathed a significant portion of the collection to the Hospital of Santa Maria Nuova in Florence, where there already existed an extensive library. The value of Galileo's possessions was not realised, and duplicate copies were dispersed to other libraries, such as the Biblioteca Comunale degli Intronati, the public library in Sienna. In a later attempt to specialise the library's holdings, volumes unrelated to medicine were transferred to the Biblioteca Magliabechiana, an early foundation for what was to become the Biblioteca Nazionale Centrale di Firenze, the National Central Library in Florence.A small portion of Viviani's collection, including the manuscripts of Galileo and those of his peers Evangelista Torricelli and Benedetto Castelli, were left to his nephew, Abbot Jacopo Panzanini. This minor collection was preserved until Panzanini's death when it passed to his great-nephews, Carlo and Angelo Panzanini. The books from both Galileo and Viviani's collections began to disperse as the heirs failed to protect their inheritance. Their servants sold several of the volumes for waste paper. Around 1750 the Florentine senator Giovanni Battista Clemente de'Nelli heard of this and purchased the books and manuscripts from the shopkeepers, and the remainder of Viviani's collection from the Panzanini brothers. As recounted in Nelli's memoirs: \"My great fortune in obtaining such a wonderful treasure so cheaply came about through the ignorance of the people selling it, who were not aware of the value of those manuscripts...\"\n",
      "The library remained in Nelli's care until his death in 1793. Knowing the value of their father's collected manuscripts, Nelli's sons attempted to sell what was left to them to the French government. Grand Duke Ferdinand III of Tuscany intervened in the sale and purchased the entire collection. The archive of manuscripts, printed books and personal papers were deposited with the Biblioteca Palatina in Florence, merging the collection with the Biblioteca Magliabechiana in 1861.\n",
      "\n",
      "See also\n",
      "Catholic Church and science\n",
      "Seconds pendulum\n",
      "Tribune of Galileo\n",
      "Villa Il Gioiello\n",
      "\n",
      "Notes\n",
      "References\n",
      "Citations\n",
      "General sources\n",
      "Further reading\n",
      "External links\n",
      "\n",
      "Works by Galileo Galilei at Open Library\n",
      "Works by Galileo Galilei at Project Gutenberg\n",
      "Works by Galileo Galilei at LibriVox (public domain audiobooks) \n",
      "Works by or about Galileo Galilei at Internet Archive\n",
      "Works in Galileo's Personal Library at LibraryThingBiofuel is a fuel that is produced over a short period from biomass, rather than by the very slow natural processes involved in the formation of fossil fuels, such as oil. Biofuel can be produced from plants or agricultural, domestic, or industrial biowaste. Biofuels are mostly used for transportation but can also be used for heating and electricity.: 173  Biofuels (and bioenergy in general) are regarded as a renewable energy source.: 11  However, the use of biofuel has been controversial because of the several disadvantages associated with the use of it. These include for example (and this varies on a case-by-case basis): the \"food vs fuel\" debate, biofuel production methods being sustainable or not, leading to deforestation and loss of biodiversity or not. \n",
      "In general, biofuels emit fewer greenhouse gas emissions when burned in an engine and are generally considered carbon-neutral fuels as the carbon emitted has been captured from the atmosphere by the crops used in production. However, life-cycle assessments of biofuels have shown large emissions associated with the potential land-use change required to produce additional biofuel feedstocks. Estimates about the climate impact from biofuels vary widely based on the methodology and exact situation examined. Therefore, the climate change mitigation potential of biofuel varies considerably: in some scenarios, emission levels are comparable to fossil fuels and in other scenarios the biofuel emissions result in negative emissions.   \n",
      "The two most common types of biofuel are bioethanol and biodiesel. Brazil is the largest producer of bioethanol, while the EU is the largest producer of biodiesel. The energy content in the global production of bioethanol and biodiesel is 2.2 and 1.8 EJ per year, respectively. Demand for aviation biofuel is forecast to increase.Bioethanol is an alcohol made by fermentation, mostly from carbohydrates produced in sugar or starch crops such as maize, sugarcane, or sweet sorghum. Cellulosic biomass, derived from non-food sources, such as trees and grasses, is also being developed as a feedstock for ethanol production. Ethanol can be used as a fuel for vehicles in its pure form (E100), but it is usually used as a gasoline additive to increase octane ratings and improve vehicle emissions.\n",
      "\n",
      "Biodiesel is produced from oils or fats using transesterification. It can be used as a fuel for vehicles in its pure form (B100), but it is usually used as a diesel additive to reduce levels of particulates, carbon monoxide, and hydrocarbons from diesel-powered vehicles.\n",
      "\n",
      "Terminology\n",
      "The term \"biofuel\" is used in different ways. One definition is \"Biofuels are biobased products, in solid, liquid, or gaseous forms. They are produced from crops or natural products, such as wood, or agricultural residues, such as molasses and bagasse.\": 173 Other publications reserve the term biofuel for liquid or gaseous fuels, used for transportation.\n",
      "\n",
      "Conventional biofuels (first generation)\n",
      "First-generation biofuels (also denoted as \"conventional biofuels\") are made from food crops grown on arable land.: 447  The crop's sugar, starch, or oil content is converted into biodiesel or ethanol, using transesterification, or yeast fermentation.The main advantage of First-Generation biofuels is how readily available and relatively easy they are to use. However, the downsides greatly outweigh the potential benefits associated with the use of First-Generation biofuels because they are low in efficiency but produce mass quantities of particle matter and pollutants.\n",
      "\n",
      "Advanced biofuels (second generation)\n",
      "To avoid a \"food versus fuel\" dilemma, second-generation biofuels (also called advanced biofuels or sustainable biofuels) are made from waste products. These are derived from agriculture and forestry activities such as rice straw, rice husk, wood chips, and sawdust.: 448 The feedstock used to make the fuels either grow on arable land but are byproducts of the main crop, or they are grown on marginal land. Second-generation feedstocks also include straw, bagasse, perennial grasses, jatropha, waste vegetable oil, municipal solid waste and so forth.Second generation biofuels are not without plenty of downsides in contrast with the seemingly ideal benefits over first-generation biofuels. The competition between food or fuel still persists with this kind of fuel on top of the extremely expensive production costs and need for massive quantities of water.\n",
      "\n",
      "Types\n",
      "Liquid\n",
      "Ethanol\n",
      "Biologically produced alcohols, most commonly ethanol, and less commonly propanol and butanol, are produced by the action of microorganisms and enzymes through the fermentation of sugars or starches (easiest), or cellulose (which is more difficult).The IEA estimates that ethanol production used 20% of sugar supplies and 13% of corn supplies in 2021.\n",
      "Ethanol fuel is the most common biofuel worldwide, particularly in Brazil. Alcohol fuels are produced by fermentation of sugars derived from wheat, corn, sugar beets, sugar cane, molasses and any sugar or starch from which alcoholic beverages such as whiskey, can be made (such as potato and fruit waste, etc.). The ethanol production methods used are enzyme digestion (to release sugars from stored starches), fermentation of the sugars, distillation and drying. The distillation process requires significant energy input for heat (sometimes unsustainable natural gas fossil fuel, but cellulosic biomass such as bagasse, the waste left after sugar cane is pressed to extract its juice, is the most common fuel in Brazil, while pellets, wood chips and also waste heat are more common in Europe) Waste steam fuels ethanol factory – where waste heat from the factories also is used in the district heating grid. Corn-to-ethanol and other food stocks has led to the development of cellulosic ethanol.\n",
      "\n",
      "Other bioalcohols\n",
      "Methanol is currently produced from natural gas, a non-renewable fossil fuel. In the future it is hoped to be produced from biomass as biomethanol. This is technically feasible, but the production is currently being postponed for concerns that the economic viability is still pending. The methanol economy is an alternative to the hydrogen economy to be contrasted with today's hydrogen production from natural gas.\n",
      "Butanol (C4H9OH) is formed by ABE fermentation (acetone, butanol, ethanol) and experimental modifications of the process show potentially high net energy gains with biobutanol as the only liquid product. \n",
      "Biobutanol is often claimed to provide a direct replacement for gasoline, because it will produce more energy than ethanol and allegedly can be burned \"straight\" in existing gasoline engines (without modification to the engine or car), and is less corrosive and less water-soluble than ethanol, and could be distributed via existing infrastructures. Escherichia coli strains have also been successfully engineered to produce butanol by modifying their amino acid metabolism. One drawback to butanol production in E. coli remains the high cost of nutrient rich media, however, recent work has demonstrated E. coli can produce butanol with minimal nutritional supplementation.\n",
      "Biobutanol is sometimes called biogasoline, which is not correct, as it is chemically different, being an alcohol, not a hydrocarbon, like gasoline.\n",
      "\n",
      "Biodiesel\n",
      "Biodiesel is the most common biofuel in Europe. It is produced from oils or fats using transesterification and is a liquid similar in composition to fossil/mineral diesel. Chemically, it consists mostly of fatty acid methyl (or ethyl) esters (FAMEs). Feedstocks for biodiesel include animal fats, vegetable oils, soy, rapeseed, jatropha, mahua, mustard, flax, sunflower, palm oil, hemp, field pennycress, Pongamia pinnata and algae. Pure biodiesel (B100, also known as \"neat\" biodiesel) currently reduces emissions with up to 60% compared to diesel Second generation B100. As of 2020, researchers at Australia's CSIRO have been studying safflower oil as an engine lubricant, and researchers at Montana State University's Advanced Fuels Center in the US have been studying the oil's performance in a large diesel engine, with results described as a \"game-changer\".\n",
      "Biodiesel can be used in any diesel engine and modified equipment when mixed with mineral diesel. It can also be used in its pure form (B100) in diesel engines, but some maintenance and performance problems may then occur during wintertime utilization, since the fuel becomes somewhat more viscous at lower temperatures, depending on the feedstock used.Electronically controlled 'common rail' and 'Unit Injector' type systems from the late 1990s onwards may only use biodiesel blended with conventional diesel fuel. These engines have finely metered and atomized multiple-stage injection systems that are very sensitive to the viscosity of the fuel. Many current-generation diesel engines are made so that they can run on B100 without altering the engine itself, although this depends on the fuel rail design.\n",
      "Since biodiesel is an effective solvent and cleans residues deposited by mineral diesel, engine filters may need to be replaced more often, as the biofuel dissolves old deposits in the fuel tank and pipes. It also effectively cleans the engine combustion chamber of carbon deposits, helping to maintain efficiency. In many European countries, a 5% biodiesel blend is widely used and is available at thousands of gas stations. Biodiesel is also an oxygenated fuel, meaning it contains a reduced amount of carbon and higher hydrogen and oxygen content than fossil diesel. This improves the combustion of biodiesel and reduces the particulate emissions from unburnt carbon. However, using pure biodiesel may increase NOx-emissionsBiodiesel is also safe to handle and transport because it is non-toxic and biodegradable, and has a high flash point of about 300 °F (148 °C) compared to petroleum diesel fuel, which has a flash point of 125 °F (52 °C).In France, biodiesel is incorporated at a rate of 8% in the fuel used by all French diesel vehicles. Avril Group produces under the brand Diester, a fifth of 11 million tons of biodiesel consumed annually by the European Union. It is the leading European producer of biodiesel.\n",
      "\n",
      "Green diesel\n",
      "Green diesel is produced through hydrocracking biological oil feedstocks, such as vegetable oils and animal fats. Hydrocracking is a refinery method that uses elevated temperatures and pressure in the presence of a catalyst to break down larger molecules, such as those found in vegetable oils, into shorter hydrocarbon chains used in diesel engines. It may also be called renewable diesel, hydrotreated vegetable oil (HVO fuel) or hydrogen-derived renewable diesel. Unlike biodiesel, green diesel has exactly the same chemical properties as petroleum-based diesel. It does not require new engines, pipelines or infrastructure to distribute and use, but has not been produced at a cost that is competitive with petroleum. Gasoline versions are also being developed. Green diesel is being developed in Louisiana and Singapore by ConocoPhillips, Neste Oil, Valero, Dynamic Fuels, and Honeywell UOP as well as Preem in Gothenburg, Sweden, creating what is known as Evolution Diesel.\n",
      "\n",
      "Straight vegetable oil\n",
      "Straight unmodified edible vegetable oil is generally not used as fuel, but lower-quality oil has been used for this purpose. Used vegetable oil is increasingly being processed into biodiesel, or (more rarely) cleaned of water and particulates and then used as a fuel. The IEA estimates that biodiesel production used 17% of global vegetable oil supplies in 2021.Oils and fats reacted with 10 pounds of a short-chain alcohol (usually methanol) in the presence of a catalyst (usually sodium hydroxide [NaOH] can be hydrogenated to give a diesel substitute. The resulting product is a straight-chain hydrocarbon with a high cetane number, low in aromatics and sulfur and does not contain oxygen. Hydrogenated oils can be blended with diesel in all proportions. They have several advantages over biodiesel, including good performance at low temperatures, no storage stability problems and no susceptibility to microbial attack.\n",
      "\n",
      "Biogasoline\n",
      "A study led by Professor Lee Sang-yup at the Korea Advanced Institute of Science and Technology (KAIST) and published in the international science journal Nature used modified E. coli fed with glucose found in plants or other non-food crops to produce biogasoline with the produced enzymes. The enzymes converted the sugar into fatty acids and then turned these into hydrocarbons that were chemically and structurally identical to those found in commercial gasoline fuel.\n",
      "\n",
      "Bioethers\n",
      "Bioethers (also referred to as fuel ethers or oxygenated fuels) are cost-effective compounds that act as octane rating enhancers. \"Bioethers are produced by the reaction of reactive iso-olefins, such as iso-butylene, with bioethanol.\" Bioethers are created from wheat or sugar beets, and also be produced from the waste glycerol that results from the production of biodiesel. They also enhance engine performance, while significantly reducing engine wear and toxic exhaust emissions. Although bioethers are likely to replace ethers produced from petroleum in the UK, it is highly unlikely they will become a fuel in and of itself due to the low energy density. By greatly reducing the amount of ground-level ozone emissions, they contribute to air quality.When it comes to transportation fuel there are six ether additives: dimethyl ether (DME), diethyl ether (DEE), methyl tert-butyl ether (MTBE), ethyl tert-butyl ether (ETBE), tert-amyl methyl ether (TAME), and tert-amyl ethyl ether (TAEE).The European Fuel Oxygenates Association identifies MTBE and ETBE as the most commonly used ethers in fuel to replace lead. Ethers were introduced in Europe in the 1970s to replace the highly toxic compound. Although Europeans still use bioether additives, the U.S. Energy Policy Act of 2005 lifted a requirement for reformulated gasoline to include an oxygenate, leading to less MTBE being added to fuel.\n",
      "\n",
      "Aviation biofuel\n",
      "Gaseous\n",
      "Biogas and biomethane\n",
      "Biogas is a mixture composed primarily of methane and carbon dioxide produced by the process of anaerobic digestion of organic material by micro-organisms. Other trace components of this mixture includes water vapor, hydrogen sulfide, siloxanes, hydrocarbons, ammonia, oxygen, carbon monoxide, and nitrogen. It can be produced either from biodegradable waste materials or by the use of energy crops fed into anaerobic digesters to supplement gas yields. The solid byproduct, digestate, can be used as a biofuel or a fertilizer. When CO2 and other impurities are removed from biogas, it is called biomethane.\n",
      "Biogas can be recovered from mechanical biological treatment waste processing systems. Landfill gas, a less clean form of biogas, is produced in landfills through naturally occurring anaerobic digestion. If it escapes into the atmosphere, it acts as a greenhouse gas.\n",
      "Farmers can produce biogas from manure from their cattle by using anaerobic digesters.\n",
      "\n",
      "Syngas\n",
      "Syngas, a mixture of carbon monoxide, hydrogen and various hydrocarbons, is produced by partial combustion of biomass, that is, combustion with an amount of oxygen that is not sufficient to convert the biomass completely to carbon dioxide and water. Before partial combustion, the biomass is dried, and sometimes pyrolysed. The resulting gas mixture, syngas, is more efficient than direct combustion of the original biofuel; more of the energy contained in the fuel is extracted.\n",
      "Syngas may be burned directly in internal combustion engines, turbines or high-temperature fuel cells. The wood gas generator, a wood-fueled gasification reactor, can be connected to an internal combustion engine.\n",
      "Syngas can be used to produce methanol, dimethyl ether and hydrogen, or converted via the Fischer–Tropsch process to produce a diesel substitute, or a mixture of alcohols that can be blended into gasoline. Gasification normally relies on temperatures greater than 700 °C.\n",
      "Lower-temperature gasification is desirable when co-producing biochar, but results in syngas polluted with tar.\n",
      "\n",
      "Solid\n",
      "The term \"biofuels\" is also used for solid fuels that are made from biomass, even though this is less common.\n",
      "\n",
      "Research into other types\n",
      "Algae-based biofuels\n",
      "Algae can be produced in ponds or tanks on land, and out at sea. Algal fuels have high yields, can be grown with minimal impact on fresh water resources, can be produced using saline water and wastewater, have a high ignition point, and are biodegradable and relatively harmless to the environment if spilled. Production requires large amounts of energy and fertilizer, the produced fuel degrades faster than other biofuels, and it does not flow well in cold temperatures.By 2017, due to economic considerations, most efforts to produce fuel from algae have been abandoned or changed to other applications.Algae has the potential to yield more than 5,000 gallons of per acre year of biodiesel which is part of the reason in 2010 NAAB attempted to widely commercialize the use of algae-based biofuels. The Eldorado Biofuels (NAAB member) aimed to create commercial algae-based biofuels that not only made repurposed wastewater but did not require food crops or freshwater in order to produce energy. This cite which was stationed in southeastern Mexico and constructed by Alfonz Visozlay utilizes a system that separates petroleum related toxins and trace elements that aid in the growth of algae.\n",
      "\n",
      "Electrofuels and solar fuels\n",
      "This class of biofuels includes electrofuels and solar fuels. Electrofuels are made by storing electrical energy in the chemical bonds of liquids and gases. The primary targets are butanol, biodiesel, and hydrogen, but include other alcohols and carbon-containing gases such as methane and butane. A solar fuel is a synthetic chemical fuel produced from solar energy. Light is converted to chemical energy, typically by reducing protons to hydrogen, or carbon dioxide to organic compounds.Third and fourth-generation biofuels also include biofuels that are produced by bioengineered organisms i.e. algae and cyanobacteria. Algae and cyanobacteria will use water, carbon dioxide, and solar energy to produce biofuels. This method of biofuel production is still at the research level. The biofuels that are secreted by the bioengineered organisms are expected to have higher photon-to-fuel conversion efficiency, compared to older generations of biofuels. One of the advantages of this class of biofuels is that the cultivation of the organisms that produce the biofuels does not require the use of arable land. The disadvantages include the cost of cultivating the biofuel-producing organisms being very high.\n",
      "\n",
      "Extent of production and use\n",
      "The following fuels can be produced using first, second, third or fourth-generation biofuel production procedures. Most of these can be produced using two or three of the different biofuel generation procedures.\n",
      "Global biofuel production was 81 Mtoe in 2017 which represented an annual increase of about 3% compared to 2010.: 12  Mtoe stands for Million Tonnes of Oil Equivalent. Furthermore: \"the US is the largest producer in the world producing 37 Mtoe in 2017; Brazil and South America, 23 Mtoe; and Europe (mainly Germany) 12 Mtoe\".: 12 An assessment from 2017 found that: \"Biofuels will never be a major transport fuel as there is just not enough land in the world to grow plants to make biofuel for all vehicles. It can however, be part of an energy mix to take us into a future of renewable energy.\": 11 In 2021, worldwide biofuel production provided 4.3% of the world's fuels for transport, including a very small amount of aviation biofuel. By 2027 worldwide biofuel production is expected to supply 5.4% of the world's fuels for transport including 1% of aviation fuel. The International Energy Agency (IEA) wants biofuels to make up 64% of the world demand for transportation fuels by 2050, in order to reduce dependency on petroleum. However, the production and consumption of biofuels are not on track to meet the IEA's sustainable development scenario. From 2020 to 2030 global biofuel output has to increase by 16% each year to reach IEA's goal.\n",
      "\n",
      "Issues\n",
      "Environmental impacts\n",
      "Estimates about the climate impact from biofuels vary widely based on the methodology and exact situation examined.In general, biofuels emit fewer greenhouse gas emissions when burned in an engine and are generally considered carbon-neutral fuels as the carbon emitted has been captured from the atmosphere by the crops used in production. However, life-cycle assessments of biofuels have shown large emissions associated with the potential land-use change required to produce additional biofuel feedstocks. A review of 179 studies published between 2009 and 2020 found that if no land-use change is involved, first-generation biofuels can—on average—have lower emissions than fossil fuels. However, there is an issue with competition with food. Up to 40% of corn produced in the United States is used to make ethanol, and worldwide 10% of all grain is turned into biofuel. A 50% reduction in grain used for biofuels in the US and Europe would replace all of Ukraine's grain exports. Also, several studies have shown that reductions in emissions from biofuels are achieved at the expense of other impacts, such as acidification, eutrophication, water footprint and biodiversity loss.The use of second generation biofuels is thought to increase environmental sustainability, since the non-food part of plants is being used to produce second-generation biofuels, instead of being disposed.  But the use of this class of biofuels increases the competition for lignocellulosic biomass, increasing the cost of these biofuels.The European Commission officially approved a measure to phase out palm oil-based biofuels by 2030. During a meeting with European Commission President Ursula von der Leyen, Indonesian Prime Minister Joko Widodo expressed concern about the EU Deforestation Regulation (EUDR), which aims to prevent products linked to deforestation from reaching the EU market.\n",
      "\n",
      "Indirect land use change impacts of biofuels\n",
      "See also\n",
      "References\n",
      "Sources\n",
      "Avril Group, ed. (2015). A new springtime for the oils and proteins sectors : Activity Report 2014 (PDF) (Report). Paris: Avril. p. 65. Archived from the original (PDF) on 26 October 2020. Retrieved 11 August 2022.\n",
      "EurObserv (July 2014). Biofuel barometer (PDF) (Report).\n",
      "\n",
      "External links\n",
      "\n",
      "Biofuels Journal\n",
      "Alternative Fueling Station Locator Archived 14 July 2008 at the Wayback Machine (EERE)\n",
      "Towards Sustainable Production and Use of Resources: Assessing Biofuels by the United Nations Environment Programme, October 2009.\n",
      "Biofuels guidance for businesses, including permits and licences required on NetRegs.gov.uk\n",
      "How Much Water Does It Take to Make Electricity?—Natural gas requires the least water to produce energy, some biofuels the most, according to a new study.\n",
      "International Conference on Biofuels Standards – European Union Biofuels Standardization\n",
      "Biofuels from Biomass: Technology and Policy Considerations Thorough overview from MIT\n",
      "The Guardian news on biofuels\n",
      "The US DOE Clean Cities Program – links to the 87 US Clean Cities coalitions, as of 2004.\n",
      "Biofuels Factsheet by the University of Michigan's Center for Sustainable Systems\n",
      "Learn Biofuels – Educational Resource for StudentsAbraham Lincoln ( LINK-ən; February 12, 1809 – April 15, 1865) was an American lawyer, politician, and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the United States through the American Civil War, defending the nation as a constitutional union, defeating the insurgent Confederacy, abolishing slavery, expanding the power of the federal government, and modernizing the U.S. economy.\n",
      "Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier, primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. congressman from Illinois. In 1849, he returned to his successful law practice in Springfield, Illinois. In 1854, he was angered by the Kansas–Nebraska Act, which opened the territories to slavery, causing him to re-enter politics. He soon became a leader of the new Republican Party. He reached a national audience in the 1858 Senate campaign debates against Stephen A. Douglas. Lincoln ran for president in 1860, sweeping the North to gain victory. Pro-slavery elements in the South viewed his election as a threat to slavery, and Southern states began seceding from the nation. During this time, the newly formed Confederate States of America began seizing federal military bases in the South. A little over one month after Lincoln assumed the presidency, Confederate forces attacked Fort Sumter, a U.S. fort in South Carolina. Following the bombardment, Lincoln mobilized forces to suppress the rebellion and restore the union.\n",
      "Lincoln, a moderate Republican, had to navigate a contentious array of factions with friends and opponents from both the Democratic and Republican parties. His allies, the War Democrats and the Radical Republicans, demanded harsh treatment of the Southern Confederates. He managed the factions by exploiting their mutual enmity, carefully distributing political patronage, and by appealing to the American people. Anti-war Democrats (called \"Copperheads\") despised Lincoln, and some irreconcilable pro-Confederate elements went so far as to plot his assassination. His Gettysburg Address came to be seen as one of the greatest and most influential statements of American national purpose. Lincoln closely supervised the strategy and tactics in the war effort, including the selection of generals, and implemented a naval blockade of the South's trade. He suspended habeas corpus in Maryland and elsewhere, and averted British intervention by defusing the Trent Affair. In 1863, he issued the Emancipation Proclamation, which declared the slaves in the states \"in rebellion\" to be free. It also directed the Army and Navy to \"recognize and maintain the freedom of such persons\", and to receive them \"into the armed service of the United States.\" Lincoln pressured border states to outlaw slavery, and he promoted the Thirteenth Amendment to the U.S. Constitution, which abolished slavery, except as punishment for a crime.\n",
      "Lincoln managed his own successful re-election campaign. He sought to heal the war-torn nation through reconciliation. On April 14, 1865, just five days after the Confederate surrender at Appomattox, he was attending a play at Ford's Theatre in Washington, D.C., with his wife, Mary, when he was fatally shot by Confederate sympathizer John Wilkes Booth. Lincoln is remembered as a martyr and a national hero for his wartime leadership and for his efforts to preserve the Union and abolish slavery. Lincoln is often ranked in both popular and scholarly polls as the greatest president in American history.\n",
      "\n",
      "Family and childhood\n",
      "Early life\n",
      "Abraham Lincoln was born on February 12, 1809, the second child of Thomas Lincoln and Nancy Hanks Lincoln, in a log cabin on Sinking Spring Farm near Hodgenville, Kentucky. He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham, Norfolk, to its namesake, Hingham, Massachusetts, in 1638. The family then migrated west, passing through New Jersey, Pennsylvania, and Virginia. Lincoln was also a descendant of the Harrison family of Virginia; his paternal grandfather and namesake, Captain Abraham Lincoln and wife Bathsheba (née Herring) moved the family from Virginia to Jefferson County, Kentucky. The captain was killed in an Indian raid in 1786. His children, including eight-year-old Thomas, Abraham's father, witnessed the attack. Thomas then worked at odd jobs in Kentucky and Tennessee before the family settled in Hardin County, Kentucky, in the early 1800s.\n",
      "Lincoln's mother Nancy Lincoln is widely assumed to be the daughter of Lucy Hanks. Thomas and Nancy married on June 12, 1806, in Washington County, and moved to Elizabethtown, Kentucky. They had three children: Sarah, Abraham, and Thomas, who died as an infant.Thomas Lincoln bought or leased farms in Kentucky before losing all but 200 acres (81 ha) of his land in court disputes over property titles. In 1816, the family moved to Indiana where the land surveys and titles were more reliable. Indiana was a \"free\" (non-slaveholding) territory, and they settled in an \"unbroken forest\" in Hurricane Township, Perry County, Indiana. In 1860, Lincoln noted that the family's move to Indiana was \"partly on account of slavery\", but mainly due to land title difficulties.In Kentucky and Indiana, Thomas worked as a farmer, cabinetmaker, and carpenter. At various times, he owned farms, livestock, and town lots, paid taxes, sat on juries, appraised estates, and served on county patrols. Thomas and Nancy were members of a Separate Baptists church, which forbade alcohol, dancing, and slavery.Overcoming financial challenges, Thomas in 1827 obtained clear title to 80 acres (32 ha) in Indiana, an area which became the Little Pigeon Creek Community.\n",
      "\n",
      "Mother's death\n",
      "On October 5, 1818, Nancy Lincoln died from milk sickness, leaving 11-year-old Sarah in charge of a household including her father, 9-year-old Abraham, and Nancy's 19-year-old orphan cousin, Dennis Hanks. Ten years later, on January 20, 1828, Sarah died while giving birth to a stillborn son, devastating Lincoln.On December 2, 1819, Thomas married Sarah Bush Johnston, a widow from Elizabethtown, Kentucky, with three children of her own. Abraham became close to his stepmother and called her \"Mother\". Lincoln disliked the hard labor associated with farm life. His family even said he was lazy, for all his \"reading, scribbling, writing, ciphering, writing Poetry, etc.\". His stepmother acknowledged he did not enjoy \"physical labor\", but loved to read.\n",
      "\n",
      "Education and move to Illinois\n",
      "Lincoln was largely self-educated. His formal schooling was from itinerant teachers. It included two short stints in Kentucky, where he learned to read but probably not to write, at age seven, and in Indiana, where he went to school sporadically due to farm chores, for a total of fewer than 12 months in aggregate by the age of 15. He persisted as an avid reader and retained a lifelong interest in learning. Family, neighbors, and schoolmates recalled that his reading included the King James Bible, Aesop's Fables, John Bunyan's The Pilgrim's Progress, Daniel Defoe's Robinson Crusoe, and The Autobiography of Benjamin Franklin. Despite being self-educated, Lincoln was the recipient of honorary degrees later in life, including an honorary Doctor of Laws from Columbia University in June 1861.\n",
      "As a teen, Lincoln took responsibility for chores and customarily gave his father all earnings from work outside the home until he was 21. Lincoln was tall, strong, and athletic, and became adept at using an ax. He was an active wrestler during his youth and trained in the rough catch-as-catch-can style (also known as catch wrestling). He became county wrestling champion at the age of 21. He gained a reputation for strength and audacity after winning a wrestling match with the renowned leader of ruffians known as \"the Clary's Grove Boys\".\n",
      "In March 1830, fearing another milk sickness outbreak, several members of the extended Lincoln family, including Abraham, moved west to Illinois, a free state, and settled in Macon County. Abraham then became increasingly distant from Thomas, in part due to his father's lack of education. In 1831, as Thomas and other family members prepared to move to a new homestead in Coles County, Illinois, Abraham struck out on his own. He made his home in New Salem, Illinois, for six years. Lincoln and some friends took goods, including live hogs, by flatboat to New Orleans, Louisiana, where he first witnessed slavery.\n",
      "\n",
      "Marriage and children\n",
      "Speculation persists that Lincoln's first romantic interest was Ann Rutledge, whom he met when he moved to New Salem. Witness testimony, given decades afterward, showed a lack of any specific recollection of a romance between the two. Rutledge died on August 25, 1835, most likely of typhoid fever; saying that he could not bear the idea of rain falling on Ann's grave, Lincoln sunk into a serious episode of depression, and this gave rise to speculation that he had been in love with her.In the early 1830s, he met Mary Owens from Kentucky. Late in 1836, Lincoln agreed to a match with Owens if she returned to New Salem. Owens arrived that November and he courted her for a time; however, they both had second thoughts. On August 16, 1837, he wrote Owens a letter saying he would not blame her if she ended the relationship, and she never replied.In 1839, Lincoln met Mary Todd in Springfield, Illinois, and the following year they became engaged. She was the daughter of Robert Smith Todd, a wealthy lawyer and businessman in Lexington, Kentucky. A wedding set for January 1, 1841, was canceled at Lincoln's request, but they reconciled and married on November 4, 1842, in the Springfield mansion of Mary's sister. While anxiously preparing for the nuptials, he was asked where he was going and replied, \"To hell, I suppose.\" In 1844, the couple bought a house in Springfield near his law office. Mary kept house with the help of a hired servant and a relative.Lincoln was an affectionate husband and father of four sons, though his work regularly kept him away from home. The oldest, Robert Todd Lincoln, was born in 1843 and was the only child to live to maturity. Edward Baker Lincoln (Eddie), born in 1846, died February 1, 1850, probably of tuberculosis. Lincoln's third son, \"Willie\" Lincoln was born on December 21, 1850, and died of a fever at the White House on February 20, 1862. The youngest, Thomas \"Tad\" Lincoln, was born on April 4, 1853, and survived his father but died of heart failure at age 18 on July 16, 1871. Lincoln \"was remarkably fond of children\" and the Lincolns were not considered to be strict with their own. In fact, Lincoln's law partner William H. Herndon would grow irritated when Lincoln brought his children to the law office. Their father, it seemed, was often too absorbed in his work to notice his children's behavior. Herndon recounted, \"I have felt many and many a time that I wanted to wring their little necks, and yet out of respect for Lincoln I kept my mouth shut. Lincoln did not note what his children were doing or had done.\"The deaths of their sons, Eddie and Willie, had profound effects on both parents. Lincoln suffered from \"melancholy\", a condition now thought to be clinical depression. Later in life, Mary struggled with the stresses of losing her husband and sons, and Robert committed her for a time to an asylum in 1875.\n",
      "\n",
      "Early career and militia service\n",
      "During 1831 and 1832, Lincoln worked at a general store in New Salem, Illinois. In 1832, he declared his candidacy for the Illinois House of Representatives, but interrupted his campaign to serve as a captain in the Illinois Militia during the Black Hawk War. When Lincoln returned home from the Black Hawk War, he planned to become a blacksmith, but instead formed a partnership with 21-year-old William Berry, with whom he purchased a New Salem general store on credit. Because a license was required to sell customers single beverages, Berry obtained bartending licenses for $7 each for Lincoln and himself, and in 1833 the Lincoln-Berry General Store became a tavern as well. As licensed bartenders, Lincoln and Berry were able to sell spirits, including liquor, for 12 cents a pint. They offered a wide range of alcoholic beverages as well as food, including takeout dinners. But Berry became an alcoholic, was often too drunk to work, and Lincoln ended up running the store by himself. Although the economy was booming, the business struggled and went into debt, causing Lincoln to sell his share.\n",
      "In his first campaign speech after returning from his military service, Lincoln observed a supporter in the crowd under attack, grabbed the assailant by his \"neck and the seat of his trousers\", and tossed him. In the campaign, Lincoln advocated for navigational improvements on the Sangamon River. He could draw crowds as a raconteur, but lacked the requisite formal education, powerful friends, and money, and lost the election. Lincoln finished eighth out of 13 candidates (the top four were elected), though he received 277 of the 300 votes cast in the New Salem precinct.Lincoln served as New Salem's postmaster and later as county surveyor, but continued his voracious reading and decided to become a lawyer. Rather than studying in the office of an established attorney, as was the custom, Lincoln borrowed legal texts from attorneys John Todd Stuart and Thomas Drummond, purchased books including Blackstone's Commentaries and Chitty's Pleadings, and read law on his own. He later said of his legal education that \"I studied with nobody.\"\n",
      "\n",
      "Illinois state legislature (1834–1842)\n",
      "Lincoln's second state house campaign in 1834, this time as a Whig, was a success over a powerful Whig opponent. Then followed his four terms in the Illinois House of Representatives for Sangamon County. He championed construction of the Illinois and Michigan Canal, and later was a Canal Commissioner. He voted to expand suffrage beyond white landowners to all white males, but adopted a \"free soil\" stance opposing both slavery and abolition. In 1837, he declared, \"[The] Institution of slavery is founded on both injustice and bad policy, but the promulgation of abolition doctrines tends rather to increase than abate its evils.\" He echoed Henry Clay's support for the American Colonization Society which advocated a program of abolition in conjunction with settling freed slaves in Liberia.He was admitted to the Illinois bar on September 9, 1836, and moved to Springfield and began to practice law under John T. Stuart, Mary Todd's cousin. Lincoln emerged as a formidable trial combatant during cross-examinations and closing arguments. He partnered several years with Stephen T. Logan, and in 1844 began his practice with William Herndon, \"a studious young man\".On January 27, 1838, Abraham Lincoln, then twenty-eight years old, delivered his first major speech at the Lyceum in Springfield, Illinois, after the murder of newspaper editor Elijah Parish Lovejoy in Alton. Lincoln warned that no trans-Atlantic military giant could ever crush us as a nation. \"It cannot come from abroad. If destruction be our lot, we must ourselves be its author and finisher\", said Lincoln. Prior to that, on April 28, 1836, an innocent black man, Francis McIntosh, was burned alive in St. Louis, Missouri. Zann Gill describes how these two murders set off a chain reaction that ultimately prompted Abraham Lincoln to run for President.\n",
      "\n",
      "U.S. House of Representatives (1847–1849)\n",
      "True to his record, Lincoln professed to friends in 1861 to be \"an old line Whig, a disciple of Henry Clay\". Their party favored economic modernization in banking, tariffs to fund internal improvements including railroads, and urbanization.In 1843, Lincoln sought the Whig nomination for Illinois's 7th district seat in the U.S. House of Representatives; he was defeated by John J. Hardin, though he prevailed with the party in limiting Hardin to one term. Lincoln not only pulled off his strategy of gaining the nomination in 1846, but also won the election. He was the only Whig in the Illinois delegation, but as dutiful as any participated in almost all votes and made speeches that toed the party line. He was assigned to the Committee on Post Office and Post Roads and the Committee on Expenditures in the War Department. Lincoln teamed with Joshua R. Giddings on a bill to abolish slavery in the District of Columbia with compensation for the owners, enforcement to capture fugitive slaves, and a popular vote on the matter. He dropped the bill when it eluded Whig support.\n",
      "\n",
      "Political views\n",
      "On foreign and military policy, Lincoln spoke against the Mexican–American War, which he imputed to President James K. Polk's desire for \"military glory — that attractive rainbow, that rises in showers of blood\". He supported the Wilmot Proviso, a failed proposal to ban slavery in any U.S. territory won from Mexico.Lincoln emphasized his opposition to Polk by drafting and introducing his Spot Resolutions. The war had begun with a killing of American soldiers by Mexican cavalry patrol in disputed territory, and Polk insisted that Mexican soldiers had \"invaded our territory and shed the blood of our fellow-citizens on our own soil\". Lincoln demanded that Polk show Congress the exact spot on which blood had been shed and prove that the spot was on American soil. The resolution was ignored in both Congress and the national papers, and it cost Lincoln political support in his district. One Illinois newspaper derisively nicknamed him \"spotty Lincoln\". Lincoln later regretted some of his statements, especially his attack on presidential war-making powers.Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election. Taylor won and Lincoln hoped in vain to be appointed Commissioner of the United States General Land Office. The administration offered to appoint him secretary or governor of the Oregon Territory as consolation. This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.\n",
      "\n",
      "Prairie lawyer\n",
      "In his Springfield practice, Lincoln handled \"every kind of business that could come before a prairie lawyer\". Twice a year he appeared for 10 consecutive weeks in county seats in the Midstate county courts; this continued for 16 years. Lincoln handled transportation cases in the midst of the nation's western expansion, particularly river barge conflicts under the many new railroad bridges. As a riverboat man, Lincoln initially favored those interests, but ultimately represented whoever hired him. He later represented a bridge company against a riverboat company in Hurd v. Rock Island Bridge Company, a landmark case involving a canal boat that sank after hitting a bridge. In 1849, he received a patent for a flotation device for the movement of boats in shallow water. The idea was never commercialized, but it made Lincoln the only president to hold a patent.Lincoln appeared before the Illinois Supreme Court in 175 cases; he was sole counsel in 51 cases, of which 31 were decided in his favor. From 1853 to 1860, one of his largest clients was the Illinois Central Railroad. His legal reputation gave rise to the nickname \"Honest Abe\".Lincoln argued in an 1858 criminal trial, defending William \"Duff\" Armstrong, who was on trial for the murder of James Preston Metzker. The case is famous for Lincoln's use of a fact established by judicial notice to challenge the credibility of an eyewitness. After an opposing witness testified to seeing the crime in the moonlight, Lincoln produced a Farmers' Almanac showing the Moon was at a low angle, drastically reducing visibility. Armstrong was acquitted.Leading up to his presidential campaign, Lincoln elevated his profile in an 1859 murder case, with his defense of Simeon Quinn \"Peachy\" Harrison who was a third cousin; Harrison was also the grandson of Lincoln's political opponent, Rev. Peter Cartwright. Harrison was charged with the murder of Greek Crafton who, as he lay dying of his wounds, confessed to Cartwright that he had provoked Harrison. Lincoln angrily protested the judge's initial decision to exclude Cartwright's testimony about the confession as inadmissible hearsay. Lincoln argued that the testimony involved a dying declaration and was not subject to the hearsay rule. Instead of holding Lincoln in contempt of court as expected, the judge, a Democrat, reversed his ruling and admitted the testimony into evidence, resulting in Harrison's acquittal.\n",
      "\n",
      "Republican politics (1854–1860)\n",
      "Emergence as Republican leader\n",
      "The debate over the status of slavery in the territories failed to alleviate tensions between the slave-holding South and the free North, with the failure of the Compromise of 1850, a legislative package designed to address the issue. In his 1852 eulogy for Clay, Lincoln highlighted the latter's support for gradual emancipation and opposition to \"both extremes\" on the slavery issue. As the slavery debate in the Nebraska and Kansas territories became particularly acrimonious, Illinois Senator Stephen A. Douglas proposed popular sovereignty as a compromise; the measure would allow the electorate of each territory to decide the status of slavery. The legislation alarmed many Northerners, who sought to prevent the spread of slavery that could result, but Douglas's Kansas–Nebraska Act narrowly passed Congress in May 1854.Lincoln did not comment on the act until months later in his \"Peoria Speech\" of October 1854. Lincoln then declared his opposition to slavery, which he repeated en route to the presidency. He said the Kansas Act had a \"declared indifference, but as I must think, a covert real zeal for the spread of slavery. I cannot but hate it. I hate it because of the monstrous injustice of slavery itself. I hate it because it deprives our republican example of its just influence in the world....\" Lincoln's attacks on the Kansas–Nebraska Act marked his return to political life.Nationally, the Whigs were irreparably split by the Kansas–Nebraska Act and other efforts to compromise on the slavery issue. Reflecting on the demise of his party, Lincoln wrote in 1855, \"I think I am a Whig, but others say there are no Whigs, and that I am an abolitionist. ... I do no more than oppose the extension of slavery.\" The new Republican Party was formed as a northern party dedicated to antislavery, drawing from the antislavery wing of the Whig Party and combining Free Soil, Liberty, and antislavery Democratic Party members, Lincoln resisted early Republican entreaties, fearing that the new party would become a platform for extreme abolitionists. Lincoln held out hope for rejuvenating the Whigs, though he lamented his party's growing closeness with the nativist Know Nothing movement.In 1854, Lincoln was elected to the Illinois legislature but declined to take his seat. The year's elections showed the strong opposition to the Kansas–Nebraska Act, and in the aftermath, Lincoln sought election to the United States Senate. At that time, senators were elected by the state legislature. After leading in the first six rounds of voting, he was unable to obtain a majority. Lincoln instructed his backers to vote for Lyman Trumbull. Trumbull was an antislavery Democrat, and had received few votes in the earlier ballots; his supporters, also antislavery Democrats, had vowed not to support any Whig. Lincoln's decision to withdraw enabled his Whig supporters and Trumbull's antislavery Democrats to combine and defeat the mainstream Democratic candidate, Joel Aldrich Matteson.\n",
      "\n",
      "1856 campaign\n",
      "Violent political confrontations in Kansas continued, and opposition to the Kansas–Nebraska Act remained strong throughout the North. As the 1856 elections approached, Lincoln joined the Republicans and attended the Bloomington Convention, which formally established the Illinois Republican Party. The convention platform endorsed Congress's right to regulate slavery in the territories and backed the admission of Kansas as a free state. Lincoln gave the final speech of the convention supporting the party platform and called for the preservation of the Union. At the June 1856 Republican National Convention, though Lincoln received support to run as vice president, John C. Frémont and William Dayton were on the ticket, which Lincoln supported throughout Illinois. The Democrats nominated former Secretary of State James Buchanan and the Know-Nothings nominated former Whig President Millard Fillmore. Buchanan prevailed, while Republican William Henry Bissell won election as Governor of Illinois, and Lincoln became a leading Republican in Illinois.\n",
      "\n",
      "Dred Scott v. Sandford\n",
      "Dred Scott was a slave whose master took him from a slave state to a territory that was free as a result of the Missouri Compromise. After Scott was returned to the slave state, he petitioned a federal court for his freedom. His petition was denied in Dred Scott v. Sandford (1857). In his opinion, Supreme Court Chief Justice Roger B. Taney wrote that black people were not citizens and derived no rights from the Constitution, and that the Missouri Compromise was unconstitutional for infringing upon slave owners' \"property\" rights. While many Democrats hoped that Dred Scott would end the dispute over slavery in the territories, the decision sparked further outrage in the North. Lincoln denounced it as the product of a conspiracy of Democrats to support the Slave Power. He argued the decision was at variance with the Declaration of Independence; he said that while the founding fathers did not believe all men equal in every respect, they believed all men were equal \"in certain inalienable rights, among which are life, liberty, and the pursuit of happiness\".\n",
      "\n",
      "Lincoln–Douglas debates and Cooper Union speech\n",
      "In 1858, Douglas was up for re-election in the U.S. Senate, and Lincoln hoped to defeat him. Many in the party felt that a former Whig should be nominated in 1858, and Lincoln's 1856 campaigning and support of Trumbull had earned him a favor. Some eastern Republicans supported Douglas for his opposition to the Lecompton Constitution and admission of Kansas as a slave state. Many Illinois Republicans resented this eastern interference. For the first time, Illinois Republicans held a convention to agree upon a Senate candidate, and Lincoln won the nomination with little opposition.\n",
      "Lincoln accepted the nomination with great enthusiasm and zeal. After his nomination he delivered his House Divided Speech, with the biblical reference Mark 3:25, \"A house divided against itself cannot stand. I believe this government cannot endure permanently half slave and half free. I do not expect the Union to be dissolved—I do not expect the house to fall—but I do expect it will cease to be divided. It will become all one thing, or all the other.\" The speech created a stark image of the danger of disunion. The stage was then set for the election of the Illinois legislature which would, in turn, select Lincoln or Douglas. When informed of Lincoln's nomination, Douglas stated, \"[Lincoln] is the strong man of the party ... and if I beat him, my victory will be hardly won.\"The Senate campaign featured seven debates between Lincoln and Douglas. These were the most famous political debates in American history; they had an atmosphere akin to a prizefight and drew crowds in the thousands. The principals stood in stark contrast both physically and politically. Lincoln warned that the Slave Power was threatening the values of republicanism, and he accused Douglas of distorting the Founding Fathers' premise that all men are created equal. In his Freeport Doctrine, Douglas argued that, despite the Dred Scott decision, which he claimed to support, local settlers, under the doctrine of popular sovereignty, should be free to choose whether to allow slavery within their territory, and he accused Lincoln of having joined the abolitionists. Lincoln's argument assumed a moral tone, as he claimed that Douglas represented a conspiracy to promote slavery. Douglas's argument was more legal in nature, claiming that Lincoln was defying the authority of the U.S. Supreme Court as exercised in the Dred Scott decision.Though the Republican legislative candidates won more popular votes, the Democrats won more seats, and the legislature re-elected Douglas. However, Lincoln's articulation of the issues had given him a national political presence. In May 1859, Lincoln purchased the Illinois Staats-Anzeiger, a German-language newspaper that was consistently supportive; most of the state's 130,000 German Americans voted for Democrats, but the German-language paper mobilized Republican support. In the aftermath of the 1858 election, newspapers frequently mentioned Lincoln as a potential Republican presidential candidate, rivaled by William H. Seward, Salmon P. Chase, Edward Bates, and Simon Cameron. While Lincoln was popular in the Midwest, he lacked support in the Northeast and was unsure whether to seek the office. In January 1860, Lincoln told a group of political allies that he would accept the presidential nomination if offered and, in the following months, several local papers endorsed his candidacy.Over the coming months, Lincoln was tireless, making nearly fifty speeches along the campaign trail. By the quality and simplicity of his rhetoric, he quickly became the champion of the Republican party. However, despite his overwhelming support in the Midwestern United States, he was less appreciated in the east. Horace Greeley, editor of the New York Tribune, at that time wrote up an unflattering account of Lincoln's compromising position on slavery and his reluctance to challenge the court's Dred Scott ruling, which was promptly used against him by his political rivals.On February 27, 1860, powerful New York Republicans invited Lincoln to give a speech at Cooper Union, in which he argued that the Founding Fathers of the United States had little use for popular sovereignty and had repeatedly sought to restrict slavery. He insisted that morality required opposition to slavery and rejected any \"groping for some middle ground between the right and the wrong\". Many in the audience thought he appeared awkward and even ugly. But Lincoln demonstrated intellectual leadership, which brought him into contention. Journalist Noah Brooks reported, \"No man ever before made such an impression on his first appeal to a New York audience\".Historian David Herbert Donald described the speech as \"a superb political move for an unannounced presidential aspirant. Appearing in Seward's home state, sponsored by a group largely loyal to Chase, Lincoln shrewdly made no reference to either of these Republican rivals for the nomination.\" In response to an inquiry about his ambitions, Lincoln said, \"The taste is in my mouth a little\".\n",
      "\n",
      "1860 presidential election\n",
      "On May 9–10, 1860, the Illinois Republican State Convention was held in Decatur. Lincoln's followers organized a campaign team led by David Davis, Norman Judd, Leonard Swett, and Jesse DuBois, and Lincoln received his first endorsement. Exploiting his embellished frontier legend (clearing land and splitting fence rails), Lincoln's supporters adopted the label of \"The Rail Candidate\". In 1860, Lincoln described himself: \"I am in height, six feet, four inches, nearly; lean in flesh, weighing, on an average, one hundred and eighty pounds; dark complexion, with coarse black hair, and gray eyes.\" Michael Martinez wrote about the effective imaging of Lincoln by his campaign. At times he was presented as the plain-talking \"Rail Splitter\" and at other times he was \"Honest Abe\", unpolished but trustworthy.On May 18, at the Republican National Convention in Chicago, Lincoln won the nomination on the third ballot, beating candidates such as Seward and Chase. A former Democrat, Hannibal Hamlin of Maine, was nominated for vice president to balance the ticket. Lincoln's success depended on his campaign team, his reputation as a moderate on the slavery issue, and his strong support for internal improvements and the tariff. Pennsylvania put him over the top, led by the state's iron interests who were reassured by his tariff support. Lincoln's managers had focused on this delegation while honoring Lincoln's dictate to \"Make no contracts that will bind me\".As the Slave Power tightened its grip on the national government, most Republicans agreed with Lincoln that the North was the aggrieved party. Throughout the 1850s, Lincoln had doubted the prospects of civil war, and his supporters rejected claims that his election would incite secession. When Douglas was selected as the candidate of the Northern Democrats, delegates from eleven slave states walked out of the Democratic convention; they opposed Douglas's position on popular sovereignty, and selected incumbent Vice President John C. Breckinridge as their candidate. A group of former Whigs and Know Nothings formed the Constitutional Union Party and nominated John Bell of Tennessee. Lincoln and Douglas competed for votes in the North, while Bell and Breckinridge primarily found support in the South.Prior to the Republican convention, the Lincoln campaign began cultivating a nationwide youth organization, the Wide Awakes, which it used to generate popular support throughout the country to spearhead voter registration drives, thinking that new voters and young voters tended to embrace new parties. People of the Northern states knew the Southern states would vote against Lincoln and rallied supporters for Lincoln.As Douglas and the other candidates campaigned, Lincoln gave no speeches, relying on the enthusiasm of the Republican Party. The party did the leg work that produced majorities across the North and produced an abundance of campaign posters, leaflets, and newspaper editorials. Republican speakers focused first on the party platform, and second on Lincoln's life story, emphasizing his childhood poverty. The goal was to demonstrate the power of \"free labor\", which allowed a common farm boy to work his way to the top by his own efforts. The Republican Party's production of campaign literature dwarfed the combined opposition; a Chicago Tribune writer produced a pamphlet that detailed Lincoln's life and sold 100,000–200,000 copies. Though he did not give public appearances, many sought to visit him and write him. In the runup to the election, he took an office in the Illinois state capitol to deal with the influx of attention. He also hired John George Nicolay as his personal secretary, who would remain in that role during the presidency.On November 6, 1860, Lincoln was elected the 16th president. He was the first Republican president and his victory was entirely due to his support in the North and West. No ballots were cast for him in 10 of the 15 Southern slave states, and he won only two of 996 counties in all the Southern states, an omen of the impending Civil War. Lincoln received 1,866,452 votes, or 39.8% of the total in a four-way race, carrying the free Northern states, as well as California and Oregon. His victory in the Electoral College was decisive: Lincoln had 180 votes to 123 for his opponents.\n",
      "\n",
      "Presidency (1861–1865)\n",
      "Secession and inauguration\n",
      "The South was outraged by Lincoln's election, and in response secessionists implemented plans to leave the Union before he took office in March 1861. On December 20, 1860, South Carolina took the lead by adopting an ordinance of secession; by February 1, 1861, Florida, Mississippi, Alabama, Georgia, Louisiana, and Texas followed. Six of these states declared themselves to be a sovereign nation, the Confederate States of America, and adopted a constitution. The upper South and border states (Delaware, Maryland, Virginia, North Carolina, Tennessee, Kentucky, Missouri, and Arkansas) initially rejected the secessionist appeal. President Buchanan and President-elect Lincoln refused to recognize the Confederacy, declaring secession illegal. The Confederacy selected Jefferson Davis as its provisional president on February 9, 1861.Attempts at compromise followed but Lincoln and the Republicans rejected the proposed Crittenden Compromise as contrary to the Party's platform of free-soil in the territories. Lincoln said, \"I will suffer death before I consent ... to any concession or compromise which looks like buying the privilege to take possession of this government to which we have a constitutional right\".Lincoln supported the Corwin Amendment to the Constitution, which passed Congress and was awaiting ratification by the states when Lincoln took office. That doomed amendment would have protected slavery in states where it already existed. On March 4, 1861, in his first inaugural address, Lincoln said that, because he holds \"such a provision to now be implied constitutional law, I have no objection to its being made express and irrevocable\". A few weeks before the war, Lincoln sent a letter to every governor informing them Congress had passed a joint resolution to amend the Constitution.On February 11, 1861, Lincoln gave a particularly emotional farewell address upon leaving Springfield; he would never again return to Springfield alive. Lincoln traveled east in a special train. Due to secessionist plots, a then-unprecedented attention to security was given to him and his train. En route to his inauguration, Lincoln addressed crowds and legislatures across the North. The president-elect evaded suspected assassins in Baltimore. On February 23, 1861, he arrived in disguise in Washington, D.C., which was placed under substantial military guard. Lincoln directed his inaugural address to the South, proclaiming once again that he had no inclination to abolish slavery in the Southern states:\n",
      "\n",
      "Apprehension seems to exist among the people of the Southern States, that by the accession of a Republican Administration, their property, and their peace, and personal security, are to be endangered. There has never been any reasonable cause for such apprehension. Indeed, the most ample evidence to the contrary has all the while existed, and been open to their inspection. It is found in nearly all the published speeches of him who now addresses you. I do but quote from one of those speeches when I declare that \"I have no purpose, directly or indirectly, to interfere with the institution of slavery in the States where it exists. I believe I have no lawful right to do so, and I have no inclination to do so.\" Lincoln cited his plans for banning the expansion of slavery as the key source of conflict between North and South, stating \"One section of our country believes slavery is right and ought to be extended, while the other believes it is wrong and ought not to be extended. This is the only substantial dispute.\" The president ended his address with an appeal to the people of the South: \"We are not enemies, but friends. We must not be enemies.... The mystic chords of memory, stretching from every battlefield, and patriot grave, to every living heart and hearthstone, all over this broad land, will yet swell the chorus of the Union, when again touched, as surely they will be, by the better angels of our nature.\" The failure of the Peace Conference of 1861 signaled that legislative compromise was impossible. By March 1861, no leaders of the insurrection had proposed rejoining the Union on any terms. Meanwhile, Lincoln and the Republican leadership agreed that the dismantling of the Union could not be tolerated. In his second inaugural address, Lincoln looked back on the situation at the time and said: \"Both parties deprecated war, but one of them would make war rather than let the Nation survive, and the other would accept war rather than let it perish, and the war came.\"\n",
      "\n",
      "Civil War\n",
      "Major Robert Anderson, commander of the Union's Fort Sumter in Charleston, South Carolina, sent a request for provisions to Washington, and Lincoln's order to meet that request was seen by the secessionists as an act of war. On April 12, 1861, Confederate forces fired on Union troops at Fort Sumter and began the fight. Historian Allan Nevins argued that the newly inaugurated Lincoln made three miscalculations: underestimating the gravity of the crisis, exaggerating the strength of Unionist sentiment in the South, and overlooking Southern Unionist opposition to an invasion.William Tecumseh Sherman talked to Lincoln during inauguration week and was \"sadly disappointed\" at his failure to realize that \"the country was sleeping on a volcano\" and that the South was preparing for war. Donald concludes, \"His repeated efforts to avoid collision in the months between inauguration and the firing on Ft. Sumter showed he adhered to his vow not to be the first to shed fraternal blood. But he also vowed not to surrender the forts. The only resolution of these contradictory positions was for the confederates to fire the first shot; they did just that.\"On April 15, Lincoln called on the states to send a total of 75,000 volunteer troops to recapture forts, protect Washington, and \"preserve the Union\", which, in his view, remained intact despite the seceding states. This call forced states to choose sides. Virginia seceded and was rewarded with the designation of Richmond as the Confederate capital, despite its exposure to Union lines. North Carolina, Tennessee, and Arkansas followed over the following two months. Secession sentiment was strong in Missouri and Maryland, but did not prevail; Kentucky remained neutral. The Fort Sumter attack rallied Americans north of the Mason-Dixon line to defend the nation.\n",
      "As states sent Union regiments south, on April 19, Baltimore mobs in control of the rail links attacked Union troops who were changing trains. Local leaders' groups later burned critical rail bridges to the capital and the Army responded by arresting local Maryland officials. Lincoln suspended the writ of habeas corpus in an effort to protect the troops trying to reach Washington. John Merryman, one Maryland official hindering the U.S. troop movements, petitioned Supreme Court Chief Justice Roger B. Taney to issue a writ of habeas corpus. In June, in Ex parte Merryman, Taney, not ruling on behalf of the Supreme Court, issued the writ, believing that Article I, section 9 of the Constitution authorized only Congress and not the president to suspend it. But Lincoln persisted with the policy of suspension in select areas.\n",
      "\n",
      "Union military strategy\n",
      "Lincoln took executive control of the war and shaped the Union military strategy. He responded to the unprecedented political and military crisis as commander-in-chief by exercising unprecedented authority. He expanded his war powers, imposed a blockade on Confederate ports, disbursed funds before appropriation by Congress, suspended habeas corpus, and arrested and imprisoned thousands of suspected Confederate sympathizers. Lincoln gained the support of Congress and the northern public for these actions. Lincoln also had to reinforce Union sympathies in the border slave states and keep the war from becoming an international conflict.\n",
      "It was clear from the outset that bipartisan support was essential to success, and that any compromise alienated factions on both sides of the aisle, such as the appointment of Republicans and Democrats to command positions. Copperheads criticized Lincoln for refusing to compromise on slavery. The Radical Republicans criticized him for moving too slowly in abolishing slavery. On August 6, 1861, Lincoln signed the Confiscation Act, which authorized judicial proceedings to confiscate and free slaves who were used to support the Confederates. The law had little practical effect, but it signaled political support for abolishing slavery.In August 1861, General John C. Frémont, the 1856 Republican presidential nominee, without consulting Washington, issued a martial edict freeing slaves of the rebels. Lincoln canceled the illegal proclamation as politically motivated and lacking military necessity. As a result, Union enlistments from Maryland, Kentucky, and Missouri increased by over 40,000.Internationally, Lincoln wanted to forestall foreign military aid to the Confederacy. He relied on his combative Secretary of State William Seward while working closely with Senate Foreign Relations Committee chairman Charles Sumner. In the 1861 Trent Affair, which threatened war with Great Britain, the U.S. Navy illegally intercepted a British mail ship, the Trent, on the high seas and seized two Confederate envoys; Britain protested vehemently while the U.S. cheered. Lincoln ended the crisis by releasing the two diplomats. Biographer James G. Randall dissected Lincoln's successful techniques:\n",
      "his restraint, his avoidance of any outward expression of truculence, his early softening of State Department's attitude toward Britain, his deference toward Seward and Sumner, his withholding of his paper prepared for the occasion, his readiness to arbitrate, his golden silence in addressing Congress, his shrewdness in recognizing that war must be averted, and his clear perception that a point could be clinched for America's true position at the same time that satisfaction was given to a friendly country.\n",
      "Lincoln painstakingly monitored the telegraph reports coming into the War Department. He tracked all phases of the effort, consulting with governors and selecting generals based on their success, their state, and their party. In January 1862, after complaints of inefficiency and profiteering in the War Department, Lincoln replaced War Secretary Simon Cameron with Edwin Stanton. Stanton centralized the War Department's activities, auditing and canceling contracts, thereby saving the federal government $17,000,000. Stanton was a staunch Unionist, pro-business, conservative Democrat who gravitated toward the Radical Republican faction. He worked more often and more closely with Lincoln than did any other senior official. \"Stanton and Lincoln virtually conducted the war together\", say Thomas and Hyman.Lincoln's war strategy had two priorities: ensuring that Washington was well-defended and conducting an aggressive war effort for a prompt, decisive victory. Twice a week, Lincoln met with his cabinet in the afternoon. Occasionally Mary prevailed on him to take a carriage ride, concerned that he was working too hard. For his edification Lincoln relied upon a book by his chief of staff General Henry Halleck entitled Elements of Military Art and Science; Halleck was a disciple of the European strategist Antoine-Henri Jomini. Lincoln began to appreciate the critical need to control strategic points, such as the Mississippi River. Lincoln saw the importance of Vicksburg and understood the necessity of defeating the enemy's army, rather than merely capturing territory.In directing the Union's war strategy, Lincoln valued the advice of Gen. Winfield Scott, even after his retirement as Commanding General of the United States Army. On June 23–24, 1862, Lincoln made an unannounced visit to West Point, where he spent five hours consulting with Scott regarding the handling of the Civil War and the staffing of the War Department.\n",
      "\n",
      "General McClellan\n",
      "After the Union rout at Bull Run and Winfield Scott's retirement, Lincoln appointed Major General George B. McClellan general-in-chief. McClellan then took months to plan his Virginia Peninsula Campaign. McClellan's slow progress frustrated Lincoln, as did his position that no troops were needed to defend Washington. McClellan, in turn, blamed the failure of the campaign on Lincoln's reservation of troops for the capital.\n",
      "\n",
      "In 1862, Lincoln removed McClellan for the general's continued inaction. He elevated Henry Halleck in July and appointed John Pope as head of the new Army of Virginia. Pope satisfied Lincoln's desire to advance on Richmond from the north, thus protecting Washington from counterattack. But Pope was then soundly defeated at the Second Battle of Bull Run in the summer of 1862, forcing the Army of the Potomac back to defend Washington.Despite his dissatisfaction with McClellan's failure to reinforce Pope, Lincoln restored him to command of all forces around Washington. Two days after McClellan's return to command, General Robert E. Lee's forces crossed the Potomac River into Maryland, leading to the Battle of Antietam. That battle, a Union victory, was among the bloodiest in American history; it facilitated Lincoln's Emancipation Proclamation in January.McClellan then resisted the president's demand that he pursue Lee's withdrawing army, while General Don Carlos Buell likewise refused orders to move the Army of the Ohio against rebel forces in eastern Tennessee. Lincoln replaced Buell with William Rosecrans; and after the 1862 midterm elections he replaced McClellan with Ambrose Burnside. The appointments were both politically neutral and adroit on Lincoln's part.Burnside, against presidential advice, launched an offensive across the Rappahannock River and was defeated by Lee at Fredericksburg in December. Desertions during 1863 came in the thousands and only increased after Fredericksburg, so Lincoln replaced Burnside with Joseph Hooker.In the 1862 midterm elections the Republicans suffered severe losses due to rising inflation, high taxes, rumors of corruption, suspension of habeas corpus, military draft law, and fears that freed slaves would come North and undermine the labor market. The Emancipation Proclamation gained votes for Republicans in rural New England and the upper Midwest, but cost votes in the Irish and German strongholds and in the lower Midwest, where many Southerners had lived for generations.In the spring of 1863 Lincoln was sufficiently optimistic about upcoming military campaigns to think the end of the war could be near; the plans included attacks by Hooker on Lee north of Richmond, Rosecrans on Chattanooga, Grant on Vicksburg, and a naval assault on Charleston.Hooker was routed by Lee at the Battle of Chancellorsville in May, then resigned and was replaced by George Meade. Meade followed Lee north into Pennsylvania and beat him in the Gettysburg Campaign, but then failed to follow up despite Lincoln's demands. At the same time, Grant captured Vicksburg and gained control of the Mississippi River, splitting the far western rebel states.\n",
      "\n",
      "Emancipation Proclamation\n",
      "The Federal government's power to end slavery was limited by the Constitution, which before 1865 was understood to reserve the issue to the individual states. Lincoln believed that slavery would be rendered obsolete if its expansion into new territories were prevented, because these territories would be admitted to the Union as free states, and free states would come to outnumber slave states. He sought to persuade the states to agree to compensation for emancipating their slaves. Lincoln rejected Major General John C. Frémont's August 1861 emancipation attempt, as well as one by Major General David Hunter in May 1862, on the grounds that it was not within their power and might upset loyal border states enough for them to secede.In June 1862, Congress passed an act banning slavery on all federal territory, which Lincoln signed. In July, the Confiscation Act of 1862 was enacted, providing court procedures to free the slaves of those convicted of aiding the rebellion; Lincoln approved the bill despite his belief that it was unconstitutional. He felt such action could be taken only within the war powers of the commander-in-chief, which he planned to exercise. On July 22, 1862, Lincoln reviewed a draft of the Emancipation Proclamation with his cabinet.Peace Democrats (Copperheads) argued that emancipation was a stumbling block to peace and reunification, but Republican editor Horace Greeley of the New-York Tribune, in his public letter, \"The Prayer of Twenty Millions\", implored Lincoln to embrace emancipation. In a public letter of August 22, 1862, Lincoln replied to Greeley, writing that while he personally wished all men could be free, his first obligation as president was to preserve the Union:\n",
      "My paramount object in this struggle is to save the Union, and is not either to save or to destroy slavery. If I could save the Union without freeing any slave I would do it, and if I could save it by freeing all the slaves I would do it; and if I could save it by freeing some and leaving others alone I would also do that. What I do about slavery, and the colored race, I do because I believe it helps to save the Union; and what I forbear, I forbear because I do not believe it would help to save the Union ... [¶] I have here stated my purpose according to my view of official duty; and I intend no modification of my oft-expressed personal wish that all men everywhere could be free.\n",
      "On September 22, 1862, Lincoln issued the preliminary Emancipation Proclamation, which announced that, in states still in rebellion on January 1, 1863, the slaves would be freed. He spent the next 100 days, between September 22 and January 1, preparing the army and the nation for emancipation, while Democrats rallied their voters by warning of the threat that freed slaves posed to northern whites. At the same time, during those 100 days, Lincoln made efforts to end the war with slavery intact. But, on January 1, 1863, keeping his word, Lincoln issued the Emancipation Proclamation, freeing the slaves in 10 states not then under Union control, with exemptions specified for areas under such control. Lincoln's comment on signing the Proclamation was: \"I never, in my life, felt more certain that I was doing right, than I do in signing this paper.\"With the abolition of slavery in the rebel states now a military objective, Union armies advancing south \"enable[d] thousands of slaves to escape to freedom\". The Emancipation Proclamation having stated that freedmen would be \"received into the armed service of the United States,\" enlisting these freedmen became official policy. By the spring of 1863, Lincoln was ready to recruit black troops in more than token numbers. In a letter to Tennessee military governor Andrew Johnson encouraging him to lead the way in raising black troops, Lincoln wrote, \"The bare sight of fifty thousand armed, and drilled black soldiers on the banks of the Mississippi would end the rebellion at once\". By the end of 1863, at Lincoln's direction, General Lorenzo Thomas \"had enrolled twenty regiments of African Americans\" from the Mississippi Valley.\n",
      "\n",
      "Gettysburg Address (1863)\n",
      "Lincoln spoke at the dedication of the Gettysburg battlefield cemetery on November 19, 1863. In 272 words, and three minutes, Lincoln asserted that the nation was born not in 1789, but in 1776, \"conceived in Liberty, and dedicated to the proposition that all men are created equal\". He defined the war as dedicated to the principles of liberty and equality for all. He declared that the deaths of so many brave soldiers would not be in vain, that slavery would end, and the future of democracy would be assured, that \"government of the people, by the people, for the people, shall not perish from the earth\".Defying his prediction that \"the world will little note, nor long remember what we say here\", the Address became the most quoted speech in American history.\n",
      "\n",
      "Promoting General Grant\n",
      "General Ulysses Grant's victories at the Battle of Shiloh and in the Vicksburg campaign impressed Lincoln. Responding to criticism of Grant after Shiloh, Lincoln had said, \"I can't spare this man. He fights.\" With Grant in command, Lincoln felt the Union Army could advance in multiple theaters, while also including black troops. Meade's failure to capture Lee's army after Gettysburg and the continued passivity of the Army of the Potomac persuaded Lincoln to promote Grant to supreme commander. Grant then assumed command of Meade's army.Lincoln was concerned that Grant might be considering a presidential candidacy in 1864. He arranged for an intermediary to inquire into Grant's political intentions, and once assured that he had none, Lincoln promoted Grant to the newly revived rank of Lieutenant General, a rank which had been unoccupied since George Washington. Authorization for such a promotion \"with the advice and consent of the Senate\" was provided by a new bill which Lincoln signed the same day he submitted Grant's name to the Senate. His nomination was confirmed by the Senate on March 2, 1864.Grant in 1864 waged the bloody Overland Campaign, which exacted heavy losses on both sides. When Lincoln asked what Grant's plans were, the persistent general replied, \"I propose to fight it out on this line if it takes all summer.\" Grant's army moved steadily south. Lincoln traveled to Grant's headquarters at City Point, Virginia, to confer with Grant and William Tecumseh Sherman. Lincoln reacted to Union losses by mobilizing support throughout the North. Lincoln authorized Grant to target infrastructure—plantations, railroads, and bridges—hoping to weaken the South's morale and fighting ability. He emphasized defeat of the Confederate armies over destruction (which was considerable) for its own sake. Lincoln's engagement became distinctly personal on one occasion in 1864 when Confederate general Jubal Early raided Washington, D.C. Legend has it that while Lincoln watched from an exposed position, Union Captain (and future Supreme Court Justice) Oliver Wendell Holmes Jr. shouted at him, \"Get down, you damn fool, before you get shot!\" But this story is commonly regarded as apocryphal.As Grant continued to weaken Lee's forces, efforts to discuss peace began. Confederate Vice President Stephens led a group meeting with Lincoln, Seward, and others at Hampton Roads. Lincoln refused to negotiate with the Confederacy as a coequal; his objective to end the fighting was not realized. On April 1, 1865, Grant nearly encircled Petersburg in a siege. The Confederate government evacuated Richmond and Lincoln visited the conquered capital. On April 9, Lee surrendered to Grant at Appomattox, officially ending the war.\n",
      "\n",
      "Reelection\n",
      "Lincoln ran for reelection in 1864, while uniting the main Republican factions, along with War Democrats Edwin M. Stanton and Andrew Johnson. Lincoln used conversation and his patronage powers—greatly expanded from peacetime—to build support and fend off the Radicals' efforts to replace him. At its convention, the Republicans selected Johnson as his running mate. To broaden his coalition to include War Democrats as well as Republicans, Lincoln ran under the label of the new Union Party.\n",
      "Grant's bloody stalemates damaged Lincoln's re-election prospects, and many Republicans feared defeat. Lincoln confidentially pledged in writing that if he should lose the election, he would still defeat the Confederacy before turning over the White House; Lincoln did not show the pledge to his cabinet, but asked them to sign the sealed envelope. The pledge read as follows:This morning, as for some days past, it seems exceedingly probable that this Administration will not be re-elected. Then it will be my duty to so co-operate with the President elect, as to save the Union between the election and the inauguration; as he will have secured his election on such ground that he cannot possibly save it afterward.\n",
      "The Democratic platform followed the \"Peace wing\" of the party and called the war a \"failure\"; but their candidate, McClellan, supported the war and repudiated the platform. Meanwhile, Lincoln emboldened Grant with more troops and Republican party support. Sherman's capture of Atlanta in September and David Farragut's capture of Mobile ended defeatism. The Democratic Party was deeply split, with some leaders and most soldiers openly for Lincoln. The National Union Party was united by Lincoln's support for emancipation. State Republican parties stressed the perfidy of the Copperheads. On November 8, Lincoln carried all but three states, including 78 percent of Union soldiers.\n",
      "On March 4, 1865, Lincoln delivered his second inaugural address. In it, he deemed the war casualties to be God's will. Historian Mark Noll places the speech \"among the small handful of semi-sacred texts by which Americans conceive their place in the world;\" it is inscribed in the Lincoln Memorial. Lincoln said:\n",
      "\n",
      "Fondly do we hope—fervently do we pray—that this mighty scourge of war may speedily pass away. Yet, if God wills that it continue, until all the wealth piled by the bond-man's 250 years of unrequited toil shall be sunk, and until every drop of blood drawn with the lash, shall be paid by another drawn with the sword, as was said 3,000 years ago, so still it must be said, \"the judgments of the Lord, are true and righteous altogether\". With malice toward none; with charity for all; with firmness in the right, as God gives us to see the right, let us strive on to finish the work we are in; to bind up the nation's wounds; to care for him who shall have borne the battle, and for his widow, and his orphan—to do all which may achieve and cherish a just and lasting peace, among ourselves, and with all nations.\n",
      "\n",
      "Reconstruction\n",
      "Reconstruction preceded the war's end, as Lincoln and his associates considered the reintegration of the nation, and the fates of Confederate leaders and freed slaves. When a general asked Lincoln how the defeated Confederates were to be treated, Lincoln replied, \"Let 'em up easy.\" Lincoln was determined to find meaning in the war in its aftermath, and did not want to continue to outcast the southern states. His main goal was to keep the union together, so he proceeded by focusing not on whom to blame, but on how to rebuild the nation as one. Lincoln led the moderates in Reconstruction policy and was opposed by the Radicals, under Rep. Thaddeus Stevens, Sen. Charles Sumner and Sen. Benjamin Wade, who otherwise remained Lincoln's allies. Determined to reunite the nation and not alienate the South, Lincoln urged that speedy elections under generous terms be held. His Amnesty Proclamation of December 8, 1863, offered pardons to those who had not held a Confederate civil office and had not mistreated Union prisoners, if they were willing to sign an oath of allegiance.\n",
      "As Southern states fell, they needed leaders while their administrations were restored. In Tennessee and Arkansas, Lincoln respectively appointed Johnson and Frederick Steele as military governors. In Louisiana, Lincoln ordered General Nathaniel P. Banks to promote a plan that would reestablish statehood when 10 percent of the voters agreed, and only if the reconstructed states abolished slavery. Democratic opponents accused Lincoln of using the military to ensure his and the Republicans' political aspirations. The Radicals denounced his policy as too lenient, and passed their own plan, the 1864 Wade–Davis Bill, which Lincoln vetoed. The Radicals retaliated by refusing to seat elected representatives from Louisiana, Arkansas, and Tennessee.Lincoln's appointments were designed to harness both moderates and Radicals. To fill Chief Justice Taney's seat on the Supreme Court, he named the Radicals' choice, Salmon P. Chase, who Lincoln believed would uphold his emancipation and paper money policies.After implementing the Emancipation Proclamation, Lincoln increased pressure on Congress to outlaw slavery throughout the nation with a constitutional amendment. He declared that such an amendment would \"clinch the whole matter\" and by December 1863 an amendment was brought to Congress. The Senate passed it on April 8, 1864, but the first vote in the House of Representatives fell short of the required two-thirds majority. Passage became part of Lincoln's reelection platform, and after his successful reelection, the second attempt in the House passed on January 31, 1865. With ratification, it became the Thirteenth Amendment to the United States Constitution on December 6, 1865.Lincoln believed the federal government had limited responsibility to the millions of freedmen. He signed Senator Charles Sumner's Freedmen's Bureau bill that set up a temporary federal agency designed to meet the immediate needs of former slaves. The law opened land for a lease of three years with the ability to purchase title for the freedmen. Lincoln announced a Reconstruction plan that involved short-term military control, pending readmission under the control of southern Unionists.Historians agree that it is impossible to predict how Reconstruction would have proceeded had Lincoln lived. Biographers James G. Randall and Richard Current, according to David Lincove, argue that:\n",
      "It is likely that had he lived, Lincoln would have followed a policy similar to Johnson's, that he would have clashed with congressional Radicals, that he would have produced a better result for the freedmen than occurred, and that his political skills would have helped him avoid Johnson's mistakes.\n",
      "Eric Foner argues that:\n",
      "Unlike Sumner and other Radicals, Lincoln did not see Reconstruction as an opportunity for a sweeping political and social revolution beyond emancipation. He had long made clear his opposition to the confiscation and redistribution of land. He believed, as most Republicans did in April 1865, that the voting requirements should be determined by the states. He assumed that political control in the South would pass to white Unionists, reluctant secessionists, and forward-looking former Confederates. But time and again during the war, Lincoln, after initial opposition, had come to embrace positions first advanced by abolitionists and Radical Republicans. ... Lincoln undoubtedly would have listened carefully to the outcry for further protection for the former slaves ... It is entirely plausible to imagine Lincoln and Congress agreeing on a Reconstruction policy that encompassed federal protection for basic civil rights plus limited black suffrage, along the lines Lincoln proposed just before his death.\n",
      "\n",
      "Native Americans\n",
      "Lincoln's experience with Native Americans started early with their killing of his grandfather in front of the family. Later he served as a captain in the state militia during the Black Hawk War but saw no combat. During his presidency, his policy toward Indians was based on politics. He used appointments to the Indian Bureau as a reward to supporters from Minnesota and Wisconsin. While in office his administration faced difficulties guarding Western settlers, railroads, and telegraphs, from Indian attacks.On August 17, 1862, the Sioux or Dakota uprising broke out in Minnesota. Hundreds of settlers were killed, 30,000 were displaced from their homes, and Washington was deeply alarmed. Some feared incorrectly that it might represent a Confederate conspiracy to start a war on the Northwestern frontier. Lincoln ordered thousands of Confederate prisoners of war sent by railroad to put down the uprising. When the Confederates protested forcing Confederate prisoners to fight Indians, Lincoln revoked the policy and none set foot in Minnesota. Lincoln sent General John Pope to Minnesota as commander of the new Department of the Northwest a couple of weeks into the hostilities. Before he arrived, the Fond Du Lac band of Chippewa sent Lincoln a letter begging to go to war for the United States against the Sioux, so Lincoln could send Minnesota's troops to fight the South. Shortly after, a Mille Lacs Band Chief offered the same at St. Cloud, Minnesota. In it the Chippewa specified that they wanted to use the indigenous rules of warfare. That meant there would be no prisoners of war, no surrender, no peace agreement. Lincoln did not accept the Chippewa offer, as he had no means to control the outcome and women and children were considered legitimate casualties in native American warfare. One of the Chippewa signing the letter, Chief Naw-Gaw-Nub, had received a Presidential medal from Lincoln earlier in the year.Serving under Gen. Pope was Minnesota Congressman Henry H. Sibley. Minnesota's Governor had made Sibley a Colonel United States Volunteers to command the US force tasked with fighting the war and that eventually defeated Little Crow's forces at the Battle of Wood Lake. \n",
      "The day the Mdewakanton force surrendered at Camp Release, a Chippewa war council met at Minnesota's capitol with another Chippewa offer to Lincoln, to fight the Sioux. Sibley ordered a military commission to review that actions of the captured to try those that had committed war crimes. The legitimacy of military commissions trying opposing combatants had been established during the Mexican War. Sibley thought he had 16 to 20 of men he wanted for trial while Gen. Pope ordered that all detained warriors be tried. When it was done, 303 had been given death sentences that were subject to Presidential review. Lincoln ordered Gen Pope send all of the trial transcripts to Washington where he and two of his staff pored over the trials. The lawyer in Lincoln saw issues. He slowly realized that the trials could be divided into two groups: combat between combatants and combat against civilians. The groups could be identified by their transcripts, the first group were all just three pages in length while the second group had more pages, some up to twelve. He placed 263 cases into the first group and commuted their sentences for the largest mass commutation in history. Into the second group went forty. One he commuted for turning state's witness. Sibley dismissed another when overwhelming proof surfaced exonerating the man. The remaining 38 were executed in the largest mass hanging in U.S. history. Very quickly questions arose concerning three of the executions that have not been answered. Less than four months after the executions, Lincoln issued General Order 100 that relates more to the Minnesota War than the Civil War. Now a congressman, Alexander Ramsey told Lincoln, in 1864, that he would have gotten more re-election support in Minnesota had he executed all 303 of the Mdewakanton. Lincoln responded, \"I could not afford to hang men for votes.\" The men whose sentences he commuted were sent to a military prison at Davenport, Iowa. A few of those he had released due to the efforts of Bishop Henry Whipple.\n",
      "\n",
      "Whig theory of a presidency\n",
      "Lincoln adhered to the Whig theory of a presidency focused on executing laws while deferring to Congress' responsibility for legislating. Lincoln vetoed only four bills, including the Wade-Davis Bill with its harsh Reconstruction program. The 1862 Homestead Act made millions of acres of Western government-held land available for purchase at low cost. The 1862 Morrill Land-Grant Colleges Act provided government grants for agricultural colleges in each state. The Pacific Railway Acts of 1862 and 1864 granted federal support for the construction of the United States' first transcontinental railroad, which was completed in 1869. The passage of the Homestead Act and the Pacific Railway Acts was enabled by the absence of Southern congressmen and senators who had opposed the measures in the 1850s.\n",
      "In the selection and use of his cabinet, Lincoln employed the strengths of his opponents in a manner that emboldened his presidency. Lincoln commented on his thought process, \"We need the strongest men of the party in the Cabinet. We needed to hold our own people together. I had looked the party over and concluded that these were the very strongest men. Then I had no right to deprive the country of their services.\" Goodwin described the group in her biography as a Team of Rivals.There were two measures passed to raise revenues for the Federal government: tariffs (a policy with long precedent), and a Federal income tax. In 1861, Lincoln signed the second and third Morrill Tariffs, following the first enacted by Buchanan. He also signed the Revenue Act of 1861, creating the first U.S. income tax—a flat tax of 3 percent on incomes above $800 (equivalent to $26,056 in 2022). The Revenue Act of 1862 adopted rates that increased with income.The Lincoln Administration presided over the expansion of the federal government's economic influence in other areas. The National Banking Act created the system of national banks. The US issued paper currency for the first time, known as greenbacks—printed in green on the reverse side. In 1862, Congress created the Department of Agriculture.In response to rumors of a renewed draft, the editors of the New York World and the Journal of Commerce published a false draft proclamation that created an opportunity for the editors and others to corner the gold market. Lincoln attacked the media for such behavior, and ordered a military seizure of the two papers which lasted for two days.\n",
      "\n",
      "Lincoln is largely responsible for the Thanksgiving holiday. Thanksgiving had become a regional holiday in New England in the 17th century. It had been sporadically proclaimed by the federal government on irregular dates. The prior proclamation had been during James Madison's presidency 50 years earlier. In 1863, Lincoln declared the final Thursday in November of that year to be a day of Thanksgiving.In June 1864, Lincoln approved the Yosemite Grant enacted by Congress, which provided unprecedented federal protection for the area now known as Yosemite National Park.\n",
      "\n",
      "Supreme Court appointments\n",
      "Lincoln's philosophy on court nominations was that \"we cannot ask a man what he will do, and if we should, and he should answer us, we should despise him for it. Therefore we must take a man whose opinions are known.\" Lincoln made five appointments to the Supreme Court. Noah Haynes Swayne was an anti-slavery lawyer who was committed to the Union. Samuel Freeman Miller supported Lincoln in the 1860 election and was an avowed abolitionist. David Davis was Lincoln's campaign manager in 1860 and had served as a judge in the Illinois court circuit where Lincoln practiced. Democrat Stephen Johnson Field, a previous California Supreme Court justice, provided geographic and political balance. Finally, Lincoln's Treasury Secretary, Salmon P. Chase, became Chief Justice. Lincoln believed Chase was an able jurist, would support Reconstruction legislation, and that his appointment united the Republican Party.\n",
      "\n",
      "Foreign policy\n",
      "Lincoln named his main political rival, William H. Seward, as Secretary of State and left most diplomatic issues in his portfolio. However, Lincoln did select some top diplomats as part of his patronage policy. He also closely watched the handling of the Trent Affair in late 1861 to make sure there was no escalation into a war with Britain. Seward's main role was to keep Britain and France from supporting the Confederacy. He was successful after indicating to Britain and France that the Union would declare war on them if they supported the South.\n",
      "\n",
      "Assassination\n",
      "John Wilkes Booth was a well-known actor and a Confederate spy from Maryland; though he never joined the Confederate army, he had contacts with the Confederate secret service. After attending Lincoln's last public address, on April 11, 1865, in which Lincoln stated his preference that the franchise be conferred on some black men, specifically \"on the very intelligent, and on those who serve our cause as soldiers\", Booth hatched a plot to assassinate the President. When Booth learned of the Lincolns' intent to attend a play with General Grant, he planned to assassinate Lincoln and Grant at Ford's Theatre. Lincoln and his wife attended the play Our American Cousin on the evening of April 14, just five days after the Union victory at the Battle of Appomattox Courthouse. At the last minute, Grant decided to go to New Jersey to visit his children instead of attending the play.On April 14, 1865, hours before he was assassinated, Lincoln signed legislation establishing the United States Secret Service, and, at 10:15 in the evening, Booth entered the back of Lincoln's theater box, crept up from behind, and fired at the back of Lincoln's head, mortally wounding him. Lincoln's guest, Major Henry Rathbone, momentarily grappled with Booth, but Booth stabbed him and escaped. After being attended by Doctor Charles Leale and two other doctors, Lincoln was taken across the street to Petersen House. After remaining in a coma for eight hours, Lincoln died at 7:22 in the morning on April 15. Stanton saluted and said, \"Now he belongs to the ages.\" Lincoln's body was placed in a flag-wrapped coffin, which was loaded into a hearse and escorted to the White House by Union soldiers. President Johnson was sworn in later that same day.Two weeks later, Booth, refusing to surrender, was tracked to a farm in Virginia, and was mortally shot by Sergeant Boston Corbett and died on April 26. Secretary of War Stanton had issued orders that Booth be taken alive, so Corbett was initially arrested to be court martialed. After a brief interview, Stanton declared him a patriot and dismissed the charge.\n",
      "\n",
      "Funeral and burial\n",
      "The late President lay in state, first in the East Room of the White House, and then in the Capitol Rotunda from April 19 to 21. The caskets containing Lincoln's body and the body of his son Willie traveled for three weeks on the Lincoln Special funeral train. The train followed a circuitous route from Washington D.C. to Springfield, Illinois, stopping at many cities for memorials attended by hundreds of thousands. Many others gathered along the tracks as the train passed with bands, bonfires, and hymn singing or in silent grief. Poet Walt Whitman composed \"When Lilacs Last in the Dooryard Bloom'd\" to eulogize him, one of four poems he wrote about Lincoln. African Americans were especially moved; they had lost their \"Moses\". In a larger sense, the reaction was in response to the deaths of so many men in the war. Historians emphasized the widespread shock and sorrow, but noted that some Lincoln haters celebrated his death. Lincoln's body was buried at Oak Ridge Cemetery in Springfield and now lies within the Lincoln Tomb.\n",
      "\n",
      "Religious and philosophical beliefs\n",
      "As a young man, Lincoln was a religious skeptic. He was deeply familiar with the Bible, quoting and praising it. He was private about his position on organized religion and respected the beliefs of others. He never made a clear profession of Christian beliefs. Throughout his public career, Lincoln often quoted Scripture. His three most famous speeches—the House Divided Speech, the Gettysburg Address, and his second inaugural—each contain direct allusions to Providence and quotes from Scripture.\n",
      "In the 1840s, Lincoln subscribed to the Doctrine of Necessity, a belief that the human mind was controlled by a higher power. With the death of his son Edward in 1850 he more frequently expressed a dependence on God. He never joined a church, although he frequently attended First Presbyterian Church with his wife beginning in 1852.In the 1850s, Lincoln asserted his belief in \"providence\" in a general way, and rarely used the language or imagery of the evangelicals; he regarded the republicanism of the Founding Fathers with an almost religious reverence. The death of his son Willie in February 1862 may have caused him to look toward religion for solace. After Willie's death, he questioned the divine necessity of the war's severity. He wrote at this time that God \"could have either saved or destroyed the Union without a human contest. Yet the contest began. And having begun, He could give the final victory to either side any day. Yet the contest proceeds.\"\n",
      "Lincoln did believe in an all-powerful God that shaped events and by 1865 was expressing that belief in major speeches. By the end of the war, he increasingly appealed to the Almighty for solace and to explain events, writing on April 4, 1864, to a newspaper editor in Kentucky: I claim not to have controlled events, but confess plainly that events have controlled me. Now, at the end of three years struggle the nation's condition is not what either party, or any man devised, or expected. God alone can claim it. Whither it is tending seems plain. If God now wills the removal of a great wrong, and wills also that we of the North as well as you of the South, shall pay fairly for our complicity in that wrong, impartial history will find therein new cause to attest and revere the justice and goodness of God.This spirituality can best be seen in his second inaugural address, considered by some scholars as the greatest such address in American history, and by Lincoln himself as his own greatest speech, or one of them at the very least. Lincoln explains therein that the cause, purpose, and result of the war was God's will. Lincoln's frequent use of religious imagery and language toward the end of his life may have reflected his own personal beliefs or might have been a device to reach his audiences, who were mostly evangelical Protestants. On the day Lincoln was assassinated, he reportedly told his wife he desired to visit the Holy Land.\n",
      "\n",
      "Health\n",
      "Lincoln is believed to have had depression, smallpox, and malaria. He took blue mass pills, which contained mercury, to treat constipation. It is unknown to what extent this may have resulted in mercury poisoning.Several claims have been made that Lincoln's health was declining before the assassination. These are often based on photographs of Lincoln appearing to show weight loss and muscle wasting. It is also suspected that he might have had a rare genetic disease such as Marfan syndrome or multiple endocrine neoplasia type 2B.\n",
      "\n",
      "Legacy\n",
      "Republican values\n",
      "Lincoln's redefinition of republican values has been stressed by historians such as John Patrick Diggins, Harry V. Jaffa, Vernon Burton, Eric Foner, and Herman J. Belz. Lincoln called the Declaration of Independence—which emphasized freedom and equality for all—the \"sheet anchor\" of republicanism beginning in the 1850s. He did this at a time when the Constitution, which \"tolerated slavery\", was the focus of most political discourse. Diggins notes, \"Lincoln presented Americans a theory of history that offers a profound contribution to the theory and destiny of republicanism itself\" in the 1860 Cooper Union speech. Instead of focusing on the legality of an argument, he focused on the moral basis of republicanism.His position on war was founded on a legal argument regarding the Constitution as essentially a contract among the states, and all parties must agree to pull out of the contract. Furthermore, it was a national duty to ensure the republic stands in every state. Many soldiers and religious leaders from the north, though, felt the fight for liberty and freedom of slaves was ordained by their moral and religious beliefs.As a Whig activist, Lincoln was a spokesman for business interests, favoring high tariffs, banks, infrastructure improvements, and railroads, in opposition to Jacksonian democrats. Lincoln shared the sympathies that the Jacksonians professed for the common man, but he disagreed with the Jacksonian view that the government should be divorced from economic enterprise. Nevertheless, Lincoln admired Andrew Jackson's steeliness as well as his patriotism. According to historian Sean Wilentz:\n",
      "Just as the Republican Party of the 1850s absorbed certain elements of Jacksonianism, so Lincoln, whose Whiggery had always been more egalitarian than that of other Whigs, found himself absorbing some of them as well. And some of the Jacksonian spirit resided inside the Lincoln White House.\n",
      "William C. Harris found that Lincoln's \"reverence for the Founding Fathers, the Constitution, the laws under it, and the preservation of the Republic and its institutions strengthened his conservatism.\" James G. Randall emphasizes his tolerance and moderation \"in his preference for orderly progress, his distrust of dangerous agitation, and his reluctance toward ill digested schemes of reform.\" Randall concludes that \"he was conservative in his complete avoidance of that type of so-called 'radicalism' which involved abuse of the South, hatred for the slaveholder, thirst for vengeance, partisan plotting, and ungenerous demands that Southern institutions be transformed overnight by outsiders.\"\n",
      "\n",
      "Reunification of the states\n",
      "In Lincoln's first inaugural address, he explored the nature of democracy. He denounced secession as anarchy, and he explained that majority rule had to be balanced by constitutional restraints. He said, \"A majority held in restraint by constitutional checks and limitations, and always changing easily with deliberate changes of popular opinions and sentiments, is the only true sovereign of a free people.\"The successful reunification of the states had consequences for how people viewed the country. The term \"the United States\" has historically been used sometimes in the plural (\"these United States\") and other times in the singular. The Civil War was a significant force in the eventual dominance of the singular usage by the end of the 19th century.\n",
      "\n",
      "Historical reputation\n",
      "In his company, I was never reminded of my humble origin, or of my unpopular color.\n",
      "In surveys of U.S. scholars ranking presidents conducted since 1948, the top three presidents are Lincoln, Washington, and Franklin Delano Roosevelt, although the order varies. Between 1999 and 2011, Lincoln, John F. Kennedy, and Ronald Reagan were the top-ranked presidents in eight public opinion surveys, according to Gallup. A 2004 study found that scholars in the fields of history and politics ranked Lincoln number one, while legal scholars placed him second after George Washington.Lincoln's assassination left him a national martyr. He was viewed by abolitionists as a champion of human liberty. Republicans linked Lincoln's name to their party. Many, though not all, in the South considered Lincoln as a man of outstanding ability. Historians have said he was \"a classical liberal\" in the 19th-century sense. Allen C. Guelzo states that Lincoln was a \"classical liberal democrat—an enemy of artificial hierarchy, a friend to trade and business as ennobling and enabling, and an American counterpart to Mill, Cobden, and Bright\", whose portrait Lincoln hung in his White House office.Sociologist Barry Schwartz argues that Lincoln's American reputation grew slowly from the late 19th century until the Progressive Era (1900–1920s), when he emerged as one of America's most venerated heroes, even among white Southerners. The high point came in 1922 with the dedication of the Lincoln Memorial on the National Mall in Washington, D.C.Union nationalism, as envisioned by Lincoln, \"helped lead America to the nationalism of Theodore Roosevelt, Woodrow Wilson, and Franklin Delano Roosevelt.\" In the New Deal era, liberals honored Lincoln not so much as the self-made man or the great war president, but as the advocate of the common man who they claimed would have supported the welfare state.Schwartz argues that in the 1930s and 1940s the memory of Abraham Lincoln was practically sacred and provided the nation with \"a moral symbol inspiring and guiding American life.\" During the Great Depression, he argues, Lincoln served \"as a means for seeing the world's disappointments, for making its sufferings not so much explicable as meaningful.\" Franklin D. Roosevelt, preparing America for war, used the words of the Civil War president to clarify the threat posed by Germany and Japan. Americans asked, \"What would Lincoln do?\" However, Schwartz also finds that since World War II Lincoln's symbolic power has lost relevance, and this \"fading hero is symptomatic of fading confidence in national greatness.\" He suggested that postmodernism and multiculturalism have diluted greatness as a concept.In the Cold War years, Lincoln's image shifted to a symbol of freedom who brought hope to those oppressed by Communist regimes. He had long been known as the Great Emancipator, but, by the late 1960s, some African American intellectuals, led by Lerone Bennett Jr., denied that Lincoln deserved that title. Bennett won wide attention when he called Lincoln a white supremacist in 1968. He noted that Lincoln used ethnic slurs and told jokes that ridiculed blacks. Bennett argued that Lincoln opposed social equality and proposed that freed slaves voluntarily move to another country. The emphasis shifted away from Lincoln the emancipator to an argument that blacks had freed themselves from slavery, or at least were responsible for pressuring the government to emancipate them. Defenders of Lincoln, such as authors Dirck and Cashin, retorted that he was not as bad as most politicians of his day and that he was a \"moral visionary\" who deftly advanced the abolitionist cause, as fast as politically possible. Dirck stated that few Civil War scholars take Bennett seriously, pointing to his \"narrow political agenda and faulty research\".By the 1970s, Lincoln had become a hero to political conservatives—apart from neo-Confederates such as Mel Bradford, who denounced his treatment of the white South—for his intense nationalism, his support for business, his insistence on stopping the spread of slavery, his acting on Lockean and Burkean principles on behalf of both liberty and tradition, and his devotion to the principles of the Founding Fathers. Lincoln became a favorite of liberal intellectuals across the world.Barry Schwartz wrote in 2009 that Lincoln's image suffered \"erosion, fading prestige, benign ridicule\" in the late 20th century. On the other hand, Donald opined in his 1996 biography that Lincoln was distinctly endowed with the personality trait of negative capability, defined by the poet John Keats and attributed to extraordinary leaders who were \"content in the midst of uncertainties and doubts, and not compelled toward fact or reason\".In the 21st century, President Barack Obama named Lincoln his favorite president and insisted on using the Lincoln Bible for his inaugural ceremonies.Lincoln has often been portrayed by Hollywood, almost always in a flattering light.Lincoln has been also admired by political figures outside the U.S., including German political theorist Karl Marx, Indian independence leader Mahatma Gandhi, former Liberian president Ellen Johnson Sirleaf, and Libyan revolutionary Muammar Gaddafi.\n",
      "\n",
      "Memory and memorials\n",
      "Lincoln's portrait appears on two denominations of United States currency, the penny and the $5 bill. His likeness also appears on many postage stamps. While he is usually portrayed bearded, he did not grow a beard until 1860 at the suggestion of 11-year-old Grace Bedell. He was the first of five presidents to do so.He has been memorialized in many town, city, and county names, including the capital of Nebraska. The United States Navy Nimitz-class aircraft carrier USS Abraham Lincoln (CVN-72) is named after Lincoln, the second Navy ship to bear his name. The Lincoln Memorial is one of the most visited monuments in the nation's capital and is one of the top five most visited National Park Service sites in the country. Ford's Theatre, among the most visited sites in Washington, D.C., is across the street from Petersen House, where Lincoln died. Memorials in Springfield, Illinois, include the Abraham Lincoln Presidential Library and Museum, Lincoln's home, and his tomb. A portrait carving of Lincoln appears with those of three other presidents on Mount Rushmore, which receives about 3 million visitors a year. An influential statue of Lincoln stands in Lincoln Park, Chicago, with recastings given as diplomatic gifts standing in Parliament Square, London, and Parque Lincoln, Mexico City.In 2019, Congress officially dedicated room H-226 in the United States Capitol to Abraham Lincoln. The room is located off National Statuary Hall and served as the post office of the House while then-Representative Abraham Lincoln served in Congress from 1847 to 1849.\n",
      "\n",
      "See also\n",
      "Lincoln (film) from 2012, by Steven Spielberg\n",
      "Linconia, a proposed colony in Central America named for Lincoln\n",
      "List of civil rights leaders\n",
      "Outline of Abraham Lincoln\n",
      "The Towers (Ohio State) - Lincoln Tower\n",
      "\n",
      "Notes\n",
      "References\n",
      "Bibliography\n",
      "External links\n",
      "Official\n",
      "Abraham Lincoln Presidential Library and Museum\n",
      "The Lincoln Presidential Library's ongoing digitization of all documents written by or to Abraham Lincoln during his lifetime\n",
      "Collected Works of Abraham Lincoln – complete collected works as edited by Basler et al. (1958) – an online edition available through University of Michigan Library Digital Collections\n",
      "\n",
      "Organizations\n",
      "Abraham Lincoln Association Archived April 28, 2020, at the Wayback Machine\n",
      "Abraham Lincoln Bicentennial Foundation\n",
      "\n",
      "Media coverage\n",
      "Abraham Lincoln collected news and commentary at The New York Times\n",
      "\n",
      "Other\n",
      "United States Congress. \"Abraham Lincoln (id: L000313)\". Biographical Directory of the United States Congress.\n",
      "Abraham Lincoln: A Resource Guide from the Library of Congress\n",
      "\"Life Portrait of Abraham Lincoln\", from C-SPAN's American presidents: Life Portraits, June 28, 1999\n",
      "\"Writings of Abraham Lincoln\" from C-SPAN's American Writers: A Journey Through History\n",
      "Abraham Lincoln: Original Letters and Manuscripts – Shapell Manuscript Foundation\n",
      "Lincoln/Net: Abraham Lincoln Historical Digitization Project – Northern Illinois University Libraries\n",
      "Teaching Abraham Lincoln Archived December 10, 2017, at the Wayback Machine – National Endowment for the Humanities\n",
      "Works by Abraham Lincoln at Project Gutenberg\n",
      "Works by or about Abraham Lincoln at Internet Archive\n",
      "Works by Abraham Lincoln at LibriVox (public domain audiobooks) \n",
      "In Popular Song: Our Noble Chief Has Passed Away by Cooper/Thomas\n",
      "Abraham Lincoln Recollections and Newspaper Articles Collection Archived November 13, 2018, at the Wayback Machine, McLean County Museum of History\n",
      "Digitized items in the Alfred Whital Stern Collection of Lincolniana in the Rare Book and Special Collections Division in the Library of Congress\n"
     ]
    }
   ],
   "source": [
    "def get_wikipages_content(page_titles):\n",
    "    combined_text = \"\"\n",
    "\n",
    "    for page_title in page_titles:\n",
    "        page = wiki_wiki.page(page_title)\n",
    "        if page.exists():\n",
    "            page_content = page.text\n",
    "            combined_text += page_content \n",
    "    return combined_text\n",
    "\n",
    "page_titles = ['Polar_bear', 'Artificial_intelligence',\n",
    "    'Leonardo_da_Vinci', 'Quantum_mechanics',\n",
    "    'Great_Wall_of_China', 'Neuroscience',\n",
    "    'The_Mona_Lisa', 'Machine_learning',\n",
    "    'Amazon_Rainforest', 'Cryptocurrency',\n",
    "    'Rome', 'Renewable_energy', 'Hawaii', 'Synthetic_biology',\n",
    "    'Cleopatra', 'Artificial_neural_network',\n",
    "    'Industrial_Revolution', 'Genome_editing',\n",
    "    'Michelangelo', 'Dark_matter',\n",
    "    'The_Three_Musketeers', 'Neuromorphic_computing',\n",
    "    'Galileo_Galilei', 'Biofuel',\n",
    "    'Abraham_Lincoln',]\n",
    "\n",
    "combined_content = get_wikipages_content(page_titles)\n",
    "\n",
    "train_save_model(combined_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ac9502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('well', 0.9998226165771484), ('including', 0.999822199344635), ('bitcoin', 0.9998160600662231), ('developed', 0.9998149871826172), ('without', 0.9998133778572083)]\n"
     ]
    }
   ],
   "source": [
    "print(  model.wv.most_similar('help', topn=5)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa097ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loosely', -0.6084903478622437), ('isbn', -0.8168379068374634), ('mundi', -0.8826533555984497), ('expectancy', -0.9503160715103149), ('excluded', -0.9566439986228943)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(negative=[\"help\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a09633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loosely', -0.6092622876167297), ('isbn', -0.81650710105896), ('mundi', -0.8830470442771912), ('expectancy', -0.9500191807746887), ('excluded', -0.9564362168312073)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(negative=[\"man\"], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b531d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loosely', -0.608241856098175)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(negative=[\"white\"], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45116912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
